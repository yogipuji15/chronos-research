{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.25,
  "eval_steps": 500,
  "global_step": 100000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00125,
      "grad_norm": 0.3525909185409546,
      "learning_rate": 8.333333333333333e-07,
      "loss": 1.5313,
      "step": 500
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.3351462483406067,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 1.5147,
      "step": 1000
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.3552093505859375,
      "learning_rate": 2.5e-06,
      "loss": 1.5185,
      "step": 1500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.3421007990837097,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 1.5035,
      "step": 2000
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.32875290513038635,
      "learning_rate": 4.166666666666667e-06,
      "loss": 1.5139,
      "step": 2500
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.2871268391609192,
      "learning_rate": 5e-06,
      "loss": 1.4999,
      "step": 3000
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.3009040057659149,
      "learning_rate": 5.833333333333334e-06,
      "loss": 1.5053,
      "step": 3500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.29175248742103577,
      "learning_rate": 6.666666666666667e-06,
      "loss": 1.4892,
      "step": 4000
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.3087151348590851,
      "learning_rate": 7.5e-06,
      "loss": 1.4963,
      "step": 4500
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.2951240837574005,
      "learning_rate": 8.333333333333334e-06,
      "loss": 1.4903,
      "step": 5000
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.28416821360588074,
      "learning_rate": 9.166666666666666e-06,
      "loss": 1.4838,
      "step": 5500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.28166744112968445,
      "learning_rate": 1e-05,
      "loss": 1.4761,
      "step": 6000
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.32774046063423157,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 1.4844,
      "step": 6500
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.30377811193466187,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 1.4874,
      "step": 7000
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.30565640330314636,
      "learning_rate": 1.25e-05,
      "loss": 1.4797,
      "step": 7500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2586020231246948,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 1.483,
      "step": 8000
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.3084995150566101,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 1.4963,
      "step": 8500
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.2669362425804138,
      "learning_rate": 1.5e-05,
      "loss": 1.4849,
      "step": 9000
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.28072741627693176,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 1.4713,
      "step": 9500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.27590787410736084,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 1.4712,
      "step": 10000
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.31176143884658813,
      "learning_rate": 1.75e-05,
      "loss": 1.4691,
      "step": 10500
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.32541435956954956,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 1.481,
      "step": 11000
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.26917263865470886,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 1.4804,
      "step": 11500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3210943341255188,
      "learning_rate": 2e-05,
      "loss": 1.4766,
      "step": 12000
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.27633577585220337,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 1.4692,
      "step": 12500
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.2626376748085022,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 1.4712,
      "step": 13000
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.2367042750120163,
      "learning_rate": 2.25e-05,
      "loss": 1.4635,
      "step": 13500
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.31108391284942627,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 1.4673,
      "step": 14000
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.28660452365875244,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 1.4664,
      "step": 14500
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.26379120349884033,
      "learning_rate": 2.5e-05,
      "loss": 1.4654,
      "step": 15000
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.312003493309021,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 1.4698,
      "step": 15500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.30332088470458984,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.4651,
      "step": 16000
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.3117115795612335,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 1.4613,
      "step": 16500
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.3089132606983185,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 1.458,
      "step": 17000
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.2979090213775635,
      "learning_rate": 2.916666666666667e-05,
      "loss": 1.4601,
      "step": 17500
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.3188478946685791,
      "learning_rate": 3e-05,
      "loss": 1.4615,
      "step": 18000
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.2891157269477844,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 1.4659,
      "step": 18500
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.2979714274406433,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 1.4537,
      "step": 19000
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.29498255252838135,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 1.4505,
      "step": 19500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.258736252784729,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.461,
      "step": 20000
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.30080708861351013,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 1.4475,
      "step": 20500
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.3004177510738373,
      "learning_rate": 3.5e-05,
      "loss": 1.464,
      "step": 21000
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.30572086572647095,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 1.4452,
      "step": 21500
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.2914045751094818,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 1.4523,
      "step": 22000
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.29826250672340393,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.4583,
      "step": 22500
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.3317627012729645,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 1.4622,
      "step": 23000
    },
    {
      "epoch": 0.05875,
      "grad_norm": 0.2922152280807495,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 1.4548,
      "step": 23500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2717275619506836,
      "learning_rate": 4e-05,
      "loss": 1.4483,
      "step": 24000
    },
    {
      "epoch": 0.06125,
      "grad_norm": 0.2963342070579529,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 1.4454,
      "step": 24500
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.27551931142807007,
      "learning_rate": 4.166666666666667e-05,
      "loss": 1.4412,
      "step": 25000
    },
    {
      "epoch": 0.06375,
      "grad_norm": 0.2860928475856781,
      "learning_rate": 4.25e-05,
      "loss": 1.4514,
      "step": 25500
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.30596813559532166,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 1.4442,
      "step": 26000
    },
    {
      "epoch": 0.06625,
      "grad_norm": 0.2752041816711426,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 1.4495,
      "step": 26500
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.29134446382522583,
      "learning_rate": 4.5e-05,
      "loss": 1.4337,
      "step": 27000
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.30855628848075867,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 1.4474,
      "step": 27500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3000379502773285,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.4474,
      "step": 28000
    },
    {
      "epoch": 0.07125,
      "grad_norm": 0.32909756898880005,
      "learning_rate": 4.75e-05,
      "loss": 1.4367,
      "step": 28500
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.2955915927886963,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 1.4319,
      "step": 29000
    },
    {
      "epoch": 0.07375,
      "grad_norm": 0.30392536520957947,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 1.4335,
      "step": 29500
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.313578724861145,
      "learning_rate": 5e-05,
      "loss": 1.4374,
      "step": 30000
    },
    {
      "epoch": 0.07625,
      "grad_norm": 0.34157684445381165,
      "learning_rate": 5.0833333333333333e-05,
      "loss": 1.4339,
      "step": 30500
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.33119985461235046,
      "learning_rate": 5.166666666666667e-05,
      "loss": 1.4381,
      "step": 31000
    },
    {
      "epoch": 0.07875,
      "grad_norm": 0.3226969540119171,
      "learning_rate": 5.25e-05,
      "loss": 1.4292,
      "step": 31500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.31693166494369507,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.4283,
      "step": 32000
    },
    {
      "epoch": 0.08125,
      "grad_norm": 0.3302187919616699,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 1.4427,
      "step": 32500
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.31464070081710815,
      "learning_rate": 5.500000000000001e-05,
      "loss": 1.4314,
      "step": 33000
    },
    {
      "epoch": 0.08375,
      "grad_norm": 0.30428367853164673,
      "learning_rate": 5.583333333333334e-05,
      "loss": 1.4361,
      "step": 33500
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.29349789023399353,
      "learning_rate": 5.666666666666667e-05,
      "loss": 1.4348,
      "step": 34000
    },
    {
      "epoch": 0.08625,
      "grad_norm": 0.3031628131866455,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 1.4257,
      "step": 34500
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.3175586760044098,
      "learning_rate": 5.833333333333334e-05,
      "loss": 1.4296,
      "step": 35000
    },
    {
      "epoch": 0.08875,
      "grad_norm": 0.32385051250457764,
      "learning_rate": 5.916666666666667e-05,
      "loss": 1.4317,
      "step": 35500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3424532413482666,
      "learning_rate": 6e-05,
      "loss": 1.4299,
      "step": 36000
    },
    {
      "epoch": 0.09125,
      "grad_norm": 0.3514655530452728,
      "learning_rate": 6.083333333333333e-05,
      "loss": 1.4289,
      "step": 36500
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.30826088786125183,
      "learning_rate": 6.166666666666667e-05,
      "loss": 1.4303,
      "step": 37000
    },
    {
      "epoch": 0.09375,
      "grad_norm": 0.3189523220062256,
      "learning_rate": 6.25e-05,
      "loss": 1.4281,
      "step": 37500
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.31975826621055603,
      "learning_rate": 6.333333333333333e-05,
      "loss": 1.4283,
      "step": 38000
    },
    {
      "epoch": 0.09625,
      "grad_norm": 0.3190084397792816,
      "learning_rate": 6.416666666666668e-05,
      "loss": 1.4247,
      "step": 38500
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.2871153950691223,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.4292,
      "step": 39000
    },
    {
      "epoch": 0.09875,
      "grad_norm": 0.34471604228019714,
      "learning_rate": 6.583333333333334e-05,
      "loss": 1.423,
      "step": 39500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3011622726917267,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.4205,
      "step": 40000
    },
    {
      "epoch": 0.10125,
      "grad_norm": 0.2904737591743469,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.4204,
      "step": 40500
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.31184670329093933,
      "learning_rate": 6.833333333333333e-05,
      "loss": 1.4146,
      "step": 41000
    },
    {
      "epoch": 0.10375,
      "grad_norm": 0.36600106954574585,
      "learning_rate": 6.916666666666666e-05,
      "loss": 1.4205,
      "step": 41500
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.28101205825805664,
      "learning_rate": 7e-05,
      "loss": 1.4141,
      "step": 42000
    },
    {
      "epoch": 0.10625,
      "grad_norm": 0.3399151861667633,
      "learning_rate": 7.083333333333334e-05,
      "loss": 1.4221,
      "step": 42500
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.3578092157840729,
      "learning_rate": 7.166666666666667e-05,
      "loss": 1.4211,
      "step": 43000
    },
    {
      "epoch": 0.10875,
      "grad_norm": 0.59038907289505,
      "learning_rate": 7.25e-05,
      "loss": 1.4177,
      "step": 43500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.36835119128227234,
      "learning_rate": 7.333333333333333e-05,
      "loss": 1.4129,
      "step": 44000
    },
    {
      "epoch": 0.11125,
      "grad_norm": 0.340481162071228,
      "learning_rate": 7.416666666666668e-05,
      "loss": 1.4008,
      "step": 44500
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.3548910915851593,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.4114,
      "step": 45000
    },
    {
      "epoch": 0.11375,
      "grad_norm": 0.3725699782371521,
      "learning_rate": 7.583333333333334e-05,
      "loss": 1.4139,
      "step": 45500
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.37333744764328003,
      "learning_rate": 7.666666666666667e-05,
      "loss": 1.4053,
      "step": 46000
    },
    {
      "epoch": 0.11625,
      "grad_norm": 0.3576895594596863,
      "learning_rate": 7.75e-05,
      "loss": 1.4115,
      "step": 46500
    },
    {
      "epoch": 0.1175,
      "grad_norm": 0.3674679398536682,
      "learning_rate": 7.833333333333333e-05,
      "loss": 1.4145,
      "step": 47000
    },
    {
      "epoch": 0.11875,
      "grad_norm": 0.356288880109787,
      "learning_rate": 7.916666666666666e-05,
      "loss": 1.4058,
      "step": 47500
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.355455219745636,
      "learning_rate": 8e-05,
      "loss": 1.3992,
      "step": 48000
    },
    {
      "epoch": 0.12125,
      "grad_norm": 0.36329561471939087,
      "learning_rate": 8.083333333333334e-05,
      "loss": 1.4101,
      "step": 48500
    },
    {
      "epoch": 0.1225,
      "grad_norm": 0.38877803087234497,
      "learning_rate": 8.166666666666667e-05,
      "loss": 1.4079,
      "step": 49000
    },
    {
      "epoch": 0.12375,
      "grad_norm": 0.3875250816345215,
      "learning_rate": 8.25e-05,
      "loss": 1.4034,
      "step": 49500
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.3667728304862976,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.4034,
      "step": 50000
    },
    {
      "epoch": 0.12625,
      "grad_norm": 0.34537622332572937,
      "learning_rate": 8.416666666666668e-05,
      "loss": 1.3919,
      "step": 50500
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.3556268513202667,
      "learning_rate": 8.5e-05,
      "loss": 1.4013,
      "step": 51000
    },
    {
      "epoch": 0.12875,
      "grad_norm": 0.35322293639183044,
      "learning_rate": 8.583333333333334e-05,
      "loss": 1.3961,
      "step": 51500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3394016623497009,
      "learning_rate": 8.666666666666667e-05,
      "loss": 1.4066,
      "step": 52000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 0.3958137035369873,
      "learning_rate": 8.75e-05,
      "loss": 1.4024,
      "step": 52500
    },
    {
      "epoch": 0.1325,
      "grad_norm": 0.3501269519329071,
      "learning_rate": 8.833333333333333e-05,
      "loss": 1.3909,
      "step": 53000
    },
    {
      "epoch": 0.13375,
      "grad_norm": 0.4035339057445526,
      "learning_rate": 8.916666666666667e-05,
      "loss": 1.3975,
      "step": 53500
    },
    {
      "epoch": 0.135,
      "grad_norm": 0.34879082441329956,
      "learning_rate": 9e-05,
      "loss": 1.3863,
      "step": 54000
    },
    {
      "epoch": 0.13625,
      "grad_norm": 0.4029821753501892,
      "learning_rate": 9.083333333333334e-05,
      "loss": 1.3902,
      "step": 54500
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.38911500573158264,
      "learning_rate": 9.166666666666667e-05,
      "loss": 1.3776,
      "step": 55000
    },
    {
      "epoch": 0.13875,
      "grad_norm": 0.38619962334632874,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.3864,
      "step": 55500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3575594425201416,
      "learning_rate": 9.333333333333334e-05,
      "loss": 1.3955,
      "step": 56000
    },
    {
      "epoch": 0.14125,
      "grad_norm": 0.3710726201534271,
      "learning_rate": 9.416666666666667e-05,
      "loss": 1.3883,
      "step": 56500
    },
    {
      "epoch": 0.1425,
      "grad_norm": 0.3713977336883545,
      "learning_rate": 9.5e-05,
      "loss": 1.387,
      "step": 57000
    },
    {
      "epoch": 0.14375,
      "grad_norm": 0.3626595437526703,
      "learning_rate": 9.583333333333334e-05,
      "loss": 1.3811,
      "step": 57500
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.33275386691093445,
      "learning_rate": 9.666666666666667e-05,
      "loss": 1.381,
      "step": 58000
    },
    {
      "epoch": 0.14625,
      "grad_norm": 0.4024617671966553,
      "learning_rate": 9.75e-05,
      "loss": 1.3757,
      "step": 58500
    },
    {
      "epoch": 0.1475,
      "grad_norm": 0.42343243956565857,
      "learning_rate": 9.833333333333333e-05,
      "loss": 1.381,
      "step": 59000
    },
    {
      "epoch": 0.14875,
      "grad_norm": 0.40600794553756714,
      "learning_rate": 9.916666666666667e-05,
      "loss": 1.3816,
      "step": 59500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.45413708686828613,
      "learning_rate": 0.0001,
      "loss": 1.3684,
      "step": 60000
    },
    {
      "epoch": 0.15125,
      "grad_norm": 0.3843975365161896,
      "learning_rate": 9.98529411764706e-05,
      "loss": 1.3807,
      "step": 60500
    },
    {
      "epoch": 0.1525,
      "grad_norm": 0.42381322383880615,
      "learning_rate": 9.970588235294118e-05,
      "loss": 1.373,
      "step": 61000
    },
    {
      "epoch": 0.15375,
      "grad_norm": 0.37458890676498413,
      "learning_rate": 9.955882352941178e-05,
      "loss": 1.3688,
      "step": 61500
    },
    {
      "epoch": 0.155,
      "grad_norm": 0.4026866555213928,
      "learning_rate": 9.941176470588236e-05,
      "loss": 1.3769,
      "step": 62000
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.4429400861263275,
      "learning_rate": 9.926470588235295e-05,
      "loss": 1.3715,
      "step": 62500
    },
    {
      "epoch": 0.1575,
      "grad_norm": 0.41450899839401245,
      "learning_rate": 9.911764705882353e-05,
      "loss": 1.3708,
      "step": 63000
    },
    {
      "epoch": 0.15875,
      "grad_norm": 0.4424532949924469,
      "learning_rate": 9.897058823529413e-05,
      "loss": 1.3679,
      "step": 63500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4571481943130493,
      "learning_rate": 9.882352941176471e-05,
      "loss": 1.3622,
      "step": 64000
    },
    {
      "epoch": 0.16125,
      "grad_norm": 0.4055335521697998,
      "learning_rate": 9.86764705882353e-05,
      "loss": 1.3634,
      "step": 64500
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.4132572412490845,
      "learning_rate": 9.852941176470589e-05,
      "loss": 1.3688,
      "step": 65000
    },
    {
      "epoch": 0.16375,
      "grad_norm": 0.4419463574886322,
      "learning_rate": 9.838235294117647e-05,
      "loss": 1.3689,
      "step": 65500
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.40049445629119873,
      "learning_rate": 9.823529411764706e-05,
      "loss": 1.3678,
      "step": 66000
    },
    {
      "epoch": 0.16625,
      "grad_norm": 0.4505552351474762,
      "learning_rate": 9.808823529411765e-05,
      "loss": 1.3667,
      "step": 66500
    },
    {
      "epoch": 0.1675,
      "grad_norm": 0.4224737882614136,
      "learning_rate": 9.794117647058824e-05,
      "loss": 1.3715,
      "step": 67000
    },
    {
      "epoch": 0.16875,
      "grad_norm": 0.40801677107810974,
      "learning_rate": 9.779411764705882e-05,
      "loss": 1.3637,
      "step": 67500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4422787129878998,
      "learning_rate": 9.764705882352942e-05,
      "loss": 1.3609,
      "step": 68000
    },
    {
      "epoch": 0.17125,
      "grad_norm": 0.46579277515411377,
      "learning_rate": 9.75e-05,
      "loss": 1.3533,
      "step": 68500
    },
    {
      "epoch": 0.1725,
      "grad_norm": 0.4253222942352295,
      "learning_rate": 9.73529411764706e-05,
      "loss": 1.3549,
      "step": 69000
    },
    {
      "epoch": 0.17375,
      "grad_norm": 0.44593626260757446,
      "learning_rate": 9.720588235294117e-05,
      "loss": 1.3506,
      "step": 69500
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.4062022268772125,
      "learning_rate": 9.705882352941177e-05,
      "loss": 1.3493,
      "step": 70000
    },
    {
      "epoch": 0.17625,
      "grad_norm": 0.4177446961402893,
      "learning_rate": 9.691176470588235e-05,
      "loss": 1.3527,
      "step": 70500
    },
    {
      "epoch": 0.1775,
      "grad_norm": 0.4238955080509186,
      "learning_rate": 9.676470588235295e-05,
      "loss": 1.3526,
      "step": 71000
    },
    {
      "epoch": 0.17875,
      "grad_norm": 0.4288466274738312,
      "learning_rate": 9.661764705882354e-05,
      "loss": 1.3461,
      "step": 71500
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5193110704421997,
      "learning_rate": 9.647058823529412e-05,
      "loss": 1.3549,
      "step": 72000
    },
    {
      "epoch": 0.18125,
      "grad_norm": 0.4458419978618622,
      "learning_rate": 9.632352941176472e-05,
      "loss": 1.3575,
      "step": 72500
    },
    {
      "epoch": 0.1825,
      "grad_norm": 0.43919387459754944,
      "learning_rate": 9.61764705882353e-05,
      "loss": 1.3453,
      "step": 73000
    },
    {
      "epoch": 0.18375,
      "grad_norm": 0.4897039532661438,
      "learning_rate": 9.60294117647059e-05,
      "loss": 1.337,
      "step": 73500
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.48510241508483887,
      "learning_rate": 9.588235294117648e-05,
      "loss": 1.3342,
      "step": 74000
    },
    {
      "epoch": 0.18625,
      "grad_norm": 0.4916004240512848,
      "learning_rate": 9.573529411764707e-05,
      "loss": 1.3409,
      "step": 74500
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.4690949618816376,
      "learning_rate": 9.558823529411765e-05,
      "loss": 1.3406,
      "step": 75000
    },
    {
      "epoch": 0.18875,
      "grad_norm": 0.4649909734725952,
      "learning_rate": 9.544117647058825e-05,
      "loss": 1.3516,
      "step": 75500
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4768112301826477,
      "learning_rate": 9.529411764705883e-05,
      "loss": 1.3414,
      "step": 76000
    },
    {
      "epoch": 0.19125,
      "grad_norm": 0.5153589248657227,
      "learning_rate": 9.514705882352941e-05,
      "loss": 1.3495,
      "step": 76500
    },
    {
      "epoch": 0.1925,
      "grad_norm": 0.49458926916122437,
      "learning_rate": 9.5e-05,
      "loss": 1.3368,
      "step": 77000
    },
    {
      "epoch": 0.19375,
      "grad_norm": 0.49397239089012146,
      "learning_rate": 9.485294117647059e-05,
      "loss": 1.3344,
      "step": 77500
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.4661509394645691,
      "learning_rate": 9.470588235294118e-05,
      "loss": 1.3455,
      "step": 78000
    },
    {
      "epoch": 0.19625,
      "grad_norm": 0.4386134743690491,
      "learning_rate": 9.455882352941176e-05,
      "loss": 1.3334,
      "step": 78500
    },
    {
      "epoch": 0.1975,
      "grad_norm": 0.5028902292251587,
      "learning_rate": 9.441176470588236e-05,
      "loss": 1.3387,
      "step": 79000
    },
    {
      "epoch": 0.19875,
      "grad_norm": 0.453722208738327,
      "learning_rate": 9.426470588235294e-05,
      "loss": 1.3434,
      "step": 79500
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5063848495483398,
      "learning_rate": 9.411764705882353e-05,
      "loss": 1.3351,
      "step": 80000
    },
    {
      "epoch": 0.20125,
      "grad_norm": 0.5237882733345032,
      "learning_rate": 9.397058823529412e-05,
      "loss": 1.333,
      "step": 80500
    },
    {
      "epoch": 0.2025,
      "grad_norm": 0.4875295162200928,
      "learning_rate": 9.382352941176471e-05,
      "loss": 1.3272,
      "step": 81000
    },
    {
      "epoch": 0.20375,
      "grad_norm": 0.5042937397956848,
      "learning_rate": 9.367647058823529e-05,
      "loss": 1.3321,
      "step": 81500
    },
    {
      "epoch": 0.205,
      "grad_norm": 0.5180721879005432,
      "learning_rate": 9.352941176470589e-05,
      "loss": 1.3332,
      "step": 82000
    },
    {
      "epoch": 0.20625,
      "grad_norm": 0.5147678852081299,
      "learning_rate": 9.338235294117648e-05,
      "loss": 1.3311,
      "step": 82500
    },
    {
      "epoch": 0.2075,
      "grad_norm": 0.5233386754989624,
      "learning_rate": 9.323529411764706e-05,
      "loss": 1.3255,
      "step": 83000
    },
    {
      "epoch": 0.20875,
      "grad_norm": 0.5572922825813293,
      "learning_rate": 9.308823529411766e-05,
      "loss": 1.3299,
      "step": 83500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5310779213905334,
      "learning_rate": 9.294117647058824e-05,
      "loss": 1.3255,
      "step": 84000
    },
    {
      "epoch": 0.21125,
      "grad_norm": 0.4691757559776306,
      "learning_rate": 9.279411764705884e-05,
      "loss": 1.325,
      "step": 84500
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.509333610534668,
      "learning_rate": 9.264705882352942e-05,
      "loss": 1.328,
      "step": 85000
    },
    {
      "epoch": 0.21375,
      "grad_norm": 0.4726085066795349,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.3116,
      "step": 85500
    },
    {
      "epoch": 0.215,
      "grad_norm": 0.5649380087852478,
      "learning_rate": 9.23529411764706e-05,
      "loss": 1.3282,
      "step": 86000
    },
    {
      "epoch": 0.21625,
      "grad_norm": 0.5525431036949158,
      "learning_rate": 9.220588235294119e-05,
      "loss": 1.3362,
      "step": 86500
    },
    {
      "epoch": 0.2175,
      "grad_norm": 0.5681211948394775,
      "learning_rate": 9.205882352941177e-05,
      "loss": 1.32,
      "step": 87000
    },
    {
      "epoch": 0.21875,
      "grad_norm": 0.5027126669883728,
      "learning_rate": 9.191176470588235e-05,
      "loss": 1.3243,
      "step": 87500
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5281720757484436,
      "learning_rate": 9.176470588235295e-05,
      "loss": 1.3098,
      "step": 88000
    },
    {
      "epoch": 0.22125,
      "grad_norm": 0.4852652847766876,
      "learning_rate": 9.161764705882353e-05,
      "loss": 1.3181,
      "step": 88500
    },
    {
      "epoch": 0.2225,
      "grad_norm": 0.5219762921333313,
      "learning_rate": 9.147058823529412e-05,
      "loss": 1.3062,
      "step": 89000
    },
    {
      "epoch": 0.22375,
      "grad_norm": 0.5821523070335388,
      "learning_rate": 9.13235294117647e-05,
      "loss": 1.3107,
      "step": 89500
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.5158603191375732,
      "learning_rate": 9.11764705882353e-05,
      "loss": 1.3112,
      "step": 90000
    },
    {
      "epoch": 0.22625,
      "grad_norm": 0.5200087428092957,
      "learning_rate": 9.102941176470588e-05,
      "loss": 1.3125,
      "step": 90500
    },
    {
      "epoch": 0.2275,
      "grad_norm": 0.5719851851463318,
      "learning_rate": 9.088235294117648e-05,
      "loss": 1.3202,
      "step": 91000
    },
    {
      "epoch": 0.22875,
      "grad_norm": 0.5748855471611023,
      "learning_rate": 9.073529411764706e-05,
      "loss": 1.3025,
      "step": 91500
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.602070689201355,
      "learning_rate": 9.058823529411765e-05,
      "loss": 1.31,
      "step": 92000
    },
    {
      "epoch": 0.23125,
      "grad_norm": 0.5524869561195374,
      "learning_rate": 9.044117647058823e-05,
      "loss": 1.3208,
      "step": 92500
    },
    {
      "epoch": 0.2325,
      "grad_norm": 0.46316421031951904,
      "learning_rate": 9.029411764705883e-05,
      "loss": 1.3048,
      "step": 93000
    },
    {
      "epoch": 0.23375,
      "grad_norm": 0.4462394416332245,
      "learning_rate": 9.014705882352942e-05,
      "loss": 1.3112,
      "step": 93500
    },
    {
      "epoch": 0.235,
      "grad_norm": 0.5361183285713196,
      "learning_rate": 9e-05,
      "loss": 1.3077,
      "step": 94000
    },
    {
      "epoch": 0.23625,
      "grad_norm": 0.577636182308197,
      "learning_rate": 8.98529411764706e-05,
      "loss": 1.3078,
      "step": 94500
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.5762913823127747,
      "learning_rate": 8.970588235294118e-05,
      "loss": 1.2974,
      "step": 95000
    },
    {
      "epoch": 0.23875,
      "grad_norm": 0.5734923481941223,
      "learning_rate": 8.955882352941178e-05,
      "loss": 1.3004,
      "step": 95500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5577595829963684,
      "learning_rate": 8.941176470588236e-05,
      "loss": 1.305,
      "step": 96000
    },
    {
      "epoch": 0.24125,
      "grad_norm": 0.5504409074783325,
      "learning_rate": 8.926470588235295e-05,
      "loss": 1.3151,
      "step": 96500
    },
    {
      "epoch": 0.2425,
      "grad_norm": 0.562995970249176,
      "learning_rate": 8.911764705882354e-05,
      "loss": 1.2953,
      "step": 97000
    },
    {
      "epoch": 0.24375,
      "grad_norm": 0.5009123086929321,
      "learning_rate": 8.897058823529412e-05,
      "loss": 1.2882,
      "step": 97500
    },
    {
      "epoch": 0.245,
      "grad_norm": 0.5326331257820129,
      "learning_rate": 8.882352941176471e-05,
      "loss": 1.3039,
      "step": 98000
    },
    {
      "epoch": 0.24625,
      "grad_norm": 0.5857583284378052,
      "learning_rate": 8.867647058823529e-05,
      "loss": 1.2947,
      "step": 98500
    },
    {
      "epoch": 0.2475,
      "grad_norm": 0.590550422668457,
      "learning_rate": 8.852941176470589e-05,
      "loss": 1.2987,
      "step": 99000
    },
    {
      "epoch": 0.24875,
      "grad_norm": 0.5234450697898865,
      "learning_rate": 8.838235294117647e-05,
      "loss": 1.2962,
      "step": 99500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5842458605766296,
      "learning_rate": 8.823529411764706e-05,
      "loss": 1.2871,
      "step": 100000
    }
  ],
  "logging_steps": 500,
  "max_steps": 400000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.678793019392e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
