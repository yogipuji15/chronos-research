{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 400000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00125,
      "grad_norm": 0.3525909185409546,
      "learning_rate": 8.333333333333333e-07,
      "loss": 1.5313,
      "step": 500
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.3351462483406067,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 1.5147,
      "step": 1000
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.3552093505859375,
      "learning_rate": 2.5e-06,
      "loss": 1.5185,
      "step": 1500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.3421007990837097,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 1.5035,
      "step": 2000
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.32875290513038635,
      "learning_rate": 4.166666666666667e-06,
      "loss": 1.5139,
      "step": 2500
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.2871268391609192,
      "learning_rate": 5e-06,
      "loss": 1.4999,
      "step": 3000
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.3009040057659149,
      "learning_rate": 5.833333333333334e-06,
      "loss": 1.5053,
      "step": 3500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.29175248742103577,
      "learning_rate": 6.666666666666667e-06,
      "loss": 1.4892,
      "step": 4000
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.3087151348590851,
      "learning_rate": 7.5e-06,
      "loss": 1.4963,
      "step": 4500
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.2951240837574005,
      "learning_rate": 8.333333333333334e-06,
      "loss": 1.4903,
      "step": 5000
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.28416821360588074,
      "learning_rate": 9.166666666666666e-06,
      "loss": 1.4838,
      "step": 5500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.28166744112968445,
      "learning_rate": 1e-05,
      "loss": 1.4761,
      "step": 6000
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.32774046063423157,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 1.4844,
      "step": 6500
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.30377811193466187,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 1.4874,
      "step": 7000
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.30565640330314636,
      "learning_rate": 1.25e-05,
      "loss": 1.4797,
      "step": 7500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.2586020231246948,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 1.483,
      "step": 8000
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.3084995150566101,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 1.4963,
      "step": 8500
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.2669362425804138,
      "learning_rate": 1.5e-05,
      "loss": 1.4849,
      "step": 9000
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.28072741627693176,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 1.4713,
      "step": 9500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.27590787410736084,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 1.4712,
      "step": 10000
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.31176143884658813,
      "learning_rate": 1.75e-05,
      "loss": 1.4691,
      "step": 10500
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.32541435956954956,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 1.481,
      "step": 11000
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.26917263865470886,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 1.4804,
      "step": 11500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.3210943341255188,
      "learning_rate": 2e-05,
      "loss": 1.4766,
      "step": 12000
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.27633577585220337,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 1.4692,
      "step": 12500
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.2626376748085022,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 1.4712,
      "step": 13000
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.2367042750120163,
      "learning_rate": 2.25e-05,
      "loss": 1.4635,
      "step": 13500
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.31108391284942627,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 1.4673,
      "step": 14000
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.28660452365875244,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 1.4664,
      "step": 14500
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.26379120349884033,
      "learning_rate": 2.5e-05,
      "loss": 1.4654,
      "step": 15000
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.312003493309021,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 1.4698,
      "step": 15500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.30332088470458984,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.4651,
      "step": 16000
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.3117115795612335,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 1.4613,
      "step": 16500
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.3089132606983185,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 1.458,
      "step": 17000
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.2979090213775635,
      "learning_rate": 2.916666666666667e-05,
      "loss": 1.4601,
      "step": 17500
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.3188478946685791,
      "learning_rate": 3e-05,
      "loss": 1.4615,
      "step": 18000
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.2891157269477844,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 1.4659,
      "step": 18500
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.2979714274406433,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 1.4537,
      "step": 19000
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.29498255252838135,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 1.4505,
      "step": 19500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.258736252784729,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.461,
      "step": 20000
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.30080708861351013,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 1.4475,
      "step": 20500
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.3004177510738373,
      "learning_rate": 3.5e-05,
      "loss": 1.464,
      "step": 21000
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.30572086572647095,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 1.4452,
      "step": 21500
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.2914045751094818,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 1.4523,
      "step": 22000
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.29826250672340393,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.4583,
      "step": 22500
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.3317627012729645,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 1.4622,
      "step": 23000
    },
    {
      "epoch": 0.05875,
      "grad_norm": 0.2922152280807495,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 1.4548,
      "step": 23500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2717275619506836,
      "learning_rate": 4e-05,
      "loss": 1.4483,
      "step": 24000
    },
    {
      "epoch": 0.06125,
      "grad_norm": 0.2963342070579529,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 1.4454,
      "step": 24500
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.27551931142807007,
      "learning_rate": 4.166666666666667e-05,
      "loss": 1.4412,
      "step": 25000
    },
    {
      "epoch": 0.06375,
      "grad_norm": 0.2860928475856781,
      "learning_rate": 4.25e-05,
      "loss": 1.4514,
      "step": 25500
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.30596813559532166,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 1.4442,
      "step": 26000
    },
    {
      "epoch": 0.06625,
      "grad_norm": 0.2752041816711426,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 1.4495,
      "step": 26500
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.29134446382522583,
      "learning_rate": 4.5e-05,
      "loss": 1.4337,
      "step": 27000
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.30855628848075867,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 1.4474,
      "step": 27500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3000379502773285,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.4474,
      "step": 28000
    },
    {
      "epoch": 0.07125,
      "grad_norm": 0.32909756898880005,
      "learning_rate": 4.75e-05,
      "loss": 1.4367,
      "step": 28500
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.2955915927886963,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 1.4319,
      "step": 29000
    },
    {
      "epoch": 0.07375,
      "grad_norm": 0.30392536520957947,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 1.4335,
      "step": 29500
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.313578724861145,
      "learning_rate": 5e-05,
      "loss": 1.4374,
      "step": 30000
    },
    {
      "epoch": 0.07625,
      "grad_norm": 0.34157684445381165,
      "learning_rate": 5.0833333333333333e-05,
      "loss": 1.4339,
      "step": 30500
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.33119985461235046,
      "learning_rate": 5.166666666666667e-05,
      "loss": 1.4381,
      "step": 31000
    },
    {
      "epoch": 0.07875,
      "grad_norm": 0.3226969540119171,
      "learning_rate": 5.25e-05,
      "loss": 1.4292,
      "step": 31500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.31693166494369507,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.4283,
      "step": 32000
    },
    {
      "epoch": 0.08125,
      "grad_norm": 0.3302187919616699,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 1.4427,
      "step": 32500
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.31464070081710815,
      "learning_rate": 5.500000000000001e-05,
      "loss": 1.4314,
      "step": 33000
    },
    {
      "epoch": 0.08375,
      "grad_norm": 0.30428367853164673,
      "learning_rate": 5.583333333333334e-05,
      "loss": 1.4361,
      "step": 33500
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.29349789023399353,
      "learning_rate": 5.666666666666667e-05,
      "loss": 1.4348,
      "step": 34000
    },
    {
      "epoch": 0.08625,
      "grad_norm": 0.3031628131866455,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 1.4257,
      "step": 34500
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.3175586760044098,
      "learning_rate": 5.833333333333334e-05,
      "loss": 1.4296,
      "step": 35000
    },
    {
      "epoch": 0.08875,
      "grad_norm": 0.32385051250457764,
      "learning_rate": 5.916666666666667e-05,
      "loss": 1.4317,
      "step": 35500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.3424532413482666,
      "learning_rate": 6e-05,
      "loss": 1.4299,
      "step": 36000
    },
    {
      "epoch": 0.09125,
      "grad_norm": 0.3514655530452728,
      "learning_rate": 6.083333333333333e-05,
      "loss": 1.4289,
      "step": 36500
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.30826088786125183,
      "learning_rate": 6.166666666666667e-05,
      "loss": 1.4303,
      "step": 37000
    },
    {
      "epoch": 0.09375,
      "grad_norm": 0.3189523220062256,
      "learning_rate": 6.25e-05,
      "loss": 1.4281,
      "step": 37500
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.31975826621055603,
      "learning_rate": 6.333333333333333e-05,
      "loss": 1.4283,
      "step": 38000
    },
    {
      "epoch": 0.09625,
      "grad_norm": 0.3190084397792816,
      "learning_rate": 6.416666666666668e-05,
      "loss": 1.4247,
      "step": 38500
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.2871153950691223,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.4292,
      "step": 39000
    },
    {
      "epoch": 0.09875,
      "grad_norm": 0.34471604228019714,
      "learning_rate": 6.583333333333334e-05,
      "loss": 1.423,
      "step": 39500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3011622726917267,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.4205,
      "step": 40000
    },
    {
      "epoch": 0.10125,
      "grad_norm": 0.2904737591743469,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.4204,
      "step": 40500
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.31184670329093933,
      "learning_rate": 6.833333333333333e-05,
      "loss": 1.4146,
      "step": 41000
    },
    {
      "epoch": 0.10375,
      "grad_norm": 0.36600106954574585,
      "learning_rate": 6.916666666666666e-05,
      "loss": 1.4205,
      "step": 41500
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.28101205825805664,
      "learning_rate": 7e-05,
      "loss": 1.4141,
      "step": 42000
    },
    {
      "epoch": 0.10625,
      "grad_norm": 0.3399151861667633,
      "learning_rate": 7.083333333333334e-05,
      "loss": 1.4221,
      "step": 42500
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.3578092157840729,
      "learning_rate": 7.166666666666667e-05,
      "loss": 1.4211,
      "step": 43000
    },
    {
      "epoch": 0.10875,
      "grad_norm": 0.59038907289505,
      "learning_rate": 7.25e-05,
      "loss": 1.4177,
      "step": 43500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.36835119128227234,
      "learning_rate": 7.333333333333333e-05,
      "loss": 1.4129,
      "step": 44000
    },
    {
      "epoch": 0.11125,
      "grad_norm": 0.340481162071228,
      "learning_rate": 7.416666666666668e-05,
      "loss": 1.4008,
      "step": 44500
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.3548910915851593,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.4114,
      "step": 45000
    },
    {
      "epoch": 0.11375,
      "grad_norm": 0.3725699782371521,
      "learning_rate": 7.583333333333334e-05,
      "loss": 1.4139,
      "step": 45500
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.37333744764328003,
      "learning_rate": 7.666666666666667e-05,
      "loss": 1.4053,
      "step": 46000
    },
    {
      "epoch": 0.11625,
      "grad_norm": 0.3576895594596863,
      "learning_rate": 7.75e-05,
      "loss": 1.4115,
      "step": 46500
    },
    {
      "epoch": 0.1175,
      "grad_norm": 0.3674679398536682,
      "learning_rate": 7.833333333333333e-05,
      "loss": 1.4145,
      "step": 47000
    },
    {
      "epoch": 0.11875,
      "grad_norm": 0.356288880109787,
      "learning_rate": 7.916666666666666e-05,
      "loss": 1.4058,
      "step": 47500
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.355455219745636,
      "learning_rate": 8e-05,
      "loss": 1.3992,
      "step": 48000
    },
    {
      "epoch": 0.12125,
      "grad_norm": 0.36329561471939087,
      "learning_rate": 8.083333333333334e-05,
      "loss": 1.4101,
      "step": 48500
    },
    {
      "epoch": 0.1225,
      "grad_norm": 0.38877803087234497,
      "learning_rate": 8.166666666666667e-05,
      "loss": 1.4079,
      "step": 49000
    },
    {
      "epoch": 0.12375,
      "grad_norm": 0.3875250816345215,
      "learning_rate": 8.25e-05,
      "loss": 1.4034,
      "step": 49500
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.3667728304862976,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.4034,
      "step": 50000
    },
    {
      "epoch": 0.12625,
      "grad_norm": 0.34537622332572937,
      "learning_rate": 8.416666666666668e-05,
      "loss": 1.3919,
      "step": 50500
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.3556268513202667,
      "learning_rate": 8.5e-05,
      "loss": 1.4013,
      "step": 51000
    },
    {
      "epoch": 0.12875,
      "grad_norm": 0.35322293639183044,
      "learning_rate": 8.583333333333334e-05,
      "loss": 1.3961,
      "step": 51500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3394016623497009,
      "learning_rate": 8.666666666666667e-05,
      "loss": 1.4066,
      "step": 52000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 0.3958137035369873,
      "learning_rate": 8.75e-05,
      "loss": 1.4024,
      "step": 52500
    },
    {
      "epoch": 0.1325,
      "grad_norm": 0.3501269519329071,
      "learning_rate": 8.833333333333333e-05,
      "loss": 1.3909,
      "step": 53000
    },
    {
      "epoch": 0.13375,
      "grad_norm": 0.4035339057445526,
      "learning_rate": 8.916666666666667e-05,
      "loss": 1.3975,
      "step": 53500
    },
    {
      "epoch": 0.135,
      "grad_norm": 0.34879082441329956,
      "learning_rate": 9e-05,
      "loss": 1.3863,
      "step": 54000
    },
    {
      "epoch": 0.13625,
      "grad_norm": 0.4029821753501892,
      "learning_rate": 9.083333333333334e-05,
      "loss": 1.3902,
      "step": 54500
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.38911500573158264,
      "learning_rate": 9.166666666666667e-05,
      "loss": 1.3776,
      "step": 55000
    },
    {
      "epoch": 0.13875,
      "grad_norm": 0.38619962334632874,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.3864,
      "step": 55500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3575594425201416,
      "learning_rate": 9.333333333333334e-05,
      "loss": 1.3955,
      "step": 56000
    },
    {
      "epoch": 0.14125,
      "grad_norm": 0.3710726201534271,
      "learning_rate": 9.416666666666667e-05,
      "loss": 1.3883,
      "step": 56500
    },
    {
      "epoch": 0.1425,
      "grad_norm": 0.3713977336883545,
      "learning_rate": 9.5e-05,
      "loss": 1.387,
      "step": 57000
    },
    {
      "epoch": 0.14375,
      "grad_norm": 0.3626595437526703,
      "learning_rate": 9.583333333333334e-05,
      "loss": 1.3811,
      "step": 57500
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.33275386691093445,
      "learning_rate": 9.666666666666667e-05,
      "loss": 1.381,
      "step": 58000
    },
    {
      "epoch": 0.14625,
      "grad_norm": 0.4024617671966553,
      "learning_rate": 9.75e-05,
      "loss": 1.3757,
      "step": 58500
    },
    {
      "epoch": 0.1475,
      "grad_norm": 0.42343243956565857,
      "learning_rate": 9.833333333333333e-05,
      "loss": 1.381,
      "step": 59000
    },
    {
      "epoch": 0.14875,
      "grad_norm": 0.40600794553756714,
      "learning_rate": 9.916666666666667e-05,
      "loss": 1.3816,
      "step": 59500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.45413708686828613,
      "learning_rate": 0.0001,
      "loss": 1.3684,
      "step": 60000
    },
    {
      "epoch": 0.15125,
      "grad_norm": 0.3843975365161896,
      "learning_rate": 9.98529411764706e-05,
      "loss": 1.3807,
      "step": 60500
    },
    {
      "epoch": 0.1525,
      "grad_norm": 0.42381322383880615,
      "learning_rate": 9.970588235294118e-05,
      "loss": 1.373,
      "step": 61000
    },
    {
      "epoch": 0.15375,
      "grad_norm": 0.37458890676498413,
      "learning_rate": 9.955882352941178e-05,
      "loss": 1.3688,
      "step": 61500
    },
    {
      "epoch": 0.155,
      "grad_norm": 0.4026866555213928,
      "learning_rate": 9.941176470588236e-05,
      "loss": 1.3769,
      "step": 62000
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.4429400861263275,
      "learning_rate": 9.926470588235295e-05,
      "loss": 1.3715,
      "step": 62500
    },
    {
      "epoch": 0.1575,
      "grad_norm": 0.41450899839401245,
      "learning_rate": 9.911764705882353e-05,
      "loss": 1.3708,
      "step": 63000
    },
    {
      "epoch": 0.15875,
      "grad_norm": 0.4424532949924469,
      "learning_rate": 9.897058823529413e-05,
      "loss": 1.3679,
      "step": 63500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4571481943130493,
      "learning_rate": 9.882352941176471e-05,
      "loss": 1.3622,
      "step": 64000
    },
    {
      "epoch": 0.16125,
      "grad_norm": 0.4055335521697998,
      "learning_rate": 9.86764705882353e-05,
      "loss": 1.3634,
      "step": 64500
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.4132572412490845,
      "learning_rate": 9.852941176470589e-05,
      "loss": 1.3688,
      "step": 65000
    },
    {
      "epoch": 0.16375,
      "grad_norm": 0.4419463574886322,
      "learning_rate": 9.838235294117647e-05,
      "loss": 1.3689,
      "step": 65500
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.40049445629119873,
      "learning_rate": 9.823529411764706e-05,
      "loss": 1.3678,
      "step": 66000
    },
    {
      "epoch": 0.16625,
      "grad_norm": 0.4505552351474762,
      "learning_rate": 9.808823529411765e-05,
      "loss": 1.3667,
      "step": 66500
    },
    {
      "epoch": 0.1675,
      "grad_norm": 0.4224737882614136,
      "learning_rate": 9.794117647058824e-05,
      "loss": 1.3715,
      "step": 67000
    },
    {
      "epoch": 0.16875,
      "grad_norm": 0.40801677107810974,
      "learning_rate": 9.779411764705882e-05,
      "loss": 1.3637,
      "step": 67500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.4422787129878998,
      "learning_rate": 9.764705882352942e-05,
      "loss": 1.3609,
      "step": 68000
    },
    {
      "epoch": 0.17125,
      "grad_norm": 0.46579277515411377,
      "learning_rate": 9.75e-05,
      "loss": 1.3533,
      "step": 68500
    },
    {
      "epoch": 0.1725,
      "grad_norm": 0.4253222942352295,
      "learning_rate": 9.73529411764706e-05,
      "loss": 1.3549,
      "step": 69000
    },
    {
      "epoch": 0.17375,
      "grad_norm": 0.44593626260757446,
      "learning_rate": 9.720588235294117e-05,
      "loss": 1.3506,
      "step": 69500
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.4062022268772125,
      "learning_rate": 9.705882352941177e-05,
      "loss": 1.3493,
      "step": 70000
    },
    {
      "epoch": 0.17625,
      "grad_norm": 0.4177446961402893,
      "learning_rate": 9.691176470588235e-05,
      "loss": 1.3527,
      "step": 70500
    },
    {
      "epoch": 0.1775,
      "grad_norm": 0.4238955080509186,
      "learning_rate": 9.676470588235295e-05,
      "loss": 1.3526,
      "step": 71000
    },
    {
      "epoch": 0.17875,
      "grad_norm": 0.4288466274738312,
      "learning_rate": 9.661764705882354e-05,
      "loss": 1.3461,
      "step": 71500
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5193110704421997,
      "learning_rate": 9.647058823529412e-05,
      "loss": 1.3549,
      "step": 72000
    },
    {
      "epoch": 0.18125,
      "grad_norm": 0.4458419978618622,
      "learning_rate": 9.632352941176472e-05,
      "loss": 1.3575,
      "step": 72500
    },
    {
      "epoch": 0.1825,
      "grad_norm": 0.43919387459754944,
      "learning_rate": 9.61764705882353e-05,
      "loss": 1.3453,
      "step": 73000
    },
    {
      "epoch": 0.18375,
      "grad_norm": 0.4897039532661438,
      "learning_rate": 9.60294117647059e-05,
      "loss": 1.337,
      "step": 73500
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.48510241508483887,
      "learning_rate": 9.588235294117648e-05,
      "loss": 1.3342,
      "step": 74000
    },
    {
      "epoch": 0.18625,
      "grad_norm": 0.4916004240512848,
      "learning_rate": 9.573529411764707e-05,
      "loss": 1.3409,
      "step": 74500
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.4690949618816376,
      "learning_rate": 9.558823529411765e-05,
      "loss": 1.3406,
      "step": 75000
    },
    {
      "epoch": 0.18875,
      "grad_norm": 0.4649909734725952,
      "learning_rate": 9.544117647058825e-05,
      "loss": 1.3516,
      "step": 75500
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.4768112301826477,
      "learning_rate": 9.529411764705883e-05,
      "loss": 1.3414,
      "step": 76000
    },
    {
      "epoch": 0.19125,
      "grad_norm": 0.5153589248657227,
      "learning_rate": 9.514705882352941e-05,
      "loss": 1.3495,
      "step": 76500
    },
    {
      "epoch": 0.1925,
      "grad_norm": 0.49458926916122437,
      "learning_rate": 9.5e-05,
      "loss": 1.3368,
      "step": 77000
    },
    {
      "epoch": 0.19375,
      "grad_norm": 0.49397239089012146,
      "learning_rate": 9.485294117647059e-05,
      "loss": 1.3344,
      "step": 77500
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.4661509394645691,
      "learning_rate": 9.470588235294118e-05,
      "loss": 1.3455,
      "step": 78000
    },
    {
      "epoch": 0.19625,
      "grad_norm": 0.4386134743690491,
      "learning_rate": 9.455882352941176e-05,
      "loss": 1.3334,
      "step": 78500
    },
    {
      "epoch": 0.1975,
      "grad_norm": 0.5028902292251587,
      "learning_rate": 9.441176470588236e-05,
      "loss": 1.3387,
      "step": 79000
    },
    {
      "epoch": 0.19875,
      "grad_norm": 0.453722208738327,
      "learning_rate": 9.426470588235294e-05,
      "loss": 1.3434,
      "step": 79500
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5063848495483398,
      "learning_rate": 9.411764705882353e-05,
      "loss": 1.3351,
      "step": 80000
    },
    {
      "epoch": 0.20125,
      "grad_norm": 0.5237882733345032,
      "learning_rate": 9.397058823529412e-05,
      "loss": 1.333,
      "step": 80500
    },
    {
      "epoch": 0.2025,
      "grad_norm": 0.4875295162200928,
      "learning_rate": 9.382352941176471e-05,
      "loss": 1.3272,
      "step": 81000
    },
    {
      "epoch": 0.20375,
      "grad_norm": 0.5042937397956848,
      "learning_rate": 9.367647058823529e-05,
      "loss": 1.3321,
      "step": 81500
    },
    {
      "epoch": 0.205,
      "grad_norm": 0.5180721879005432,
      "learning_rate": 9.352941176470589e-05,
      "loss": 1.3332,
      "step": 82000
    },
    {
      "epoch": 0.20625,
      "grad_norm": 0.5147678852081299,
      "learning_rate": 9.338235294117648e-05,
      "loss": 1.3311,
      "step": 82500
    },
    {
      "epoch": 0.2075,
      "grad_norm": 0.5233386754989624,
      "learning_rate": 9.323529411764706e-05,
      "loss": 1.3255,
      "step": 83000
    },
    {
      "epoch": 0.20875,
      "grad_norm": 0.5572922825813293,
      "learning_rate": 9.308823529411766e-05,
      "loss": 1.3299,
      "step": 83500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5310779213905334,
      "learning_rate": 9.294117647058824e-05,
      "loss": 1.3255,
      "step": 84000
    },
    {
      "epoch": 0.21125,
      "grad_norm": 0.4691757559776306,
      "learning_rate": 9.279411764705884e-05,
      "loss": 1.325,
      "step": 84500
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.509333610534668,
      "learning_rate": 9.264705882352942e-05,
      "loss": 1.328,
      "step": 85000
    },
    {
      "epoch": 0.21375,
      "grad_norm": 0.4726085066795349,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.3116,
      "step": 85500
    },
    {
      "epoch": 0.215,
      "grad_norm": 0.5649380087852478,
      "learning_rate": 9.23529411764706e-05,
      "loss": 1.3282,
      "step": 86000
    },
    {
      "epoch": 0.21625,
      "grad_norm": 0.5525431036949158,
      "learning_rate": 9.220588235294119e-05,
      "loss": 1.3362,
      "step": 86500
    },
    {
      "epoch": 0.2175,
      "grad_norm": 0.5681211948394775,
      "learning_rate": 9.205882352941177e-05,
      "loss": 1.32,
      "step": 87000
    },
    {
      "epoch": 0.21875,
      "grad_norm": 0.5027126669883728,
      "learning_rate": 9.191176470588235e-05,
      "loss": 1.3243,
      "step": 87500
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.5281720757484436,
      "learning_rate": 9.176470588235295e-05,
      "loss": 1.3098,
      "step": 88000
    },
    {
      "epoch": 0.22125,
      "grad_norm": 0.4852652847766876,
      "learning_rate": 9.161764705882353e-05,
      "loss": 1.3181,
      "step": 88500
    },
    {
      "epoch": 0.2225,
      "grad_norm": 0.5219762921333313,
      "learning_rate": 9.147058823529412e-05,
      "loss": 1.3062,
      "step": 89000
    },
    {
      "epoch": 0.22375,
      "grad_norm": 0.5821523070335388,
      "learning_rate": 9.13235294117647e-05,
      "loss": 1.3107,
      "step": 89500
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.5158603191375732,
      "learning_rate": 9.11764705882353e-05,
      "loss": 1.3112,
      "step": 90000
    },
    {
      "epoch": 0.22625,
      "grad_norm": 0.5200087428092957,
      "learning_rate": 9.102941176470588e-05,
      "loss": 1.3125,
      "step": 90500
    },
    {
      "epoch": 0.2275,
      "grad_norm": 0.5719851851463318,
      "learning_rate": 9.088235294117648e-05,
      "loss": 1.3202,
      "step": 91000
    },
    {
      "epoch": 0.22875,
      "grad_norm": 0.5748855471611023,
      "learning_rate": 9.073529411764706e-05,
      "loss": 1.3025,
      "step": 91500
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.602070689201355,
      "learning_rate": 9.058823529411765e-05,
      "loss": 1.31,
      "step": 92000
    },
    {
      "epoch": 0.23125,
      "grad_norm": 0.5524869561195374,
      "learning_rate": 9.044117647058823e-05,
      "loss": 1.3208,
      "step": 92500
    },
    {
      "epoch": 0.2325,
      "grad_norm": 0.46316421031951904,
      "learning_rate": 9.029411764705883e-05,
      "loss": 1.3048,
      "step": 93000
    },
    {
      "epoch": 0.23375,
      "grad_norm": 0.4462394416332245,
      "learning_rate": 9.014705882352942e-05,
      "loss": 1.3112,
      "step": 93500
    },
    {
      "epoch": 0.235,
      "grad_norm": 0.5361183285713196,
      "learning_rate": 9e-05,
      "loss": 1.3077,
      "step": 94000
    },
    {
      "epoch": 0.23625,
      "grad_norm": 0.577636182308197,
      "learning_rate": 8.98529411764706e-05,
      "loss": 1.3078,
      "step": 94500
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.5762913823127747,
      "learning_rate": 8.970588235294118e-05,
      "loss": 1.2974,
      "step": 95000
    },
    {
      "epoch": 0.23875,
      "grad_norm": 0.5734923481941223,
      "learning_rate": 8.955882352941178e-05,
      "loss": 1.3004,
      "step": 95500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5577595829963684,
      "learning_rate": 8.941176470588236e-05,
      "loss": 1.305,
      "step": 96000
    },
    {
      "epoch": 0.24125,
      "grad_norm": 0.5504409074783325,
      "learning_rate": 8.926470588235295e-05,
      "loss": 1.3151,
      "step": 96500
    },
    {
      "epoch": 0.2425,
      "grad_norm": 0.562995970249176,
      "learning_rate": 8.911764705882354e-05,
      "loss": 1.2953,
      "step": 97000
    },
    {
      "epoch": 0.24375,
      "grad_norm": 0.5009123086929321,
      "learning_rate": 8.897058823529412e-05,
      "loss": 1.2882,
      "step": 97500
    },
    {
      "epoch": 0.245,
      "grad_norm": 0.5326331257820129,
      "learning_rate": 8.882352941176471e-05,
      "loss": 1.3039,
      "step": 98000
    },
    {
      "epoch": 0.24625,
      "grad_norm": 0.5857583284378052,
      "learning_rate": 8.867647058823529e-05,
      "loss": 1.2947,
      "step": 98500
    },
    {
      "epoch": 0.2475,
      "grad_norm": 0.590550422668457,
      "learning_rate": 8.852941176470589e-05,
      "loss": 1.2987,
      "step": 99000
    },
    {
      "epoch": 0.24875,
      "grad_norm": 0.5234450697898865,
      "learning_rate": 8.838235294117647e-05,
      "loss": 1.2962,
      "step": 99500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5842458605766296,
      "learning_rate": 8.823529411764706e-05,
      "loss": 1.2871,
      "step": 100000
    },
    {
      "epoch": 0.25125,
      "grad_norm": 0.5584490895271301,
      "learning_rate": 8.808823529411765e-05,
      "loss": 1.2944,
      "step": 100500
    },
    {
      "epoch": 0.2525,
      "grad_norm": 0.5325509905815125,
      "learning_rate": 8.794117647058824e-05,
      "loss": 1.2849,
      "step": 101000
    },
    {
      "epoch": 0.25375,
      "grad_norm": 0.6134979724884033,
      "learning_rate": 8.779411764705882e-05,
      "loss": 1.2912,
      "step": 101500
    },
    {
      "epoch": 0.255,
      "grad_norm": 0.5959237217903137,
      "learning_rate": 8.764705882352942e-05,
      "loss": 1.2794,
      "step": 102000
    },
    {
      "epoch": 0.25625,
      "grad_norm": 0.5768120288848877,
      "learning_rate": 8.75e-05,
      "loss": 1.2835,
      "step": 102500
    },
    {
      "epoch": 0.2575,
      "grad_norm": 0.6156759262084961,
      "learning_rate": 8.73529411764706e-05,
      "loss": 1.2704,
      "step": 103000
    },
    {
      "epoch": 0.25875,
      "grad_norm": 0.5939354300498962,
      "learning_rate": 8.720588235294118e-05,
      "loss": 1.2962,
      "step": 103500
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6154354214668274,
      "learning_rate": 8.705882352941177e-05,
      "loss": 1.292,
      "step": 104000
    },
    {
      "epoch": 0.26125,
      "grad_norm": 0.5874418020248413,
      "learning_rate": 8.691176470588237e-05,
      "loss": 1.2816,
      "step": 104500
    },
    {
      "epoch": 0.2625,
      "grad_norm": 0.5950140953063965,
      "learning_rate": 8.676470588235295e-05,
      "loss": 1.2725,
      "step": 105000
    },
    {
      "epoch": 0.26375,
      "grad_norm": 0.5640875697135925,
      "learning_rate": 8.661764705882354e-05,
      "loss": 1.277,
      "step": 105500
    },
    {
      "epoch": 0.265,
      "grad_norm": 0.612426221370697,
      "learning_rate": 8.647058823529412e-05,
      "loss": 1.2849,
      "step": 106000
    },
    {
      "epoch": 0.26625,
      "grad_norm": 0.6005223393440247,
      "learning_rate": 8.632352941176472e-05,
      "loss": 1.2869,
      "step": 106500
    },
    {
      "epoch": 0.2675,
      "grad_norm": 0.5692949891090393,
      "learning_rate": 8.61764705882353e-05,
      "loss": 1.2794,
      "step": 107000
    },
    {
      "epoch": 0.26875,
      "grad_norm": 0.581389844417572,
      "learning_rate": 8.60294117647059e-05,
      "loss": 1.2849,
      "step": 107500
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6825534701347351,
      "learning_rate": 8.588235294117646e-05,
      "loss": 1.2827,
      "step": 108000
    },
    {
      "epoch": 0.27125,
      "grad_norm": 0.5441576242446899,
      "learning_rate": 8.573529411764706e-05,
      "loss": 1.2768,
      "step": 108500
    },
    {
      "epoch": 0.2725,
      "grad_norm": 0.5717966556549072,
      "learning_rate": 8.558823529411765e-05,
      "loss": 1.2783,
      "step": 109000
    },
    {
      "epoch": 0.27375,
      "grad_norm": 0.5672899484634399,
      "learning_rate": 8.544117647058823e-05,
      "loss": 1.2722,
      "step": 109500
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.5841063261032104,
      "learning_rate": 8.529411764705883e-05,
      "loss": 1.2633,
      "step": 110000
    },
    {
      "epoch": 0.27625,
      "grad_norm": 0.5032175183296204,
      "learning_rate": 8.514705882352941e-05,
      "loss": 1.2657,
      "step": 110500
    },
    {
      "epoch": 0.2775,
      "grad_norm": 0.6399956345558167,
      "learning_rate": 8.5e-05,
      "loss": 1.2655,
      "step": 111000
    },
    {
      "epoch": 0.27875,
      "grad_norm": 0.6310605406761169,
      "learning_rate": 8.485294117647059e-05,
      "loss": 1.275,
      "step": 111500
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6282780170440674,
      "learning_rate": 8.470588235294118e-05,
      "loss": 1.2675,
      "step": 112000
    },
    {
      "epoch": 0.28125,
      "grad_norm": 0.6188015341758728,
      "learning_rate": 8.455882352941176e-05,
      "loss": 1.2728,
      "step": 112500
    },
    {
      "epoch": 0.2825,
      "grad_norm": 0.6524316072463989,
      "learning_rate": 8.441176470588236e-05,
      "loss": 1.2731,
      "step": 113000
    },
    {
      "epoch": 0.28375,
      "grad_norm": 0.5614326596260071,
      "learning_rate": 8.426470588235294e-05,
      "loss": 1.2548,
      "step": 113500
    },
    {
      "epoch": 0.285,
      "grad_norm": 0.5931857824325562,
      "learning_rate": 8.411764705882354e-05,
      "loss": 1.2722,
      "step": 114000
    },
    {
      "epoch": 0.28625,
      "grad_norm": 0.6190201044082642,
      "learning_rate": 8.397058823529412e-05,
      "loss": 1.2708,
      "step": 114500
    },
    {
      "epoch": 0.2875,
      "grad_norm": 0.6317391991615295,
      "learning_rate": 8.382352941176471e-05,
      "loss": 1.2599,
      "step": 115000
    },
    {
      "epoch": 0.28875,
      "grad_norm": 0.5837651491165161,
      "learning_rate": 8.367647058823531e-05,
      "loss": 1.2778,
      "step": 115500
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5810502171516418,
      "learning_rate": 8.352941176470589e-05,
      "loss": 1.2584,
      "step": 116000
    },
    {
      "epoch": 0.29125,
      "grad_norm": 0.6096926927566528,
      "learning_rate": 8.338235294117648e-05,
      "loss": 1.2584,
      "step": 116500
    },
    {
      "epoch": 0.2925,
      "grad_norm": 0.6102877259254456,
      "learning_rate": 8.323529411764707e-05,
      "loss": 1.261,
      "step": 117000
    },
    {
      "epoch": 0.29375,
      "grad_norm": 0.5977135896682739,
      "learning_rate": 8.308823529411766e-05,
      "loss": 1.2647,
      "step": 117500
    },
    {
      "epoch": 0.295,
      "grad_norm": 0.7062002420425415,
      "learning_rate": 8.294117647058824e-05,
      "loss": 1.2559,
      "step": 118000
    },
    {
      "epoch": 0.29625,
      "grad_norm": 0.6497128009796143,
      "learning_rate": 8.279411764705882e-05,
      "loss": 1.2563,
      "step": 118500
    },
    {
      "epoch": 0.2975,
      "grad_norm": 0.6723485589027405,
      "learning_rate": 8.26470588235294e-05,
      "loss": 1.2641,
      "step": 119000
    },
    {
      "epoch": 0.29875,
      "grad_norm": 0.725718080997467,
      "learning_rate": 8.25e-05,
      "loss": 1.2669,
      "step": 119500
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6538354158401489,
      "learning_rate": 8.23529411764706e-05,
      "loss": 1.2487,
      "step": 120000
    },
    {
      "epoch": 0.30125,
      "grad_norm": 0.703742265701294,
      "learning_rate": 8.220588235294118e-05,
      "loss": 1.2609,
      "step": 120500
    },
    {
      "epoch": 0.3025,
      "grad_norm": 0.5715253353118896,
      "learning_rate": 8.205882352941177e-05,
      "loss": 1.2555,
      "step": 121000
    },
    {
      "epoch": 0.30375,
      "grad_norm": 0.6139172315597534,
      "learning_rate": 8.191176470588235e-05,
      "loss": 1.256,
      "step": 121500
    },
    {
      "epoch": 0.305,
      "grad_norm": 0.6550194621086121,
      "learning_rate": 8.176470588235295e-05,
      "loss": 1.2451,
      "step": 122000
    },
    {
      "epoch": 0.30625,
      "grad_norm": 0.6240108013153076,
      "learning_rate": 8.161764705882353e-05,
      "loss": 1.2508,
      "step": 122500
    },
    {
      "epoch": 0.3075,
      "grad_norm": 0.6478844285011292,
      "learning_rate": 8.147058823529412e-05,
      "loss": 1.2506,
      "step": 123000
    },
    {
      "epoch": 0.30875,
      "grad_norm": 0.6336901783943176,
      "learning_rate": 8.13235294117647e-05,
      "loss": 1.2545,
      "step": 123500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5981606245040894,
      "learning_rate": 8.11764705882353e-05,
      "loss": 1.241,
      "step": 124000
    },
    {
      "epoch": 0.31125,
      "grad_norm": 0.6539360284805298,
      "learning_rate": 8.102941176470588e-05,
      "loss": 1.2465,
      "step": 124500
    },
    {
      "epoch": 0.3125,
      "grad_norm": 0.6498755812644958,
      "learning_rate": 8.088235294117648e-05,
      "loss": 1.2478,
      "step": 125000
    },
    {
      "epoch": 0.31375,
      "grad_norm": 0.6599276661872864,
      "learning_rate": 8.073529411764706e-05,
      "loss": 1.2486,
      "step": 125500
    },
    {
      "epoch": 0.315,
      "grad_norm": 0.6543036699295044,
      "learning_rate": 8.058823529411765e-05,
      "loss": 1.2531,
      "step": 126000
    },
    {
      "epoch": 0.31625,
      "grad_norm": 0.6876549124717712,
      "learning_rate": 8.044117647058825e-05,
      "loss": 1.2391,
      "step": 126500
    },
    {
      "epoch": 0.3175,
      "grad_norm": 0.6597864627838135,
      "learning_rate": 8.029411764705883e-05,
      "loss": 1.2389,
      "step": 127000
    },
    {
      "epoch": 0.31875,
      "grad_norm": 0.6945083737373352,
      "learning_rate": 8.014705882352943e-05,
      "loss": 1.2454,
      "step": 127500
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6915631294250488,
      "learning_rate": 8e-05,
      "loss": 1.2496,
      "step": 128000
    },
    {
      "epoch": 0.32125,
      "grad_norm": 0.6206929087638855,
      "learning_rate": 7.98529411764706e-05,
      "loss": 1.2442,
      "step": 128500
    },
    {
      "epoch": 0.3225,
      "grad_norm": 0.5812049508094788,
      "learning_rate": 7.970588235294118e-05,
      "loss": 1.2469,
      "step": 129000
    },
    {
      "epoch": 0.32375,
      "grad_norm": 0.6775445342063904,
      "learning_rate": 7.955882352941176e-05,
      "loss": 1.2479,
      "step": 129500
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.6673624515533447,
      "learning_rate": 7.941176470588235e-05,
      "loss": 1.2369,
      "step": 130000
    },
    {
      "epoch": 0.32625,
      "grad_norm": 0.6370402574539185,
      "learning_rate": 7.926470588235294e-05,
      "loss": 1.2475,
      "step": 130500
    },
    {
      "epoch": 0.3275,
      "grad_norm": 0.7118747234344482,
      "learning_rate": 7.911764705882354e-05,
      "loss": 1.248,
      "step": 131000
    },
    {
      "epoch": 0.32875,
      "grad_norm": 0.6784961223602295,
      "learning_rate": 7.897058823529412e-05,
      "loss": 1.2386,
      "step": 131500
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6300753355026245,
      "learning_rate": 7.882352941176471e-05,
      "loss": 1.2321,
      "step": 132000
    },
    {
      "epoch": 0.33125,
      "grad_norm": 0.695592999458313,
      "learning_rate": 7.86764705882353e-05,
      "loss": 1.2336,
      "step": 132500
    },
    {
      "epoch": 0.3325,
      "grad_norm": 0.65760737657547,
      "learning_rate": 7.852941176470589e-05,
      "loss": 1.2334,
      "step": 133000
    },
    {
      "epoch": 0.33375,
      "grad_norm": 0.6628692746162415,
      "learning_rate": 7.838235294117647e-05,
      "loss": 1.2388,
      "step": 133500
    },
    {
      "epoch": 0.335,
      "grad_norm": 0.6560651659965515,
      "learning_rate": 7.823529411764707e-05,
      "loss": 1.2395,
      "step": 134000
    },
    {
      "epoch": 0.33625,
      "grad_norm": 0.6244592070579529,
      "learning_rate": 7.808823529411765e-05,
      "loss": 1.2438,
      "step": 134500
    },
    {
      "epoch": 0.3375,
      "grad_norm": 0.7794779539108276,
      "learning_rate": 7.794117647058824e-05,
      "loss": 1.2369,
      "step": 135000
    },
    {
      "epoch": 0.33875,
      "grad_norm": 0.6838257908821106,
      "learning_rate": 7.779411764705882e-05,
      "loss": 1.2429,
      "step": 135500
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7296789884567261,
      "learning_rate": 7.764705882352942e-05,
      "loss": 1.2264,
      "step": 136000
    },
    {
      "epoch": 0.34125,
      "grad_norm": 0.7179789543151855,
      "learning_rate": 7.75e-05,
      "loss": 1.2278,
      "step": 136500
    },
    {
      "epoch": 0.3425,
      "grad_norm": 0.5958263874053955,
      "learning_rate": 7.73529411764706e-05,
      "loss": 1.2213,
      "step": 137000
    },
    {
      "epoch": 0.34375,
      "grad_norm": 0.7468476891517639,
      "learning_rate": 7.720588235294119e-05,
      "loss": 1.2244,
      "step": 137500
    },
    {
      "epoch": 0.345,
      "grad_norm": 0.7536217570304871,
      "learning_rate": 7.705882352941177e-05,
      "loss": 1.2205,
      "step": 138000
    },
    {
      "epoch": 0.34625,
      "grad_norm": 0.6884872317314148,
      "learning_rate": 7.691176470588237e-05,
      "loss": 1.223,
      "step": 138500
    },
    {
      "epoch": 0.3475,
      "grad_norm": 0.6690054535865784,
      "learning_rate": 7.676470588235295e-05,
      "loss": 1.2279,
      "step": 139000
    },
    {
      "epoch": 0.34875,
      "grad_norm": 0.675452709197998,
      "learning_rate": 7.661764705882354e-05,
      "loss": 1.221,
      "step": 139500
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6618687510490417,
      "learning_rate": 7.647058823529411e-05,
      "loss": 1.2321,
      "step": 140000
    },
    {
      "epoch": 0.35125,
      "grad_norm": 0.7058676481246948,
      "learning_rate": 7.63235294117647e-05,
      "loss": 1.2225,
      "step": 140500
    },
    {
      "epoch": 0.3525,
      "grad_norm": 0.6822875142097473,
      "learning_rate": 7.617647058823529e-05,
      "loss": 1.2247,
      "step": 141000
    },
    {
      "epoch": 0.35375,
      "grad_norm": 0.6641433835029602,
      "learning_rate": 7.602941176470588e-05,
      "loss": 1.2231,
      "step": 141500
    },
    {
      "epoch": 0.355,
      "grad_norm": 0.6739371418952942,
      "learning_rate": 7.588235294117648e-05,
      "loss": 1.2201,
      "step": 142000
    },
    {
      "epoch": 0.35625,
      "grad_norm": 0.7598466873168945,
      "learning_rate": 7.573529411764706e-05,
      "loss": 1.2158,
      "step": 142500
    },
    {
      "epoch": 0.3575,
      "grad_norm": 0.687851071357727,
      "learning_rate": 7.558823529411765e-05,
      "loss": 1.2273,
      "step": 143000
    },
    {
      "epoch": 0.35875,
      "grad_norm": 0.6796706914901733,
      "learning_rate": 7.544117647058824e-05,
      "loss": 1.2072,
      "step": 143500
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7227337956428528,
      "learning_rate": 7.529411764705883e-05,
      "loss": 1.221,
      "step": 144000
    },
    {
      "epoch": 0.36125,
      "grad_norm": 0.722067654132843,
      "learning_rate": 7.514705882352941e-05,
      "loss": 1.2186,
      "step": 144500
    },
    {
      "epoch": 0.3625,
      "grad_norm": 0.705664336681366,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.2159,
      "step": 145000
    },
    {
      "epoch": 0.36375,
      "grad_norm": 0.6792964339256287,
      "learning_rate": 7.485294117647059e-05,
      "loss": 1.2107,
      "step": 145500
    },
    {
      "epoch": 0.365,
      "grad_norm": 0.6732668876647949,
      "learning_rate": 7.470588235294118e-05,
      "loss": 1.2097,
      "step": 146000
    },
    {
      "epoch": 0.36625,
      "grad_norm": 0.7153657674789429,
      "learning_rate": 7.455882352941176e-05,
      "loss": 1.2106,
      "step": 146500
    },
    {
      "epoch": 0.3675,
      "grad_norm": 0.6489487290382385,
      "learning_rate": 7.441176470588236e-05,
      "loss": 1.2103,
      "step": 147000
    },
    {
      "epoch": 0.36875,
      "grad_norm": 0.6558957695960999,
      "learning_rate": 7.426470588235294e-05,
      "loss": 1.209,
      "step": 147500
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7500330805778503,
      "learning_rate": 7.411764705882354e-05,
      "loss": 1.2198,
      "step": 148000
    },
    {
      "epoch": 0.37125,
      "grad_norm": 0.6706681847572327,
      "learning_rate": 7.397058823529413e-05,
      "loss": 1.2117,
      "step": 148500
    },
    {
      "epoch": 0.3725,
      "grad_norm": 0.7548220157623291,
      "learning_rate": 7.382352941176471e-05,
      "loss": 1.2158,
      "step": 149000
    },
    {
      "epoch": 0.37375,
      "grad_norm": 0.7313188910484314,
      "learning_rate": 7.367647058823531e-05,
      "loss": 1.207,
      "step": 149500
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.764620840549469,
      "learning_rate": 7.352941176470589e-05,
      "loss": 1.2128,
      "step": 150000
    },
    {
      "epoch": 0.37625,
      "grad_norm": 0.7321850061416626,
      "learning_rate": 7.338235294117647e-05,
      "loss": 1.2142,
      "step": 150500
    },
    {
      "epoch": 0.3775,
      "grad_norm": 0.736045777797699,
      "learning_rate": 7.323529411764705e-05,
      "loss": 1.2153,
      "step": 151000
    },
    {
      "epoch": 0.37875,
      "grad_norm": 0.632385790348053,
      "learning_rate": 7.308823529411765e-05,
      "loss": 1.2027,
      "step": 151500
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6761655211448669,
      "learning_rate": 7.294117647058823e-05,
      "loss": 1.2084,
      "step": 152000
    },
    {
      "epoch": 0.38125,
      "grad_norm": 0.6928530931472778,
      "learning_rate": 7.279411764705882e-05,
      "loss": 1.2038,
      "step": 152500
    },
    {
      "epoch": 0.3825,
      "grad_norm": 0.7458816766738892,
      "learning_rate": 7.264705882352942e-05,
      "loss": 1.2078,
      "step": 153000
    },
    {
      "epoch": 0.38375,
      "grad_norm": 0.7743690013885498,
      "learning_rate": 7.25e-05,
      "loss": 1.2114,
      "step": 153500
    },
    {
      "epoch": 0.385,
      "grad_norm": 0.83058100938797,
      "learning_rate": 7.23529411764706e-05,
      "loss": 1.211,
      "step": 154000
    },
    {
      "epoch": 0.38625,
      "grad_norm": 0.7502697110176086,
      "learning_rate": 7.220588235294118e-05,
      "loss": 1.2128,
      "step": 154500
    },
    {
      "epoch": 0.3875,
      "grad_norm": 0.7030344009399414,
      "learning_rate": 7.205882352941177e-05,
      "loss": 1.2125,
      "step": 155000
    },
    {
      "epoch": 0.38875,
      "grad_norm": 0.8304486274719238,
      "learning_rate": 7.191176470588235e-05,
      "loss": 1.2033,
      "step": 155500
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7741556167602539,
      "learning_rate": 7.176470588235295e-05,
      "loss": 1.197,
      "step": 156000
    },
    {
      "epoch": 0.39125,
      "grad_norm": 0.7401458024978638,
      "learning_rate": 7.161764705882353e-05,
      "loss": 1.1994,
      "step": 156500
    },
    {
      "epoch": 0.3925,
      "grad_norm": 0.7214021682739258,
      "learning_rate": 7.147058823529412e-05,
      "loss": 1.2017,
      "step": 157000
    },
    {
      "epoch": 0.39375,
      "grad_norm": 0.7453362345695496,
      "learning_rate": 7.13235294117647e-05,
      "loss": 1.1994,
      "step": 157500
    },
    {
      "epoch": 0.395,
      "grad_norm": 0.7418411374092102,
      "learning_rate": 7.11764705882353e-05,
      "loss": 1.1963,
      "step": 158000
    },
    {
      "epoch": 0.39625,
      "grad_norm": 0.6815983057022095,
      "learning_rate": 7.102941176470588e-05,
      "loss": 1.2023,
      "step": 158500
    },
    {
      "epoch": 0.3975,
      "grad_norm": 0.7467872500419617,
      "learning_rate": 7.088235294117648e-05,
      "loss": 1.2043,
      "step": 159000
    },
    {
      "epoch": 0.39875,
      "grad_norm": 0.7427062392234802,
      "learning_rate": 7.073529411764707e-05,
      "loss": 1.1889,
      "step": 159500
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.7656083703041077,
      "learning_rate": 7.058823529411765e-05,
      "loss": 1.2055,
      "step": 160000
    },
    {
      "epoch": 0.40125,
      "grad_norm": 0.7165980935096741,
      "learning_rate": 7.044117647058825e-05,
      "loss": 1.1917,
      "step": 160500
    },
    {
      "epoch": 0.4025,
      "grad_norm": 0.6230360865592957,
      "learning_rate": 7.029411764705882e-05,
      "loss": 1.1875,
      "step": 161000
    },
    {
      "epoch": 0.40375,
      "grad_norm": 0.6965070366859436,
      "learning_rate": 7.014705882352941e-05,
      "loss": 1.1895,
      "step": 161500
    },
    {
      "epoch": 0.405,
      "grad_norm": 0.7309156656265259,
      "learning_rate": 7e-05,
      "loss": 1.1999,
      "step": 162000
    },
    {
      "epoch": 0.40625,
      "grad_norm": 0.7599288821220398,
      "learning_rate": 6.985294117647059e-05,
      "loss": 1.193,
      "step": 162500
    },
    {
      "epoch": 0.4075,
      "grad_norm": 0.6452474594116211,
      "learning_rate": 6.970588235294117e-05,
      "loss": 1.1905,
      "step": 163000
    },
    {
      "epoch": 0.40875,
      "grad_norm": 0.8592128157615662,
      "learning_rate": 6.955882352941177e-05,
      "loss": 1.1973,
      "step": 163500
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7510495781898499,
      "learning_rate": 6.941176470588236e-05,
      "loss": 1.202,
      "step": 164000
    },
    {
      "epoch": 0.41125,
      "grad_norm": 0.7418169975280762,
      "learning_rate": 6.926470588235294e-05,
      "loss": 1.1972,
      "step": 164500
    },
    {
      "epoch": 0.4125,
      "grad_norm": 0.6833311319351196,
      "learning_rate": 6.911764705882354e-05,
      "loss": 1.1939,
      "step": 165000
    },
    {
      "epoch": 0.41375,
      "grad_norm": 0.7874114513397217,
      "learning_rate": 6.897058823529412e-05,
      "loss": 1.1893,
      "step": 165500
    },
    {
      "epoch": 0.415,
      "grad_norm": 0.688873291015625,
      "learning_rate": 6.882352941176471e-05,
      "loss": 1.189,
      "step": 166000
    },
    {
      "epoch": 0.41625,
      "grad_norm": 0.7053990960121155,
      "learning_rate": 6.86764705882353e-05,
      "loss": 1.1859,
      "step": 166500
    },
    {
      "epoch": 0.4175,
      "grad_norm": 0.8034976720809937,
      "learning_rate": 6.852941176470589e-05,
      "loss": 1.1835,
      "step": 167000
    },
    {
      "epoch": 0.41875,
      "grad_norm": 0.8780719637870789,
      "learning_rate": 6.838235294117647e-05,
      "loss": 1.197,
      "step": 167500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7197210788726807,
      "learning_rate": 6.823529411764707e-05,
      "loss": 1.191,
      "step": 168000
    },
    {
      "epoch": 0.42125,
      "grad_norm": 0.8550724983215332,
      "learning_rate": 6.808823529411765e-05,
      "loss": 1.1882,
      "step": 168500
    },
    {
      "epoch": 0.4225,
      "grad_norm": 0.7942594885826111,
      "learning_rate": 6.794117647058824e-05,
      "loss": 1.19,
      "step": 169000
    },
    {
      "epoch": 0.42375,
      "grad_norm": 0.754675567150116,
      "learning_rate": 6.779411764705882e-05,
      "loss": 1.1923,
      "step": 169500
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.7343711853027344,
      "learning_rate": 6.764705882352942e-05,
      "loss": 1.1774,
      "step": 170000
    },
    {
      "epoch": 0.42625,
      "grad_norm": 0.7745625972747803,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.1858,
      "step": 170500
    },
    {
      "epoch": 0.4275,
      "grad_norm": 0.7807990312576294,
      "learning_rate": 6.73529411764706e-05,
      "loss": 1.1853,
      "step": 171000
    },
    {
      "epoch": 0.42875,
      "grad_norm": 0.8270683288574219,
      "learning_rate": 6.720588235294119e-05,
      "loss": 1.1823,
      "step": 171500
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8159874677658081,
      "learning_rate": 6.705882352941176e-05,
      "loss": 1.1837,
      "step": 172000
    },
    {
      "epoch": 0.43125,
      "grad_norm": 0.7625930905342102,
      "learning_rate": 6.691176470588235e-05,
      "loss": 1.1768,
      "step": 172500
    },
    {
      "epoch": 0.4325,
      "grad_norm": 0.7346326112747192,
      "learning_rate": 6.676470588235294e-05,
      "loss": 1.1708,
      "step": 173000
    },
    {
      "epoch": 0.43375,
      "grad_norm": 0.8093426823616028,
      "learning_rate": 6.661764705882353e-05,
      "loss": 1.1742,
      "step": 173500
    },
    {
      "epoch": 0.435,
      "grad_norm": 0.6701012253761292,
      "learning_rate": 6.647058823529411e-05,
      "loss": 1.1745,
      "step": 174000
    },
    {
      "epoch": 0.43625,
      "grad_norm": 0.7621423006057739,
      "learning_rate": 6.632352941176471e-05,
      "loss": 1.1805,
      "step": 174500
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.7542241811752319,
      "learning_rate": 6.61764705882353e-05,
      "loss": 1.176,
      "step": 175000
    },
    {
      "epoch": 0.43875,
      "grad_norm": 0.7431454658508301,
      "learning_rate": 6.602941176470588e-05,
      "loss": 1.176,
      "step": 175500
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7528695464134216,
      "learning_rate": 6.588235294117648e-05,
      "loss": 1.1754,
      "step": 176000
    },
    {
      "epoch": 0.44125,
      "grad_norm": 0.6872010231018066,
      "learning_rate": 6.573529411764706e-05,
      "loss": 1.1698,
      "step": 176500
    },
    {
      "epoch": 0.4425,
      "grad_norm": 0.7773473262786865,
      "learning_rate": 6.558823529411765e-05,
      "loss": 1.1709,
      "step": 177000
    },
    {
      "epoch": 0.44375,
      "grad_norm": 0.7635877132415771,
      "learning_rate": 6.544117647058824e-05,
      "loss": 1.1751,
      "step": 177500
    },
    {
      "epoch": 0.445,
      "grad_norm": 0.7373131513595581,
      "learning_rate": 6.529411764705883e-05,
      "loss": 1.1875,
      "step": 178000
    },
    {
      "epoch": 0.44625,
      "grad_norm": 0.694984495639801,
      "learning_rate": 6.514705882352941e-05,
      "loss": 1.1813,
      "step": 178500
    },
    {
      "epoch": 0.4475,
      "grad_norm": 0.8417930006980896,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.1753,
      "step": 179000
    },
    {
      "epoch": 0.44875,
      "grad_norm": 0.7526365518569946,
      "learning_rate": 6.485294117647059e-05,
      "loss": 1.1753,
      "step": 179500
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.8192877173423767,
      "learning_rate": 6.470588235294118e-05,
      "loss": 1.1665,
      "step": 180000
    },
    {
      "epoch": 0.45125,
      "grad_norm": 0.7828648686408997,
      "learning_rate": 6.455882352941177e-05,
      "loss": 1.1779,
      "step": 180500
    },
    {
      "epoch": 0.4525,
      "grad_norm": 0.6727885603904724,
      "learning_rate": 6.441176470588236e-05,
      "loss": 1.1823,
      "step": 181000
    },
    {
      "epoch": 0.45375,
      "grad_norm": 0.8381927013397217,
      "learning_rate": 6.426470588235294e-05,
      "loss": 1.1691,
      "step": 181500
    },
    {
      "epoch": 0.455,
      "grad_norm": 0.7833046317100525,
      "learning_rate": 6.411764705882354e-05,
      "loss": 1.1702,
      "step": 182000
    },
    {
      "epoch": 0.45625,
      "grad_norm": 0.7041696906089783,
      "learning_rate": 6.397058823529412e-05,
      "loss": 1.1722,
      "step": 182500
    },
    {
      "epoch": 0.4575,
      "grad_norm": 0.8212038278579712,
      "learning_rate": 6.38235294117647e-05,
      "loss": 1.1587,
      "step": 183000
    },
    {
      "epoch": 0.45875,
      "grad_norm": 0.8085634708404541,
      "learning_rate": 6.36764705882353e-05,
      "loss": 1.1692,
      "step": 183500
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6966994404792786,
      "learning_rate": 6.352941176470588e-05,
      "loss": 1.1644,
      "step": 184000
    },
    {
      "epoch": 0.46125,
      "grad_norm": 0.8036017417907715,
      "learning_rate": 6.338235294117647e-05,
      "loss": 1.1694,
      "step": 184500
    },
    {
      "epoch": 0.4625,
      "grad_norm": 0.789499819278717,
      "learning_rate": 6.323529411764705e-05,
      "loss": 1.1617,
      "step": 185000
    },
    {
      "epoch": 0.46375,
      "grad_norm": 0.762230634689331,
      "learning_rate": 6.308823529411765e-05,
      "loss": 1.1578,
      "step": 185500
    },
    {
      "epoch": 0.465,
      "grad_norm": 0.7109630107879639,
      "learning_rate": 6.294117647058824e-05,
      "loss": 1.1671,
      "step": 186000
    },
    {
      "epoch": 0.46625,
      "grad_norm": 0.6794013977050781,
      "learning_rate": 6.279411764705882e-05,
      "loss": 1.1651,
      "step": 186500
    },
    {
      "epoch": 0.4675,
      "grad_norm": 0.7519468665122986,
      "learning_rate": 6.264705882352942e-05,
      "loss": 1.1705,
      "step": 187000
    },
    {
      "epoch": 0.46875,
      "grad_norm": 0.7834174036979675,
      "learning_rate": 6.25e-05,
      "loss": 1.1713,
      "step": 187500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8611716032028198,
      "learning_rate": 6.23529411764706e-05,
      "loss": 1.1574,
      "step": 188000
    },
    {
      "epoch": 0.47125,
      "grad_norm": 0.7115111947059631,
      "learning_rate": 6.220588235294118e-05,
      "loss": 1.1619,
      "step": 188500
    },
    {
      "epoch": 0.4725,
      "grad_norm": 0.7285589575767517,
      "learning_rate": 6.205882352941177e-05,
      "loss": 1.1639,
      "step": 189000
    },
    {
      "epoch": 0.47375,
      "grad_norm": 0.7426314949989319,
      "learning_rate": 6.191176470588235e-05,
      "loss": 1.1625,
      "step": 189500
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.7736914157867432,
      "learning_rate": 6.176470588235295e-05,
      "loss": 1.1634,
      "step": 190000
    },
    {
      "epoch": 0.47625,
      "grad_norm": 0.8440233469009399,
      "learning_rate": 6.161764705882353e-05,
      "loss": 1.1731,
      "step": 190500
    },
    {
      "epoch": 0.4775,
      "grad_norm": 0.7890370488166809,
      "learning_rate": 6.147058823529413e-05,
      "loss": 1.1629,
      "step": 191000
    },
    {
      "epoch": 0.47875,
      "grad_norm": 0.8508287072181702,
      "learning_rate": 6.132352941176471e-05,
      "loss": 1.164,
      "step": 191500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7951375842094421,
      "learning_rate": 6.11764705882353e-05,
      "loss": 1.1631,
      "step": 192000
    },
    {
      "epoch": 0.48125,
      "grad_norm": 0.7704848647117615,
      "learning_rate": 6.102941176470589e-05,
      "loss": 1.149,
      "step": 192500
    },
    {
      "epoch": 0.4825,
      "grad_norm": 0.8054688572883606,
      "learning_rate": 6.0882352941176465e-05,
      "loss": 1.1595,
      "step": 193000
    },
    {
      "epoch": 0.48375,
      "grad_norm": 0.8035234808921814,
      "learning_rate": 6.073529411764706e-05,
      "loss": 1.1533,
      "step": 193500
    },
    {
      "epoch": 0.485,
      "grad_norm": 0.8733749985694885,
      "learning_rate": 6.058823529411765e-05,
      "loss": 1.1535,
      "step": 194000
    },
    {
      "epoch": 0.48625,
      "grad_norm": 0.747753918170929,
      "learning_rate": 6.044117647058824e-05,
      "loss": 1.1546,
      "step": 194500
    },
    {
      "epoch": 0.4875,
      "grad_norm": 0.8186653852462769,
      "learning_rate": 6.0294117647058825e-05,
      "loss": 1.1619,
      "step": 195000
    },
    {
      "epoch": 0.48875,
      "grad_norm": 0.7450565099716187,
      "learning_rate": 6.014705882352941e-05,
      "loss": 1.1461,
      "step": 195500
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.736038863658905,
      "learning_rate": 6e-05,
      "loss": 1.1472,
      "step": 196000
    },
    {
      "epoch": 0.49125,
      "grad_norm": 0.8951025605201721,
      "learning_rate": 5.985294117647059e-05,
      "loss": 1.1543,
      "step": 196500
    },
    {
      "epoch": 0.4925,
      "grad_norm": 0.8705339431762695,
      "learning_rate": 5.970588235294118e-05,
      "loss": 1.1528,
      "step": 197000
    },
    {
      "epoch": 0.49375,
      "grad_norm": 0.7694308757781982,
      "learning_rate": 5.9558823529411766e-05,
      "loss": 1.1487,
      "step": 197500
    },
    {
      "epoch": 0.495,
      "grad_norm": 0.7667076587677002,
      "learning_rate": 5.9411764705882355e-05,
      "loss": 1.1529,
      "step": 198000
    },
    {
      "epoch": 0.49625,
      "grad_norm": 0.7996194958686829,
      "learning_rate": 5.926470588235294e-05,
      "loss": 1.1544,
      "step": 198500
    },
    {
      "epoch": 0.4975,
      "grad_norm": 0.9102248549461365,
      "learning_rate": 5.911764705882353e-05,
      "loss": 1.1508,
      "step": 199000
    },
    {
      "epoch": 0.49875,
      "grad_norm": 0.753984808921814,
      "learning_rate": 5.897058823529412e-05,
      "loss": 1.1586,
      "step": 199500
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7864643335342407,
      "learning_rate": 5.882352941176471e-05,
      "loss": 1.1505,
      "step": 200000
    },
    {
      "epoch": 0.50125,
      "grad_norm": 0.7667080760002136,
      "learning_rate": 5.86764705882353e-05,
      "loss": 1.1445,
      "step": 200500
    },
    {
      "epoch": 0.5025,
      "grad_norm": 0.8067312240600586,
      "learning_rate": 5.852941176470589e-05,
      "loss": 1.1473,
      "step": 201000
    },
    {
      "epoch": 0.50375,
      "grad_norm": 0.7765271663665771,
      "learning_rate": 5.838235294117648e-05,
      "loss": 1.1532,
      "step": 201500
    },
    {
      "epoch": 0.505,
      "grad_norm": 0.7286154627799988,
      "learning_rate": 5.823529411764707e-05,
      "loss": 1.1446,
      "step": 202000
    },
    {
      "epoch": 0.50625,
      "grad_norm": 0.8057987689971924,
      "learning_rate": 5.8088235294117656e-05,
      "loss": 1.1417,
      "step": 202500
    },
    {
      "epoch": 0.5075,
      "grad_norm": 0.8502460718154907,
      "learning_rate": 5.7941176470588244e-05,
      "loss": 1.157,
      "step": 203000
    },
    {
      "epoch": 0.50875,
      "grad_norm": 0.8622282147407532,
      "learning_rate": 5.779411764705882e-05,
      "loss": 1.1491,
      "step": 203500
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.7909150123596191,
      "learning_rate": 5.764705882352941e-05,
      "loss": 1.1484,
      "step": 204000
    },
    {
      "epoch": 0.51125,
      "grad_norm": 0.886883556842804,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 1.1561,
      "step": 204500
    },
    {
      "epoch": 0.5125,
      "grad_norm": 0.8074644207954407,
      "learning_rate": 5.735294117647059e-05,
      "loss": 1.1549,
      "step": 205000
    },
    {
      "epoch": 0.51375,
      "grad_norm": 0.8264004588127136,
      "learning_rate": 5.720588235294118e-05,
      "loss": 1.1439,
      "step": 205500
    },
    {
      "epoch": 0.515,
      "grad_norm": 0.6528800129890442,
      "learning_rate": 5.7058823529411766e-05,
      "loss": 1.14,
      "step": 206000
    },
    {
      "epoch": 0.51625,
      "grad_norm": 0.836468517780304,
      "learning_rate": 5.6911764705882355e-05,
      "loss": 1.1512,
      "step": 206500
    },
    {
      "epoch": 0.5175,
      "grad_norm": 0.7722639441490173,
      "learning_rate": 5.676470588235294e-05,
      "loss": 1.1442,
      "step": 207000
    },
    {
      "epoch": 0.51875,
      "grad_norm": 0.8699845671653748,
      "learning_rate": 5.661764705882353e-05,
      "loss": 1.143,
      "step": 207500
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.807118833065033,
      "learning_rate": 5.647058823529412e-05,
      "loss": 1.138,
      "step": 208000
    },
    {
      "epoch": 0.52125,
      "grad_norm": 0.8795046806335449,
      "learning_rate": 5.632352941176471e-05,
      "loss": 1.144,
      "step": 208500
    },
    {
      "epoch": 0.5225,
      "grad_norm": 0.8819580078125,
      "learning_rate": 5.6176470588235296e-05,
      "loss": 1.1411,
      "step": 209000
    },
    {
      "epoch": 0.52375,
      "grad_norm": 0.8814345598220825,
      "learning_rate": 5.6029411764705884e-05,
      "loss": 1.1474,
      "step": 209500
    },
    {
      "epoch": 0.525,
      "grad_norm": 0.8002222180366516,
      "learning_rate": 5.588235294117647e-05,
      "loss": 1.1442,
      "step": 210000
    },
    {
      "epoch": 0.52625,
      "grad_norm": 0.8033428192138672,
      "learning_rate": 5.573529411764706e-05,
      "loss": 1.1437,
      "step": 210500
    },
    {
      "epoch": 0.5275,
      "grad_norm": 0.8437348008155823,
      "learning_rate": 5.558823529411765e-05,
      "loss": 1.1441,
      "step": 211000
    },
    {
      "epoch": 0.52875,
      "grad_norm": 0.9386709928512573,
      "learning_rate": 5.5441176470588244e-05,
      "loss": 1.1418,
      "step": 211500
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8330758810043335,
      "learning_rate": 5.529411764705883e-05,
      "loss": 1.1331,
      "step": 212000
    },
    {
      "epoch": 0.53125,
      "grad_norm": 0.8317567110061646,
      "learning_rate": 5.514705882352942e-05,
      "loss": 1.1421,
      "step": 212500
    },
    {
      "epoch": 0.5325,
      "grad_norm": 0.807702362537384,
      "learning_rate": 5.500000000000001e-05,
      "loss": 1.1369,
      "step": 213000
    },
    {
      "epoch": 0.53375,
      "grad_norm": 0.8285407423973083,
      "learning_rate": 5.48529411764706e-05,
      "loss": 1.1402,
      "step": 213500
    },
    {
      "epoch": 0.535,
      "grad_norm": 0.8739692568778992,
      "learning_rate": 5.4705882352941185e-05,
      "loss": 1.136,
      "step": 214000
    },
    {
      "epoch": 0.53625,
      "grad_norm": 0.7825589776039124,
      "learning_rate": 5.455882352941176e-05,
      "loss": 1.1328,
      "step": 214500
    },
    {
      "epoch": 0.5375,
      "grad_norm": 0.7684712409973145,
      "learning_rate": 5.441176470588235e-05,
      "loss": 1.1297,
      "step": 215000
    },
    {
      "epoch": 0.53875,
      "grad_norm": 0.8680952191352844,
      "learning_rate": 5.4264705882352936e-05,
      "loss": 1.1391,
      "step": 215500
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8050139546394348,
      "learning_rate": 5.411764705882353e-05,
      "loss": 1.1367,
      "step": 216000
    },
    {
      "epoch": 0.54125,
      "grad_norm": 0.7827380299568176,
      "learning_rate": 5.397058823529412e-05,
      "loss": 1.1438,
      "step": 216500
    },
    {
      "epoch": 0.5425,
      "grad_norm": 0.7798337936401367,
      "learning_rate": 5.382352941176471e-05,
      "loss": 1.1357,
      "step": 217000
    },
    {
      "epoch": 0.54375,
      "grad_norm": 0.970299243927002,
      "learning_rate": 5.3676470588235296e-05,
      "loss": 1.1373,
      "step": 217500
    },
    {
      "epoch": 0.545,
      "grad_norm": 0.8883040547370911,
      "learning_rate": 5.3529411764705884e-05,
      "loss": 1.1313,
      "step": 218000
    },
    {
      "epoch": 0.54625,
      "grad_norm": 0.7565598487854004,
      "learning_rate": 5.338235294117647e-05,
      "loss": 1.1237,
      "step": 218500
    },
    {
      "epoch": 0.5475,
      "grad_norm": 0.8160844445228577,
      "learning_rate": 5.323529411764706e-05,
      "loss": 1.1325,
      "step": 219000
    },
    {
      "epoch": 0.54875,
      "grad_norm": 0.7732144594192505,
      "learning_rate": 5.308823529411765e-05,
      "loss": 1.1265,
      "step": 219500
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7569660544395447,
      "learning_rate": 5.294117647058824e-05,
      "loss": 1.1288,
      "step": 220000
    },
    {
      "epoch": 0.55125,
      "grad_norm": 0.8200750350952148,
      "learning_rate": 5.2794117647058826e-05,
      "loss": 1.1335,
      "step": 220500
    },
    {
      "epoch": 0.5525,
      "grad_norm": 0.7888165712356567,
      "learning_rate": 5.2647058823529414e-05,
      "loss": 1.131,
      "step": 221000
    },
    {
      "epoch": 0.55375,
      "grad_norm": 0.8177734017372131,
      "learning_rate": 5.25e-05,
      "loss": 1.1389,
      "step": 221500
    },
    {
      "epoch": 0.555,
      "grad_norm": 0.8569052815437317,
      "learning_rate": 5.235294117647059e-05,
      "loss": 1.1287,
      "step": 222000
    },
    {
      "epoch": 0.55625,
      "grad_norm": 0.8093001246452332,
      "learning_rate": 5.2205882352941185e-05,
      "loss": 1.1319,
      "step": 222500
    },
    {
      "epoch": 0.5575,
      "grad_norm": 0.854965329170227,
      "learning_rate": 5.2058823529411774e-05,
      "loss": 1.132,
      "step": 223000
    },
    {
      "epoch": 0.55875,
      "grad_norm": 0.7510936856269836,
      "learning_rate": 5.191176470588236e-05,
      "loss": 1.1236,
      "step": 223500
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.9139103293418884,
      "learning_rate": 5.176470588235295e-05,
      "loss": 1.1352,
      "step": 224000
    },
    {
      "epoch": 0.56125,
      "grad_norm": 0.9147526025772095,
      "learning_rate": 5.161764705882354e-05,
      "loss": 1.1299,
      "step": 224500
    },
    {
      "epoch": 0.5625,
      "grad_norm": 0.7939046621322632,
      "learning_rate": 5.147058823529411e-05,
      "loss": 1.1269,
      "step": 225000
    },
    {
      "epoch": 0.56375,
      "grad_norm": 0.862836480140686,
      "learning_rate": 5.13235294117647e-05,
      "loss": 1.123,
      "step": 225500
    },
    {
      "epoch": 0.565,
      "grad_norm": 0.7759357690811157,
      "learning_rate": 5.117647058823529e-05,
      "loss": 1.1228,
      "step": 226000
    },
    {
      "epoch": 0.56625,
      "grad_norm": 0.8915035128593445,
      "learning_rate": 5.102941176470588e-05,
      "loss": 1.1203,
      "step": 226500
    },
    {
      "epoch": 0.5675,
      "grad_norm": 0.8301019668579102,
      "learning_rate": 5.088235294117647e-05,
      "loss": 1.1224,
      "step": 227000
    },
    {
      "epoch": 0.56875,
      "grad_norm": 0.7725403904914856,
      "learning_rate": 5.073529411764706e-05,
      "loss": 1.1236,
      "step": 227500
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8553059697151184,
      "learning_rate": 5.058823529411765e-05,
      "loss": 1.1265,
      "step": 228000
    },
    {
      "epoch": 0.57125,
      "grad_norm": 0.9505121111869812,
      "learning_rate": 5.044117647058824e-05,
      "loss": 1.1244,
      "step": 228500
    },
    {
      "epoch": 0.5725,
      "grad_norm": 0.8290032744407654,
      "learning_rate": 5.0294117647058826e-05,
      "loss": 1.1216,
      "step": 229000
    },
    {
      "epoch": 0.57375,
      "grad_norm": 0.8893381357192993,
      "learning_rate": 5.0147058823529414e-05,
      "loss": 1.1196,
      "step": 229500
    },
    {
      "epoch": 0.575,
      "grad_norm": 0.8076086640357971,
      "learning_rate": 5e-05,
      "loss": 1.1173,
      "step": 230000
    },
    {
      "epoch": 0.57625,
      "grad_norm": 0.867129385471344,
      "learning_rate": 4.985294117647059e-05,
      "loss": 1.1223,
      "step": 230500
    },
    {
      "epoch": 0.5775,
      "grad_norm": 0.8866677284240723,
      "learning_rate": 4.970588235294118e-05,
      "loss": 1.1193,
      "step": 231000
    },
    {
      "epoch": 0.57875,
      "grad_norm": 0.7992478013038635,
      "learning_rate": 4.955882352941177e-05,
      "loss": 1.125,
      "step": 231500
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8908443450927734,
      "learning_rate": 4.9411764705882355e-05,
      "loss": 1.1211,
      "step": 232000
    },
    {
      "epoch": 0.58125,
      "grad_norm": 0.9244027733802795,
      "learning_rate": 4.9264705882352944e-05,
      "loss": 1.1139,
      "step": 232500
    },
    {
      "epoch": 0.5825,
      "grad_norm": 0.8358755111694336,
      "learning_rate": 4.911764705882353e-05,
      "loss": 1.1322,
      "step": 233000
    },
    {
      "epoch": 0.58375,
      "grad_norm": 0.8106239438056946,
      "learning_rate": 4.897058823529412e-05,
      "loss": 1.1181,
      "step": 233500
    },
    {
      "epoch": 0.585,
      "grad_norm": 0.9506667256355286,
      "learning_rate": 4.882352941176471e-05,
      "loss": 1.1211,
      "step": 234000
    },
    {
      "epoch": 0.58625,
      "grad_norm": 0.7954404950141907,
      "learning_rate": 4.86764705882353e-05,
      "loss": 1.1207,
      "step": 234500
    },
    {
      "epoch": 0.5875,
      "grad_norm": 0.8986244201660156,
      "learning_rate": 4.8529411764705885e-05,
      "loss": 1.1132,
      "step": 235000
    },
    {
      "epoch": 0.58875,
      "grad_norm": 0.9412253499031067,
      "learning_rate": 4.838235294117647e-05,
      "loss": 1.1187,
      "step": 235500
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8888540863990784,
      "learning_rate": 4.823529411764706e-05,
      "loss": 1.1136,
      "step": 236000
    },
    {
      "epoch": 0.59125,
      "grad_norm": 0.8104798197746277,
      "learning_rate": 4.808823529411765e-05,
      "loss": 1.1011,
      "step": 236500
    },
    {
      "epoch": 0.5925,
      "grad_norm": 0.8826358914375305,
      "learning_rate": 4.794117647058824e-05,
      "loss": 1.117,
      "step": 237000
    },
    {
      "epoch": 0.59375,
      "grad_norm": 0.8668436408042908,
      "learning_rate": 4.7794117647058826e-05,
      "loss": 1.1165,
      "step": 237500
    },
    {
      "epoch": 0.595,
      "grad_norm": 0.8030479550361633,
      "learning_rate": 4.7647058823529414e-05,
      "loss": 1.1247,
      "step": 238000
    },
    {
      "epoch": 0.59625,
      "grad_norm": 0.8756508231163025,
      "learning_rate": 4.75e-05,
      "loss": 1.1158,
      "step": 238500
    },
    {
      "epoch": 0.5975,
      "grad_norm": 0.907965362071991,
      "learning_rate": 4.735294117647059e-05,
      "loss": 1.1256,
      "step": 239000
    },
    {
      "epoch": 0.59875,
      "grad_norm": 0.9201554656028748,
      "learning_rate": 4.720588235294118e-05,
      "loss": 1.1011,
      "step": 239500
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.886621356010437,
      "learning_rate": 4.705882352941177e-05,
      "loss": 1.1125,
      "step": 240000
    },
    {
      "epoch": 0.60125,
      "grad_norm": 0.8906792998313904,
      "learning_rate": 4.6911764705882356e-05,
      "loss": 1.1136,
      "step": 240500
    },
    {
      "epoch": 0.6025,
      "grad_norm": 0.8522485494613647,
      "learning_rate": 4.6764705882352944e-05,
      "loss": 1.1114,
      "step": 241000
    },
    {
      "epoch": 0.60375,
      "grad_norm": 0.8635308146476746,
      "learning_rate": 4.661764705882353e-05,
      "loss": 1.1119,
      "step": 241500
    },
    {
      "epoch": 0.605,
      "grad_norm": 0.9829491972923279,
      "learning_rate": 4.647058823529412e-05,
      "loss": 1.1155,
      "step": 242000
    },
    {
      "epoch": 0.60625,
      "grad_norm": 0.8450056314468384,
      "learning_rate": 4.632352941176471e-05,
      "loss": 1.1154,
      "step": 242500
    },
    {
      "epoch": 0.6075,
      "grad_norm": 0.8618903160095215,
      "learning_rate": 4.61764705882353e-05,
      "loss": 1.1155,
      "step": 243000
    },
    {
      "epoch": 0.60875,
      "grad_norm": 0.9201657772064209,
      "learning_rate": 4.6029411764705885e-05,
      "loss": 1.1082,
      "step": 243500
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7758542895317078,
      "learning_rate": 4.588235294117647e-05,
      "loss": 1.1082,
      "step": 244000
    },
    {
      "epoch": 0.61125,
      "grad_norm": 0.8583528995513916,
      "learning_rate": 4.573529411764706e-05,
      "loss": 1.108,
      "step": 244500
    },
    {
      "epoch": 0.6125,
      "grad_norm": 0.8350582122802734,
      "learning_rate": 4.558823529411765e-05,
      "loss": 1.1146,
      "step": 245000
    },
    {
      "epoch": 0.61375,
      "grad_norm": 0.9271150231361389,
      "learning_rate": 4.544117647058824e-05,
      "loss": 1.105,
      "step": 245500
    },
    {
      "epoch": 0.615,
      "grad_norm": 0.8159608244895935,
      "learning_rate": 4.5294117647058826e-05,
      "loss": 1.1051,
      "step": 246000
    },
    {
      "epoch": 0.61625,
      "grad_norm": 0.8587772846221924,
      "learning_rate": 4.5147058823529415e-05,
      "loss": 1.1046,
      "step": 246500
    },
    {
      "epoch": 0.6175,
      "grad_norm": 0.7952526807785034,
      "learning_rate": 4.5e-05,
      "loss": 1.1084,
      "step": 247000
    },
    {
      "epoch": 0.61875,
      "grad_norm": 0.8826681971549988,
      "learning_rate": 4.485294117647059e-05,
      "loss": 1.1126,
      "step": 247500
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8116206526756287,
      "learning_rate": 4.470588235294118e-05,
      "loss": 1.103,
      "step": 248000
    },
    {
      "epoch": 0.62125,
      "grad_norm": 0.9157653450965881,
      "learning_rate": 4.455882352941177e-05,
      "loss": 1.1125,
      "step": 248500
    },
    {
      "epoch": 0.6225,
      "grad_norm": 0.9009856581687927,
      "learning_rate": 4.4411764705882356e-05,
      "loss": 1.0988,
      "step": 249000
    },
    {
      "epoch": 0.62375,
      "grad_norm": 0.8963831663131714,
      "learning_rate": 4.4264705882352944e-05,
      "loss": 1.0987,
      "step": 249500
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.9257298111915588,
      "learning_rate": 4.411764705882353e-05,
      "loss": 1.1055,
      "step": 250000
    },
    {
      "epoch": 0.62625,
      "grad_norm": 0.9106019139289856,
      "learning_rate": 4.397058823529412e-05,
      "loss": 1.1047,
      "step": 250500
    },
    {
      "epoch": 0.6275,
      "grad_norm": 0.9332042932510376,
      "learning_rate": 4.382352941176471e-05,
      "loss": 1.1054,
      "step": 251000
    },
    {
      "epoch": 0.62875,
      "grad_norm": 0.885600209236145,
      "learning_rate": 4.36764705882353e-05,
      "loss": 1.1028,
      "step": 251500
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8547480702400208,
      "learning_rate": 4.3529411764705885e-05,
      "loss": 1.1087,
      "step": 252000
    },
    {
      "epoch": 0.63125,
      "grad_norm": 0.9109575152397156,
      "learning_rate": 4.3382352941176474e-05,
      "loss": 1.1015,
      "step": 252500
    },
    {
      "epoch": 0.6325,
      "grad_norm": 0.8281680941581726,
      "learning_rate": 4.323529411764706e-05,
      "loss": 1.1069,
      "step": 253000
    },
    {
      "epoch": 0.63375,
      "grad_norm": 0.775118350982666,
      "learning_rate": 4.308823529411765e-05,
      "loss": 1.1011,
      "step": 253500
    },
    {
      "epoch": 0.635,
      "grad_norm": 0.979868471622467,
      "learning_rate": 4.294117647058823e-05,
      "loss": 1.0967,
      "step": 254000
    },
    {
      "epoch": 0.63625,
      "grad_norm": 0.8289753198623657,
      "learning_rate": 4.2794117647058827e-05,
      "loss": 1.1092,
      "step": 254500
    },
    {
      "epoch": 0.6375,
      "grad_norm": 0.8649542331695557,
      "learning_rate": 4.2647058823529415e-05,
      "loss": 1.0981,
      "step": 255000
    },
    {
      "epoch": 0.63875,
      "grad_norm": 0.9271538257598877,
      "learning_rate": 4.25e-05,
      "loss": 1.099,
      "step": 255500
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.794394850730896,
      "learning_rate": 4.235294117647059e-05,
      "loss": 1.1056,
      "step": 256000
    },
    {
      "epoch": 0.64125,
      "grad_norm": 0.867863655090332,
      "learning_rate": 4.220588235294118e-05,
      "loss": 1.0961,
      "step": 256500
    },
    {
      "epoch": 0.6425,
      "grad_norm": 0.9847224950790405,
      "learning_rate": 4.205882352941177e-05,
      "loss": 1.1034,
      "step": 257000
    },
    {
      "epoch": 0.64375,
      "grad_norm": 0.9043511748313904,
      "learning_rate": 4.1911764705882356e-05,
      "loss": 1.1006,
      "step": 257500
    },
    {
      "epoch": 0.645,
      "grad_norm": 0.9136033058166504,
      "learning_rate": 4.1764705882352944e-05,
      "loss": 1.1016,
      "step": 258000
    },
    {
      "epoch": 0.64625,
      "grad_norm": 0.9817437529563904,
      "learning_rate": 4.161764705882353e-05,
      "loss": 1.0967,
      "step": 258500
    },
    {
      "epoch": 0.6475,
      "grad_norm": 1.0095624923706055,
      "learning_rate": 4.147058823529412e-05,
      "loss": 1.1021,
      "step": 259000
    },
    {
      "epoch": 0.64875,
      "grad_norm": 0.9843223690986633,
      "learning_rate": 4.13235294117647e-05,
      "loss": 1.1049,
      "step": 259500
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.9274758696556091,
      "learning_rate": 4.11764705882353e-05,
      "loss": 1.0962,
      "step": 260000
    },
    {
      "epoch": 0.65125,
      "grad_norm": 0.8660079836845398,
      "learning_rate": 4.1029411764705886e-05,
      "loss": 1.0946,
      "step": 260500
    },
    {
      "epoch": 0.6525,
      "grad_norm": 0.9117825031280518,
      "learning_rate": 4.0882352941176474e-05,
      "loss": 1.101,
      "step": 261000
    },
    {
      "epoch": 0.65375,
      "grad_norm": 0.9196301102638245,
      "learning_rate": 4.073529411764706e-05,
      "loss": 1.1099,
      "step": 261500
    },
    {
      "epoch": 0.655,
      "grad_norm": 0.9749738574028015,
      "learning_rate": 4.058823529411765e-05,
      "loss": 1.1094,
      "step": 262000
    },
    {
      "epoch": 0.65625,
      "grad_norm": 0.9226157665252686,
      "learning_rate": 4.044117647058824e-05,
      "loss": 1.094,
      "step": 262500
    },
    {
      "epoch": 0.6575,
      "grad_norm": 0.8844392895698547,
      "learning_rate": 4.029411764705883e-05,
      "loss": 1.1025,
      "step": 263000
    },
    {
      "epoch": 0.65875,
      "grad_norm": 0.8565831780433655,
      "learning_rate": 4.0147058823529415e-05,
      "loss": 1.1021,
      "step": 263500
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.8810070753097534,
      "learning_rate": 4e-05,
      "loss": 1.0954,
      "step": 264000
    },
    {
      "epoch": 0.66125,
      "grad_norm": 0.8008565902709961,
      "learning_rate": 3.985294117647059e-05,
      "loss": 1.0938,
      "step": 264500
    },
    {
      "epoch": 0.6625,
      "grad_norm": 0.8963289260864258,
      "learning_rate": 3.970588235294117e-05,
      "loss": 1.1019,
      "step": 265000
    },
    {
      "epoch": 0.66375,
      "grad_norm": 0.8557049632072449,
      "learning_rate": 3.955882352941177e-05,
      "loss": 1.0904,
      "step": 265500
    },
    {
      "epoch": 0.665,
      "grad_norm": 0.9271975755691528,
      "learning_rate": 3.9411764705882356e-05,
      "loss": 1.0997,
      "step": 266000
    },
    {
      "epoch": 0.66625,
      "grad_norm": 0.8731263875961304,
      "learning_rate": 3.9264705882352945e-05,
      "loss": 1.0878,
      "step": 266500
    },
    {
      "epoch": 0.6675,
      "grad_norm": 0.8582344055175781,
      "learning_rate": 3.911764705882353e-05,
      "loss": 1.0886,
      "step": 267000
    },
    {
      "epoch": 0.66875,
      "grad_norm": 0.9234610199928284,
      "learning_rate": 3.897058823529412e-05,
      "loss": 1.0964,
      "step": 267500
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.8996588587760925,
      "learning_rate": 3.882352941176471e-05,
      "loss": 1.0999,
      "step": 268000
    },
    {
      "epoch": 0.67125,
      "grad_norm": 0.8096599578857422,
      "learning_rate": 3.86764705882353e-05,
      "loss": 1.0894,
      "step": 268500
    },
    {
      "epoch": 0.6725,
      "grad_norm": 0.8542688488960266,
      "learning_rate": 3.8529411764705886e-05,
      "loss": 1.0883,
      "step": 269000
    },
    {
      "epoch": 0.67375,
      "grad_norm": 0.8938359022140503,
      "learning_rate": 3.8382352941176474e-05,
      "loss": 1.0931,
      "step": 269500
    },
    {
      "epoch": 0.675,
      "grad_norm": 0.9939298629760742,
      "learning_rate": 3.8235294117647055e-05,
      "loss": 1.0931,
      "step": 270000
    },
    {
      "epoch": 0.67625,
      "grad_norm": 0.9127238392829895,
      "learning_rate": 3.8088235294117644e-05,
      "loss": 1.0896,
      "step": 270500
    },
    {
      "epoch": 0.6775,
      "grad_norm": 0.8296138644218445,
      "learning_rate": 3.794117647058824e-05,
      "loss": 1.1058,
      "step": 271000
    },
    {
      "epoch": 0.67875,
      "grad_norm": 0.9351180791854858,
      "learning_rate": 3.779411764705883e-05,
      "loss": 1.089,
      "step": 271500
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.8701271414756775,
      "learning_rate": 3.7647058823529415e-05,
      "loss": 1.0898,
      "step": 272000
    },
    {
      "epoch": 0.68125,
      "grad_norm": 0.9611274600028992,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.0921,
      "step": 272500
    },
    {
      "epoch": 0.6825,
      "grad_norm": 0.8332632184028625,
      "learning_rate": 3.735294117647059e-05,
      "loss": 1.0869,
      "step": 273000
    },
    {
      "epoch": 0.68375,
      "grad_norm": 0.8896571397781372,
      "learning_rate": 3.720588235294118e-05,
      "loss": 1.0885,
      "step": 273500
    },
    {
      "epoch": 0.685,
      "grad_norm": 0.9265855550765991,
      "learning_rate": 3.705882352941177e-05,
      "loss": 1.1031,
      "step": 274000
    },
    {
      "epoch": 0.68625,
      "grad_norm": 0.9584115147590637,
      "learning_rate": 3.6911764705882356e-05,
      "loss": 1.0891,
      "step": 274500
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.9484722018241882,
      "learning_rate": 3.6764705882352945e-05,
      "loss": 1.092,
      "step": 275000
    },
    {
      "epoch": 0.68875,
      "grad_norm": 0.8569876551628113,
      "learning_rate": 3.6617647058823526e-05,
      "loss": 1.0839,
      "step": 275500
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8531108498573303,
      "learning_rate": 3.6470588235294114e-05,
      "loss": 1.0883,
      "step": 276000
    },
    {
      "epoch": 0.69125,
      "grad_norm": 0.8899979591369629,
      "learning_rate": 3.632352941176471e-05,
      "loss": 1.0918,
      "step": 276500
    },
    {
      "epoch": 0.6925,
      "grad_norm": 0.9103285074234009,
      "learning_rate": 3.61764705882353e-05,
      "loss": 1.0759,
      "step": 277000
    },
    {
      "epoch": 0.69375,
      "grad_norm": 0.7628711462020874,
      "learning_rate": 3.6029411764705886e-05,
      "loss": 1.0914,
      "step": 277500
    },
    {
      "epoch": 0.695,
      "grad_norm": 0.8302034735679626,
      "learning_rate": 3.5882352941176474e-05,
      "loss": 1.0873,
      "step": 278000
    },
    {
      "epoch": 0.69625,
      "grad_norm": 0.8866155743598938,
      "learning_rate": 3.573529411764706e-05,
      "loss": 1.086,
      "step": 278500
    },
    {
      "epoch": 0.6975,
      "grad_norm": 1.0539602041244507,
      "learning_rate": 3.558823529411765e-05,
      "loss": 1.0907,
      "step": 279000
    },
    {
      "epoch": 0.69875,
      "grad_norm": 0.8784270882606506,
      "learning_rate": 3.544117647058824e-05,
      "loss": 1.0881,
      "step": 279500
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9658410549163818,
      "learning_rate": 3.529411764705883e-05,
      "loss": 1.0932,
      "step": 280000
    },
    {
      "epoch": 0.70125,
      "grad_norm": 0.8122528791427612,
      "learning_rate": 3.514705882352941e-05,
      "loss": 1.0953,
      "step": 280500
    },
    {
      "epoch": 0.7025,
      "grad_norm": 1.0572506189346313,
      "learning_rate": 3.5e-05,
      "loss": 1.0871,
      "step": 281000
    },
    {
      "epoch": 0.70375,
      "grad_norm": 0.8535562753677368,
      "learning_rate": 3.4852941176470585e-05,
      "loss": 1.0878,
      "step": 281500
    },
    {
      "epoch": 0.705,
      "grad_norm": 0.8878078460693359,
      "learning_rate": 3.470588235294118e-05,
      "loss": 1.0802,
      "step": 282000
    },
    {
      "epoch": 0.70625,
      "grad_norm": 1.0209842920303345,
      "learning_rate": 3.455882352941177e-05,
      "loss": 1.0773,
      "step": 282500
    },
    {
      "epoch": 0.7075,
      "grad_norm": 0.9169302582740784,
      "learning_rate": 3.441176470588236e-05,
      "loss": 1.0813,
      "step": 283000
    },
    {
      "epoch": 0.70875,
      "grad_norm": 0.8771536946296692,
      "learning_rate": 3.4264705882352945e-05,
      "loss": 1.0906,
      "step": 283500
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8821290135383606,
      "learning_rate": 3.411764705882353e-05,
      "loss": 1.0816,
      "step": 284000
    },
    {
      "epoch": 0.71125,
      "grad_norm": 0.9125442504882812,
      "learning_rate": 3.397058823529412e-05,
      "loss": 1.0833,
      "step": 284500
    },
    {
      "epoch": 0.7125,
      "grad_norm": 0.9469643831253052,
      "learning_rate": 3.382352941176471e-05,
      "loss": 1.0987,
      "step": 285000
    },
    {
      "epoch": 0.71375,
      "grad_norm": 0.8321104645729065,
      "learning_rate": 3.36764705882353e-05,
      "loss": 1.0881,
      "step": 285500
    },
    {
      "epoch": 0.715,
      "grad_norm": 0.8583334684371948,
      "learning_rate": 3.352941176470588e-05,
      "loss": 1.0811,
      "step": 286000
    },
    {
      "epoch": 0.71625,
      "grad_norm": 0.8594087362289429,
      "learning_rate": 3.338235294117647e-05,
      "loss": 1.0794,
      "step": 286500
    },
    {
      "epoch": 0.7175,
      "grad_norm": 0.8587962985038757,
      "learning_rate": 3.3235294117647056e-05,
      "loss": 1.0754,
      "step": 287000
    },
    {
      "epoch": 0.71875,
      "grad_norm": 0.913872480392456,
      "learning_rate": 3.308823529411765e-05,
      "loss": 1.0888,
      "step": 287500
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.8669331073760986,
      "learning_rate": 3.294117647058824e-05,
      "loss": 1.0763,
      "step": 288000
    },
    {
      "epoch": 0.72125,
      "grad_norm": 0.8221537470817566,
      "learning_rate": 3.279411764705883e-05,
      "loss": 1.092,
      "step": 288500
    },
    {
      "epoch": 0.7225,
      "grad_norm": 0.8833361864089966,
      "learning_rate": 3.2647058823529416e-05,
      "loss": 1.0778,
      "step": 289000
    },
    {
      "epoch": 0.72375,
      "grad_norm": 0.909511148929596,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 1.0785,
      "step": 289500
    },
    {
      "epoch": 0.725,
      "grad_norm": 0.9593850374221802,
      "learning_rate": 3.235294117647059e-05,
      "loss": 1.0877,
      "step": 290000
    },
    {
      "epoch": 0.72625,
      "grad_norm": 0.9347679018974304,
      "learning_rate": 3.220588235294118e-05,
      "loss": 1.0811,
      "step": 290500
    },
    {
      "epoch": 0.7275,
      "grad_norm": 0.9263092875480652,
      "learning_rate": 3.205882352941177e-05,
      "loss": 1.0694,
      "step": 291000
    },
    {
      "epoch": 0.72875,
      "grad_norm": 0.8758149147033691,
      "learning_rate": 3.191176470588235e-05,
      "loss": 1.0846,
      "step": 291500
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9030700325965881,
      "learning_rate": 3.176470588235294e-05,
      "loss": 1.0788,
      "step": 292000
    },
    {
      "epoch": 0.73125,
      "grad_norm": 0.8737515211105347,
      "learning_rate": 3.161764705882353e-05,
      "loss": 1.0792,
      "step": 292500
    },
    {
      "epoch": 0.7325,
      "grad_norm": 0.8572671413421631,
      "learning_rate": 3.147058823529412e-05,
      "loss": 1.0838,
      "step": 293000
    },
    {
      "epoch": 0.73375,
      "grad_norm": 0.9469262361526489,
      "learning_rate": 3.132352941176471e-05,
      "loss": 1.0824,
      "step": 293500
    },
    {
      "epoch": 0.735,
      "grad_norm": 0.8927041292190552,
      "learning_rate": 3.11764705882353e-05,
      "loss": 1.0847,
      "step": 294000
    },
    {
      "epoch": 0.73625,
      "grad_norm": 0.8986392021179199,
      "learning_rate": 3.1029411764705886e-05,
      "loss": 1.077,
      "step": 294500
    },
    {
      "epoch": 0.7375,
      "grad_norm": 1.0225828886032104,
      "learning_rate": 3.0882352941176475e-05,
      "loss": 1.0799,
      "step": 295000
    },
    {
      "epoch": 0.73875,
      "grad_norm": 0.9290077090263367,
      "learning_rate": 3.073529411764706e-05,
      "loss": 1.0878,
      "step": 295500
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8696361780166626,
      "learning_rate": 3.058823529411765e-05,
      "loss": 1.0772,
      "step": 296000
    },
    {
      "epoch": 0.74125,
      "grad_norm": 0.9090414047241211,
      "learning_rate": 3.0441176470588233e-05,
      "loss": 1.0822,
      "step": 296500
    },
    {
      "epoch": 0.7425,
      "grad_norm": 0.9896296858787537,
      "learning_rate": 3.0294117647058824e-05,
      "loss": 1.073,
      "step": 297000
    },
    {
      "epoch": 0.74375,
      "grad_norm": 1.017789363861084,
      "learning_rate": 3.0147058823529413e-05,
      "loss": 1.0809,
      "step": 297500
    },
    {
      "epoch": 0.745,
      "grad_norm": 0.9542858600616455,
      "learning_rate": 3e-05,
      "loss": 1.0785,
      "step": 298000
    },
    {
      "epoch": 0.74625,
      "grad_norm": 0.9845845699310303,
      "learning_rate": 2.985294117647059e-05,
      "loss": 1.079,
      "step": 298500
    },
    {
      "epoch": 0.7475,
      "grad_norm": 0.9228905439376831,
      "learning_rate": 2.9705882352941177e-05,
      "loss": 1.0753,
      "step": 299000
    },
    {
      "epoch": 0.74875,
      "grad_norm": 1.644553780555725,
      "learning_rate": 2.9558823529411766e-05,
      "loss": 1.0698,
      "step": 299500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.8670729994773865,
      "learning_rate": 2.9411764705882354e-05,
      "loss": 1.0826,
      "step": 300000
    },
    {
      "epoch": 0.75125,
      "grad_norm": 0.9939693212509155,
      "learning_rate": 2.9264705882352945e-05,
      "loss": 1.0776,
      "step": 300500
    },
    {
      "epoch": 0.7525,
      "grad_norm": 0.9698814749717712,
      "learning_rate": 2.9117647058823534e-05,
      "loss": 1.0733,
      "step": 301000
    },
    {
      "epoch": 0.75375,
      "grad_norm": 0.9245229959487915,
      "learning_rate": 2.8970588235294122e-05,
      "loss": 1.0757,
      "step": 301500
    },
    {
      "epoch": 0.755,
      "grad_norm": 0.9899224638938904,
      "learning_rate": 2.8823529411764703e-05,
      "loss": 1.0783,
      "step": 302000
    },
    {
      "epoch": 0.75625,
      "grad_norm": 0.9983203411102295,
      "learning_rate": 2.8676470588235295e-05,
      "loss": 1.0813,
      "step": 302500
    },
    {
      "epoch": 0.7575,
      "grad_norm": 0.985569417476654,
      "learning_rate": 2.8529411764705883e-05,
      "loss": 1.0811,
      "step": 303000
    },
    {
      "epoch": 0.75875,
      "grad_norm": 0.8523150682449341,
      "learning_rate": 2.838235294117647e-05,
      "loss": 1.0731,
      "step": 303500
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8831020593643188,
      "learning_rate": 2.823529411764706e-05,
      "loss": 1.0763,
      "step": 304000
    },
    {
      "epoch": 0.76125,
      "grad_norm": 0.8914468884468079,
      "learning_rate": 2.8088235294117648e-05,
      "loss": 1.0747,
      "step": 304500
    },
    {
      "epoch": 0.7625,
      "grad_norm": 0.8386173248291016,
      "learning_rate": 2.7941176470588236e-05,
      "loss": 1.0697,
      "step": 305000
    },
    {
      "epoch": 0.76375,
      "grad_norm": 0.910363495349884,
      "learning_rate": 2.7794117647058824e-05,
      "loss": 1.0756,
      "step": 305500
    },
    {
      "epoch": 0.765,
      "grad_norm": 0.9515566825866699,
      "learning_rate": 2.7647058823529416e-05,
      "loss": 1.0693,
      "step": 306000
    },
    {
      "epoch": 0.76625,
      "grad_norm": 0.9043166637420654,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 1.0679,
      "step": 306500
    },
    {
      "epoch": 0.7675,
      "grad_norm": 0.9981286525726318,
      "learning_rate": 2.7352941176470593e-05,
      "loss": 1.0741,
      "step": 307000
    },
    {
      "epoch": 0.76875,
      "grad_norm": 0.8978111147880554,
      "learning_rate": 2.7205882352941174e-05,
      "loss": 1.0759,
      "step": 307500
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.8535884022712708,
      "learning_rate": 2.7058823529411766e-05,
      "loss": 1.0818,
      "step": 308000
    },
    {
      "epoch": 0.77125,
      "grad_norm": 0.9955114126205444,
      "learning_rate": 2.6911764705882354e-05,
      "loss": 1.076,
      "step": 308500
    },
    {
      "epoch": 0.7725,
      "grad_norm": 0.8773077726364136,
      "learning_rate": 2.6764705882352942e-05,
      "loss": 1.0722,
      "step": 309000
    },
    {
      "epoch": 0.77375,
      "grad_norm": 1.001082420349121,
      "learning_rate": 2.661764705882353e-05,
      "loss": 1.073,
      "step": 309500
    },
    {
      "epoch": 0.775,
      "grad_norm": 0.8407207131385803,
      "learning_rate": 2.647058823529412e-05,
      "loss": 1.0781,
      "step": 310000
    },
    {
      "epoch": 0.77625,
      "grad_norm": 1.0977181196212769,
      "learning_rate": 2.6323529411764707e-05,
      "loss": 1.0683,
      "step": 310500
    },
    {
      "epoch": 0.7775,
      "grad_norm": 0.9293188452720642,
      "learning_rate": 2.6176470588235295e-05,
      "loss": 1.076,
      "step": 311000
    },
    {
      "epoch": 0.77875,
      "grad_norm": 0.9452913403511047,
      "learning_rate": 2.6029411764705887e-05,
      "loss": 1.0735,
      "step": 311500
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.9232944846153259,
      "learning_rate": 2.5882352941176475e-05,
      "loss": 1.0684,
      "step": 312000
    },
    {
      "epoch": 0.78125,
      "grad_norm": 0.9419521689414978,
      "learning_rate": 2.5735294117647057e-05,
      "loss": 1.0719,
      "step": 312500
    },
    {
      "epoch": 0.7825,
      "grad_norm": 0.8350271582603455,
      "learning_rate": 2.5588235294117645e-05,
      "loss": 1.0671,
      "step": 313000
    },
    {
      "epoch": 0.78375,
      "grad_norm": 0.8855959177017212,
      "learning_rate": 2.5441176470588236e-05,
      "loss": 1.0715,
      "step": 313500
    },
    {
      "epoch": 0.785,
      "grad_norm": 0.9514048099517822,
      "learning_rate": 2.5294117647058825e-05,
      "loss": 1.0688,
      "step": 314000
    },
    {
      "epoch": 0.78625,
      "grad_norm": 0.9662899374961853,
      "learning_rate": 2.5147058823529413e-05,
      "loss": 1.073,
      "step": 314500
    },
    {
      "epoch": 0.7875,
      "grad_norm": 0.9153221845626831,
      "learning_rate": 2.5e-05,
      "loss": 1.0676,
      "step": 315000
    },
    {
      "epoch": 0.78875,
      "grad_norm": 0.9273921251296997,
      "learning_rate": 2.485294117647059e-05,
      "loss": 1.0662,
      "step": 315500
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.903906524181366,
      "learning_rate": 2.4705882352941178e-05,
      "loss": 1.0644,
      "step": 316000
    },
    {
      "epoch": 0.79125,
      "grad_norm": 1.0449203252792358,
      "learning_rate": 2.4558823529411766e-05,
      "loss": 1.0667,
      "step": 316500
    },
    {
      "epoch": 0.7925,
      "grad_norm": 0.8478853106498718,
      "learning_rate": 2.4411764705882354e-05,
      "loss": 1.0692,
      "step": 317000
    },
    {
      "epoch": 0.79375,
      "grad_norm": 0.8225612640380859,
      "learning_rate": 2.4264705882352942e-05,
      "loss": 1.0634,
      "step": 317500
    },
    {
      "epoch": 0.795,
      "grad_norm": 0.9419565200805664,
      "learning_rate": 2.411764705882353e-05,
      "loss": 1.0715,
      "step": 318000
    },
    {
      "epoch": 0.79625,
      "grad_norm": 0.8826260566711426,
      "learning_rate": 2.397058823529412e-05,
      "loss": 1.077,
      "step": 318500
    },
    {
      "epoch": 0.7975,
      "grad_norm": 0.9794453382492065,
      "learning_rate": 2.3823529411764707e-05,
      "loss": 1.0639,
      "step": 319000
    },
    {
      "epoch": 0.79875,
      "grad_norm": 1.0798388719558716,
      "learning_rate": 2.3676470588235295e-05,
      "loss": 1.0659,
      "step": 319500
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.9557994604110718,
      "learning_rate": 2.3529411764705884e-05,
      "loss": 1.0676,
      "step": 320000
    },
    {
      "epoch": 0.80125,
      "grad_norm": 0.888164758682251,
      "learning_rate": 2.3382352941176472e-05,
      "loss": 1.077,
      "step": 320500
    },
    {
      "epoch": 0.8025,
      "grad_norm": 1.0803172588348389,
      "learning_rate": 2.323529411764706e-05,
      "loss": 1.0701,
      "step": 321000
    },
    {
      "epoch": 0.80375,
      "grad_norm": 0.9739827513694763,
      "learning_rate": 2.308823529411765e-05,
      "loss": 1.0674,
      "step": 321500
    },
    {
      "epoch": 0.805,
      "grad_norm": 1.0623798370361328,
      "learning_rate": 2.2941176470588237e-05,
      "loss": 1.0671,
      "step": 322000
    },
    {
      "epoch": 0.80625,
      "grad_norm": 0.9261273145675659,
      "learning_rate": 2.2794117647058825e-05,
      "loss": 1.063,
      "step": 322500
    },
    {
      "epoch": 0.8075,
      "grad_norm": 0.9636663198471069,
      "learning_rate": 2.2647058823529413e-05,
      "loss": 1.0625,
      "step": 323000
    },
    {
      "epoch": 0.80875,
      "grad_norm": 1.0465730428695679,
      "learning_rate": 2.25e-05,
      "loss": 1.0637,
      "step": 323500
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.01650071144104,
      "learning_rate": 2.235294117647059e-05,
      "loss": 1.0636,
      "step": 324000
    },
    {
      "epoch": 0.81125,
      "grad_norm": 0.9603028297424316,
      "learning_rate": 2.2205882352941178e-05,
      "loss": 1.0671,
      "step": 324500
    },
    {
      "epoch": 0.8125,
      "grad_norm": 1.0081984996795654,
      "learning_rate": 2.2058823529411766e-05,
      "loss": 1.0708,
      "step": 325000
    },
    {
      "epoch": 0.81375,
      "grad_norm": 0.9882996082305908,
      "learning_rate": 2.1911764705882354e-05,
      "loss": 1.0663,
      "step": 325500
    },
    {
      "epoch": 0.815,
      "grad_norm": 0.9162032008171082,
      "learning_rate": 2.1764705882352943e-05,
      "loss": 1.0553,
      "step": 326000
    },
    {
      "epoch": 0.81625,
      "grad_norm": 0.8627511858940125,
      "learning_rate": 2.161764705882353e-05,
      "loss": 1.0583,
      "step": 326500
    },
    {
      "epoch": 0.8175,
      "grad_norm": 0.8820652961730957,
      "learning_rate": 2.1470588235294116e-05,
      "loss": 1.0691,
      "step": 327000
    },
    {
      "epoch": 0.81875,
      "grad_norm": 0.8384200930595398,
      "learning_rate": 2.1323529411764707e-05,
      "loss": 1.0637,
      "step": 327500
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.8952100872993469,
      "learning_rate": 2.1176470588235296e-05,
      "loss": 1.0675,
      "step": 328000
    },
    {
      "epoch": 0.82125,
      "grad_norm": 0.9172313809394836,
      "learning_rate": 2.1029411764705884e-05,
      "loss": 1.0534,
      "step": 328500
    },
    {
      "epoch": 0.8225,
      "grad_norm": 0.9412811398506165,
      "learning_rate": 2.0882352941176472e-05,
      "loss": 1.0637,
      "step": 329000
    },
    {
      "epoch": 0.82375,
      "grad_norm": 0.8874025344848633,
      "learning_rate": 2.073529411764706e-05,
      "loss": 1.0607,
      "step": 329500
    },
    {
      "epoch": 0.825,
      "grad_norm": 0.9280862808227539,
      "learning_rate": 2.058823529411765e-05,
      "loss": 1.0576,
      "step": 330000
    },
    {
      "epoch": 0.82625,
      "grad_norm": 0.8921778798103333,
      "learning_rate": 2.0441176470588237e-05,
      "loss": 1.0656,
      "step": 330500
    },
    {
      "epoch": 0.8275,
      "grad_norm": 0.9561966061592102,
      "learning_rate": 2.0294117647058825e-05,
      "loss": 1.0657,
      "step": 331000
    },
    {
      "epoch": 0.82875,
      "grad_norm": 0.9655880928039551,
      "learning_rate": 2.0147058823529413e-05,
      "loss": 1.0609,
      "step": 331500
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.0119332075119019,
      "learning_rate": 2e-05,
      "loss": 1.0733,
      "step": 332000
    },
    {
      "epoch": 0.83125,
      "grad_norm": 0.912475049495697,
      "learning_rate": 1.9852941176470586e-05,
      "loss": 1.0686,
      "step": 332500
    },
    {
      "epoch": 0.8325,
      "grad_norm": 1.066818118095398,
      "learning_rate": 1.9705882352941178e-05,
      "loss": 1.0609,
      "step": 333000
    },
    {
      "epoch": 0.83375,
      "grad_norm": 0.9043962955474854,
      "learning_rate": 1.9558823529411766e-05,
      "loss": 1.066,
      "step": 333500
    },
    {
      "epoch": 0.835,
      "grad_norm": 1.0095255374908447,
      "learning_rate": 1.9411764705882355e-05,
      "loss": 1.0683,
      "step": 334000
    },
    {
      "epoch": 0.83625,
      "grad_norm": 0.9313106536865234,
      "learning_rate": 1.9264705882352943e-05,
      "loss": 1.0612,
      "step": 334500
    },
    {
      "epoch": 0.8375,
      "grad_norm": 0.947770893573761,
      "learning_rate": 1.9117647058823528e-05,
      "loss": 1.0603,
      "step": 335000
    },
    {
      "epoch": 0.83875,
      "grad_norm": 0.9790318012237549,
      "learning_rate": 1.897058823529412e-05,
      "loss": 1.0616,
      "step": 335500
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9714659452438354,
      "learning_rate": 1.8823529411764708e-05,
      "loss": 1.0645,
      "step": 336000
    },
    {
      "epoch": 0.84125,
      "grad_norm": 0.9714359641075134,
      "learning_rate": 1.8676470588235296e-05,
      "loss": 1.0667,
      "step": 336500
    },
    {
      "epoch": 0.8425,
      "grad_norm": 0.9894239902496338,
      "learning_rate": 1.8529411764705884e-05,
      "loss": 1.064,
      "step": 337000
    },
    {
      "epoch": 0.84375,
      "grad_norm": 0.8606913685798645,
      "learning_rate": 1.8382352941176472e-05,
      "loss": 1.055,
      "step": 337500
    },
    {
      "epoch": 0.845,
      "grad_norm": 0.9669888615608215,
      "learning_rate": 1.8235294117647057e-05,
      "loss": 1.0637,
      "step": 338000
    },
    {
      "epoch": 0.84625,
      "grad_norm": 0.9103085398674011,
      "learning_rate": 1.808823529411765e-05,
      "loss": 1.0602,
      "step": 338500
    },
    {
      "epoch": 0.8475,
      "grad_norm": 0.8847541213035583,
      "learning_rate": 1.7941176470588237e-05,
      "loss": 1.0561,
      "step": 339000
    },
    {
      "epoch": 0.84875,
      "grad_norm": 0.9425493478775024,
      "learning_rate": 1.7794117647058825e-05,
      "loss": 1.0565,
      "step": 339500
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.0275906324386597,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 1.0587,
      "step": 340000
    },
    {
      "epoch": 0.85125,
      "grad_norm": 0.9083384275436401,
      "learning_rate": 1.75e-05,
      "loss": 1.0589,
      "step": 340500
    },
    {
      "epoch": 0.8525,
      "grad_norm": 0.9292646646499634,
      "learning_rate": 1.735294117647059e-05,
      "loss": 1.0575,
      "step": 341000
    },
    {
      "epoch": 0.85375,
      "grad_norm": 0.9678083658218384,
      "learning_rate": 1.720588235294118e-05,
      "loss": 1.0569,
      "step": 341500
    },
    {
      "epoch": 0.855,
      "grad_norm": 0.9966362118721008,
      "learning_rate": 1.7058823529411767e-05,
      "loss": 1.053,
      "step": 342000
    },
    {
      "epoch": 0.85625,
      "grad_norm": 0.8389337062835693,
      "learning_rate": 1.6911764705882355e-05,
      "loss": 1.0578,
      "step": 342500
    },
    {
      "epoch": 0.8575,
      "grad_norm": 0.923226535320282,
      "learning_rate": 1.676470588235294e-05,
      "loss": 1.0625,
      "step": 343000
    },
    {
      "epoch": 0.85875,
      "grad_norm": 0.9495370984077454,
      "learning_rate": 1.6617647058823528e-05,
      "loss": 1.0587,
      "step": 343500
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.9023343324661255,
      "learning_rate": 1.647058823529412e-05,
      "loss": 1.0512,
      "step": 344000
    },
    {
      "epoch": 0.86125,
      "grad_norm": 0.9169178605079651,
      "learning_rate": 1.6323529411764708e-05,
      "loss": 1.059,
      "step": 344500
    },
    {
      "epoch": 0.8625,
      "grad_norm": 0.9974145889282227,
      "learning_rate": 1.6176470588235296e-05,
      "loss": 1.0589,
      "step": 345000
    },
    {
      "epoch": 0.86375,
      "grad_norm": 1.016916036605835,
      "learning_rate": 1.6029411764705884e-05,
      "loss": 1.0578,
      "step": 345500
    },
    {
      "epoch": 0.865,
      "grad_norm": 0.8868731260299683,
      "learning_rate": 1.588235294117647e-05,
      "loss": 1.0586,
      "step": 346000
    },
    {
      "epoch": 0.86625,
      "grad_norm": 0.9810419678688049,
      "learning_rate": 1.573529411764706e-05,
      "loss": 1.0692,
      "step": 346500
    },
    {
      "epoch": 0.8675,
      "grad_norm": 1.0216878652572632,
      "learning_rate": 1.558823529411765e-05,
      "loss": 1.053,
      "step": 347000
    },
    {
      "epoch": 0.86875,
      "grad_norm": 0.807556688785553,
      "learning_rate": 1.5441176470588237e-05,
      "loss": 1.0639,
      "step": 347500
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.9636844396591187,
      "learning_rate": 1.5294117647058826e-05,
      "loss": 1.0586,
      "step": 348000
    },
    {
      "epoch": 0.87125,
      "grad_norm": 0.9242932796478271,
      "learning_rate": 1.5147058823529412e-05,
      "loss": 1.0597,
      "step": 348500
    },
    {
      "epoch": 0.8725,
      "grad_norm": 0.9801921844482422,
      "learning_rate": 1.5e-05,
      "loss": 1.0586,
      "step": 349000
    },
    {
      "epoch": 0.87375,
      "grad_norm": 0.990183413028717,
      "learning_rate": 1.4852941176470589e-05,
      "loss": 1.0623,
      "step": 349500
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.0204252004623413,
      "learning_rate": 1.4705882352941177e-05,
      "loss": 1.0572,
      "step": 350000
    },
    {
      "epoch": 0.87625,
      "grad_norm": 0.9813087582588196,
      "learning_rate": 1.4558823529411767e-05,
      "loss": 1.0583,
      "step": 350500
    },
    {
      "epoch": 0.8775,
      "grad_norm": 1.0292314291000366,
      "learning_rate": 1.4411764705882352e-05,
      "loss": 1.0582,
      "step": 351000
    },
    {
      "epoch": 0.87875,
      "grad_norm": 0.9314088225364685,
      "learning_rate": 1.4264705882352942e-05,
      "loss": 1.0542,
      "step": 351500
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.9838250875473022,
      "learning_rate": 1.411764705882353e-05,
      "loss": 1.0595,
      "step": 352000
    },
    {
      "epoch": 0.88125,
      "grad_norm": 0.9702385067939758,
      "learning_rate": 1.3970588235294118e-05,
      "loss": 1.0554,
      "step": 352500
    },
    {
      "epoch": 0.8825,
      "grad_norm": 0.863006591796875,
      "learning_rate": 1.3823529411764708e-05,
      "loss": 1.0597,
      "step": 353000
    },
    {
      "epoch": 0.88375,
      "grad_norm": 0.8656606078147888,
      "learning_rate": 1.3676470588235296e-05,
      "loss": 1.057,
      "step": 353500
    },
    {
      "epoch": 0.885,
      "grad_norm": 0.966298520565033,
      "learning_rate": 1.3529411764705883e-05,
      "loss": 1.0581,
      "step": 354000
    },
    {
      "epoch": 0.88625,
      "grad_norm": 0.89706951379776,
      "learning_rate": 1.3382352941176471e-05,
      "loss": 1.0601,
      "step": 354500
    },
    {
      "epoch": 0.8875,
      "grad_norm": 1.0724908113479614,
      "learning_rate": 1.323529411764706e-05,
      "loss": 1.0625,
      "step": 355000
    },
    {
      "epoch": 0.88875,
      "grad_norm": 0.8274827599525452,
      "learning_rate": 1.3088235294117648e-05,
      "loss": 1.0538,
      "step": 355500
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.9851537942886353,
      "learning_rate": 1.2941176470588238e-05,
      "loss": 1.066,
      "step": 356000
    },
    {
      "epoch": 0.89125,
      "grad_norm": 0.9733806252479553,
      "learning_rate": 1.2794117647058822e-05,
      "loss": 1.0606,
      "step": 356500
    },
    {
      "epoch": 0.8925,
      "grad_norm": 0.9649959802627563,
      "learning_rate": 1.2647058823529412e-05,
      "loss": 1.0545,
      "step": 357000
    },
    {
      "epoch": 0.89375,
      "grad_norm": 0.9336249828338623,
      "learning_rate": 1.25e-05,
      "loss": 1.0578,
      "step": 357500
    },
    {
      "epoch": 0.895,
      "grad_norm": 0.9141954779624939,
      "learning_rate": 1.2352941176470589e-05,
      "loss": 1.0537,
      "step": 358000
    },
    {
      "epoch": 0.89625,
      "grad_norm": 1.0180621147155762,
      "learning_rate": 1.2205882352941177e-05,
      "loss": 1.0467,
      "step": 358500
    },
    {
      "epoch": 0.8975,
      "grad_norm": 0.9459463953971863,
      "learning_rate": 1.2058823529411765e-05,
      "loss": 1.0499,
      "step": 359000
    },
    {
      "epoch": 0.89875,
      "grad_norm": 0.9324408173561096,
      "learning_rate": 1.1911764705882354e-05,
      "loss": 1.0545,
      "step": 359500
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.0473101139068604,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 1.053,
      "step": 360000
    },
    {
      "epoch": 0.90125,
      "grad_norm": 0.9950019121170044,
      "learning_rate": 1.161764705882353e-05,
      "loss": 1.0561,
      "step": 360500
    },
    {
      "epoch": 0.9025,
      "grad_norm": 0.881533682346344,
      "learning_rate": 1.1470588235294118e-05,
      "loss": 1.0524,
      "step": 361000
    },
    {
      "epoch": 0.90375,
      "grad_norm": 0.9780207872390747,
      "learning_rate": 1.1323529411764707e-05,
      "loss": 1.0538,
      "step": 361500
    },
    {
      "epoch": 0.905,
      "grad_norm": 1.0412421226501465,
      "learning_rate": 1.1176470588235295e-05,
      "loss": 1.0483,
      "step": 362000
    },
    {
      "epoch": 0.90625,
      "grad_norm": 0.9245169758796692,
      "learning_rate": 1.1029411764705883e-05,
      "loss": 1.059,
      "step": 362500
    },
    {
      "epoch": 0.9075,
      "grad_norm": 1.0000622272491455,
      "learning_rate": 1.0882352941176471e-05,
      "loss": 1.0576,
      "step": 363000
    },
    {
      "epoch": 0.90875,
      "grad_norm": 1.028679370880127,
      "learning_rate": 1.0735294117647058e-05,
      "loss": 1.0534,
      "step": 363500
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.0715056657791138,
      "learning_rate": 1.0588235294117648e-05,
      "loss": 1.0465,
      "step": 364000
    },
    {
      "epoch": 0.91125,
      "grad_norm": 0.8893612623214722,
      "learning_rate": 1.0441176470588236e-05,
      "loss": 1.0529,
      "step": 364500
    },
    {
      "epoch": 0.9125,
      "grad_norm": 0.9358640909194946,
      "learning_rate": 1.0294117647058824e-05,
      "loss": 1.0528,
      "step": 365000
    },
    {
      "epoch": 0.91375,
      "grad_norm": 1.0659288167953491,
      "learning_rate": 1.0147058823529413e-05,
      "loss": 1.0523,
      "step": 365500
    },
    {
      "epoch": 0.915,
      "grad_norm": 1.0289887189865112,
      "learning_rate": 1e-05,
      "loss": 1.0554,
      "step": 366000
    },
    {
      "epoch": 0.91625,
      "grad_norm": 0.9449515342712402,
      "learning_rate": 9.852941176470589e-06,
      "loss": 1.0569,
      "step": 366500
    },
    {
      "epoch": 0.9175,
      "grad_norm": 1.011973261833191,
      "learning_rate": 9.705882352941177e-06,
      "loss": 1.0507,
      "step": 367000
    },
    {
      "epoch": 0.91875,
      "grad_norm": 0.993446409702301,
      "learning_rate": 9.558823529411764e-06,
      "loss": 1.0519,
      "step": 367500
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8504928350448608,
      "learning_rate": 9.411764705882354e-06,
      "loss": 1.0539,
      "step": 368000
    },
    {
      "epoch": 0.92125,
      "grad_norm": 1.0076106786727905,
      "learning_rate": 9.264705882352942e-06,
      "loss": 1.054,
      "step": 368500
    },
    {
      "epoch": 0.9225,
      "grad_norm": 0.8891541361808777,
      "learning_rate": 9.117647058823529e-06,
      "loss": 1.0506,
      "step": 369000
    },
    {
      "epoch": 0.92375,
      "grad_norm": 0.9270692467689514,
      "learning_rate": 8.970588235294119e-06,
      "loss": 1.0533,
      "step": 369500
    },
    {
      "epoch": 0.925,
      "grad_norm": 0.9166755080223083,
      "learning_rate": 8.823529411764707e-06,
      "loss": 1.0497,
      "step": 370000
    },
    {
      "epoch": 0.92625,
      "grad_norm": 1.002041220664978,
      "learning_rate": 8.676470588235295e-06,
      "loss": 1.0479,
      "step": 370500
    },
    {
      "epoch": 0.9275,
      "grad_norm": 0.8432400822639465,
      "learning_rate": 8.529411764705883e-06,
      "loss": 1.0534,
      "step": 371000
    },
    {
      "epoch": 0.92875,
      "grad_norm": 0.8407866358757019,
      "learning_rate": 8.38235294117647e-06,
      "loss": 1.0502,
      "step": 371500
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.982756495475769,
      "learning_rate": 8.23529411764706e-06,
      "loss": 1.0542,
      "step": 372000
    },
    {
      "epoch": 0.93125,
      "grad_norm": 0.9180310368537903,
      "learning_rate": 8.088235294117648e-06,
      "loss": 1.0572,
      "step": 372500
    },
    {
      "epoch": 0.9325,
      "grad_norm": 0.9519780278205872,
      "learning_rate": 7.941176470588235e-06,
      "loss": 1.0525,
      "step": 373000
    },
    {
      "epoch": 0.93375,
      "grad_norm": 0.9038566946983337,
      "learning_rate": 7.794117647058825e-06,
      "loss": 1.0433,
      "step": 373500
    },
    {
      "epoch": 0.935,
      "grad_norm": 0.9205678701400757,
      "learning_rate": 7.647058823529413e-06,
      "loss": 1.0541,
      "step": 374000
    },
    {
      "epoch": 0.93625,
      "grad_norm": 1.0369104146957397,
      "learning_rate": 7.5e-06,
      "loss": 1.0513,
      "step": 374500
    },
    {
      "epoch": 0.9375,
      "grad_norm": 0.9149197340011597,
      "learning_rate": 7.3529411764705884e-06,
      "loss": 1.0545,
      "step": 375000
    },
    {
      "epoch": 0.93875,
      "grad_norm": 1.0114521980285645,
      "learning_rate": 7.205882352941176e-06,
      "loss": 1.0419,
      "step": 375500
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.9859254360198975,
      "learning_rate": 7.058823529411765e-06,
      "loss": 1.0507,
      "step": 376000
    },
    {
      "epoch": 0.94125,
      "grad_norm": 0.9999420642852783,
      "learning_rate": 6.911764705882354e-06,
      "loss": 1.0557,
      "step": 376500
    },
    {
      "epoch": 0.9425,
      "grad_norm": 0.9057645201683044,
      "learning_rate": 6.7647058823529414e-06,
      "loss": 1.0528,
      "step": 377000
    },
    {
      "epoch": 0.94375,
      "grad_norm": 0.9507510662078857,
      "learning_rate": 6.61764705882353e-06,
      "loss": 1.0538,
      "step": 377500
    },
    {
      "epoch": 0.945,
      "grad_norm": 0.9592535495758057,
      "learning_rate": 6.470588235294119e-06,
      "loss": 1.0528,
      "step": 378000
    },
    {
      "epoch": 0.94625,
      "grad_norm": 1.0256582498550415,
      "learning_rate": 6.323529411764706e-06,
      "loss": 1.0545,
      "step": 378500
    },
    {
      "epoch": 0.9475,
      "grad_norm": 0.922775149345398,
      "learning_rate": 6.1764705882352944e-06,
      "loss": 1.055,
      "step": 379000
    },
    {
      "epoch": 0.94875,
      "grad_norm": 0.9330239295959473,
      "learning_rate": 6.029411764705883e-06,
      "loss": 1.0528,
      "step": 379500
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.010904312133789,
      "learning_rate": 5.882352941176471e-06,
      "loss": 1.0462,
      "step": 380000
    },
    {
      "epoch": 0.95125,
      "grad_norm": 0.9113101363182068,
      "learning_rate": 5.735294117647059e-06,
      "loss": 1.0564,
      "step": 380500
    },
    {
      "epoch": 0.9525,
      "grad_norm": 0.7605059146881104,
      "learning_rate": 5.588235294117647e-06,
      "loss": 1.0525,
      "step": 381000
    },
    {
      "epoch": 0.95375,
      "grad_norm": 0.9558447599411011,
      "learning_rate": 5.441176470588236e-06,
      "loss": 1.05,
      "step": 381500
    },
    {
      "epoch": 0.955,
      "grad_norm": 0.9095848202705383,
      "learning_rate": 5.294117647058824e-06,
      "loss": 1.0532,
      "step": 382000
    },
    {
      "epoch": 0.95625,
      "grad_norm": 0.9260687828063965,
      "learning_rate": 5.147058823529412e-06,
      "loss": 1.0496,
      "step": 382500
    },
    {
      "epoch": 0.9575,
      "grad_norm": 0.9289600253105164,
      "learning_rate": 5e-06,
      "loss": 1.0503,
      "step": 383000
    },
    {
      "epoch": 0.95875,
      "grad_norm": 0.9302130341529846,
      "learning_rate": 4.852941176470589e-06,
      "loss": 1.0489,
      "step": 383500
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9720468521118164,
      "learning_rate": 4.705882352941177e-06,
      "loss": 1.0505,
      "step": 384000
    },
    {
      "epoch": 0.96125,
      "grad_norm": 0.9530165791511536,
      "learning_rate": 4.558823529411764e-06,
      "loss": 1.0529,
      "step": 384500
    },
    {
      "epoch": 0.9625,
      "grad_norm": 0.937650203704834,
      "learning_rate": 4.411764705882353e-06,
      "loss": 1.0479,
      "step": 385000
    },
    {
      "epoch": 0.96375,
      "grad_norm": 0.9903994798660278,
      "learning_rate": 4.264705882352942e-06,
      "loss": 1.0574,
      "step": 385500
    },
    {
      "epoch": 0.965,
      "grad_norm": 0.8703513145446777,
      "learning_rate": 4.11764705882353e-06,
      "loss": 1.0547,
      "step": 386000
    },
    {
      "epoch": 0.96625,
      "grad_norm": 0.9618780612945557,
      "learning_rate": 3.970588235294117e-06,
      "loss": 1.0512,
      "step": 386500
    },
    {
      "epoch": 0.9675,
      "grad_norm": 0.9382399916648865,
      "learning_rate": 3.823529411764706e-06,
      "loss": 1.0502,
      "step": 387000
    },
    {
      "epoch": 0.96875,
      "grad_norm": 0.9891356229782104,
      "learning_rate": 3.6764705882352942e-06,
      "loss": 1.0533,
      "step": 387500
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.2453527450561523,
      "learning_rate": 3.5294117647058825e-06,
      "loss": 1.0447,
      "step": 388000
    },
    {
      "epoch": 0.97125,
      "grad_norm": 1.0773837566375732,
      "learning_rate": 3.3823529411764707e-06,
      "loss": 1.0537,
      "step": 388500
    },
    {
      "epoch": 0.9725,
      "grad_norm": 0.9791383743286133,
      "learning_rate": 3.2352941176470594e-06,
      "loss": 1.0495,
      "step": 389000
    },
    {
      "epoch": 0.97375,
      "grad_norm": 0.9661936163902283,
      "learning_rate": 3.0882352941176472e-06,
      "loss": 1.0472,
      "step": 389500
    },
    {
      "epoch": 0.975,
      "grad_norm": 1.058257818222046,
      "learning_rate": 2.9411764705882355e-06,
      "loss": 1.048,
      "step": 390000
    },
    {
      "epoch": 0.97625,
      "grad_norm": 0.8803148865699768,
      "learning_rate": 2.7941176470588237e-06,
      "loss": 1.0406,
      "step": 390500
    },
    {
      "epoch": 0.9775,
      "grad_norm": 0.9165066480636597,
      "learning_rate": 2.647058823529412e-06,
      "loss": 1.0497,
      "step": 391000
    },
    {
      "epoch": 0.97875,
      "grad_norm": 0.9852697253227234,
      "learning_rate": 2.5e-06,
      "loss": 1.0437,
      "step": 391500
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.9023734331130981,
      "learning_rate": 2.3529411764705885e-06,
      "loss": 1.0471,
      "step": 392000
    },
    {
      "epoch": 0.98125,
      "grad_norm": 0.9228295087814331,
      "learning_rate": 2.2058823529411767e-06,
      "loss": 1.0436,
      "step": 392500
    },
    {
      "epoch": 0.9825,
      "grad_norm": 0.8152249455451965,
      "learning_rate": 2.058823529411765e-06,
      "loss": 1.0487,
      "step": 393000
    },
    {
      "epoch": 0.98375,
      "grad_norm": 0.9838380217552185,
      "learning_rate": 1.911764705882353e-06,
      "loss": 1.0521,
      "step": 393500
    },
    {
      "epoch": 0.985,
      "grad_norm": 0.9510999917984009,
      "learning_rate": 1.7647058823529412e-06,
      "loss": 1.0444,
      "step": 394000
    },
    {
      "epoch": 0.98625,
      "grad_norm": 1.052035927772522,
      "learning_rate": 1.6176470588235297e-06,
      "loss": 1.0467,
      "step": 394500
    },
    {
      "epoch": 0.9875,
      "grad_norm": 0.9552780389785767,
      "learning_rate": 1.4705882352941177e-06,
      "loss": 1.0508,
      "step": 395000
    },
    {
      "epoch": 0.98875,
      "grad_norm": 1.0191222429275513,
      "learning_rate": 1.323529411764706e-06,
      "loss": 1.0555,
      "step": 395500
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.9563516974449158,
      "learning_rate": 1.1764705882352942e-06,
      "loss": 1.0567,
      "step": 396000
    },
    {
      "epoch": 0.99125,
      "grad_norm": 0.8916611671447754,
      "learning_rate": 1.0294117647058825e-06,
      "loss": 1.0433,
      "step": 396500
    },
    {
      "epoch": 0.9925,
      "grad_norm": 0.9412599205970764,
      "learning_rate": 8.823529411764706e-07,
      "loss": 1.047,
      "step": 397000
    },
    {
      "epoch": 0.99375,
      "grad_norm": 0.8824490904808044,
      "learning_rate": 7.352941176470589e-07,
      "loss": 1.048,
      "step": 397500
    },
    {
      "epoch": 0.995,
      "grad_norm": 1.1002321243286133,
      "learning_rate": 5.882352941176471e-07,
      "loss": 1.0429,
      "step": 398000
    },
    {
      "epoch": 0.99625,
      "grad_norm": 0.9863912463188171,
      "learning_rate": 4.411764705882353e-07,
      "loss": 1.0477,
      "step": 398500
    },
    {
      "epoch": 0.9975,
      "grad_norm": 0.9374304413795471,
      "learning_rate": 2.9411764705882356e-07,
      "loss": 1.0527,
      "step": 399000
    },
    {
      "epoch": 0.99875,
      "grad_norm": 0.9416661858558655,
      "learning_rate": 1.4705882352941178e-07,
      "loss": 1.0516,
      "step": 399500
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.9254446625709534,
      "learning_rate": 0.0,
      "loss": 1.0425,
      "step": 400000
    }
  ],
  "logging_steps": 500,
  "max_steps": 400000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.4715172077568e+18,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
