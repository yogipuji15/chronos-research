{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.75,
  "eval_steps": 500,
  "global_step": 300000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00125,
      "grad_norm": 0.3965936005115509,
      "learning_rate": 8.333333333333333e-07,
      "loss": 1.8391,
      "step": 500
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.3080460727214813,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 1.8441,
      "step": 1000
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.305588036775589,
      "learning_rate": 2.5e-06,
      "loss": 1.8271,
      "step": 1500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.285957932472229,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 1.8135,
      "step": 2000
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.29649654030799866,
      "learning_rate": 4.166666666666667e-06,
      "loss": 1.8292,
      "step": 2500
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.32879841327667236,
      "learning_rate": 5e-06,
      "loss": 1.8227,
      "step": 3000
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.2655847668647766,
      "learning_rate": 5.833333333333334e-06,
      "loss": 1.8157,
      "step": 3500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.277055948972702,
      "learning_rate": 6.666666666666667e-06,
      "loss": 1.8167,
      "step": 4000
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.24110299348831177,
      "learning_rate": 7.5e-06,
      "loss": 1.803,
      "step": 4500
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.3010740578174591,
      "learning_rate": 8.333333333333334e-06,
      "loss": 1.8181,
      "step": 5000
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.28713274002075195,
      "learning_rate": 9.166666666666666e-06,
      "loss": 1.8105,
      "step": 5500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.2596791982650757,
      "learning_rate": 1e-05,
      "loss": 1.8092,
      "step": 6000
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.3304290771484375,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 1.8024,
      "step": 6500
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.2913386821746826,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 1.8009,
      "step": 7000
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.2325076311826706,
      "learning_rate": 1.25e-05,
      "loss": 1.7951,
      "step": 7500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.29610252380371094,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 1.7964,
      "step": 8000
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.2960455119609833,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 1.7942,
      "step": 8500
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.2669047713279724,
      "learning_rate": 1.5e-05,
      "loss": 1.8008,
      "step": 9000
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.24875275790691376,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 1.7983,
      "step": 9500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.24964024126529694,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 1.7954,
      "step": 10000
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.32929572463035583,
      "learning_rate": 1.75e-05,
      "loss": 1.8029,
      "step": 10500
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.30232298374176025,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 1.8019,
      "step": 11000
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.25025495886802673,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 1.7925,
      "step": 11500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.22676324844360352,
      "learning_rate": 2e-05,
      "loss": 1.7963,
      "step": 12000
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.27403199672698975,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 1.7789,
      "step": 12500
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.2133154422044754,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 1.7895,
      "step": 13000
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.2564372420310974,
      "learning_rate": 2.25e-05,
      "loss": 1.7878,
      "step": 13500
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.26612094044685364,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 1.7774,
      "step": 14000
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.30583053827285767,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 1.7935,
      "step": 14500
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.2623724043369293,
      "learning_rate": 2.5e-05,
      "loss": 1.7872,
      "step": 15000
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.25921913981437683,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 1.7876,
      "step": 15500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.29753926396369934,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.7793,
      "step": 16000
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.2524040937423706,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 1.7879,
      "step": 16500
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.25968363881111145,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 1.7851,
      "step": 17000
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.27761855721473694,
      "learning_rate": 2.916666666666667e-05,
      "loss": 1.7702,
      "step": 17500
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.28709521889686584,
      "learning_rate": 3e-05,
      "loss": 1.7827,
      "step": 18000
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.27923768758773804,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 1.7746,
      "step": 18500
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.29258134961128235,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 1.7784,
      "step": 19000
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.27435219287872314,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 1.7724,
      "step": 19500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2840578556060791,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.7762,
      "step": 20000
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.28274959325790405,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 1.7713,
      "step": 20500
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.2887325882911682,
      "learning_rate": 3.5e-05,
      "loss": 1.7651,
      "step": 21000
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.23875805735588074,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 1.7703,
      "step": 21500
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.23569244146347046,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 1.7727,
      "step": 22000
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.3068108558654785,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.7712,
      "step": 22500
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.2756037712097168,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 1.7614,
      "step": 23000
    },
    {
      "epoch": 0.05875,
      "grad_norm": 0.3071737587451935,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 1.768,
      "step": 23500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.29972967505455017,
      "learning_rate": 4e-05,
      "loss": 1.7661,
      "step": 24000
    },
    {
      "epoch": 0.06125,
      "grad_norm": 0.27429911494255066,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 1.7729,
      "step": 24500
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.2951068878173828,
      "learning_rate": 4.166666666666667e-05,
      "loss": 1.7598,
      "step": 25000
    },
    {
      "epoch": 0.06375,
      "grad_norm": 0.2692449688911438,
      "learning_rate": 4.25e-05,
      "loss": 1.7627,
      "step": 25500
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.31761711835861206,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 1.7585,
      "step": 26000
    },
    {
      "epoch": 0.06625,
      "grad_norm": 0.2926730811595917,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 1.7645,
      "step": 26500
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.25728651881217957,
      "learning_rate": 4.5e-05,
      "loss": 1.7595,
      "step": 27000
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.2643634080886841,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 1.7532,
      "step": 27500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2808900773525238,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.7561,
      "step": 28000
    },
    {
      "epoch": 0.07125,
      "grad_norm": 0.3050808310508728,
      "learning_rate": 4.75e-05,
      "loss": 1.7526,
      "step": 28500
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.2786082327365875,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 1.7581,
      "step": 29000
    },
    {
      "epoch": 0.07375,
      "grad_norm": 0.27996209263801575,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 1.7504,
      "step": 29500
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.2714375853538513,
      "learning_rate": 5e-05,
      "loss": 1.7516,
      "step": 30000
    },
    {
      "epoch": 0.07625,
      "grad_norm": 0.28951916098594666,
      "learning_rate": 5.0833333333333333e-05,
      "loss": 1.7602,
      "step": 30500
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.3048747181892395,
      "learning_rate": 5.166666666666667e-05,
      "loss": 1.738,
      "step": 31000
    },
    {
      "epoch": 0.07875,
      "grad_norm": 0.3003440797328949,
      "learning_rate": 5.25e-05,
      "loss": 1.7477,
      "step": 31500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.32511106133461,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.7431,
      "step": 32000
    },
    {
      "epoch": 0.08125,
      "grad_norm": 0.30635157227516174,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 1.7298,
      "step": 32500
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.31054139137268066,
      "learning_rate": 5.500000000000001e-05,
      "loss": 1.7455,
      "step": 33000
    },
    {
      "epoch": 0.08375,
      "grad_norm": 0.3075023889541626,
      "learning_rate": 5.583333333333334e-05,
      "loss": 1.7413,
      "step": 33500
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.30683964490890503,
      "learning_rate": 5.666666666666667e-05,
      "loss": 1.7356,
      "step": 34000
    },
    {
      "epoch": 0.08625,
      "grad_norm": 0.33302393555641174,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 1.7421,
      "step": 34500
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.24339702725410461,
      "learning_rate": 5.833333333333334e-05,
      "loss": 1.7364,
      "step": 35000
    },
    {
      "epoch": 0.08875,
      "grad_norm": 0.31881600618362427,
      "learning_rate": 5.916666666666667e-05,
      "loss": 1.7398,
      "step": 35500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2995544373989105,
      "learning_rate": 6e-05,
      "loss": 1.7425,
      "step": 36000
    },
    {
      "epoch": 0.09125,
      "grad_norm": 0.2647571563720703,
      "learning_rate": 6.083333333333333e-05,
      "loss": 1.7337,
      "step": 36500
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.3045324385166168,
      "learning_rate": 6.166666666666667e-05,
      "loss": 1.7372,
      "step": 37000
    },
    {
      "epoch": 0.09375,
      "grad_norm": 0.33696621656417847,
      "learning_rate": 6.25e-05,
      "loss": 1.7292,
      "step": 37500
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.29061657190322876,
      "learning_rate": 6.333333333333333e-05,
      "loss": 1.7327,
      "step": 38000
    },
    {
      "epoch": 0.09625,
      "grad_norm": 0.3155269920825958,
      "learning_rate": 6.416666666666668e-05,
      "loss": 1.7309,
      "step": 38500
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.3516119718551636,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.724,
      "step": 39000
    },
    {
      "epoch": 0.09875,
      "grad_norm": 0.3345243036746979,
      "learning_rate": 6.583333333333334e-05,
      "loss": 1.7221,
      "step": 39500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.29643064737319946,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.7259,
      "step": 40000
    },
    {
      "epoch": 0.10125,
      "grad_norm": 0.2995443344116211,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.7267,
      "step": 40500
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.28133177757263184,
      "learning_rate": 6.833333333333333e-05,
      "loss": 1.7207,
      "step": 41000
    },
    {
      "epoch": 0.10375,
      "grad_norm": 0.33666127920150757,
      "learning_rate": 6.916666666666666e-05,
      "loss": 1.7215,
      "step": 41500
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.3393573462963104,
      "learning_rate": 7e-05,
      "loss": 1.7179,
      "step": 42000
    },
    {
      "epoch": 0.10625,
      "grad_norm": 0.35483357310295105,
      "learning_rate": 7.083333333333334e-05,
      "loss": 1.7224,
      "step": 42500
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.34516221284866333,
      "learning_rate": 7.166666666666667e-05,
      "loss": 1.7185,
      "step": 43000
    },
    {
      "epoch": 0.10875,
      "grad_norm": 0.3483272194862366,
      "learning_rate": 7.25e-05,
      "loss": 1.7101,
      "step": 43500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3300081789493561,
      "learning_rate": 7.333333333333333e-05,
      "loss": 1.7089,
      "step": 44000
    },
    {
      "epoch": 0.11125,
      "grad_norm": 0.37269896268844604,
      "learning_rate": 7.416666666666668e-05,
      "loss": 1.7253,
      "step": 44500
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.352305144071579,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.7081,
      "step": 45000
    },
    {
      "epoch": 0.11375,
      "grad_norm": 0.3742040991783142,
      "learning_rate": 7.583333333333334e-05,
      "loss": 1.7139,
      "step": 45500
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.35160407423973083,
      "learning_rate": 7.666666666666667e-05,
      "loss": 1.7053,
      "step": 46000
    },
    {
      "epoch": 0.11625,
      "grad_norm": 0.33448660373687744,
      "learning_rate": 7.75e-05,
      "loss": 1.7113,
      "step": 46500
    },
    {
      "epoch": 0.1175,
      "grad_norm": 0.31512096524238586,
      "learning_rate": 7.833333333333333e-05,
      "loss": 1.7095,
      "step": 47000
    },
    {
      "epoch": 0.11875,
      "grad_norm": 0.336465984582901,
      "learning_rate": 7.916666666666666e-05,
      "loss": 1.7152,
      "step": 47500
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.318123996257782,
      "learning_rate": 8e-05,
      "loss": 1.6952,
      "step": 48000
    },
    {
      "epoch": 0.12125,
      "grad_norm": 0.3817586302757263,
      "learning_rate": 8.083333333333334e-05,
      "loss": 1.7093,
      "step": 48500
    },
    {
      "epoch": 0.1225,
      "grad_norm": 0.33122026920318604,
      "learning_rate": 8.166666666666667e-05,
      "loss": 1.7055,
      "step": 49000
    },
    {
      "epoch": 0.12375,
      "grad_norm": 0.3406773507595062,
      "learning_rate": 8.25e-05,
      "loss": 1.6917,
      "step": 49500
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.35693106055259705,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.6929,
      "step": 50000
    },
    {
      "epoch": 0.12625,
      "grad_norm": 0.3897812068462372,
      "learning_rate": 8.416666666666668e-05,
      "loss": 1.703,
      "step": 50500
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.37787866592407227,
      "learning_rate": 8.5e-05,
      "loss": 1.6984,
      "step": 51000
    },
    {
      "epoch": 0.12875,
      "grad_norm": 0.36986562609672546,
      "learning_rate": 8.583333333333334e-05,
      "loss": 1.6991,
      "step": 51500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3455484211444855,
      "learning_rate": 8.666666666666667e-05,
      "loss": 1.6994,
      "step": 52000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 0.33623000979423523,
      "learning_rate": 8.75e-05,
      "loss": 1.6931,
      "step": 52500
    },
    {
      "epoch": 0.1325,
      "grad_norm": 0.4285266697406769,
      "learning_rate": 8.833333333333333e-05,
      "loss": 1.7029,
      "step": 53000
    },
    {
      "epoch": 0.13375,
      "grad_norm": 0.358153373003006,
      "learning_rate": 8.916666666666667e-05,
      "loss": 1.6991,
      "step": 53500
    },
    {
      "epoch": 0.135,
      "grad_norm": 0.35793787240982056,
      "learning_rate": 9e-05,
      "loss": 1.695,
      "step": 54000
    },
    {
      "epoch": 0.13625,
      "grad_norm": 0.33504530787467957,
      "learning_rate": 9.083333333333334e-05,
      "loss": 1.6791,
      "step": 54500
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.328583687543869,
      "learning_rate": 9.166666666666667e-05,
      "loss": 1.6779,
      "step": 55000
    },
    {
      "epoch": 0.13875,
      "grad_norm": 0.3535928428173065,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.6835,
      "step": 55500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3551371991634369,
      "learning_rate": 9.333333333333334e-05,
      "loss": 1.6913,
      "step": 56000
    },
    {
      "epoch": 0.14125,
      "grad_norm": 0.4095412790775299,
      "learning_rate": 9.416666666666667e-05,
      "loss": 1.6934,
      "step": 56500
    },
    {
      "epoch": 0.1425,
      "grad_norm": 0.3452630043029785,
      "learning_rate": 9.5e-05,
      "loss": 1.6819,
      "step": 57000
    },
    {
      "epoch": 0.14375,
      "grad_norm": 0.36045897006988525,
      "learning_rate": 9.583333333333334e-05,
      "loss": 1.6718,
      "step": 57500
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.37568575143814087,
      "learning_rate": 9.666666666666667e-05,
      "loss": 1.6746,
      "step": 58000
    },
    {
      "epoch": 0.14625,
      "grad_norm": 0.4119630753993988,
      "learning_rate": 9.75e-05,
      "loss": 1.6762,
      "step": 58500
    },
    {
      "epoch": 0.1475,
      "grad_norm": 0.34359216690063477,
      "learning_rate": 9.833333333333333e-05,
      "loss": 1.6745,
      "step": 59000
    },
    {
      "epoch": 0.14875,
      "grad_norm": 0.36260008811950684,
      "learning_rate": 9.916666666666667e-05,
      "loss": 1.6817,
      "step": 59500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3880370855331421,
      "learning_rate": 0.0001,
      "loss": 1.6827,
      "step": 60000
    },
    {
      "epoch": 0.15125,
      "grad_norm": 0.4216972291469574,
      "learning_rate": 9.98529411764706e-05,
      "loss": 1.6678,
      "step": 60500
    },
    {
      "epoch": 0.1525,
      "grad_norm": 0.39023301005363464,
      "learning_rate": 9.970588235294118e-05,
      "loss": 1.6723,
      "step": 61000
    },
    {
      "epoch": 0.15375,
      "grad_norm": 0.41266247630119324,
      "learning_rate": 9.955882352941178e-05,
      "loss": 1.6827,
      "step": 61500
    },
    {
      "epoch": 0.155,
      "grad_norm": 0.38324448466300964,
      "learning_rate": 9.941176470588236e-05,
      "loss": 1.6781,
      "step": 62000
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.41438043117523193,
      "learning_rate": 9.926470588235295e-05,
      "loss": 1.6682,
      "step": 62500
    },
    {
      "epoch": 0.1575,
      "grad_norm": 0.3732743561267853,
      "learning_rate": 9.911764705882353e-05,
      "loss": 1.6767,
      "step": 63000
    },
    {
      "epoch": 0.15875,
      "grad_norm": 0.3683856129646301,
      "learning_rate": 9.897058823529413e-05,
      "loss": 1.6681,
      "step": 63500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4191763401031494,
      "learning_rate": 9.882352941176471e-05,
      "loss": 1.6639,
      "step": 64000
    },
    {
      "epoch": 0.16125,
      "grad_norm": 0.3452666103839874,
      "learning_rate": 9.86764705882353e-05,
      "loss": 1.6609,
      "step": 64500
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.39721575379371643,
      "learning_rate": 9.852941176470589e-05,
      "loss": 1.6612,
      "step": 65000
    },
    {
      "epoch": 0.16375,
      "grad_norm": 0.3614177405834198,
      "learning_rate": 9.838235294117647e-05,
      "loss": 1.6603,
      "step": 65500
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.3600771725177765,
      "learning_rate": 9.823529411764706e-05,
      "loss": 1.6535,
      "step": 66000
    },
    {
      "epoch": 0.16625,
      "grad_norm": 0.4283366799354553,
      "learning_rate": 9.808823529411765e-05,
      "loss": 1.6641,
      "step": 66500
    },
    {
      "epoch": 0.1675,
      "grad_norm": 0.3942333161830902,
      "learning_rate": 9.794117647058824e-05,
      "loss": 1.6626,
      "step": 67000
    },
    {
      "epoch": 0.16875,
      "grad_norm": 0.40322497487068176,
      "learning_rate": 9.779411764705882e-05,
      "loss": 1.6665,
      "step": 67500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.37164050340652466,
      "learning_rate": 9.764705882352942e-05,
      "loss": 1.6577,
      "step": 68000
    },
    {
      "epoch": 0.17125,
      "grad_norm": 0.47916415333747864,
      "learning_rate": 9.75e-05,
      "loss": 1.663,
      "step": 68500
    },
    {
      "epoch": 0.1725,
      "grad_norm": 0.41116273403167725,
      "learning_rate": 9.73529411764706e-05,
      "loss": 1.662,
      "step": 69000
    },
    {
      "epoch": 0.17375,
      "grad_norm": 0.4088917374610901,
      "learning_rate": 9.720588235294117e-05,
      "loss": 1.6477,
      "step": 69500
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.4533187747001648,
      "learning_rate": 9.705882352941177e-05,
      "loss": 1.66,
      "step": 70000
    },
    {
      "epoch": 0.17625,
      "grad_norm": 0.44719505310058594,
      "learning_rate": 9.691176470588235e-05,
      "loss": 1.6483,
      "step": 70500
    },
    {
      "epoch": 0.1775,
      "grad_norm": 0.41458579897880554,
      "learning_rate": 9.676470588235295e-05,
      "loss": 1.6512,
      "step": 71000
    },
    {
      "epoch": 0.17875,
      "grad_norm": 0.4261673390865326,
      "learning_rate": 9.661764705882354e-05,
      "loss": 1.6563,
      "step": 71500
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.41107118129730225,
      "learning_rate": 9.647058823529412e-05,
      "loss": 1.6432,
      "step": 72000
    },
    {
      "epoch": 0.18125,
      "grad_norm": 0.4575132727622986,
      "learning_rate": 9.632352941176472e-05,
      "loss": 1.637,
      "step": 72500
    },
    {
      "epoch": 0.1825,
      "grad_norm": 0.37223654985427856,
      "learning_rate": 9.61764705882353e-05,
      "loss": 1.6484,
      "step": 73000
    },
    {
      "epoch": 0.18375,
      "grad_norm": 0.4229198396205902,
      "learning_rate": 9.60294117647059e-05,
      "loss": 1.6448,
      "step": 73500
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.37884482741355896,
      "learning_rate": 9.588235294117648e-05,
      "loss": 1.6468,
      "step": 74000
    },
    {
      "epoch": 0.18625,
      "grad_norm": 0.5390732288360596,
      "learning_rate": 9.573529411764707e-05,
      "loss": 1.6469,
      "step": 74500
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.486435204744339,
      "learning_rate": 9.558823529411765e-05,
      "loss": 1.6429,
      "step": 75000
    },
    {
      "epoch": 0.18875,
      "grad_norm": 0.3907312750816345,
      "learning_rate": 9.544117647058825e-05,
      "loss": 1.6392,
      "step": 75500
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.40394824743270874,
      "learning_rate": 9.529411764705883e-05,
      "loss": 1.6457,
      "step": 76000
    },
    {
      "epoch": 0.19125,
      "grad_norm": 0.4110022485256195,
      "learning_rate": 9.514705882352941e-05,
      "loss": 1.6443,
      "step": 76500
    },
    {
      "epoch": 0.1925,
      "grad_norm": 0.44748222827911377,
      "learning_rate": 9.5e-05,
      "loss": 1.6424,
      "step": 77000
    },
    {
      "epoch": 0.19375,
      "grad_norm": 0.40395447611808777,
      "learning_rate": 9.485294117647059e-05,
      "loss": 1.6339,
      "step": 77500
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.5019798874855042,
      "learning_rate": 9.470588235294118e-05,
      "loss": 1.6427,
      "step": 78000
    },
    {
      "epoch": 0.19625,
      "grad_norm": 0.46941933035850525,
      "learning_rate": 9.455882352941176e-05,
      "loss": 1.6262,
      "step": 78500
    },
    {
      "epoch": 0.1975,
      "grad_norm": 0.3930617570877075,
      "learning_rate": 9.441176470588236e-05,
      "loss": 1.6297,
      "step": 79000
    },
    {
      "epoch": 0.19875,
      "grad_norm": 0.4903254210948944,
      "learning_rate": 9.426470588235294e-05,
      "loss": 1.6355,
      "step": 79500
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.47429540753364563,
      "learning_rate": 9.411764705882353e-05,
      "loss": 1.6353,
      "step": 80000
    },
    {
      "epoch": 0.20125,
      "grad_norm": 0.47476595640182495,
      "learning_rate": 9.397058823529412e-05,
      "loss": 1.6344,
      "step": 80500
    },
    {
      "epoch": 0.2025,
      "grad_norm": 0.4357253611087799,
      "learning_rate": 9.382352941176471e-05,
      "loss": 1.635,
      "step": 81000
    },
    {
      "epoch": 0.20375,
      "grad_norm": 0.46009543538093567,
      "learning_rate": 9.367647058823529e-05,
      "loss": 1.628,
      "step": 81500
    },
    {
      "epoch": 0.205,
      "grad_norm": 0.4663400948047638,
      "learning_rate": 9.352941176470589e-05,
      "loss": 1.6193,
      "step": 82000
    },
    {
      "epoch": 0.20625,
      "grad_norm": 0.3870235085487366,
      "learning_rate": 9.338235294117648e-05,
      "loss": 1.6272,
      "step": 82500
    },
    {
      "epoch": 0.2075,
      "grad_norm": 0.4751451015472412,
      "learning_rate": 9.323529411764706e-05,
      "loss": 1.6252,
      "step": 83000
    },
    {
      "epoch": 0.20875,
      "grad_norm": 0.4714394211769104,
      "learning_rate": 9.308823529411766e-05,
      "loss": 1.6291,
      "step": 83500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4286724627017975,
      "learning_rate": 9.294117647058824e-05,
      "loss": 1.6204,
      "step": 84000
    },
    {
      "epoch": 0.21125,
      "grad_norm": 0.43996310234069824,
      "learning_rate": 9.279411764705884e-05,
      "loss": 1.6283,
      "step": 84500
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.437835693359375,
      "learning_rate": 9.264705882352942e-05,
      "loss": 1.6114,
      "step": 85000
    },
    {
      "epoch": 0.21375,
      "grad_norm": 0.43815916776657104,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.6171,
      "step": 85500
    },
    {
      "epoch": 0.215,
      "grad_norm": 0.4829290509223938,
      "learning_rate": 9.23529411764706e-05,
      "loss": 1.6297,
      "step": 86000
    },
    {
      "epoch": 0.21625,
      "grad_norm": 0.48703333735466003,
      "learning_rate": 9.220588235294119e-05,
      "loss": 1.6301,
      "step": 86500
    },
    {
      "epoch": 0.2175,
      "grad_norm": 0.4574023485183716,
      "learning_rate": 9.205882352941177e-05,
      "loss": 1.6122,
      "step": 87000
    },
    {
      "epoch": 0.21875,
      "grad_norm": 0.5148200988769531,
      "learning_rate": 9.191176470588235e-05,
      "loss": 1.6253,
      "step": 87500
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4771931767463684,
      "learning_rate": 9.176470588235295e-05,
      "loss": 1.6252,
      "step": 88000
    },
    {
      "epoch": 0.22125,
      "grad_norm": 0.4449193775653839,
      "learning_rate": 9.161764705882353e-05,
      "loss": 1.6156,
      "step": 88500
    },
    {
      "epoch": 0.2225,
      "grad_norm": 0.44582101702690125,
      "learning_rate": 9.147058823529412e-05,
      "loss": 1.6142,
      "step": 89000
    },
    {
      "epoch": 0.22375,
      "grad_norm": 0.4331035912036896,
      "learning_rate": 9.13235294117647e-05,
      "loss": 1.6097,
      "step": 89500
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.43235719203948975,
      "learning_rate": 9.11764705882353e-05,
      "loss": 1.6074,
      "step": 90000
    },
    {
      "epoch": 0.22625,
      "grad_norm": 0.5079482197761536,
      "learning_rate": 9.102941176470588e-05,
      "loss": 1.61,
      "step": 90500
    },
    {
      "epoch": 0.2275,
      "grad_norm": 0.4910871386528015,
      "learning_rate": 9.088235294117648e-05,
      "loss": 1.6208,
      "step": 91000
    },
    {
      "epoch": 0.22875,
      "grad_norm": 0.4896155297756195,
      "learning_rate": 9.073529411764706e-05,
      "loss": 1.6092,
      "step": 91500
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4492570459842682,
      "learning_rate": 9.058823529411765e-05,
      "loss": 1.6039,
      "step": 92000
    },
    {
      "epoch": 0.23125,
      "grad_norm": 0.49751242995262146,
      "learning_rate": 9.044117647058823e-05,
      "loss": 1.604,
      "step": 92500
    },
    {
      "epoch": 0.2325,
      "grad_norm": 0.5014136433601379,
      "learning_rate": 9.029411764705883e-05,
      "loss": 1.6077,
      "step": 93000
    },
    {
      "epoch": 0.23375,
      "grad_norm": 0.47676050662994385,
      "learning_rate": 9.014705882352942e-05,
      "loss": 1.6031,
      "step": 93500
    },
    {
      "epoch": 0.235,
      "grad_norm": 0.5757561922073364,
      "learning_rate": 9e-05,
      "loss": 1.6076,
      "step": 94000
    },
    {
      "epoch": 0.23625,
      "grad_norm": 0.46745312213897705,
      "learning_rate": 8.98529411764706e-05,
      "loss": 1.6088,
      "step": 94500
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.400686651468277,
      "learning_rate": 8.970588235294118e-05,
      "loss": 1.5984,
      "step": 95000
    },
    {
      "epoch": 0.23875,
      "grad_norm": 0.5649771094322205,
      "learning_rate": 8.955882352941178e-05,
      "loss": 1.6035,
      "step": 95500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4160470962524414,
      "learning_rate": 8.941176470588236e-05,
      "loss": 1.6053,
      "step": 96000
    },
    {
      "epoch": 0.24125,
      "grad_norm": 0.47487449645996094,
      "learning_rate": 8.926470588235295e-05,
      "loss": 1.6041,
      "step": 96500
    },
    {
      "epoch": 0.2425,
      "grad_norm": 0.6136535406112671,
      "learning_rate": 8.911764705882354e-05,
      "loss": 1.6008,
      "step": 97000
    },
    {
      "epoch": 0.24375,
      "grad_norm": 0.4180643856525421,
      "learning_rate": 8.897058823529412e-05,
      "loss": 1.598,
      "step": 97500
    },
    {
      "epoch": 0.245,
      "grad_norm": 0.5150108337402344,
      "learning_rate": 8.882352941176471e-05,
      "loss": 1.6043,
      "step": 98000
    },
    {
      "epoch": 0.24625,
      "grad_norm": 0.5082566738128662,
      "learning_rate": 8.867647058823529e-05,
      "loss": 1.5953,
      "step": 98500
    },
    {
      "epoch": 0.2475,
      "grad_norm": 0.551842212677002,
      "learning_rate": 8.852941176470589e-05,
      "loss": 1.5916,
      "step": 99000
    },
    {
      "epoch": 0.24875,
      "grad_norm": 0.5332151651382446,
      "learning_rate": 8.838235294117647e-05,
      "loss": 1.602,
      "step": 99500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5041967630386353,
      "learning_rate": 8.823529411764706e-05,
      "loss": 1.5911,
      "step": 100000
    },
    {
      "epoch": 0.25125,
      "grad_norm": 0.5348301529884338,
      "learning_rate": 8.808823529411765e-05,
      "loss": 1.589,
      "step": 100500
    },
    {
      "epoch": 0.2525,
      "grad_norm": 0.4740676283836365,
      "learning_rate": 8.794117647058824e-05,
      "loss": 1.5927,
      "step": 101000
    },
    {
      "epoch": 0.25375,
      "grad_norm": 0.43280094861984253,
      "learning_rate": 8.779411764705882e-05,
      "loss": 1.5886,
      "step": 101500
    },
    {
      "epoch": 0.255,
      "grad_norm": 0.4901924431324005,
      "learning_rate": 8.764705882352942e-05,
      "loss": 1.5822,
      "step": 102000
    },
    {
      "epoch": 0.25625,
      "grad_norm": 0.5920217037200928,
      "learning_rate": 8.75e-05,
      "loss": 1.5896,
      "step": 102500
    },
    {
      "epoch": 0.2575,
      "grad_norm": 0.43340548872947693,
      "learning_rate": 8.73529411764706e-05,
      "loss": 1.5853,
      "step": 103000
    },
    {
      "epoch": 0.25875,
      "grad_norm": 0.5129938721656799,
      "learning_rate": 8.720588235294118e-05,
      "loss": 1.5914,
      "step": 103500
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.45787155628204346,
      "learning_rate": 8.705882352941177e-05,
      "loss": 1.5967,
      "step": 104000
    },
    {
      "epoch": 0.26125,
      "grad_norm": 0.4729342460632324,
      "learning_rate": 8.691176470588237e-05,
      "loss": 1.5855,
      "step": 104500
    },
    {
      "epoch": 0.2625,
      "grad_norm": 0.46954384446144104,
      "learning_rate": 8.676470588235295e-05,
      "loss": 1.5902,
      "step": 105000
    },
    {
      "epoch": 0.26375,
      "grad_norm": 0.5703432559967041,
      "learning_rate": 8.661764705882354e-05,
      "loss": 1.5791,
      "step": 105500
    },
    {
      "epoch": 0.265,
      "grad_norm": 0.5544886589050293,
      "learning_rate": 8.647058823529412e-05,
      "loss": 1.5757,
      "step": 106000
    },
    {
      "epoch": 0.26625,
      "grad_norm": 0.5577684044837952,
      "learning_rate": 8.632352941176472e-05,
      "loss": 1.5823,
      "step": 106500
    },
    {
      "epoch": 0.2675,
      "grad_norm": 0.4736819863319397,
      "learning_rate": 8.61764705882353e-05,
      "loss": 1.5851,
      "step": 107000
    },
    {
      "epoch": 0.26875,
      "grad_norm": 0.5300942063331604,
      "learning_rate": 8.60294117647059e-05,
      "loss": 1.5803,
      "step": 107500
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.48813092708587646,
      "learning_rate": 8.588235294117646e-05,
      "loss": 1.5747,
      "step": 108000
    },
    {
      "epoch": 0.27125,
      "grad_norm": 0.5298958420753479,
      "learning_rate": 8.573529411764706e-05,
      "loss": 1.5768,
      "step": 108500
    },
    {
      "epoch": 0.2725,
      "grad_norm": 0.6354179382324219,
      "learning_rate": 8.558823529411765e-05,
      "loss": 1.5878,
      "step": 109000
    },
    {
      "epoch": 0.27375,
      "grad_norm": 0.5040727853775024,
      "learning_rate": 8.544117647058823e-05,
      "loss": 1.5757,
      "step": 109500
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.6058778166770935,
      "learning_rate": 8.529411764705883e-05,
      "loss": 1.5694,
      "step": 110000
    },
    {
      "epoch": 0.27625,
      "grad_norm": 0.4979189336299896,
      "learning_rate": 8.514705882352941e-05,
      "loss": 1.5754,
      "step": 110500
    },
    {
      "epoch": 0.2775,
      "grad_norm": 0.5982831716537476,
      "learning_rate": 8.5e-05,
      "loss": 1.5763,
      "step": 111000
    },
    {
      "epoch": 0.27875,
      "grad_norm": 0.5377408266067505,
      "learning_rate": 8.485294117647059e-05,
      "loss": 1.5809,
      "step": 111500
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6004562377929688,
      "learning_rate": 8.470588235294118e-05,
      "loss": 1.5775,
      "step": 112000
    },
    {
      "epoch": 0.28125,
      "grad_norm": 0.48757943511009216,
      "learning_rate": 8.455882352941176e-05,
      "loss": 1.569,
      "step": 112500
    },
    {
      "epoch": 0.2825,
      "grad_norm": 0.4685388505458832,
      "learning_rate": 8.441176470588236e-05,
      "loss": 1.5722,
      "step": 113000
    },
    {
      "epoch": 0.28375,
      "grad_norm": 0.5293340682983398,
      "learning_rate": 8.426470588235294e-05,
      "loss": 1.5693,
      "step": 113500
    },
    {
      "epoch": 0.285,
      "grad_norm": 0.494690477848053,
      "learning_rate": 8.411764705882354e-05,
      "loss": 1.5654,
      "step": 114000
    },
    {
      "epoch": 0.28625,
      "grad_norm": 0.5457216501235962,
      "learning_rate": 8.397058823529412e-05,
      "loss": 1.5802,
      "step": 114500
    },
    {
      "epoch": 0.2875,
      "grad_norm": 0.5230000615119934,
      "learning_rate": 8.382352941176471e-05,
      "loss": 1.574,
      "step": 115000
    },
    {
      "epoch": 0.28875,
      "grad_norm": 0.6242391467094421,
      "learning_rate": 8.367647058823531e-05,
      "loss": 1.5695,
      "step": 115500
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5597373247146606,
      "learning_rate": 8.352941176470589e-05,
      "loss": 1.5624,
      "step": 116000
    },
    {
      "epoch": 0.29125,
      "grad_norm": 0.5657733678817749,
      "learning_rate": 8.338235294117648e-05,
      "loss": 1.5666,
      "step": 116500
    },
    {
      "epoch": 0.2925,
      "grad_norm": 0.5043824315071106,
      "learning_rate": 8.323529411764707e-05,
      "loss": 1.5631,
      "step": 117000
    },
    {
      "epoch": 0.29375,
      "grad_norm": 0.6176803112030029,
      "learning_rate": 8.308823529411766e-05,
      "loss": 1.5753,
      "step": 117500
    },
    {
      "epoch": 0.295,
      "grad_norm": 0.5629258155822754,
      "learning_rate": 8.294117647058824e-05,
      "loss": 1.5603,
      "step": 118000
    },
    {
      "epoch": 0.29625,
      "grad_norm": 0.48812437057495117,
      "learning_rate": 8.279411764705882e-05,
      "loss": 1.5552,
      "step": 118500
    },
    {
      "epoch": 0.2975,
      "grad_norm": 0.5131939053535461,
      "learning_rate": 8.26470588235294e-05,
      "loss": 1.5716,
      "step": 119000
    },
    {
      "epoch": 0.29875,
      "grad_norm": 0.5197107195854187,
      "learning_rate": 8.25e-05,
      "loss": 1.5607,
      "step": 119500
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5385016798973083,
      "learning_rate": 8.23529411764706e-05,
      "loss": 1.5609,
      "step": 120000
    },
    {
      "epoch": 0.30125,
      "grad_norm": 0.5296224355697632,
      "learning_rate": 8.220588235294118e-05,
      "loss": 1.5659,
      "step": 120500
    },
    {
      "epoch": 0.3025,
      "grad_norm": 0.5514806509017944,
      "learning_rate": 8.205882352941177e-05,
      "loss": 1.5646,
      "step": 121000
    },
    {
      "epoch": 0.30375,
      "grad_norm": 0.585320770740509,
      "learning_rate": 8.191176470588235e-05,
      "loss": 1.5637,
      "step": 121500
    },
    {
      "epoch": 0.305,
      "grad_norm": 0.6013701558113098,
      "learning_rate": 8.176470588235295e-05,
      "loss": 1.5534,
      "step": 122000
    },
    {
      "epoch": 0.30625,
      "grad_norm": 0.5381532311439514,
      "learning_rate": 8.161764705882353e-05,
      "loss": 1.5688,
      "step": 122500
    },
    {
      "epoch": 0.3075,
      "grad_norm": 0.5404754281044006,
      "learning_rate": 8.147058823529412e-05,
      "loss": 1.5532,
      "step": 123000
    },
    {
      "epoch": 0.30875,
      "grad_norm": 0.6145194172859192,
      "learning_rate": 8.13235294117647e-05,
      "loss": 1.5627,
      "step": 123500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.552057147026062,
      "learning_rate": 8.11764705882353e-05,
      "loss": 1.5402,
      "step": 124000
    },
    {
      "epoch": 0.31125,
      "grad_norm": 0.5587040185928345,
      "learning_rate": 8.102941176470588e-05,
      "loss": 1.5514,
      "step": 124500
    },
    {
      "epoch": 0.3125,
      "grad_norm": 0.4438443183898926,
      "learning_rate": 8.088235294117648e-05,
      "loss": 1.5504,
      "step": 125000
    },
    {
      "epoch": 0.31375,
      "grad_norm": 0.4720279574394226,
      "learning_rate": 8.073529411764706e-05,
      "loss": 1.5565,
      "step": 125500
    },
    {
      "epoch": 0.315,
      "grad_norm": 0.5128805637359619,
      "learning_rate": 8.058823529411765e-05,
      "loss": 1.5509,
      "step": 126000
    },
    {
      "epoch": 0.31625,
      "grad_norm": 0.6100932359695435,
      "learning_rate": 8.044117647058825e-05,
      "loss": 1.5577,
      "step": 126500
    },
    {
      "epoch": 0.3175,
      "grad_norm": 0.5893574357032776,
      "learning_rate": 8.029411764705883e-05,
      "loss": 1.5531,
      "step": 127000
    },
    {
      "epoch": 0.31875,
      "grad_norm": 0.4585348963737488,
      "learning_rate": 8.014705882352943e-05,
      "loss": 1.5545,
      "step": 127500
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5369756817817688,
      "learning_rate": 8e-05,
      "loss": 1.558,
      "step": 128000
    },
    {
      "epoch": 0.32125,
      "grad_norm": 0.6249573230743408,
      "learning_rate": 7.98529411764706e-05,
      "loss": 1.5426,
      "step": 128500
    },
    {
      "epoch": 0.3225,
      "grad_norm": 0.5390204191207886,
      "learning_rate": 7.970588235294118e-05,
      "loss": 1.5475,
      "step": 129000
    },
    {
      "epoch": 0.32375,
      "grad_norm": 0.542033851146698,
      "learning_rate": 7.955882352941176e-05,
      "loss": 1.5469,
      "step": 129500
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.5636777281761169,
      "learning_rate": 7.941176470588235e-05,
      "loss": 1.5476,
      "step": 130000
    },
    {
      "epoch": 0.32625,
      "grad_norm": 0.5879814624786377,
      "learning_rate": 7.926470588235294e-05,
      "loss": 1.5444,
      "step": 130500
    },
    {
      "epoch": 0.3275,
      "grad_norm": 0.5705644488334656,
      "learning_rate": 7.911764705882354e-05,
      "loss": 1.5478,
      "step": 131000
    },
    {
      "epoch": 0.32875,
      "grad_norm": 0.5669952034950256,
      "learning_rate": 7.897058823529412e-05,
      "loss": 1.5411,
      "step": 131500
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6611229181289673,
      "learning_rate": 7.882352941176471e-05,
      "loss": 1.5396,
      "step": 132000
    },
    {
      "epoch": 0.33125,
      "grad_norm": 0.5504366159439087,
      "learning_rate": 7.86764705882353e-05,
      "loss": 1.5436,
      "step": 132500
    },
    {
      "epoch": 0.3325,
      "grad_norm": 0.5994719862937927,
      "learning_rate": 7.852941176470589e-05,
      "loss": 1.5369,
      "step": 133000
    },
    {
      "epoch": 0.33375,
      "grad_norm": 0.5124653577804565,
      "learning_rate": 7.838235294117647e-05,
      "loss": 1.5508,
      "step": 133500
    },
    {
      "epoch": 0.335,
      "grad_norm": 0.5520735383033752,
      "learning_rate": 7.823529411764707e-05,
      "loss": 1.5501,
      "step": 134000
    },
    {
      "epoch": 0.33625,
      "grad_norm": 0.48696592450141907,
      "learning_rate": 7.808823529411765e-05,
      "loss": 1.5438,
      "step": 134500
    },
    {
      "epoch": 0.3375,
      "grad_norm": 0.5071452856063843,
      "learning_rate": 7.794117647058824e-05,
      "loss": 1.5486,
      "step": 135000
    },
    {
      "epoch": 0.33875,
      "grad_norm": 0.6850264668464661,
      "learning_rate": 7.779411764705882e-05,
      "loss": 1.5508,
      "step": 135500
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5349662899971008,
      "learning_rate": 7.764705882352942e-05,
      "loss": 1.543,
      "step": 136000
    },
    {
      "epoch": 0.34125,
      "grad_norm": 0.5103552937507629,
      "learning_rate": 7.75e-05,
      "loss": 1.5346,
      "step": 136500
    },
    {
      "epoch": 0.3425,
      "grad_norm": 0.4926303029060364,
      "learning_rate": 7.73529411764706e-05,
      "loss": 1.5369,
      "step": 137000
    },
    {
      "epoch": 0.34375,
      "grad_norm": 0.5279684662818909,
      "learning_rate": 7.720588235294119e-05,
      "loss": 1.5354,
      "step": 137500
    },
    {
      "epoch": 0.345,
      "grad_norm": 0.6035869121551514,
      "learning_rate": 7.705882352941177e-05,
      "loss": 1.5403,
      "step": 138000
    },
    {
      "epoch": 0.34625,
      "grad_norm": 0.6349599361419678,
      "learning_rate": 7.691176470588237e-05,
      "loss": 1.5391,
      "step": 138500
    },
    {
      "epoch": 0.3475,
      "grad_norm": 0.5610659122467041,
      "learning_rate": 7.676470588235295e-05,
      "loss": 1.5326,
      "step": 139000
    },
    {
      "epoch": 0.34875,
      "grad_norm": 0.6806707978248596,
      "learning_rate": 7.661764705882354e-05,
      "loss": 1.536,
      "step": 139500
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5820637941360474,
      "learning_rate": 7.647058823529411e-05,
      "loss": 1.5358,
      "step": 140000
    },
    {
      "epoch": 0.35125,
      "grad_norm": 0.6457843780517578,
      "learning_rate": 7.63235294117647e-05,
      "loss": 1.5364,
      "step": 140500
    },
    {
      "epoch": 0.3525,
      "grad_norm": 0.6000287532806396,
      "learning_rate": 7.617647058823529e-05,
      "loss": 1.5252,
      "step": 141000
    },
    {
      "epoch": 0.35375,
      "grad_norm": 0.5776185393333435,
      "learning_rate": 7.602941176470588e-05,
      "loss": 1.5319,
      "step": 141500
    },
    {
      "epoch": 0.355,
      "grad_norm": 0.5531497597694397,
      "learning_rate": 7.588235294117648e-05,
      "loss": 1.5362,
      "step": 142000
    },
    {
      "epoch": 0.35625,
      "grad_norm": 0.600351095199585,
      "learning_rate": 7.573529411764706e-05,
      "loss": 1.5316,
      "step": 142500
    },
    {
      "epoch": 0.3575,
      "grad_norm": 0.548278272151947,
      "learning_rate": 7.558823529411765e-05,
      "loss": 1.5301,
      "step": 143000
    },
    {
      "epoch": 0.35875,
      "grad_norm": 0.580625593662262,
      "learning_rate": 7.544117647058824e-05,
      "loss": 1.5325,
      "step": 143500
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6104080080986023,
      "learning_rate": 7.529411764705883e-05,
      "loss": 1.532,
      "step": 144000
    },
    {
      "epoch": 0.36125,
      "grad_norm": 0.6526150107383728,
      "learning_rate": 7.514705882352941e-05,
      "loss": 1.5319,
      "step": 144500
    },
    {
      "epoch": 0.3625,
      "grad_norm": 0.5481992959976196,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.5356,
      "step": 145000
    },
    {
      "epoch": 0.36375,
      "grad_norm": 0.4715416729450226,
      "learning_rate": 7.485294117647059e-05,
      "loss": 1.5223,
      "step": 145500
    },
    {
      "epoch": 0.365,
      "grad_norm": 0.5702419877052307,
      "learning_rate": 7.470588235294118e-05,
      "loss": 1.5301,
      "step": 146000
    },
    {
      "epoch": 0.36625,
      "grad_norm": 0.6339670419692993,
      "learning_rate": 7.455882352941176e-05,
      "loss": 1.5253,
      "step": 146500
    },
    {
      "epoch": 0.3675,
      "grad_norm": 0.5848110318183899,
      "learning_rate": 7.441176470588236e-05,
      "loss": 1.5327,
      "step": 147000
    },
    {
      "epoch": 0.36875,
      "grad_norm": 0.5497899651527405,
      "learning_rate": 7.426470588235294e-05,
      "loss": 1.5164,
      "step": 147500
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5480470657348633,
      "learning_rate": 7.411764705882354e-05,
      "loss": 1.5318,
      "step": 148000
    },
    {
      "epoch": 0.37125,
      "grad_norm": 0.5633416771888733,
      "learning_rate": 7.397058823529413e-05,
      "loss": 1.5243,
      "step": 148500
    },
    {
      "epoch": 0.3725,
      "grad_norm": 0.529867947101593,
      "learning_rate": 7.382352941176471e-05,
      "loss": 1.5191,
      "step": 149000
    },
    {
      "epoch": 0.37375,
      "grad_norm": 0.619105875492096,
      "learning_rate": 7.367647058823531e-05,
      "loss": 1.5165,
      "step": 149500
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.5718478560447693,
      "learning_rate": 7.352941176470589e-05,
      "loss": 1.519,
      "step": 150000
    },
    {
      "epoch": 0.37625,
      "grad_norm": 0.5424156188964844,
      "learning_rate": 7.338235294117647e-05,
      "loss": 1.5233,
      "step": 150500
    },
    {
      "epoch": 0.3775,
      "grad_norm": 0.6004109382629395,
      "learning_rate": 7.323529411764705e-05,
      "loss": 1.5134,
      "step": 151000
    },
    {
      "epoch": 0.37875,
      "grad_norm": 0.5737623572349548,
      "learning_rate": 7.308823529411765e-05,
      "loss": 1.5064,
      "step": 151500
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5524547696113586,
      "learning_rate": 7.294117647058823e-05,
      "loss": 1.5254,
      "step": 152000
    },
    {
      "epoch": 0.38125,
      "grad_norm": 0.6064949035644531,
      "learning_rate": 7.279411764705882e-05,
      "loss": 1.5147,
      "step": 152500
    },
    {
      "epoch": 0.3825,
      "grad_norm": 0.6252626180648804,
      "learning_rate": 7.264705882352942e-05,
      "loss": 1.5218,
      "step": 153000
    },
    {
      "epoch": 0.38375,
      "grad_norm": 0.5914250016212463,
      "learning_rate": 7.25e-05,
      "loss": 1.5252,
      "step": 153500
    },
    {
      "epoch": 0.385,
      "grad_norm": 0.626559317111969,
      "learning_rate": 7.23529411764706e-05,
      "loss": 1.5122,
      "step": 154000
    },
    {
      "epoch": 0.38625,
      "grad_norm": 0.5572981834411621,
      "learning_rate": 7.220588235294118e-05,
      "loss": 1.519,
      "step": 154500
    },
    {
      "epoch": 0.3875,
      "grad_norm": 0.633377730846405,
      "learning_rate": 7.205882352941177e-05,
      "loss": 1.5221,
      "step": 155000
    },
    {
      "epoch": 0.38875,
      "grad_norm": 0.6761481761932373,
      "learning_rate": 7.191176470588235e-05,
      "loss": 1.5196,
      "step": 155500
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6324052810668945,
      "learning_rate": 7.176470588235295e-05,
      "loss": 1.52,
      "step": 156000
    },
    {
      "epoch": 0.39125,
      "grad_norm": 0.5578495264053345,
      "learning_rate": 7.161764705882353e-05,
      "loss": 1.51,
      "step": 156500
    },
    {
      "epoch": 0.3925,
      "grad_norm": 0.6663876175880432,
      "learning_rate": 7.147058823529412e-05,
      "loss": 1.5171,
      "step": 157000
    },
    {
      "epoch": 0.39375,
      "grad_norm": 0.619512140750885,
      "learning_rate": 7.13235294117647e-05,
      "loss": 1.5168,
      "step": 157500
    },
    {
      "epoch": 0.395,
      "grad_norm": 0.710852861404419,
      "learning_rate": 7.11764705882353e-05,
      "loss": 1.5078,
      "step": 158000
    },
    {
      "epoch": 0.39625,
      "grad_norm": 0.6404141783714294,
      "learning_rate": 7.102941176470588e-05,
      "loss": 1.5145,
      "step": 158500
    },
    {
      "epoch": 0.3975,
      "grad_norm": 0.563887357711792,
      "learning_rate": 7.088235294117648e-05,
      "loss": 1.5055,
      "step": 159000
    },
    {
      "epoch": 0.39875,
      "grad_norm": 0.6402040123939514,
      "learning_rate": 7.073529411764707e-05,
      "loss": 1.5069,
      "step": 159500
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6321465969085693,
      "learning_rate": 7.058823529411765e-05,
      "loss": 1.5161,
      "step": 160000
    },
    {
      "epoch": 0.40125,
      "grad_norm": 0.6180980801582336,
      "learning_rate": 7.044117647058825e-05,
      "loss": 1.5115,
      "step": 160500
    },
    {
      "epoch": 0.4025,
      "grad_norm": 0.562781572341919,
      "learning_rate": 7.029411764705882e-05,
      "loss": 1.5155,
      "step": 161000
    },
    {
      "epoch": 0.40375,
      "grad_norm": 0.6468377113342285,
      "learning_rate": 7.014705882352941e-05,
      "loss": 1.5017,
      "step": 161500
    },
    {
      "epoch": 0.405,
      "grad_norm": 0.5943900942802429,
      "learning_rate": 7e-05,
      "loss": 1.5088,
      "step": 162000
    },
    {
      "epoch": 0.40625,
      "grad_norm": 0.5960394740104675,
      "learning_rate": 6.985294117647059e-05,
      "loss": 1.5083,
      "step": 162500
    },
    {
      "epoch": 0.4075,
      "grad_norm": 0.6520020961761475,
      "learning_rate": 6.970588235294117e-05,
      "loss": 1.5,
      "step": 163000
    },
    {
      "epoch": 0.40875,
      "grad_norm": 0.6144118905067444,
      "learning_rate": 6.955882352941177e-05,
      "loss": 1.5174,
      "step": 163500
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6546695232391357,
      "learning_rate": 6.941176470588236e-05,
      "loss": 1.5135,
      "step": 164000
    },
    {
      "epoch": 0.41125,
      "grad_norm": 0.6551181077957153,
      "learning_rate": 6.926470588235294e-05,
      "loss": 1.5119,
      "step": 164500
    },
    {
      "epoch": 0.4125,
      "grad_norm": 0.5747898817062378,
      "learning_rate": 6.911764705882354e-05,
      "loss": 1.512,
      "step": 165000
    },
    {
      "epoch": 0.41375,
      "grad_norm": 0.6587594747543335,
      "learning_rate": 6.897058823529412e-05,
      "loss": 1.5039,
      "step": 165500
    },
    {
      "epoch": 0.415,
      "grad_norm": 0.6438773274421692,
      "learning_rate": 6.882352941176471e-05,
      "loss": 1.4986,
      "step": 166000
    },
    {
      "epoch": 0.41625,
      "grad_norm": 0.6790168881416321,
      "learning_rate": 6.86764705882353e-05,
      "loss": 1.5033,
      "step": 166500
    },
    {
      "epoch": 0.4175,
      "grad_norm": 0.6377038359642029,
      "learning_rate": 6.852941176470589e-05,
      "loss": 1.5012,
      "step": 167000
    },
    {
      "epoch": 0.41875,
      "grad_norm": 0.6582176685333252,
      "learning_rate": 6.838235294117647e-05,
      "loss": 1.502,
      "step": 167500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.615825891494751,
      "learning_rate": 6.823529411764707e-05,
      "loss": 1.5013,
      "step": 168000
    },
    {
      "epoch": 0.42125,
      "grad_norm": 0.5313482880592346,
      "learning_rate": 6.808823529411765e-05,
      "loss": 1.4997,
      "step": 168500
    },
    {
      "epoch": 0.4225,
      "grad_norm": 0.668434739112854,
      "learning_rate": 6.794117647058824e-05,
      "loss": 1.4942,
      "step": 169000
    },
    {
      "epoch": 0.42375,
      "grad_norm": 0.5895818471908569,
      "learning_rate": 6.779411764705882e-05,
      "loss": 1.4983,
      "step": 169500
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.7003729939460754,
      "learning_rate": 6.764705882352942e-05,
      "loss": 1.5092,
      "step": 170000
    },
    {
      "epoch": 0.42625,
      "grad_norm": 0.6338965892791748,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.4952,
      "step": 170500
    },
    {
      "epoch": 0.4275,
      "grad_norm": 0.5987322926521301,
      "learning_rate": 6.73529411764706e-05,
      "loss": 1.4883,
      "step": 171000
    },
    {
      "epoch": 0.42875,
      "grad_norm": 0.6193413734436035,
      "learning_rate": 6.720588235294119e-05,
      "loss": 1.4948,
      "step": 171500
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7338741421699524,
      "learning_rate": 6.705882352941176e-05,
      "loss": 1.5065,
      "step": 172000
    },
    {
      "epoch": 0.43125,
      "grad_norm": 0.6073386073112488,
      "learning_rate": 6.691176470588235e-05,
      "loss": 1.4912,
      "step": 172500
    },
    {
      "epoch": 0.4325,
      "grad_norm": 0.5749716758728027,
      "learning_rate": 6.676470588235294e-05,
      "loss": 1.4968,
      "step": 173000
    },
    {
      "epoch": 0.43375,
      "grad_norm": 0.7402700185775757,
      "learning_rate": 6.661764705882353e-05,
      "loss": 1.4891,
      "step": 173500
    },
    {
      "epoch": 0.435,
      "grad_norm": 0.615627646446228,
      "learning_rate": 6.647058823529411e-05,
      "loss": 1.4974,
      "step": 174000
    },
    {
      "epoch": 0.43625,
      "grad_norm": 0.6327902674674988,
      "learning_rate": 6.632352941176471e-05,
      "loss": 1.486,
      "step": 174500
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.6262918710708618,
      "learning_rate": 6.61764705882353e-05,
      "loss": 1.4821,
      "step": 175000
    },
    {
      "epoch": 0.43875,
      "grad_norm": 0.559240996837616,
      "learning_rate": 6.602941176470588e-05,
      "loss": 1.4919,
      "step": 175500
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5900192260742188,
      "learning_rate": 6.588235294117648e-05,
      "loss": 1.491,
      "step": 176000
    },
    {
      "epoch": 0.44125,
      "grad_norm": 0.7525394558906555,
      "learning_rate": 6.573529411764706e-05,
      "loss": 1.4921,
      "step": 176500
    },
    {
      "epoch": 0.4425,
      "grad_norm": 0.6822799444198608,
      "learning_rate": 6.558823529411765e-05,
      "loss": 1.4884,
      "step": 177000
    },
    {
      "epoch": 0.44375,
      "grad_norm": 0.649639368057251,
      "learning_rate": 6.544117647058824e-05,
      "loss": 1.4874,
      "step": 177500
    },
    {
      "epoch": 0.445,
      "grad_norm": 0.620243489742279,
      "learning_rate": 6.529411764705883e-05,
      "loss": 1.4902,
      "step": 178000
    },
    {
      "epoch": 0.44625,
      "grad_norm": 0.5911624431610107,
      "learning_rate": 6.514705882352941e-05,
      "loss": 1.4863,
      "step": 178500
    },
    {
      "epoch": 0.4475,
      "grad_norm": 0.7231693267822266,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.4868,
      "step": 179000
    },
    {
      "epoch": 0.44875,
      "grad_norm": 0.6495659947395325,
      "learning_rate": 6.485294117647059e-05,
      "loss": 1.4853,
      "step": 179500
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7527486085891724,
      "learning_rate": 6.470588235294118e-05,
      "loss": 1.4919,
      "step": 180000
    },
    {
      "epoch": 0.45125,
      "grad_norm": 0.683658242225647,
      "learning_rate": 6.455882352941177e-05,
      "loss": 1.4884,
      "step": 180500
    },
    {
      "epoch": 0.4525,
      "grad_norm": 0.6728870272636414,
      "learning_rate": 6.441176470588236e-05,
      "loss": 1.4945,
      "step": 181000
    },
    {
      "epoch": 0.45375,
      "grad_norm": 0.6039154529571533,
      "learning_rate": 6.426470588235294e-05,
      "loss": 1.4846,
      "step": 181500
    },
    {
      "epoch": 0.455,
      "grad_norm": 0.7144126892089844,
      "learning_rate": 6.411764705882354e-05,
      "loss": 1.4941,
      "step": 182000
    },
    {
      "epoch": 0.45625,
      "grad_norm": 0.6731909513473511,
      "learning_rate": 6.397058823529412e-05,
      "loss": 1.4874,
      "step": 182500
    },
    {
      "epoch": 0.4575,
      "grad_norm": 0.5899732112884521,
      "learning_rate": 6.38235294117647e-05,
      "loss": 1.4871,
      "step": 183000
    },
    {
      "epoch": 0.45875,
      "grad_norm": 0.6897416114807129,
      "learning_rate": 6.36764705882353e-05,
      "loss": 1.4794,
      "step": 183500
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6190197467803955,
      "learning_rate": 6.352941176470588e-05,
      "loss": 1.4806,
      "step": 184000
    },
    {
      "epoch": 0.46125,
      "grad_norm": 0.6561251282691956,
      "learning_rate": 6.338235294117647e-05,
      "loss": 1.4825,
      "step": 184500
    },
    {
      "epoch": 0.4625,
      "grad_norm": 0.6397194266319275,
      "learning_rate": 6.323529411764705e-05,
      "loss": 1.4868,
      "step": 185000
    },
    {
      "epoch": 0.46375,
      "grad_norm": 0.6607552170753479,
      "learning_rate": 6.308823529411765e-05,
      "loss": 1.4844,
      "step": 185500
    },
    {
      "epoch": 0.465,
      "grad_norm": 0.6460170149803162,
      "learning_rate": 6.294117647058824e-05,
      "loss": 1.4781,
      "step": 186000
    },
    {
      "epoch": 0.46625,
      "grad_norm": 0.6848528385162354,
      "learning_rate": 6.279411764705882e-05,
      "loss": 1.4838,
      "step": 186500
    },
    {
      "epoch": 0.4675,
      "grad_norm": 0.6156576871871948,
      "learning_rate": 6.264705882352942e-05,
      "loss": 1.4865,
      "step": 187000
    },
    {
      "epoch": 0.46875,
      "grad_norm": 0.698315441608429,
      "learning_rate": 6.25e-05,
      "loss": 1.4842,
      "step": 187500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.7467146515846252,
      "learning_rate": 6.23529411764706e-05,
      "loss": 1.4692,
      "step": 188000
    },
    {
      "epoch": 0.47125,
      "grad_norm": 0.6484739184379578,
      "learning_rate": 6.220588235294118e-05,
      "loss": 1.4823,
      "step": 188500
    },
    {
      "epoch": 0.4725,
      "grad_norm": 0.7255105376243591,
      "learning_rate": 6.205882352941177e-05,
      "loss": 1.4795,
      "step": 189000
    },
    {
      "epoch": 0.47375,
      "grad_norm": 0.6873486042022705,
      "learning_rate": 6.191176470588235e-05,
      "loss": 1.4797,
      "step": 189500
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.652290403842926,
      "learning_rate": 6.176470588235295e-05,
      "loss": 1.4677,
      "step": 190000
    },
    {
      "epoch": 0.47625,
      "grad_norm": 0.7096394300460815,
      "learning_rate": 6.161764705882353e-05,
      "loss": 1.4763,
      "step": 190500
    },
    {
      "epoch": 0.4775,
      "grad_norm": 0.6716086864471436,
      "learning_rate": 6.147058823529413e-05,
      "loss": 1.4771,
      "step": 191000
    },
    {
      "epoch": 0.47875,
      "grad_norm": 0.7119430899620056,
      "learning_rate": 6.132352941176471e-05,
      "loss": 1.4724,
      "step": 191500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5888644456863403,
      "learning_rate": 6.11764705882353e-05,
      "loss": 1.4827,
      "step": 192000
    },
    {
      "epoch": 0.48125,
      "grad_norm": 0.697348952293396,
      "learning_rate": 6.102941176470589e-05,
      "loss": 1.4713,
      "step": 192500
    },
    {
      "epoch": 0.4825,
      "grad_norm": 0.7667014598846436,
      "learning_rate": 6.0882352941176465e-05,
      "loss": 1.4852,
      "step": 193000
    },
    {
      "epoch": 0.48375,
      "grad_norm": 0.6124850511550903,
      "learning_rate": 6.073529411764706e-05,
      "loss": 1.4719,
      "step": 193500
    },
    {
      "epoch": 0.485,
      "grad_norm": 0.6600767970085144,
      "learning_rate": 6.058823529411765e-05,
      "loss": 1.4723,
      "step": 194000
    },
    {
      "epoch": 0.48625,
      "grad_norm": 0.660106897354126,
      "learning_rate": 6.044117647058824e-05,
      "loss": 1.4717,
      "step": 194500
    },
    {
      "epoch": 0.4875,
      "grad_norm": 0.5847179889678955,
      "learning_rate": 6.0294117647058825e-05,
      "loss": 1.4745,
      "step": 195000
    },
    {
      "epoch": 0.48875,
      "grad_norm": 0.7387760281562805,
      "learning_rate": 6.014705882352941e-05,
      "loss": 1.478,
      "step": 195500
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6177048087120056,
      "learning_rate": 6e-05,
      "loss": 1.4774,
      "step": 196000
    },
    {
      "epoch": 0.49125,
      "grad_norm": 0.6283248066902161,
      "learning_rate": 5.985294117647059e-05,
      "loss": 1.4676,
      "step": 196500
    },
    {
      "epoch": 0.4925,
      "grad_norm": 0.744762659072876,
      "learning_rate": 5.970588235294118e-05,
      "loss": 1.4759,
      "step": 197000
    },
    {
      "epoch": 0.49375,
      "grad_norm": 0.6519237756729126,
      "learning_rate": 5.9558823529411766e-05,
      "loss": 1.4695,
      "step": 197500
    },
    {
      "epoch": 0.495,
      "grad_norm": 0.6921090483665466,
      "learning_rate": 5.9411764705882355e-05,
      "loss": 1.4714,
      "step": 198000
    },
    {
      "epoch": 0.49625,
      "grad_norm": 0.6538721919059753,
      "learning_rate": 5.926470588235294e-05,
      "loss": 1.4592,
      "step": 198500
    },
    {
      "epoch": 0.4975,
      "grad_norm": 0.6356940269470215,
      "learning_rate": 5.911764705882353e-05,
      "loss": 1.4713,
      "step": 199000
    },
    {
      "epoch": 0.49875,
      "grad_norm": 0.6360440254211426,
      "learning_rate": 5.897058823529412e-05,
      "loss": 1.4681,
      "step": 199500
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6653905510902405,
      "learning_rate": 5.882352941176471e-05,
      "loss": 1.4662,
      "step": 200000
    },
    {
      "epoch": 0.50125,
      "grad_norm": 0.731296718120575,
      "learning_rate": 5.86764705882353e-05,
      "loss": 1.4683,
      "step": 200500
    },
    {
      "epoch": 0.5025,
      "grad_norm": 0.656462550163269,
      "learning_rate": 5.852941176470589e-05,
      "loss": 1.4688,
      "step": 201000
    },
    {
      "epoch": 0.50375,
      "grad_norm": 0.7090157270431519,
      "learning_rate": 5.838235294117648e-05,
      "loss": 1.4599,
      "step": 201500
    },
    {
      "epoch": 0.505,
      "grad_norm": 0.5852875709533691,
      "learning_rate": 5.823529411764707e-05,
      "loss": 1.4652,
      "step": 202000
    },
    {
      "epoch": 0.50625,
      "grad_norm": 0.6492103934288025,
      "learning_rate": 5.8088235294117656e-05,
      "loss": 1.468,
      "step": 202500
    },
    {
      "epoch": 0.5075,
      "grad_norm": 0.7345753908157349,
      "learning_rate": 5.7941176470588244e-05,
      "loss": 1.4768,
      "step": 203000
    },
    {
      "epoch": 0.50875,
      "grad_norm": 0.7421537041664124,
      "learning_rate": 5.779411764705882e-05,
      "loss": 1.4608,
      "step": 203500
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6515030264854431,
      "learning_rate": 5.764705882352941e-05,
      "loss": 1.4648,
      "step": 204000
    },
    {
      "epoch": 0.51125,
      "grad_norm": 0.6711190938949585,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 1.4679,
      "step": 204500
    },
    {
      "epoch": 0.5125,
      "grad_norm": 0.6660329699516296,
      "learning_rate": 5.735294117647059e-05,
      "loss": 1.4679,
      "step": 205000
    },
    {
      "epoch": 0.51375,
      "grad_norm": 0.6942870616912842,
      "learning_rate": 5.720588235294118e-05,
      "loss": 1.4669,
      "step": 205500
    },
    {
      "epoch": 0.515,
      "grad_norm": 0.6801084280014038,
      "learning_rate": 5.7058823529411766e-05,
      "loss": 1.4671,
      "step": 206000
    },
    {
      "epoch": 0.51625,
      "grad_norm": 0.6354805827140808,
      "learning_rate": 5.6911764705882355e-05,
      "loss": 1.4624,
      "step": 206500
    },
    {
      "epoch": 0.5175,
      "grad_norm": 0.6586462259292603,
      "learning_rate": 5.676470588235294e-05,
      "loss": 1.464,
      "step": 207000
    },
    {
      "epoch": 0.51875,
      "grad_norm": 0.7765603065490723,
      "learning_rate": 5.661764705882353e-05,
      "loss": 1.4606,
      "step": 207500
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7787635326385498,
      "learning_rate": 5.647058823529412e-05,
      "loss": 1.4639,
      "step": 208000
    },
    {
      "epoch": 0.52125,
      "grad_norm": 0.7707017660140991,
      "learning_rate": 5.632352941176471e-05,
      "loss": 1.4678,
      "step": 208500
    },
    {
      "epoch": 0.5225,
      "grad_norm": 0.6879509687423706,
      "learning_rate": 5.6176470588235296e-05,
      "loss": 1.4554,
      "step": 209000
    },
    {
      "epoch": 0.52375,
      "grad_norm": 0.6731281876564026,
      "learning_rate": 5.6029411764705884e-05,
      "loss": 1.4628,
      "step": 209500
    },
    {
      "epoch": 0.525,
      "grad_norm": 0.6904767751693726,
      "learning_rate": 5.588235294117647e-05,
      "loss": 1.4588,
      "step": 210000
    },
    {
      "epoch": 0.52625,
      "grad_norm": 0.7730052471160889,
      "learning_rate": 5.573529411764706e-05,
      "loss": 1.4678,
      "step": 210500
    },
    {
      "epoch": 0.5275,
      "grad_norm": 0.6798396110534668,
      "learning_rate": 5.558823529411765e-05,
      "loss": 1.4598,
      "step": 211000
    },
    {
      "epoch": 0.52875,
      "grad_norm": 0.7277945280075073,
      "learning_rate": 5.5441176470588244e-05,
      "loss": 1.4554,
      "step": 211500
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.703272819519043,
      "learning_rate": 5.529411764705883e-05,
      "loss": 1.4617,
      "step": 212000
    },
    {
      "epoch": 0.53125,
      "grad_norm": 0.7693483233451843,
      "learning_rate": 5.514705882352942e-05,
      "loss": 1.4498,
      "step": 212500
    },
    {
      "epoch": 0.5325,
      "grad_norm": 0.6801632046699524,
      "learning_rate": 5.500000000000001e-05,
      "loss": 1.451,
      "step": 213000
    },
    {
      "epoch": 0.53375,
      "grad_norm": 0.7442557215690613,
      "learning_rate": 5.48529411764706e-05,
      "loss": 1.4613,
      "step": 213500
    },
    {
      "epoch": 0.535,
      "grad_norm": 0.6688953042030334,
      "learning_rate": 5.4705882352941185e-05,
      "loss": 1.4652,
      "step": 214000
    },
    {
      "epoch": 0.53625,
      "grad_norm": 0.7415958046913147,
      "learning_rate": 5.455882352941176e-05,
      "loss": 1.4618,
      "step": 214500
    },
    {
      "epoch": 0.5375,
      "grad_norm": 0.7197293639183044,
      "learning_rate": 5.441176470588235e-05,
      "loss": 1.4527,
      "step": 215000
    },
    {
      "epoch": 0.53875,
      "grad_norm": 0.694607675075531,
      "learning_rate": 5.4264705882352936e-05,
      "loss": 1.4598,
      "step": 215500
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6833911538124084,
      "learning_rate": 5.411764705882353e-05,
      "loss": 1.4555,
      "step": 216000
    },
    {
      "epoch": 0.54125,
      "grad_norm": 0.7306301593780518,
      "learning_rate": 5.397058823529412e-05,
      "loss": 1.4532,
      "step": 216500
    },
    {
      "epoch": 0.5425,
      "grad_norm": 0.7510893940925598,
      "learning_rate": 5.382352941176471e-05,
      "loss": 1.458,
      "step": 217000
    },
    {
      "epoch": 0.54375,
      "grad_norm": 0.7492392063140869,
      "learning_rate": 5.3676470588235296e-05,
      "loss": 1.454,
      "step": 217500
    },
    {
      "epoch": 0.545,
      "grad_norm": 0.6667763590812683,
      "learning_rate": 5.3529411764705884e-05,
      "loss": 1.458,
      "step": 218000
    },
    {
      "epoch": 0.54625,
      "grad_norm": 0.7444689273834229,
      "learning_rate": 5.338235294117647e-05,
      "loss": 1.4513,
      "step": 218500
    },
    {
      "epoch": 0.5475,
      "grad_norm": 0.7024514675140381,
      "learning_rate": 5.323529411764706e-05,
      "loss": 1.445,
      "step": 219000
    },
    {
      "epoch": 0.54875,
      "grad_norm": 0.6921144723892212,
      "learning_rate": 5.308823529411765e-05,
      "loss": 1.4572,
      "step": 219500
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7709452509880066,
      "learning_rate": 5.294117647058824e-05,
      "loss": 1.4583,
      "step": 220000
    },
    {
      "epoch": 0.55125,
      "grad_norm": 0.7790828943252563,
      "learning_rate": 5.2794117647058826e-05,
      "loss": 1.4533,
      "step": 220500
    },
    {
      "epoch": 0.5525,
      "grad_norm": 0.6645743250846863,
      "learning_rate": 5.2647058823529414e-05,
      "loss": 1.4457,
      "step": 221000
    },
    {
      "epoch": 0.55375,
      "grad_norm": 0.8014124631881714,
      "learning_rate": 5.25e-05,
      "loss": 1.4528,
      "step": 221500
    },
    {
      "epoch": 0.555,
      "grad_norm": 0.7944854497909546,
      "learning_rate": 5.235294117647059e-05,
      "loss": 1.4469,
      "step": 222000
    },
    {
      "epoch": 0.55625,
      "grad_norm": 0.6615886092185974,
      "learning_rate": 5.2205882352941185e-05,
      "loss": 1.4456,
      "step": 222500
    },
    {
      "epoch": 0.5575,
      "grad_norm": 0.8466673493385315,
      "learning_rate": 5.2058823529411774e-05,
      "loss": 1.4529,
      "step": 223000
    },
    {
      "epoch": 0.55875,
      "grad_norm": 0.7321516871452332,
      "learning_rate": 5.191176470588236e-05,
      "loss": 1.4533,
      "step": 223500
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7734034061431885,
      "learning_rate": 5.176470588235295e-05,
      "loss": 1.4493,
      "step": 224000
    },
    {
      "epoch": 0.56125,
      "grad_norm": 0.6833087801933289,
      "learning_rate": 5.161764705882354e-05,
      "loss": 1.4479,
      "step": 224500
    },
    {
      "epoch": 0.5625,
      "grad_norm": 0.6780627369880676,
      "learning_rate": 5.147058823529411e-05,
      "loss": 1.4458,
      "step": 225000
    },
    {
      "epoch": 0.56375,
      "grad_norm": 1.1911377906799316,
      "learning_rate": 5.13235294117647e-05,
      "loss": 1.4467,
      "step": 225500
    },
    {
      "epoch": 0.565,
      "grad_norm": 0.718559741973877,
      "learning_rate": 5.117647058823529e-05,
      "loss": 1.4471,
      "step": 226000
    },
    {
      "epoch": 0.56625,
      "grad_norm": 0.7020819783210754,
      "learning_rate": 5.102941176470588e-05,
      "loss": 1.4479,
      "step": 226500
    },
    {
      "epoch": 0.5675,
      "grad_norm": 0.7503483891487122,
      "learning_rate": 5.088235294117647e-05,
      "loss": 1.4478,
      "step": 227000
    },
    {
      "epoch": 0.56875,
      "grad_norm": 0.7083794474601746,
      "learning_rate": 5.073529411764706e-05,
      "loss": 1.4558,
      "step": 227500
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7215138077735901,
      "learning_rate": 5.058823529411765e-05,
      "loss": 1.4447,
      "step": 228000
    },
    {
      "epoch": 0.57125,
      "grad_norm": 0.7072402834892273,
      "learning_rate": 5.044117647058824e-05,
      "loss": 1.4408,
      "step": 228500
    },
    {
      "epoch": 0.5725,
      "grad_norm": 0.7038008570671082,
      "learning_rate": 5.0294117647058826e-05,
      "loss": 1.4463,
      "step": 229000
    },
    {
      "epoch": 0.57375,
      "grad_norm": 0.7331360578536987,
      "learning_rate": 5.0147058823529414e-05,
      "loss": 1.4444,
      "step": 229500
    },
    {
      "epoch": 0.575,
      "grad_norm": 0.6526581048965454,
      "learning_rate": 5e-05,
      "loss": 1.4357,
      "step": 230000
    },
    {
      "epoch": 0.57625,
      "grad_norm": 0.7225860357284546,
      "learning_rate": 4.985294117647059e-05,
      "loss": 1.4455,
      "step": 230500
    },
    {
      "epoch": 0.5775,
      "grad_norm": 0.7293485999107361,
      "learning_rate": 4.970588235294118e-05,
      "loss": 1.4415,
      "step": 231000
    },
    {
      "epoch": 0.57875,
      "grad_norm": 0.7562608122825623,
      "learning_rate": 4.955882352941177e-05,
      "loss": 1.4475,
      "step": 231500
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.7188650369644165,
      "learning_rate": 4.9411764705882355e-05,
      "loss": 1.4407,
      "step": 232000
    },
    {
      "epoch": 0.58125,
      "grad_norm": 0.8218415379524231,
      "learning_rate": 4.9264705882352944e-05,
      "loss": 1.4474,
      "step": 232500
    },
    {
      "epoch": 0.5825,
      "grad_norm": 0.6728047132492065,
      "learning_rate": 4.911764705882353e-05,
      "loss": 1.4418,
      "step": 233000
    },
    {
      "epoch": 0.58375,
      "grad_norm": 0.7783110737800598,
      "learning_rate": 4.897058823529412e-05,
      "loss": 1.4316,
      "step": 233500
    },
    {
      "epoch": 0.585,
      "grad_norm": 0.6794068813323975,
      "learning_rate": 4.882352941176471e-05,
      "loss": 1.43,
      "step": 234000
    },
    {
      "epoch": 0.58625,
      "grad_norm": 0.6625158786773682,
      "learning_rate": 4.86764705882353e-05,
      "loss": 1.4445,
      "step": 234500
    },
    {
      "epoch": 0.5875,
      "grad_norm": 0.7031813263893127,
      "learning_rate": 4.8529411764705885e-05,
      "loss": 1.4419,
      "step": 235000
    },
    {
      "epoch": 0.58875,
      "grad_norm": 0.7474039793014526,
      "learning_rate": 4.838235294117647e-05,
      "loss": 1.443,
      "step": 235500
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.650769054889679,
      "learning_rate": 4.823529411764706e-05,
      "loss": 1.4413,
      "step": 236000
    },
    {
      "epoch": 0.59125,
      "grad_norm": 0.811241626739502,
      "learning_rate": 4.808823529411765e-05,
      "loss": 1.4498,
      "step": 236500
    },
    {
      "epoch": 0.5925,
      "grad_norm": 0.7635902762413025,
      "learning_rate": 4.794117647058824e-05,
      "loss": 1.4279,
      "step": 237000
    },
    {
      "epoch": 0.59375,
      "grad_norm": 0.8200134634971619,
      "learning_rate": 4.7794117647058826e-05,
      "loss": 1.4392,
      "step": 237500
    },
    {
      "epoch": 0.595,
      "grad_norm": 0.7249804735183716,
      "learning_rate": 4.7647058823529414e-05,
      "loss": 1.4417,
      "step": 238000
    },
    {
      "epoch": 0.59625,
      "grad_norm": 0.6821783781051636,
      "learning_rate": 4.75e-05,
      "loss": 1.4387,
      "step": 238500
    },
    {
      "epoch": 0.5975,
      "grad_norm": 0.7130341529846191,
      "learning_rate": 4.735294117647059e-05,
      "loss": 1.4409,
      "step": 239000
    },
    {
      "epoch": 0.59875,
      "grad_norm": 0.6864373087882996,
      "learning_rate": 4.720588235294118e-05,
      "loss": 1.4364,
      "step": 239500
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7034333944320679,
      "learning_rate": 4.705882352941177e-05,
      "loss": 1.4371,
      "step": 240000
    },
    {
      "epoch": 0.60125,
      "grad_norm": 0.7369391918182373,
      "learning_rate": 4.6911764705882356e-05,
      "loss": 1.4347,
      "step": 240500
    },
    {
      "epoch": 0.6025,
      "grad_norm": 0.6927518844604492,
      "learning_rate": 4.6764705882352944e-05,
      "loss": 1.4455,
      "step": 241000
    },
    {
      "epoch": 0.60375,
      "grad_norm": 0.6760598421096802,
      "learning_rate": 4.661764705882353e-05,
      "loss": 1.442,
      "step": 241500
    },
    {
      "epoch": 0.605,
      "grad_norm": 0.7802419662475586,
      "learning_rate": 4.647058823529412e-05,
      "loss": 1.4392,
      "step": 242000
    },
    {
      "epoch": 0.60625,
      "grad_norm": 0.6802442073822021,
      "learning_rate": 4.632352941176471e-05,
      "loss": 1.4394,
      "step": 242500
    },
    {
      "epoch": 0.6075,
      "grad_norm": 0.6912106275558472,
      "learning_rate": 4.61764705882353e-05,
      "loss": 1.4371,
      "step": 243000
    },
    {
      "epoch": 0.60875,
      "grad_norm": 0.7063210606575012,
      "learning_rate": 4.6029411764705885e-05,
      "loss": 1.4357,
      "step": 243500
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7838940620422363,
      "learning_rate": 4.588235294117647e-05,
      "loss": 1.4326,
      "step": 244000
    },
    {
      "epoch": 0.61125,
      "grad_norm": 0.7392687201499939,
      "learning_rate": 4.573529411764706e-05,
      "loss": 1.4392,
      "step": 244500
    },
    {
      "epoch": 0.6125,
      "grad_norm": 0.730612576007843,
      "learning_rate": 4.558823529411765e-05,
      "loss": 1.4261,
      "step": 245000
    },
    {
      "epoch": 0.61375,
      "grad_norm": 0.6649684906005859,
      "learning_rate": 4.544117647058824e-05,
      "loss": 1.4478,
      "step": 245500
    },
    {
      "epoch": 0.615,
      "grad_norm": 0.8892157673835754,
      "learning_rate": 4.5294117647058826e-05,
      "loss": 1.4351,
      "step": 246000
    },
    {
      "epoch": 0.61625,
      "grad_norm": 0.6757807731628418,
      "learning_rate": 4.5147058823529415e-05,
      "loss": 1.4275,
      "step": 246500
    },
    {
      "epoch": 0.6175,
      "grad_norm": 0.7545003890991211,
      "learning_rate": 4.5e-05,
      "loss": 1.4253,
      "step": 247000
    },
    {
      "epoch": 0.61875,
      "grad_norm": 0.8012556433677673,
      "learning_rate": 4.485294117647059e-05,
      "loss": 1.4263,
      "step": 247500
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7278150320053101,
      "learning_rate": 4.470588235294118e-05,
      "loss": 1.4325,
      "step": 248000
    },
    {
      "epoch": 0.62125,
      "grad_norm": 0.667066752910614,
      "learning_rate": 4.455882352941177e-05,
      "loss": 1.4355,
      "step": 248500
    },
    {
      "epoch": 0.6225,
      "grad_norm": 0.7743713855743408,
      "learning_rate": 4.4411764705882356e-05,
      "loss": 1.4291,
      "step": 249000
    },
    {
      "epoch": 0.62375,
      "grad_norm": 0.7098279595375061,
      "learning_rate": 4.4264705882352944e-05,
      "loss": 1.4275,
      "step": 249500
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.8214651942253113,
      "learning_rate": 4.411764705882353e-05,
      "loss": 1.4274,
      "step": 250000
    },
    {
      "epoch": 0.62625,
      "grad_norm": 0.8480921983718872,
      "learning_rate": 4.397058823529412e-05,
      "loss": 1.437,
      "step": 250500
    },
    {
      "epoch": 0.6275,
      "grad_norm": 0.7272535562515259,
      "learning_rate": 4.382352941176471e-05,
      "loss": 1.4233,
      "step": 251000
    },
    {
      "epoch": 0.62875,
      "grad_norm": 0.7678875923156738,
      "learning_rate": 4.36764705882353e-05,
      "loss": 1.4214,
      "step": 251500
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.7683873176574707,
      "learning_rate": 4.3529411764705885e-05,
      "loss": 1.4242,
      "step": 252000
    },
    {
      "epoch": 0.63125,
      "grad_norm": 0.7298771142959595,
      "learning_rate": 4.3382352941176474e-05,
      "loss": 1.4192,
      "step": 252500
    },
    {
      "epoch": 0.6325,
      "grad_norm": 0.7192696928977966,
      "learning_rate": 4.323529411764706e-05,
      "loss": 1.4248,
      "step": 253000
    },
    {
      "epoch": 0.63375,
      "grad_norm": 0.683386504650116,
      "learning_rate": 4.308823529411765e-05,
      "loss": 1.4228,
      "step": 253500
    },
    {
      "epoch": 0.635,
      "grad_norm": 0.7911146879196167,
      "learning_rate": 4.294117647058823e-05,
      "loss": 1.4308,
      "step": 254000
    },
    {
      "epoch": 0.63625,
      "grad_norm": 0.7060739398002625,
      "learning_rate": 4.2794117647058827e-05,
      "loss": 1.4249,
      "step": 254500
    },
    {
      "epoch": 0.6375,
      "grad_norm": 0.7522207498550415,
      "learning_rate": 4.2647058823529415e-05,
      "loss": 1.4281,
      "step": 255000
    },
    {
      "epoch": 0.63875,
      "grad_norm": 0.6938052773475647,
      "learning_rate": 4.25e-05,
      "loss": 1.4269,
      "step": 255500
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7458187341690063,
      "learning_rate": 4.235294117647059e-05,
      "loss": 1.4265,
      "step": 256000
    },
    {
      "epoch": 0.64125,
      "grad_norm": 0.8289030194282532,
      "learning_rate": 4.220588235294118e-05,
      "loss": 1.4211,
      "step": 256500
    },
    {
      "epoch": 0.6425,
      "grad_norm": 0.7506473660469055,
      "learning_rate": 4.205882352941177e-05,
      "loss": 1.4284,
      "step": 257000
    },
    {
      "epoch": 0.64375,
      "grad_norm": 0.8449180126190186,
      "learning_rate": 4.1911764705882356e-05,
      "loss": 1.4247,
      "step": 257500
    },
    {
      "epoch": 0.645,
      "grad_norm": 0.8411017060279846,
      "learning_rate": 4.1764705882352944e-05,
      "loss": 1.4232,
      "step": 258000
    },
    {
      "epoch": 0.64625,
      "grad_norm": 0.7104800343513489,
      "learning_rate": 4.161764705882353e-05,
      "loss": 1.4251,
      "step": 258500
    },
    {
      "epoch": 0.6475,
      "grad_norm": 0.7222778797149658,
      "learning_rate": 4.147058823529412e-05,
      "loss": 1.4197,
      "step": 259000
    },
    {
      "epoch": 0.64875,
      "grad_norm": 0.7702180743217468,
      "learning_rate": 4.13235294117647e-05,
      "loss": 1.4241,
      "step": 259500
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7647685408592224,
      "learning_rate": 4.11764705882353e-05,
      "loss": 1.4241,
      "step": 260000
    },
    {
      "epoch": 0.65125,
      "grad_norm": 0.719399631023407,
      "learning_rate": 4.1029411764705886e-05,
      "loss": 1.4201,
      "step": 260500
    },
    {
      "epoch": 0.6525,
      "grad_norm": 0.8776978850364685,
      "learning_rate": 4.0882352941176474e-05,
      "loss": 1.4265,
      "step": 261000
    },
    {
      "epoch": 0.65375,
      "grad_norm": 0.7368889451026917,
      "learning_rate": 4.073529411764706e-05,
      "loss": 1.4124,
      "step": 261500
    },
    {
      "epoch": 0.655,
      "grad_norm": 0.8128510117530823,
      "learning_rate": 4.058823529411765e-05,
      "loss": 1.4348,
      "step": 262000
    },
    {
      "epoch": 0.65625,
      "grad_norm": 0.6924902200698853,
      "learning_rate": 4.044117647058824e-05,
      "loss": 1.4152,
      "step": 262500
    },
    {
      "epoch": 0.6575,
      "grad_norm": 0.7902345657348633,
      "learning_rate": 4.029411764705883e-05,
      "loss": 1.4254,
      "step": 263000
    },
    {
      "epoch": 0.65875,
      "grad_norm": 0.6731197237968445,
      "learning_rate": 4.0147058823529415e-05,
      "loss": 1.4221,
      "step": 263500
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6861028075218201,
      "learning_rate": 4e-05,
      "loss": 1.4213,
      "step": 264000
    },
    {
      "epoch": 0.66125,
      "grad_norm": 0.6781004667282104,
      "learning_rate": 3.985294117647059e-05,
      "loss": 1.4194,
      "step": 264500
    },
    {
      "epoch": 0.6625,
      "grad_norm": 0.6917858719825745,
      "learning_rate": 3.970588235294117e-05,
      "loss": 1.4133,
      "step": 265000
    },
    {
      "epoch": 0.66375,
      "grad_norm": 0.7468530535697937,
      "learning_rate": 3.955882352941177e-05,
      "loss": 1.4219,
      "step": 265500
    },
    {
      "epoch": 0.665,
      "grad_norm": 0.7323444485664368,
      "learning_rate": 3.9411764705882356e-05,
      "loss": 1.4283,
      "step": 266000
    },
    {
      "epoch": 0.66625,
      "grad_norm": 0.6199036836624146,
      "learning_rate": 3.9264705882352945e-05,
      "loss": 1.4238,
      "step": 266500
    },
    {
      "epoch": 0.6675,
      "grad_norm": 0.7856162190437317,
      "learning_rate": 3.911764705882353e-05,
      "loss": 1.421,
      "step": 267000
    },
    {
      "epoch": 0.66875,
      "grad_norm": 0.7883904576301575,
      "learning_rate": 3.897058823529412e-05,
      "loss": 1.4294,
      "step": 267500
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.7678534388542175,
      "learning_rate": 3.882352941176471e-05,
      "loss": 1.4202,
      "step": 268000
    },
    {
      "epoch": 0.67125,
      "grad_norm": 0.7759243249893188,
      "learning_rate": 3.86764705882353e-05,
      "loss": 1.4124,
      "step": 268500
    },
    {
      "epoch": 0.6725,
      "grad_norm": 0.7811341881752014,
      "learning_rate": 3.8529411764705886e-05,
      "loss": 1.4208,
      "step": 269000
    },
    {
      "epoch": 0.67375,
      "grad_norm": 0.6401872038841248,
      "learning_rate": 3.8382352941176474e-05,
      "loss": 1.4239,
      "step": 269500
    },
    {
      "epoch": 0.675,
      "grad_norm": 0.7601427435874939,
      "learning_rate": 3.8235294117647055e-05,
      "loss": 1.4166,
      "step": 270000
    },
    {
      "epoch": 0.67625,
      "grad_norm": 0.729737401008606,
      "learning_rate": 3.8088235294117644e-05,
      "loss": 1.4132,
      "step": 270500
    },
    {
      "epoch": 0.6775,
      "grad_norm": 0.6889140009880066,
      "learning_rate": 3.794117647058824e-05,
      "loss": 1.4199,
      "step": 271000
    },
    {
      "epoch": 0.67875,
      "grad_norm": 0.8022608160972595,
      "learning_rate": 3.779411764705883e-05,
      "loss": 1.4233,
      "step": 271500
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7131585478782654,
      "learning_rate": 3.7647058823529415e-05,
      "loss": 1.4086,
      "step": 272000
    },
    {
      "epoch": 0.68125,
      "grad_norm": 0.8424978256225586,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.4172,
      "step": 272500
    },
    {
      "epoch": 0.6825,
      "grad_norm": 0.7586402893066406,
      "learning_rate": 3.735294117647059e-05,
      "loss": 1.4106,
      "step": 273000
    },
    {
      "epoch": 0.68375,
      "grad_norm": 0.7778522968292236,
      "learning_rate": 3.720588235294118e-05,
      "loss": 1.4115,
      "step": 273500
    },
    {
      "epoch": 0.685,
      "grad_norm": 0.7107028961181641,
      "learning_rate": 3.705882352941177e-05,
      "loss": 1.4137,
      "step": 274000
    },
    {
      "epoch": 0.68625,
      "grad_norm": 0.8191181421279907,
      "learning_rate": 3.6911764705882356e-05,
      "loss": 1.4073,
      "step": 274500
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.7680035829544067,
      "learning_rate": 3.6764705882352945e-05,
      "loss": 1.4206,
      "step": 275000
    },
    {
      "epoch": 0.68875,
      "grad_norm": 0.7963287234306335,
      "learning_rate": 3.6617647058823526e-05,
      "loss": 1.4094,
      "step": 275500
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.790016233921051,
      "learning_rate": 3.6470588235294114e-05,
      "loss": 1.4149,
      "step": 276000
    },
    {
      "epoch": 0.69125,
      "grad_norm": 0.7618126273155212,
      "learning_rate": 3.632352941176471e-05,
      "loss": 1.4138,
      "step": 276500
    },
    {
      "epoch": 0.6925,
      "grad_norm": 0.7432742118835449,
      "learning_rate": 3.61764705882353e-05,
      "loss": 1.4173,
      "step": 277000
    },
    {
      "epoch": 0.69375,
      "grad_norm": 0.7141085267066956,
      "learning_rate": 3.6029411764705886e-05,
      "loss": 1.4131,
      "step": 277500
    },
    {
      "epoch": 0.695,
      "grad_norm": 0.6726090312004089,
      "learning_rate": 3.5882352941176474e-05,
      "loss": 1.4106,
      "step": 278000
    },
    {
      "epoch": 0.69625,
      "grad_norm": 0.8459693789482117,
      "learning_rate": 3.573529411764706e-05,
      "loss": 1.4128,
      "step": 278500
    },
    {
      "epoch": 0.6975,
      "grad_norm": 0.6387768387794495,
      "learning_rate": 3.558823529411765e-05,
      "loss": 1.4163,
      "step": 279000
    },
    {
      "epoch": 0.69875,
      "grad_norm": 0.735964834690094,
      "learning_rate": 3.544117647058824e-05,
      "loss": 1.4196,
      "step": 279500
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7564142942428589,
      "learning_rate": 3.529411764705883e-05,
      "loss": 1.416,
      "step": 280000
    },
    {
      "epoch": 0.70125,
      "grad_norm": 0.8112167716026306,
      "learning_rate": 3.514705882352941e-05,
      "loss": 1.4103,
      "step": 280500
    },
    {
      "epoch": 0.7025,
      "grad_norm": 0.7591849565505981,
      "learning_rate": 3.5e-05,
      "loss": 1.4105,
      "step": 281000
    },
    {
      "epoch": 0.70375,
      "grad_norm": 0.7916193604469299,
      "learning_rate": 3.4852941176470585e-05,
      "loss": 1.4216,
      "step": 281500
    },
    {
      "epoch": 0.705,
      "grad_norm": 0.8166086077690125,
      "learning_rate": 3.470588235294118e-05,
      "loss": 1.4101,
      "step": 282000
    },
    {
      "epoch": 0.70625,
      "grad_norm": 0.7288492918014526,
      "learning_rate": 3.455882352941177e-05,
      "loss": 1.4132,
      "step": 282500
    },
    {
      "epoch": 0.7075,
      "grad_norm": 0.7231442332267761,
      "learning_rate": 3.441176470588236e-05,
      "loss": 1.4123,
      "step": 283000
    },
    {
      "epoch": 0.70875,
      "grad_norm": 0.7551547884941101,
      "learning_rate": 3.4264705882352945e-05,
      "loss": 1.4081,
      "step": 283500
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7645693421363831,
      "learning_rate": 3.411764705882353e-05,
      "loss": 1.4117,
      "step": 284000
    },
    {
      "epoch": 0.71125,
      "grad_norm": 0.7610640525817871,
      "learning_rate": 3.397058823529412e-05,
      "loss": 1.4208,
      "step": 284500
    },
    {
      "epoch": 0.7125,
      "grad_norm": 0.8206674456596375,
      "learning_rate": 3.382352941176471e-05,
      "loss": 1.4052,
      "step": 285000
    },
    {
      "epoch": 0.71375,
      "grad_norm": 0.8130592703819275,
      "learning_rate": 3.36764705882353e-05,
      "loss": 1.4048,
      "step": 285500
    },
    {
      "epoch": 0.715,
      "grad_norm": 0.6746789813041687,
      "learning_rate": 3.352941176470588e-05,
      "loss": 1.4087,
      "step": 286000
    },
    {
      "epoch": 0.71625,
      "grad_norm": 0.8130680322647095,
      "learning_rate": 3.338235294117647e-05,
      "loss": 1.4138,
      "step": 286500
    },
    {
      "epoch": 0.7175,
      "grad_norm": 0.7136037945747375,
      "learning_rate": 3.3235294117647056e-05,
      "loss": 1.3995,
      "step": 287000
    },
    {
      "epoch": 0.71875,
      "grad_norm": 0.6908288598060608,
      "learning_rate": 3.308823529411765e-05,
      "loss": 1.4106,
      "step": 287500
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7552588582038879,
      "learning_rate": 3.294117647058824e-05,
      "loss": 1.4089,
      "step": 288000
    },
    {
      "epoch": 0.72125,
      "grad_norm": 0.8319130539894104,
      "learning_rate": 3.279411764705883e-05,
      "loss": 1.3999,
      "step": 288500
    },
    {
      "epoch": 0.7225,
      "grad_norm": 0.8377475142478943,
      "learning_rate": 3.2647058823529416e-05,
      "loss": 1.4047,
      "step": 289000
    },
    {
      "epoch": 0.72375,
      "grad_norm": 0.7393019795417786,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 1.4035,
      "step": 289500
    },
    {
      "epoch": 0.725,
      "grad_norm": 0.7632691264152527,
      "learning_rate": 3.235294117647059e-05,
      "loss": 1.4114,
      "step": 290000
    },
    {
      "epoch": 0.72625,
      "grad_norm": 0.7794134616851807,
      "learning_rate": 3.220588235294118e-05,
      "loss": 1.4072,
      "step": 290500
    },
    {
      "epoch": 0.7275,
      "grad_norm": 0.7369264364242554,
      "learning_rate": 3.205882352941177e-05,
      "loss": 1.4063,
      "step": 291000
    },
    {
      "epoch": 0.72875,
      "grad_norm": 0.8250718712806702,
      "learning_rate": 3.191176470588235e-05,
      "loss": 1.3992,
      "step": 291500
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.7881011962890625,
      "learning_rate": 3.176470588235294e-05,
      "loss": 1.4022,
      "step": 292000
    },
    {
      "epoch": 0.73125,
      "grad_norm": 0.7805868983268738,
      "learning_rate": 3.161764705882353e-05,
      "loss": 1.4012,
      "step": 292500
    },
    {
      "epoch": 0.7325,
      "grad_norm": 0.7155572772026062,
      "learning_rate": 3.147058823529412e-05,
      "loss": 1.403,
      "step": 293000
    },
    {
      "epoch": 0.73375,
      "grad_norm": 0.7696412801742554,
      "learning_rate": 3.132352941176471e-05,
      "loss": 1.4126,
      "step": 293500
    },
    {
      "epoch": 0.735,
      "grad_norm": 0.7980004549026489,
      "learning_rate": 3.11764705882353e-05,
      "loss": 1.4079,
      "step": 294000
    },
    {
      "epoch": 0.73625,
      "grad_norm": 0.7478122115135193,
      "learning_rate": 3.1029411764705886e-05,
      "loss": 1.4085,
      "step": 294500
    },
    {
      "epoch": 0.7375,
      "grad_norm": 0.721504807472229,
      "learning_rate": 3.0882352941176475e-05,
      "loss": 1.4045,
      "step": 295000
    },
    {
      "epoch": 0.73875,
      "grad_norm": 0.7599934339523315,
      "learning_rate": 3.073529411764706e-05,
      "loss": 1.4088,
      "step": 295500
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.7540886998176575,
      "learning_rate": 3.058823529411765e-05,
      "loss": 1.4043,
      "step": 296000
    },
    {
      "epoch": 0.74125,
      "grad_norm": 0.7633673548698425,
      "learning_rate": 3.0441176470588233e-05,
      "loss": 1.4046,
      "step": 296500
    },
    {
      "epoch": 0.7425,
      "grad_norm": 0.8029173016548157,
      "learning_rate": 3.0294117647058824e-05,
      "loss": 1.3948,
      "step": 297000
    },
    {
      "epoch": 0.74375,
      "grad_norm": 0.7814144492149353,
      "learning_rate": 3.0147058823529413e-05,
      "loss": 1.4023,
      "step": 297500
    },
    {
      "epoch": 0.745,
      "grad_norm": 0.7652077078819275,
      "learning_rate": 3e-05,
      "loss": 1.4107,
      "step": 298000
    },
    {
      "epoch": 0.74625,
      "grad_norm": 0.6495016813278198,
      "learning_rate": 2.985294117647059e-05,
      "loss": 1.4015,
      "step": 298500
    },
    {
      "epoch": 0.7475,
      "grad_norm": 0.8153008818626404,
      "learning_rate": 2.9705882352941177e-05,
      "loss": 1.3942,
      "step": 299000
    },
    {
      "epoch": 0.74875,
      "grad_norm": 0.7127251625061035,
      "learning_rate": 2.9558823529411766e-05,
      "loss": 1.4018,
      "step": 299500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7082922458648682,
      "learning_rate": 2.9411764705882354e-05,
      "loss": 1.4006,
      "step": 300000
    }
  ],
  "logging_steps": 500,
  "max_steps": 400000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6036379058176e+18,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
