{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5,
  "eval_steps": 500,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00125,
      "grad_norm": 0.39000874757766724,
      "learning_rate": 8.333333333333333e-07,
      "loss": 2.4167,
      "step": 500
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.44410091638565063,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 2.4164,
      "step": 1000
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.40500539541244507,
      "learning_rate": 2.5e-06,
      "loss": 2.4011,
      "step": 1500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.3969835340976715,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 2.4045,
      "step": 2000
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.44549962878227234,
      "learning_rate": 4.166666666666667e-06,
      "loss": 2.4001,
      "step": 2500
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.32723236083984375,
      "learning_rate": 5e-06,
      "loss": 2.3984,
      "step": 3000
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.34594646096229553,
      "learning_rate": 5.833333333333334e-06,
      "loss": 2.393,
      "step": 3500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3408016860485077,
      "learning_rate": 6.666666666666667e-06,
      "loss": 2.4101,
      "step": 4000
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.3256019651889801,
      "learning_rate": 7.5e-06,
      "loss": 2.3937,
      "step": 4500
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.3716220557689667,
      "learning_rate": 8.333333333333334e-06,
      "loss": 2.3866,
      "step": 5000
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.3793932795524597,
      "learning_rate": 9.166666666666666e-06,
      "loss": 2.376,
      "step": 5500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.3903319239616394,
      "learning_rate": 1e-05,
      "loss": 2.3687,
      "step": 6000
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.3552935719490051,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 2.376,
      "step": 6500
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.3378036618232727,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 2.3713,
      "step": 7000
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.3857060670852661,
      "learning_rate": 1.25e-05,
      "loss": 2.3792,
      "step": 7500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3405384421348572,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 2.3686,
      "step": 8000
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.38942721486091614,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 2.3757,
      "step": 8500
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.36850717663764954,
      "learning_rate": 1.5e-05,
      "loss": 2.3756,
      "step": 9000
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.39681366086006165,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 2.365,
      "step": 9500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.39718198776245117,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 2.3403,
      "step": 10000
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.40427714586257935,
      "learning_rate": 1.75e-05,
      "loss": 2.3505,
      "step": 10500
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.3567359745502472,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 2.3493,
      "step": 11000
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.38128820061683655,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 2.3522,
      "step": 11500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.34972527623176575,
      "learning_rate": 2e-05,
      "loss": 2.3233,
      "step": 12000
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.4104769825935364,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 2.3399,
      "step": 12500
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.3950975239276886,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 2.3365,
      "step": 13000
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.4626467823982239,
      "learning_rate": 2.25e-05,
      "loss": 2.3357,
      "step": 13500
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.4146314561367035,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 2.3228,
      "step": 14000
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.4733836054801941,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 2.3181,
      "step": 14500
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.4289213716983795,
      "learning_rate": 2.5e-05,
      "loss": 2.3193,
      "step": 15000
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.41862696409225464,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 2.308,
      "step": 15500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.419639527797699,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 2.3188,
      "step": 16000
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.4481818377971649,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 2.3129,
      "step": 16500
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.4415411651134491,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 2.319,
      "step": 17000
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.793889582157135,
      "learning_rate": 2.916666666666667e-05,
      "loss": 2.2984,
      "step": 17500
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.4177074730396271,
      "learning_rate": 3e-05,
      "loss": 2.3035,
      "step": 18000
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.46308910846710205,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 2.3012,
      "step": 18500
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.46766600012779236,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 2.2938,
      "step": 19000
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.4440237581729889,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 2.2943,
      "step": 19500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.410665899515152,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 2.2841,
      "step": 20000
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.49527159333229065,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 2.2759,
      "step": 20500
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.44913583993911743,
      "learning_rate": 3.5e-05,
      "loss": 2.2823,
      "step": 21000
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.4679615795612335,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 2.2763,
      "step": 21500
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.7596973180770874,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 2.2896,
      "step": 22000
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.5032433271408081,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 2.2766,
      "step": 22500
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.5460631847381592,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 2.2668,
      "step": 23000
    },
    {
      "epoch": 0.05875,
      "grad_norm": 0.44186636805534363,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 2.2732,
      "step": 23500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.516755223274231,
      "learning_rate": 4e-05,
      "loss": 2.2474,
      "step": 24000
    },
    {
      "epoch": 0.06125,
      "grad_norm": 0.6196421980857849,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 2.2617,
      "step": 24500
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.493625283241272,
      "learning_rate": 4.166666666666667e-05,
      "loss": 2.2521,
      "step": 25000
    },
    {
      "epoch": 0.06375,
      "grad_norm": 0.5096957683563232,
      "learning_rate": 4.25e-05,
      "loss": 2.2535,
      "step": 25500
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.4641215205192566,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 2.2623,
      "step": 26000
    },
    {
      "epoch": 0.06625,
      "grad_norm": 0.5439990162849426,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 2.2319,
      "step": 26500
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.5118359923362732,
      "learning_rate": 4.5e-05,
      "loss": 2.2384,
      "step": 27000
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.598252534866333,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 2.2314,
      "step": 27500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5931293368339539,
      "learning_rate": 4.666666666666667e-05,
      "loss": 2.2338,
      "step": 28000
    },
    {
      "epoch": 0.07125,
      "grad_norm": 0.5928198099136353,
      "learning_rate": 4.75e-05,
      "loss": 2.2217,
      "step": 28500
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.5715587139129639,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 2.2111,
      "step": 29000
    },
    {
      "epoch": 0.07375,
      "grad_norm": 0.5703795552253723,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 2.2165,
      "step": 29500
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.618956983089447,
      "learning_rate": 5e-05,
      "loss": 2.2058,
      "step": 30000
    },
    {
      "epoch": 0.07625,
      "grad_norm": 0.6187016367912292,
      "learning_rate": 5.0833333333333333e-05,
      "loss": 2.2253,
      "step": 30500
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.5512288808822632,
      "learning_rate": 5.166666666666667e-05,
      "loss": 2.2104,
      "step": 31000
    },
    {
      "epoch": 0.07875,
      "grad_norm": 0.5686080455780029,
      "learning_rate": 5.25e-05,
      "loss": 2.2077,
      "step": 31500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5892578959465027,
      "learning_rate": 5.333333333333333e-05,
      "loss": 2.1996,
      "step": 32000
    },
    {
      "epoch": 0.08125,
      "grad_norm": 0.6637934446334839,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 2.1934,
      "step": 32500
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.6596947312355042,
      "learning_rate": 5.500000000000001e-05,
      "loss": 2.1977,
      "step": 33000
    },
    {
      "epoch": 0.08375,
      "grad_norm": 0.6747428774833679,
      "learning_rate": 5.583333333333334e-05,
      "loss": 2.202,
      "step": 33500
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.5030443072319031,
      "learning_rate": 5.666666666666667e-05,
      "loss": 2.1949,
      "step": 34000
    },
    {
      "epoch": 0.08625,
      "grad_norm": 0.6172025203704834,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 2.1801,
      "step": 34500
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.5700587630271912,
      "learning_rate": 5.833333333333334e-05,
      "loss": 2.1767,
      "step": 35000
    },
    {
      "epoch": 0.08875,
      "grad_norm": 0.6840999722480774,
      "learning_rate": 5.916666666666667e-05,
      "loss": 2.1762,
      "step": 35500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6216360330581665,
      "learning_rate": 6e-05,
      "loss": 2.1647,
      "step": 36000
    },
    {
      "epoch": 0.09125,
      "grad_norm": 0.7202151417732239,
      "learning_rate": 6.083333333333333e-05,
      "loss": 2.172,
      "step": 36500
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.5861029028892517,
      "learning_rate": 6.166666666666667e-05,
      "loss": 2.1554,
      "step": 37000
    },
    {
      "epoch": 0.09375,
      "grad_norm": 0.649280846118927,
      "learning_rate": 6.25e-05,
      "loss": 2.1613,
      "step": 37500
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.6271123886108398,
      "learning_rate": 6.333333333333333e-05,
      "loss": 2.1599,
      "step": 38000
    },
    {
      "epoch": 0.09625,
      "grad_norm": 0.7024701237678528,
      "learning_rate": 6.416666666666668e-05,
      "loss": 2.146,
      "step": 38500
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.7576414346694946,
      "learning_rate": 6.500000000000001e-05,
      "loss": 2.1521,
      "step": 39000
    },
    {
      "epoch": 0.09875,
      "grad_norm": 0.661640465259552,
      "learning_rate": 6.583333333333334e-05,
      "loss": 2.1398,
      "step": 39500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.671981155872345,
      "learning_rate": 6.666666666666667e-05,
      "loss": 2.1323,
      "step": 40000
    },
    {
      "epoch": 0.10125,
      "grad_norm": 0.7591303586959839,
      "learning_rate": 6.750000000000001e-05,
      "loss": 2.1309,
      "step": 40500
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.7360257506370544,
      "learning_rate": 6.833333333333333e-05,
      "loss": 2.1328,
      "step": 41000
    },
    {
      "epoch": 0.10375,
      "grad_norm": 0.8561615347862244,
      "learning_rate": 6.916666666666666e-05,
      "loss": 2.127,
      "step": 41500
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.64764004945755,
      "learning_rate": 7e-05,
      "loss": 2.1272,
      "step": 42000
    },
    {
      "epoch": 0.10625,
      "grad_norm": 0.6324719190597534,
      "learning_rate": 7.083333333333334e-05,
      "loss": 2.1142,
      "step": 42500
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.8020241856575012,
      "learning_rate": 7.166666666666667e-05,
      "loss": 2.1182,
      "step": 43000
    },
    {
      "epoch": 0.10875,
      "grad_norm": 0.7293859720230103,
      "learning_rate": 7.25e-05,
      "loss": 2.1332,
      "step": 43500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7374685406684875,
      "learning_rate": 7.333333333333333e-05,
      "loss": 2.1016,
      "step": 44000
    },
    {
      "epoch": 0.11125,
      "grad_norm": 0.679916262626648,
      "learning_rate": 7.416666666666668e-05,
      "loss": 2.1082,
      "step": 44500
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.6835933327674866,
      "learning_rate": 7.500000000000001e-05,
      "loss": 2.0854,
      "step": 45000
    },
    {
      "epoch": 0.11375,
      "grad_norm": 0.8828842639923096,
      "learning_rate": 7.583333333333334e-05,
      "loss": 2.0986,
      "step": 45500
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.7658889889717102,
      "learning_rate": 7.666666666666667e-05,
      "loss": 2.0998,
      "step": 46000
    },
    {
      "epoch": 0.11625,
      "grad_norm": 0.7160007357597351,
      "learning_rate": 7.75e-05,
      "loss": 2.0929,
      "step": 46500
    },
    {
      "epoch": 0.1175,
      "grad_norm": 0.6835601925849915,
      "learning_rate": 7.833333333333333e-05,
      "loss": 2.0855,
      "step": 47000
    },
    {
      "epoch": 0.11875,
      "grad_norm": 0.8021605610847473,
      "learning_rate": 7.916666666666666e-05,
      "loss": 2.0811,
      "step": 47500
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.864739179611206,
      "learning_rate": 8e-05,
      "loss": 2.0726,
      "step": 48000
    },
    {
      "epoch": 0.12125,
      "grad_norm": 0.7499279379844666,
      "learning_rate": 8.083333333333334e-05,
      "loss": 2.0682,
      "step": 48500
    },
    {
      "epoch": 0.1225,
      "grad_norm": 0.7309730052947998,
      "learning_rate": 8.166666666666667e-05,
      "loss": 2.0733,
      "step": 49000
    },
    {
      "epoch": 0.12375,
      "grad_norm": 0.7929873466491699,
      "learning_rate": 8.25e-05,
      "loss": 2.0586,
      "step": 49500
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.8867877125740051,
      "learning_rate": 8.333333333333334e-05,
      "loss": 2.055,
      "step": 50000
    },
    {
      "epoch": 0.12625,
      "grad_norm": 0.8847347497940063,
      "learning_rate": 8.416666666666668e-05,
      "loss": 2.0414,
      "step": 50500
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.7903715968132019,
      "learning_rate": 8.5e-05,
      "loss": 2.0369,
      "step": 51000
    },
    {
      "epoch": 0.12875,
      "grad_norm": 0.8767091035842896,
      "learning_rate": 8.583333333333334e-05,
      "loss": 2.0426,
      "step": 51500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8719074130058289,
      "learning_rate": 8.666666666666667e-05,
      "loss": 2.0418,
      "step": 52000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 0.8383377194404602,
      "learning_rate": 8.75e-05,
      "loss": 2.0301,
      "step": 52500
    },
    {
      "epoch": 0.1325,
      "grad_norm": 0.8405119180679321,
      "learning_rate": 8.833333333333333e-05,
      "loss": 2.0361,
      "step": 53000
    },
    {
      "epoch": 0.13375,
      "grad_norm": 0.9440180063247681,
      "learning_rate": 8.916666666666667e-05,
      "loss": 2.0315,
      "step": 53500
    },
    {
      "epoch": 0.135,
      "grad_norm": 0.7790144681930542,
      "learning_rate": 9e-05,
      "loss": 2.0209,
      "step": 54000
    },
    {
      "epoch": 0.13625,
      "grad_norm": 0.8390317559242249,
      "learning_rate": 9.083333333333334e-05,
      "loss": 2.0201,
      "step": 54500
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.9158203601837158,
      "learning_rate": 9.166666666666667e-05,
      "loss": 2.0123,
      "step": 55000
    },
    {
      "epoch": 0.13875,
      "grad_norm": 0.8356723785400391,
      "learning_rate": 9.250000000000001e-05,
      "loss": 2.0256,
      "step": 55500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9133366346359253,
      "learning_rate": 9.333333333333334e-05,
      "loss": 2.0112,
      "step": 56000
    },
    {
      "epoch": 0.14125,
      "grad_norm": 0.8175301551818848,
      "learning_rate": 9.416666666666667e-05,
      "loss": 1.9966,
      "step": 56500
    },
    {
      "epoch": 0.1425,
      "grad_norm": 0.8424699306488037,
      "learning_rate": 9.5e-05,
      "loss": 1.9994,
      "step": 57000
    },
    {
      "epoch": 0.14375,
      "grad_norm": 0.8670860528945923,
      "learning_rate": 9.583333333333334e-05,
      "loss": 1.9819,
      "step": 57500
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.8265008330345154,
      "learning_rate": 9.666666666666667e-05,
      "loss": 1.9969,
      "step": 58000
    },
    {
      "epoch": 0.14625,
      "grad_norm": 1.1044143438339233,
      "learning_rate": 9.75e-05,
      "loss": 1.9912,
      "step": 58500
    },
    {
      "epoch": 0.1475,
      "grad_norm": 0.9514445066452026,
      "learning_rate": 9.833333333333333e-05,
      "loss": 1.9873,
      "step": 59000
    },
    {
      "epoch": 0.14875,
      "grad_norm": 0.8930433392524719,
      "learning_rate": 9.916666666666667e-05,
      "loss": 1.982,
      "step": 59500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8946710824966431,
      "learning_rate": 0.0001,
      "loss": 1.9766,
      "step": 60000
    },
    {
      "epoch": 0.15125,
      "grad_norm": 0.978153645992279,
      "learning_rate": 9.98529411764706e-05,
      "loss": 1.9584,
      "step": 60500
    },
    {
      "epoch": 0.1525,
      "grad_norm": 0.9144182801246643,
      "learning_rate": 9.970588235294118e-05,
      "loss": 1.9742,
      "step": 61000
    },
    {
      "epoch": 0.15375,
      "grad_norm": 1.1770414113998413,
      "learning_rate": 9.955882352941178e-05,
      "loss": 1.9543,
      "step": 61500
    },
    {
      "epoch": 0.155,
      "grad_norm": 0.9137902855873108,
      "learning_rate": 9.941176470588236e-05,
      "loss": 1.9429,
      "step": 62000
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.9435402750968933,
      "learning_rate": 9.926470588235295e-05,
      "loss": 1.9545,
      "step": 62500
    },
    {
      "epoch": 0.1575,
      "grad_norm": 1.0515755414962769,
      "learning_rate": 9.911764705882353e-05,
      "loss": 1.9496,
      "step": 63000
    },
    {
      "epoch": 0.15875,
      "grad_norm": 1.012694001197815,
      "learning_rate": 9.897058823529413e-05,
      "loss": 1.9213,
      "step": 63500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9743204712867737,
      "learning_rate": 9.882352941176471e-05,
      "loss": 1.9325,
      "step": 64000
    },
    {
      "epoch": 0.16125,
      "grad_norm": 0.9215143918991089,
      "learning_rate": 9.86764705882353e-05,
      "loss": 1.9336,
      "step": 64500
    },
    {
      "epoch": 0.1625,
      "grad_norm": 1.0017160177230835,
      "learning_rate": 9.852941176470589e-05,
      "loss": 1.9432,
      "step": 65000
    },
    {
      "epoch": 0.16375,
      "grad_norm": 0.862436830997467,
      "learning_rate": 9.838235294117647e-05,
      "loss": 1.928,
      "step": 65500
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.8925819396972656,
      "learning_rate": 9.823529411764706e-05,
      "loss": 1.9383,
      "step": 66000
    },
    {
      "epoch": 0.16625,
      "grad_norm": 0.9965906739234924,
      "learning_rate": 9.808823529411765e-05,
      "loss": 1.9112,
      "step": 66500
    },
    {
      "epoch": 0.1675,
      "grad_norm": 0.8942884802818298,
      "learning_rate": 9.794117647058824e-05,
      "loss": 1.9095,
      "step": 67000
    },
    {
      "epoch": 0.16875,
      "grad_norm": 0.9694908857345581,
      "learning_rate": 9.779411764705882e-05,
      "loss": 1.9131,
      "step": 67500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.916976273059845,
      "learning_rate": 9.764705882352942e-05,
      "loss": 1.9051,
      "step": 68000
    },
    {
      "epoch": 0.17125,
      "grad_norm": 0.9463788270950317,
      "learning_rate": 9.75e-05,
      "loss": 1.8904,
      "step": 68500
    },
    {
      "epoch": 0.1725,
      "grad_norm": 0.9563900232315063,
      "learning_rate": 9.73529411764706e-05,
      "loss": 1.8982,
      "step": 69000
    },
    {
      "epoch": 0.17375,
      "grad_norm": 0.972739577293396,
      "learning_rate": 9.720588235294117e-05,
      "loss": 1.8992,
      "step": 69500
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.9116532802581787,
      "learning_rate": 9.705882352941177e-05,
      "loss": 1.8955,
      "step": 70000
    },
    {
      "epoch": 0.17625,
      "grad_norm": 1.0523061752319336,
      "learning_rate": 9.691176470588235e-05,
      "loss": 1.8866,
      "step": 70500
    },
    {
      "epoch": 0.1775,
      "grad_norm": 1.0500668287277222,
      "learning_rate": 9.676470588235295e-05,
      "loss": 1.8745,
      "step": 71000
    },
    {
      "epoch": 0.17875,
      "grad_norm": 0.9138516783714294,
      "learning_rate": 9.661764705882354e-05,
      "loss": 1.8832,
      "step": 71500
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9562064409255981,
      "learning_rate": 9.647058823529412e-05,
      "loss": 1.8711,
      "step": 72000
    },
    {
      "epoch": 0.18125,
      "grad_norm": 0.8909802436828613,
      "learning_rate": 9.632352941176472e-05,
      "loss": 1.8703,
      "step": 72500
    },
    {
      "epoch": 0.1825,
      "grad_norm": 0.9541177153587341,
      "learning_rate": 9.61764705882353e-05,
      "loss": 1.8594,
      "step": 73000
    },
    {
      "epoch": 0.18375,
      "grad_norm": 0.9948700666427612,
      "learning_rate": 9.60294117647059e-05,
      "loss": 1.8528,
      "step": 73500
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.9724647402763367,
      "learning_rate": 9.588235294117648e-05,
      "loss": 1.8572,
      "step": 74000
    },
    {
      "epoch": 0.18625,
      "grad_norm": 0.9322614073753357,
      "learning_rate": 9.573529411764707e-05,
      "loss": 1.8604,
      "step": 74500
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.045066237449646,
      "learning_rate": 9.558823529411765e-05,
      "loss": 1.8542,
      "step": 75000
    },
    {
      "epoch": 0.18875,
      "grad_norm": 1.015150547027588,
      "learning_rate": 9.544117647058825e-05,
      "loss": 1.851,
      "step": 75500
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9660903811454773,
      "learning_rate": 9.529411764705883e-05,
      "loss": 1.8444,
      "step": 76000
    },
    {
      "epoch": 0.19125,
      "grad_norm": 1.0501844882965088,
      "learning_rate": 9.514705882352941e-05,
      "loss": 1.8477,
      "step": 76500
    },
    {
      "epoch": 0.1925,
      "grad_norm": 1.02764892578125,
      "learning_rate": 9.5e-05,
      "loss": 1.8457,
      "step": 77000
    },
    {
      "epoch": 0.19375,
      "grad_norm": 0.9321575164794922,
      "learning_rate": 9.485294117647059e-05,
      "loss": 1.8337,
      "step": 77500
    },
    {
      "epoch": 0.195,
      "grad_norm": 1.0160561800003052,
      "learning_rate": 9.470588235294118e-05,
      "loss": 1.8404,
      "step": 78000
    },
    {
      "epoch": 0.19625,
      "grad_norm": 0.9375886917114258,
      "learning_rate": 9.455882352941176e-05,
      "loss": 1.8315,
      "step": 78500
    },
    {
      "epoch": 0.1975,
      "grad_norm": 1.0671569108963013,
      "learning_rate": 9.441176470588236e-05,
      "loss": 1.8438,
      "step": 79000
    },
    {
      "epoch": 0.19875,
      "grad_norm": 1.0721641778945923,
      "learning_rate": 9.426470588235294e-05,
      "loss": 1.8098,
      "step": 79500
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1039398908615112,
      "learning_rate": 9.411764705882353e-05,
      "loss": 1.8275,
      "step": 80000
    },
    {
      "epoch": 0.20125,
      "grad_norm": 1.041576862335205,
      "learning_rate": 9.397058823529412e-05,
      "loss": 1.8071,
      "step": 80500
    },
    {
      "epoch": 0.2025,
      "grad_norm": 1.024476408958435,
      "learning_rate": 9.382352941176471e-05,
      "loss": 1.8101,
      "step": 81000
    },
    {
      "epoch": 0.20375,
      "grad_norm": 0.9767258763313293,
      "learning_rate": 9.367647058823529e-05,
      "loss": 1.8039,
      "step": 81500
    },
    {
      "epoch": 0.205,
      "grad_norm": 0.9720264673233032,
      "learning_rate": 9.352941176470589e-05,
      "loss": 1.797,
      "step": 82000
    },
    {
      "epoch": 0.20625,
      "grad_norm": 1.0194815397262573,
      "learning_rate": 9.338235294117648e-05,
      "loss": 1.8116,
      "step": 82500
    },
    {
      "epoch": 0.2075,
      "grad_norm": 0.986888587474823,
      "learning_rate": 9.323529411764706e-05,
      "loss": 1.8084,
      "step": 83000
    },
    {
      "epoch": 0.20875,
      "grad_norm": 0.9781721234321594,
      "learning_rate": 9.308823529411766e-05,
      "loss": 1.7985,
      "step": 83500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8984109163284302,
      "learning_rate": 9.294117647058824e-05,
      "loss": 1.7942,
      "step": 84000
    },
    {
      "epoch": 0.21125,
      "grad_norm": 1.014492392539978,
      "learning_rate": 9.279411764705884e-05,
      "loss": 1.7904,
      "step": 84500
    },
    {
      "epoch": 0.2125,
      "grad_norm": 1.0845412015914917,
      "learning_rate": 9.264705882352942e-05,
      "loss": 1.7981,
      "step": 85000
    },
    {
      "epoch": 0.21375,
      "grad_norm": 1.0997451543807983,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.7848,
      "step": 85500
    },
    {
      "epoch": 0.215,
      "grad_norm": 1.0529890060424805,
      "learning_rate": 9.23529411764706e-05,
      "loss": 1.7875,
      "step": 86000
    },
    {
      "epoch": 0.21625,
      "grad_norm": 1.0791754722595215,
      "learning_rate": 9.220588235294119e-05,
      "loss": 1.7845,
      "step": 86500
    },
    {
      "epoch": 0.2175,
      "grad_norm": 1.0399417877197266,
      "learning_rate": 9.205882352941177e-05,
      "loss": 1.7581,
      "step": 87000
    },
    {
      "epoch": 0.21875,
      "grad_norm": 0.9346699118614197,
      "learning_rate": 9.191176470588235e-05,
      "loss": 1.7783,
      "step": 87500
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1432490348815918,
      "learning_rate": 9.176470588235295e-05,
      "loss": 1.7666,
      "step": 88000
    },
    {
      "epoch": 0.22125,
      "grad_norm": 1.106044054031372,
      "learning_rate": 9.161764705882353e-05,
      "loss": 1.759,
      "step": 88500
    },
    {
      "epoch": 0.2225,
      "grad_norm": 1.027612328529358,
      "learning_rate": 9.147058823529412e-05,
      "loss": 1.7557,
      "step": 89000
    },
    {
      "epoch": 0.22375,
      "grad_norm": 1.1359015703201294,
      "learning_rate": 9.13235294117647e-05,
      "loss": 1.7635,
      "step": 89500
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.0556362867355347,
      "learning_rate": 9.11764705882353e-05,
      "loss": 1.7469,
      "step": 90000
    },
    {
      "epoch": 0.22625,
      "grad_norm": 1.028706431388855,
      "learning_rate": 9.102941176470588e-05,
      "loss": 1.7582,
      "step": 90500
    },
    {
      "epoch": 0.2275,
      "grad_norm": 1.070878028869629,
      "learning_rate": 9.088235294117648e-05,
      "loss": 1.7561,
      "step": 91000
    },
    {
      "epoch": 0.22875,
      "grad_norm": 1.080575942993164,
      "learning_rate": 9.073529411764706e-05,
      "loss": 1.7405,
      "step": 91500
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.0579909086227417,
      "learning_rate": 9.058823529411765e-05,
      "loss": 1.7363,
      "step": 92000
    },
    {
      "epoch": 0.23125,
      "grad_norm": 1.1837505102157593,
      "learning_rate": 9.044117647058823e-05,
      "loss": 1.7478,
      "step": 92500
    },
    {
      "epoch": 0.2325,
      "grad_norm": 1.0014238357543945,
      "learning_rate": 9.029411764705883e-05,
      "loss": 1.7428,
      "step": 93000
    },
    {
      "epoch": 0.23375,
      "grad_norm": 0.9871286749839783,
      "learning_rate": 9.014705882352942e-05,
      "loss": 1.7482,
      "step": 93500
    },
    {
      "epoch": 0.235,
      "grad_norm": 1.390264868736267,
      "learning_rate": 9e-05,
      "loss": 1.7462,
      "step": 94000
    },
    {
      "epoch": 0.23625,
      "grad_norm": 1.0838748216629028,
      "learning_rate": 8.98529411764706e-05,
      "loss": 1.7342,
      "step": 94500
    },
    {
      "epoch": 0.2375,
      "grad_norm": 1.0372405052185059,
      "learning_rate": 8.970588235294118e-05,
      "loss": 1.7323,
      "step": 95000
    },
    {
      "epoch": 0.23875,
      "grad_norm": 0.9445640444755554,
      "learning_rate": 8.955882352941178e-05,
      "loss": 1.7314,
      "step": 95500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9658527970314026,
      "learning_rate": 8.941176470588236e-05,
      "loss": 1.7185,
      "step": 96000
    },
    {
      "epoch": 0.24125,
      "grad_norm": 0.9910315871238708,
      "learning_rate": 8.926470588235295e-05,
      "loss": 1.728,
      "step": 96500
    },
    {
      "epoch": 0.2425,
      "grad_norm": 1.1893759965896606,
      "learning_rate": 8.911764705882354e-05,
      "loss": 1.709,
      "step": 97000
    },
    {
      "epoch": 0.24375,
      "grad_norm": 1.1421886682510376,
      "learning_rate": 8.897058823529412e-05,
      "loss": 1.7191,
      "step": 97500
    },
    {
      "epoch": 0.245,
      "grad_norm": 1.0963413715362549,
      "learning_rate": 8.882352941176471e-05,
      "loss": 1.7191,
      "step": 98000
    },
    {
      "epoch": 0.24625,
      "grad_norm": 0.9998875260353088,
      "learning_rate": 8.867647058823529e-05,
      "loss": 1.7116,
      "step": 98500
    },
    {
      "epoch": 0.2475,
      "grad_norm": 1.0751873254776,
      "learning_rate": 8.852941176470589e-05,
      "loss": 1.6974,
      "step": 99000
    },
    {
      "epoch": 0.24875,
      "grad_norm": 1.017346978187561,
      "learning_rate": 8.838235294117647e-05,
      "loss": 1.725,
      "step": 99500
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0553008317947388,
      "learning_rate": 8.823529411764706e-05,
      "loss": 1.7156,
      "step": 100000
    },
    {
      "epoch": 0.25125,
      "grad_norm": 1.0304749011993408,
      "learning_rate": 8.808823529411765e-05,
      "loss": 1.6996,
      "step": 100500
    },
    {
      "epoch": 0.2525,
      "grad_norm": 1.186552882194519,
      "learning_rate": 8.794117647058824e-05,
      "loss": 1.7029,
      "step": 101000
    },
    {
      "epoch": 0.25375,
      "grad_norm": 1.0511555671691895,
      "learning_rate": 8.779411764705882e-05,
      "loss": 1.6941,
      "step": 101500
    },
    {
      "epoch": 0.255,
      "grad_norm": 1.0798434019088745,
      "learning_rate": 8.764705882352942e-05,
      "loss": 1.6877,
      "step": 102000
    },
    {
      "epoch": 0.25625,
      "grad_norm": 1.1078752279281616,
      "learning_rate": 8.75e-05,
      "loss": 1.6847,
      "step": 102500
    },
    {
      "epoch": 0.2575,
      "grad_norm": 1.067064881324768,
      "learning_rate": 8.73529411764706e-05,
      "loss": 1.6777,
      "step": 103000
    },
    {
      "epoch": 0.25875,
      "grad_norm": 0.9740029573440552,
      "learning_rate": 8.720588235294118e-05,
      "loss": 1.6912,
      "step": 103500
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0660477876663208,
      "learning_rate": 8.705882352941177e-05,
      "loss": 1.6859,
      "step": 104000
    },
    {
      "epoch": 0.26125,
      "grad_norm": 1.1685421466827393,
      "learning_rate": 8.691176470588237e-05,
      "loss": 1.6906,
      "step": 104500
    },
    {
      "epoch": 0.2625,
      "grad_norm": 1.1268665790557861,
      "learning_rate": 8.676470588235295e-05,
      "loss": 1.6841,
      "step": 105000
    },
    {
      "epoch": 0.26375,
      "grad_norm": 1.118638515472412,
      "learning_rate": 8.661764705882354e-05,
      "loss": 1.6824,
      "step": 105500
    },
    {
      "epoch": 0.265,
      "grad_norm": 1.068849802017212,
      "learning_rate": 8.647058823529412e-05,
      "loss": 1.6752,
      "step": 106000
    },
    {
      "epoch": 0.26625,
      "grad_norm": 1.0309923887252808,
      "learning_rate": 8.632352941176472e-05,
      "loss": 1.6642,
      "step": 106500
    },
    {
      "epoch": 0.2675,
      "grad_norm": 1.119576334953308,
      "learning_rate": 8.61764705882353e-05,
      "loss": 1.6703,
      "step": 107000
    },
    {
      "epoch": 0.26875,
      "grad_norm": 1.0706137418746948,
      "learning_rate": 8.60294117647059e-05,
      "loss": 1.6662,
      "step": 107500
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.0806609392166138,
      "learning_rate": 8.588235294117646e-05,
      "loss": 1.6648,
      "step": 108000
    },
    {
      "epoch": 0.27125,
      "grad_norm": 1.0636329650878906,
      "learning_rate": 8.573529411764706e-05,
      "loss": 1.6533,
      "step": 108500
    },
    {
      "epoch": 0.2725,
      "grad_norm": 0.9359395503997803,
      "learning_rate": 8.558823529411765e-05,
      "loss": 1.6588,
      "step": 109000
    },
    {
      "epoch": 0.27375,
      "grad_norm": 1.2662076950073242,
      "learning_rate": 8.544117647058823e-05,
      "loss": 1.6652,
      "step": 109500
    },
    {
      "epoch": 0.275,
      "grad_norm": 1.1389105319976807,
      "learning_rate": 8.529411764705883e-05,
      "loss": 1.6704,
      "step": 110000
    },
    {
      "epoch": 0.27625,
      "grad_norm": 1.0601836442947388,
      "learning_rate": 8.514705882352941e-05,
      "loss": 1.6459,
      "step": 110500
    },
    {
      "epoch": 0.2775,
      "grad_norm": 1.0440804958343506,
      "learning_rate": 8.5e-05,
      "loss": 1.6503,
      "step": 111000
    },
    {
      "epoch": 0.27875,
      "grad_norm": 1.110800862312317,
      "learning_rate": 8.485294117647059e-05,
      "loss": 1.6518,
      "step": 111500
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0722894668579102,
      "learning_rate": 8.470588235294118e-05,
      "loss": 1.6524,
      "step": 112000
    },
    {
      "epoch": 0.28125,
      "grad_norm": 1.0665132999420166,
      "learning_rate": 8.455882352941176e-05,
      "loss": 1.6434,
      "step": 112500
    },
    {
      "epoch": 0.2825,
      "grad_norm": 0.9505478739738464,
      "learning_rate": 8.441176470588236e-05,
      "loss": 1.6544,
      "step": 113000
    },
    {
      "epoch": 0.28375,
      "grad_norm": 1.1820436716079712,
      "learning_rate": 8.426470588235294e-05,
      "loss": 1.6394,
      "step": 113500
    },
    {
      "epoch": 0.285,
      "grad_norm": 1.0077484846115112,
      "learning_rate": 8.411764705882354e-05,
      "loss": 1.6433,
      "step": 114000
    },
    {
      "epoch": 0.28625,
      "grad_norm": 1.1313366889953613,
      "learning_rate": 8.397058823529412e-05,
      "loss": 1.6405,
      "step": 114500
    },
    {
      "epoch": 0.2875,
      "grad_norm": 1.0640925168991089,
      "learning_rate": 8.382352941176471e-05,
      "loss": 1.6352,
      "step": 115000
    },
    {
      "epoch": 0.28875,
      "grad_norm": 1.0041910409927368,
      "learning_rate": 8.367647058823531e-05,
      "loss": 1.636,
      "step": 115500
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.095687747001648,
      "learning_rate": 8.352941176470589e-05,
      "loss": 1.6263,
      "step": 116000
    },
    {
      "epoch": 0.29125,
      "grad_norm": 1.2460370063781738,
      "learning_rate": 8.338235294117648e-05,
      "loss": 1.6299,
      "step": 116500
    },
    {
      "epoch": 0.2925,
      "grad_norm": 1.0610756874084473,
      "learning_rate": 8.323529411764707e-05,
      "loss": 1.624,
      "step": 117000
    },
    {
      "epoch": 0.29375,
      "grad_norm": 1.0379600524902344,
      "learning_rate": 8.308823529411766e-05,
      "loss": 1.6393,
      "step": 117500
    },
    {
      "epoch": 0.295,
      "grad_norm": 1.1399043798446655,
      "learning_rate": 8.294117647058824e-05,
      "loss": 1.6328,
      "step": 118000
    },
    {
      "epoch": 0.29625,
      "grad_norm": 0.9926223754882812,
      "learning_rate": 8.279411764705882e-05,
      "loss": 1.6277,
      "step": 118500
    },
    {
      "epoch": 0.2975,
      "grad_norm": 1.038142204284668,
      "learning_rate": 8.26470588235294e-05,
      "loss": 1.6242,
      "step": 119000
    },
    {
      "epoch": 0.29875,
      "grad_norm": 1.0826606750488281,
      "learning_rate": 8.25e-05,
      "loss": 1.6197,
      "step": 119500
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0766690969467163,
      "learning_rate": 8.23529411764706e-05,
      "loss": 1.6123,
      "step": 120000
    },
    {
      "epoch": 0.30125,
      "grad_norm": 1.8012381792068481,
      "learning_rate": 8.220588235294118e-05,
      "loss": 1.5991,
      "step": 120500
    },
    {
      "epoch": 0.3025,
      "grad_norm": 1.1695524454116821,
      "learning_rate": 8.205882352941177e-05,
      "loss": 1.6202,
      "step": 121000
    },
    {
      "epoch": 0.30375,
      "grad_norm": 1.115187406539917,
      "learning_rate": 8.191176470588235e-05,
      "loss": 1.6188,
      "step": 121500
    },
    {
      "epoch": 0.305,
      "grad_norm": 1.140049934387207,
      "learning_rate": 8.176470588235295e-05,
      "loss": 1.6124,
      "step": 122000
    },
    {
      "epoch": 0.30625,
      "grad_norm": 1.1105402708053589,
      "learning_rate": 8.161764705882353e-05,
      "loss": 1.6127,
      "step": 122500
    },
    {
      "epoch": 0.3075,
      "grad_norm": 1.0693302154541016,
      "learning_rate": 8.147058823529412e-05,
      "loss": 1.6063,
      "step": 123000
    },
    {
      "epoch": 0.30875,
      "grad_norm": 1.1094582080841064,
      "learning_rate": 8.13235294117647e-05,
      "loss": 1.605,
      "step": 123500
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0573886632919312,
      "learning_rate": 8.11764705882353e-05,
      "loss": 1.5982,
      "step": 124000
    },
    {
      "epoch": 0.31125,
      "grad_norm": 1.0659881830215454,
      "learning_rate": 8.102941176470588e-05,
      "loss": 1.5953,
      "step": 124500
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.0844167470932007,
      "learning_rate": 8.088235294117648e-05,
      "loss": 1.599,
      "step": 125000
    },
    {
      "epoch": 0.31375,
      "grad_norm": 1.1136270761489868,
      "learning_rate": 8.073529411764706e-05,
      "loss": 1.6116,
      "step": 125500
    },
    {
      "epoch": 0.315,
      "grad_norm": 1.2437853813171387,
      "learning_rate": 8.058823529411765e-05,
      "loss": 1.5933,
      "step": 126000
    },
    {
      "epoch": 0.31625,
      "grad_norm": 1.042761206626892,
      "learning_rate": 8.044117647058825e-05,
      "loss": 1.5879,
      "step": 126500
    },
    {
      "epoch": 0.3175,
      "grad_norm": 0.991053581237793,
      "learning_rate": 8.029411764705883e-05,
      "loss": 1.5957,
      "step": 127000
    },
    {
      "epoch": 0.31875,
      "grad_norm": 1.277938961982727,
      "learning_rate": 8.014705882352943e-05,
      "loss": 1.5882,
      "step": 127500
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.1539058685302734,
      "learning_rate": 8e-05,
      "loss": 1.5878,
      "step": 128000
    },
    {
      "epoch": 0.32125,
      "grad_norm": 1.1123102903366089,
      "learning_rate": 7.98529411764706e-05,
      "loss": 1.596,
      "step": 128500
    },
    {
      "epoch": 0.3225,
      "grad_norm": 1.060293197631836,
      "learning_rate": 7.970588235294118e-05,
      "loss": 1.5833,
      "step": 129000
    },
    {
      "epoch": 0.32375,
      "grad_norm": 1.1706255674362183,
      "learning_rate": 7.955882352941176e-05,
      "loss": 1.5827,
      "step": 129500
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.0388339757919312,
      "learning_rate": 7.941176470588235e-05,
      "loss": 1.5842,
      "step": 130000
    },
    {
      "epoch": 0.32625,
      "grad_norm": 1.2226077318191528,
      "learning_rate": 7.926470588235294e-05,
      "loss": 1.577,
      "step": 130500
    },
    {
      "epoch": 0.3275,
      "grad_norm": 1.158246397972107,
      "learning_rate": 7.911764705882354e-05,
      "loss": 1.5725,
      "step": 131000
    },
    {
      "epoch": 0.32875,
      "grad_norm": 1.0654172897338867,
      "learning_rate": 7.897058823529412e-05,
      "loss": 1.5845,
      "step": 131500
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.102868676185608,
      "learning_rate": 7.882352941176471e-05,
      "loss": 1.562,
      "step": 132000
    },
    {
      "epoch": 0.33125,
      "grad_norm": 1.2015105485916138,
      "learning_rate": 7.86764705882353e-05,
      "loss": 1.5731,
      "step": 132500
    },
    {
      "epoch": 0.3325,
      "grad_norm": 1.0999610424041748,
      "learning_rate": 7.852941176470589e-05,
      "loss": 1.556,
      "step": 133000
    },
    {
      "epoch": 0.33375,
      "grad_norm": 1.0552647113800049,
      "learning_rate": 7.838235294117647e-05,
      "loss": 1.575,
      "step": 133500
    },
    {
      "epoch": 0.335,
      "grad_norm": 1.1100878715515137,
      "learning_rate": 7.823529411764707e-05,
      "loss": 1.5664,
      "step": 134000
    },
    {
      "epoch": 0.33625,
      "grad_norm": 1.3012135028839111,
      "learning_rate": 7.808823529411765e-05,
      "loss": 1.5721,
      "step": 134500
    },
    {
      "epoch": 0.3375,
      "grad_norm": 1.0852946043014526,
      "learning_rate": 7.794117647058824e-05,
      "loss": 1.5643,
      "step": 135000
    },
    {
      "epoch": 0.33875,
      "grad_norm": 1.2318217754364014,
      "learning_rate": 7.779411764705882e-05,
      "loss": 1.5605,
      "step": 135500
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1106622219085693,
      "learning_rate": 7.764705882352942e-05,
      "loss": 1.5705,
      "step": 136000
    },
    {
      "epoch": 0.34125,
      "grad_norm": 1.2182278633117676,
      "learning_rate": 7.75e-05,
      "loss": 1.5632,
      "step": 136500
    },
    {
      "epoch": 0.3425,
      "grad_norm": 1.096472978591919,
      "learning_rate": 7.73529411764706e-05,
      "loss": 1.5617,
      "step": 137000
    },
    {
      "epoch": 0.34375,
      "grad_norm": 1.0127755403518677,
      "learning_rate": 7.720588235294119e-05,
      "loss": 1.5517,
      "step": 137500
    },
    {
      "epoch": 0.345,
      "grad_norm": 1.1935704946517944,
      "learning_rate": 7.705882352941177e-05,
      "loss": 1.5532,
      "step": 138000
    },
    {
      "epoch": 0.34625,
      "grad_norm": 1.1493569612503052,
      "learning_rate": 7.691176470588237e-05,
      "loss": 1.5495,
      "step": 138500
    },
    {
      "epoch": 0.3475,
      "grad_norm": 1.103772521018982,
      "learning_rate": 7.676470588235295e-05,
      "loss": 1.551,
      "step": 139000
    },
    {
      "epoch": 0.34875,
      "grad_norm": 1.0766124725341797,
      "learning_rate": 7.661764705882354e-05,
      "loss": 1.5451,
      "step": 139500
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0945515632629395,
      "learning_rate": 7.647058823529411e-05,
      "loss": 1.5429,
      "step": 140000
    },
    {
      "epoch": 0.35125,
      "grad_norm": 1.2240525484085083,
      "learning_rate": 7.63235294117647e-05,
      "loss": 1.5456,
      "step": 140500
    },
    {
      "epoch": 0.3525,
      "grad_norm": 1.1557972431182861,
      "learning_rate": 7.617647058823529e-05,
      "loss": 1.5367,
      "step": 141000
    },
    {
      "epoch": 0.35375,
      "grad_norm": 1.0846010446548462,
      "learning_rate": 7.602941176470588e-05,
      "loss": 1.5543,
      "step": 141500
    },
    {
      "epoch": 0.355,
      "grad_norm": 1.0541106462478638,
      "learning_rate": 7.588235294117648e-05,
      "loss": 1.5476,
      "step": 142000
    },
    {
      "epoch": 0.35625,
      "grad_norm": 1.097423791885376,
      "learning_rate": 7.573529411764706e-05,
      "loss": 1.5425,
      "step": 142500
    },
    {
      "epoch": 0.3575,
      "grad_norm": 1.072459101676941,
      "learning_rate": 7.558823529411765e-05,
      "loss": 1.548,
      "step": 143000
    },
    {
      "epoch": 0.35875,
      "grad_norm": 1.1192421913146973,
      "learning_rate": 7.544117647058824e-05,
      "loss": 1.558,
      "step": 143500
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0596390962600708,
      "learning_rate": 7.529411764705883e-05,
      "loss": 1.5317,
      "step": 144000
    },
    {
      "epoch": 0.36125,
      "grad_norm": 1.1224926710128784,
      "learning_rate": 7.514705882352941e-05,
      "loss": 1.5382,
      "step": 144500
    },
    {
      "epoch": 0.3625,
      "grad_norm": 1.1953181028366089,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.54,
      "step": 145000
    },
    {
      "epoch": 0.36375,
      "grad_norm": 1.1328150033950806,
      "learning_rate": 7.485294117647059e-05,
      "loss": 1.5338,
      "step": 145500
    },
    {
      "epoch": 0.365,
      "grad_norm": 1.1104637384414673,
      "learning_rate": 7.470588235294118e-05,
      "loss": 1.5377,
      "step": 146000
    },
    {
      "epoch": 0.36625,
      "grad_norm": 1.1584709882736206,
      "learning_rate": 7.455882352941176e-05,
      "loss": 1.5304,
      "step": 146500
    },
    {
      "epoch": 0.3675,
      "grad_norm": 1.04376220703125,
      "learning_rate": 7.441176470588236e-05,
      "loss": 1.5194,
      "step": 147000
    },
    {
      "epoch": 0.36875,
      "grad_norm": 1.0822999477386475,
      "learning_rate": 7.426470588235294e-05,
      "loss": 1.5321,
      "step": 147500
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1930770874023438,
      "learning_rate": 7.411764705882354e-05,
      "loss": 1.5116,
      "step": 148000
    },
    {
      "epoch": 0.37125,
      "grad_norm": 1.0792455673217773,
      "learning_rate": 7.397058823529413e-05,
      "loss": 1.5131,
      "step": 148500
    },
    {
      "epoch": 0.3725,
      "grad_norm": 1.1938793659210205,
      "learning_rate": 7.382352941176471e-05,
      "loss": 1.5309,
      "step": 149000
    },
    {
      "epoch": 0.37375,
      "grad_norm": 1.1064566373825073,
      "learning_rate": 7.367647058823531e-05,
      "loss": 1.5273,
      "step": 149500
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.2522915601730347,
      "learning_rate": 7.352941176470589e-05,
      "loss": 1.5221,
      "step": 150000
    },
    {
      "epoch": 0.37625,
      "grad_norm": 1.1071101427078247,
      "learning_rate": 7.338235294117647e-05,
      "loss": 1.5285,
      "step": 150500
    },
    {
      "epoch": 0.3775,
      "grad_norm": 1.0854088068008423,
      "learning_rate": 7.323529411764705e-05,
      "loss": 1.5081,
      "step": 151000
    },
    {
      "epoch": 0.37875,
      "grad_norm": 1.2542816400527954,
      "learning_rate": 7.308823529411765e-05,
      "loss": 1.5251,
      "step": 151500
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9061021208763123,
      "learning_rate": 7.294117647058823e-05,
      "loss": 1.514,
      "step": 152000
    },
    {
      "epoch": 0.38125,
      "grad_norm": 1.0158500671386719,
      "learning_rate": 7.279411764705882e-05,
      "loss": 1.5168,
      "step": 152500
    },
    {
      "epoch": 0.3825,
      "grad_norm": 1.1699628829956055,
      "learning_rate": 7.264705882352942e-05,
      "loss": 1.5248,
      "step": 153000
    },
    {
      "epoch": 0.38375,
      "grad_norm": 1.1357704401016235,
      "learning_rate": 7.25e-05,
      "loss": 1.5161,
      "step": 153500
    },
    {
      "epoch": 0.385,
      "grad_norm": 0.9908154010772705,
      "learning_rate": 7.23529411764706e-05,
      "loss": 1.5163,
      "step": 154000
    },
    {
      "epoch": 0.38625,
      "grad_norm": 1.293651819229126,
      "learning_rate": 7.220588235294118e-05,
      "loss": 1.504,
      "step": 154500
    },
    {
      "epoch": 0.3875,
      "grad_norm": 1.1944239139556885,
      "learning_rate": 7.205882352941177e-05,
      "loss": 1.5132,
      "step": 155000
    },
    {
      "epoch": 0.38875,
      "grad_norm": 1.0862858295440674,
      "learning_rate": 7.191176470588235e-05,
      "loss": 1.5092,
      "step": 155500
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1515109539031982,
      "learning_rate": 7.176470588235295e-05,
      "loss": 1.5164,
      "step": 156000
    },
    {
      "epoch": 0.39125,
      "grad_norm": 1.0050503015518188,
      "learning_rate": 7.161764705882353e-05,
      "loss": 1.5097,
      "step": 156500
    },
    {
      "epoch": 0.3925,
      "grad_norm": 1.1437791585922241,
      "learning_rate": 7.147058823529412e-05,
      "loss": 1.5068,
      "step": 157000
    },
    {
      "epoch": 0.39375,
      "grad_norm": 1.1514968872070312,
      "learning_rate": 7.13235294117647e-05,
      "loss": 1.5024,
      "step": 157500
    },
    {
      "epoch": 0.395,
      "grad_norm": 1.2661412954330444,
      "learning_rate": 7.11764705882353e-05,
      "loss": 1.4827,
      "step": 158000
    },
    {
      "epoch": 0.39625,
      "grad_norm": 1.144736409187317,
      "learning_rate": 7.102941176470588e-05,
      "loss": 1.4864,
      "step": 158500
    },
    {
      "epoch": 0.3975,
      "grad_norm": 1.09823477268219,
      "learning_rate": 7.088235294117648e-05,
      "loss": 1.4918,
      "step": 159000
    },
    {
      "epoch": 0.39875,
      "grad_norm": 1.0971261262893677,
      "learning_rate": 7.073529411764707e-05,
      "loss": 1.4847,
      "step": 159500
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1253957748413086,
      "learning_rate": 7.058823529411765e-05,
      "loss": 1.5002,
      "step": 160000
    },
    {
      "epoch": 0.40125,
      "grad_norm": 1.1342289447784424,
      "learning_rate": 7.044117647058825e-05,
      "loss": 1.4852,
      "step": 160500
    },
    {
      "epoch": 0.4025,
      "grad_norm": 1.130295753479004,
      "learning_rate": 7.029411764705882e-05,
      "loss": 1.4976,
      "step": 161000
    },
    {
      "epoch": 0.40375,
      "grad_norm": 1.0560537576675415,
      "learning_rate": 7.014705882352941e-05,
      "loss": 1.4883,
      "step": 161500
    },
    {
      "epoch": 0.405,
      "grad_norm": 1.122666835784912,
      "learning_rate": 7e-05,
      "loss": 1.4936,
      "step": 162000
    },
    {
      "epoch": 0.40625,
      "grad_norm": 1.1525802612304688,
      "learning_rate": 6.985294117647059e-05,
      "loss": 1.4886,
      "step": 162500
    },
    {
      "epoch": 0.4075,
      "grad_norm": 1.2106307744979858,
      "learning_rate": 6.970588235294117e-05,
      "loss": 1.5027,
      "step": 163000
    },
    {
      "epoch": 0.40875,
      "grad_norm": 1.1684606075286865,
      "learning_rate": 6.955882352941177e-05,
      "loss": 1.5036,
      "step": 163500
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9895259141921997,
      "learning_rate": 6.941176470588236e-05,
      "loss": 1.4965,
      "step": 164000
    },
    {
      "epoch": 0.41125,
      "grad_norm": 1.1802622079849243,
      "learning_rate": 6.926470588235294e-05,
      "loss": 1.4906,
      "step": 164500
    },
    {
      "epoch": 0.4125,
      "grad_norm": 1.110832929611206,
      "learning_rate": 6.911764705882354e-05,
      "loss": 1.4847,
      "step": 165000
    },
    {
      "epoch": 0.41375,
      "grad_norm": 1.2261910438537598,
      "learning_rate": 6.897058823529412e-05,
      "loss": 1.4752,
      "step": 165500
    },
    {
      "epoch": 0.415,
      "grad_norm": 1.0956801176071167,
      "learning_rate": 6.882352941176471e-05,
      "loss": 1.4816,
      "step": 166000
    },
    {
      "epoch": 0.41625,
      "grad_norm": 1.4977809190750122,
      "learning_rate": 6.86764705882353e-05,
      "loss": 1.4776,
      "step": 166500
    },
    {
      "epoch": 0.4175,
      "grad_norm": 1.1086992025375366,
      "learning_rate": 6.852941176470589e-05,
      "loss": 1.4867,
      "step": 167000
    },
    {
      "epoch": 0.41875,
      "grad_norm": 1.1938167810440063,
      "learning_rate": 6.838235294117647e-05,
      "loss": 1.4785,
      "step": 167500
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2777835130691528,
      "learning_rate": 6.823529411764707e-05,
      "loss": 1.4755,
      "step": 168000
    },
    {
      "epoch": 0.42125,
      "grad_norm": 1.2095155715942383,
      "learning_rate": 6.808823529411765e-05,
      "loss": 1.4825,
      "step": 168500
    },
    {
      "epoch": 0.4225,
      "grad_norm": 1.0423567295074463,
      "learning_rate": 6.794117647058824e-05,
      "loss": 1.4895,
      "step": 169000
    },
    {
      "epoch": 0.42375,
      "grad_norm": 1.2542248964309692,
      "learning_rate": 6.779411764705882e-05,
      "loss": 1.4678,
      "step": 169500
    },
    {
      "epoch": 0.425,
      "grad_norm": 1.150642991065979,
      "learning_rate": 6.764705882352942e-05,
      "loss": 1.4701,
      "step": 170000
    },
    {
      "epoch": 0.42625,
      "grad_norm": 1.1927731037139893,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.4727,
      "step": 170500
    },
    {
      "epoch": 0.4275,
      "grad_norm": 1.161946177482605,
      "learning_rate": 6.73529411764706e-05,
      "loss": 1.4703,
      "step": 171000
    },
    {
      "epoch": 0.42875,
      "grad_norm": 1.24138605594635,
      "learning_rate": 6.720588235294119e-05,
      "loss": 1.4708,
      "step": 171500
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1174119710922241,
      "learning_rate": 6.705882352941176e-05,
      "loss": 1.4751,
      "step": 172000
    },
    {
      "epoch": 0.43125,
      "grad_norm": 1.0947394371032715,
      "learning_rate": 6.691176470588235e-05,
      "loss": 1.4609,
      "step": 172500
    },
    {
      "epoch": 0.4325,
      "grad_norm": 1.1666021347045898,
      "learning_rate": 6.676470588235294e-05,
      "loss": 1.4548,
      "step": 173000
    },
    {
      "epoch": 0.43375,
      "grad_norm": 1.166166067123413,
      "learning_rate": 6.661764705882353e-05,
      "loss": 1.4647,
      "step": 173500
    },
    {
      "epoch": 0.435,
      "grad_norm": 1.1208754777908325,
      "learning_rate": 6.647058823529411e-05,
      "loss": 1.4567,
      "step": 174000
    },
    {
      "epoch": 0.43625,
      "grad_norm": 1.1660515069961548,
      "learning_rate": 6.632352941176471e-05,
      "loss": 1.4658,
      "step": 174500
    },
    {
      "epoch": 0.4375,
      "grad_norm": 1.2003049850463867,
      "learning_rate": 6.61764705882353e-05,
      "loss": 1.4726,
      "step": 175000
    },
    {
      "epoch": 0.43875,
      "grad_norm": 1.1400623321533203,
      "learning_rate": 6.602941176470588e-05,
      "loss": 1.4641,
      "step": 175500
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2675861120224,
      "learning_rate": 6.588235294117648e-05,
      "loss": 1.4633,
      "step": 176000
    },
    {
      "epoch": 0.44125,
      "grad_norm": 1.1868518590927124,
      "learning_rate": 6.573529411764706e-05,
      "loss": 1.4541,
      "step": 176500
    },
    {
      "epoch": 0.4425,
      "grad_norm": 1.1054306030273438,
      "learning_rate": 6.558823529411765e-05,
      "loss": 1.4469,
      "step": 177000
    },
    {
      "epoch": 0.44375,
      "grad_norm": 1.261654019355774,
      "learning_rate": 6.544117647058824e-05,
      "loss": 1.4495,
      "step": 177500
    },
    {
      "epoch": 0.445,
      "grad_norm": 1.1520850658416748,
      "learning_rate": 6.529411764705883e-05,
      "loss": 1.4647,
      "step": 178000
    },
    {
      "epoch": 0.44625,
      "grad_norm": 1.103564977645874,
      "learning_rate": 6.514705882352941e-05,
      "loss": 1.4493,
      "step": 178500
    },
    {
      "epoch": 0.4475,
      "grad_norm": 1.160789132118225,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.4559,
      "step": 179000
    },
    {
      "epoch": 0.44875,
      "grad_norm": 1.2314374446868896,
      "learning_rate": 6.485294117647059e-05,
      "loss": 1.4601,
      "step": 179500
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.137986660003662,
      "learning_rate": 6.470588235294118e-05,
      "loss": 1.4429,
      "step": 180000
    },
    {
      "epoch": 0.45125,
      "grad_norm": 1.152857780456543,
      "learning_rate": 6.455882352941177e-05,
      "loss": 1.4604,
      "step": 180500
    },
    {
      "epoch": 0.4525,
      "grad_norm": 1.141392707824707,
      "learning_rate": 6.441176470588236e-05,
      "loss": 1.4477,
      "step": 181000
    },
    {
      "epoch": 0.45375,
      "grad_norm": 1.002601146697998,
      "learning_rate": 6.426470588235294e-05,
      "loss": 1.4407,
      "step": 181500
    },
    {
      "epoch": 0.455,
      "grad_norm": 1.1859699487686157,
      "learning_rate": 6.411764705882354e-05,
      "loss": 1.4448,
      "step": 182000
    },
    {
      "epoch": 0.45625,
      "grad_norm": 1.2074555158615112,
      "learning_rate": 6.397058823529412e-05,
      "loss": 1.4502,
      "step": 182500
    },
    {
      "epoch": 0.4575,
      "grad_norm": 1.1319422721862793,
      "learning_rate": 6.38235294117647e-05,
      "loss": 1.449,
      "step": 183000
    },
    {
      "epoch": 0.45875,
      "grad_norm": 1.116026759147644,
      "learning_rate": 6.36764705882353e-05,
      "loss": 1.4388,
      "step": 183500
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.259535551071167,
      "learning_rate": 6.352941176470588e-05,
      "loss": 1.4426,
      "step": 184000
    },
    {
      "epoch": 0.46125,
      "grad_norm": 1.1120903491973877,
      "learning_rate": 6.338235294117647e-05,
      "loss": 1.4346,
      "step": 184500
    },
    {
      "epoch": 0.4625,
      "grad_norm": 1.2862030267715454,
      "learning_rate": 6.323529411764705e-05,
      "loss": 1.4432,
      "step": 185000
    },
    {
      "epoch": 0.46375,
      "grad_norm": 1.1559699773788452,
      "learning_rate": 6.308823529411765e-05,
      "loss": 1.4282,
      "step": 185500
    },
    {
      "epoch": 0.465,
      "grad_norm": 1.1588307619094849,
      "learning_rate": 6.294117647058824e-05,
      "loss": 1.4326,
      "step": 186000
    },
    {
      "epoch": 0.46625,
      "grad_norm": 1.122782588005066,
      "learning_rate": 6.279411764705882e-05,
      "loss": 1.4435,
      "step": 186500
    },
    {
      "epoch": 0.4675,
      "grad_norm": 1.2726242542266846,
      "learning_rate": 6.264705882352942e-05,
      "loss": 1.4599,
      "step": 187000
    },
    {
      "epoch": 0.46875,
      "grad_norm": 1.0796078443527222,
      "learning_rate": 6.25e-05,
      "loss": 1.4432,
      "step": 187500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9610490798950195,
      "learning_rate": 6.23529411764706e-05,
      "loss": 1.4293,
      "step": 188000
    },
    {
      "epoch": 0.47125,
      "grad_norm": 1.1047077178955078,
      "learning_rate": 6.220588235294118e-05,
      "loss": 1.4349,
      "step": 188500
    },
    {
      "epoch": 0.4725,
      "grad_norm": 1.0642168521881104,
      "learning_rate": 6.205882352941177e-05,
      "loss": 1.4379,
      "step": 189000
    },
    {
      "epoch": 0.47375,
      "grad_norm": 1.063506007194519,
      "learning_rate": 6.191176470588235e-05,
      "loss": 1.4416,
      "step": 189500
    },
    {
      "epoch": 0.475,
      "grad_norm": 1.1659696102142334,
      "learning_rate": 6.176470588235295e-05,
      "loss": 1.421,
      "step": 190000
    },
    {
      "epoch": 0.47625,
      "grad_norm": 1.3112754821777344,
      "learning_rate": 6.161764705882353e-05,
      "loss": 1.4256,
      "step": 190500
    },
    {
      "epoch": 0.4775,
      "grad_norm": 1.242988109588623,
      "learning_rate": 6.147058823529413e-05,
      "loss": 1.4368,
      "step": 191000
    },
    {
      "epoch": 0.47875,
      "grad_norm": 1.0369025468826294,
      "learning_rate": 6.132352941176471e-05,
      "loss": 1.4235,
      "step": 191500
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.2361488342285156,
      "learning_rate": 6.11764705882353e-05,
      "loss": 1.429,
      "step": 192000
    },
    {
      "epoch": 0.48125,
      "grad_norm": 1.1717125177383423,
      "learning_rate": 6.102941176470589e-05,
      "loss": 1.4224,
      "step": 192500
    },
    {
      "epoch": 0.4825,
      "grad_norm": 1.2664278745651245,
      "learning_rate": 6.0882352941176465e-05,
      "loss": 1.4294,
      "step": 193000
    },
    {
      "epoch": 0.48375,
      "grad_norm": 1.2072594165802002,
      "learning_rate": 6.073529411764706e-05,
      "loss": 1.415,
      "step": 193500
    },
    {
      "epoch": 0.485,
      "grad_norm": 1.2365494966506958,
      "learning_rate": 6.058823529411765e-05,
      "loss": 1.4181,
      "step": 194000
    },
    {
      "epoch": 0.48625,
      "grad_norm": 1.1684269905090332,
      "learning_rate": 6.044117647058824e-05,
      "loss": 1.4152,
      "step": 194500
    },
    {
      "epoch": 0.4875,
      "grad_norm": 1.0772171020507812,
      "learning_rate": 6.0294117647058825e-05,
      "loss": 1.4002,
      "step": 195000
    },
    {
      "epoch": 0.48875,
      "grad_norm": 1.181955337524414,
      "learning_rate": 6.014705882352941e-05,
      "loss": 1.4133,
      "step": 195500
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2515075206756592,
      "learning_rate": 6e-05,
      "loss": 1.4122,
      "step": 196000
    },
    {
      "epoch": 0.49125,
      "grad_norm": 1.2397629022598267,
      "learning_rate": 5.985294117647059e-05,
      "loss": 1.4255,
      "step": 196500
    },
    {
      "epoch": 0.4925,
      "grad_norm": 1.2178771495819092,
      "learning_rate": 5.970588235294118e-05,
      "loss": 1.4242,
      "step": 197000
    },
    {
      "epoch": 0.49375,
      "grad_norm": 1.2133653163909912,
      "learning_rate": 5.9558823529411766e-05,
      "loss": 1.4104,
      "step": 197500
    },
    {
      "epoch": 0.495,
      "grad_norm": 1.0123395919799805,
      "learning_rate": 5.9411764705882355e-05,
      "loss": 1.4154,
      "step": 198000
    },
    {
      "epoch": 0.49625,
      "grad_norm": 1.2027487754821777,
      "learning_rate": 5.926470588235294e-05,
      "loss": 1.4146,
      "step": 198500
    },
    {
      "epoch": 0.4975,
      "grad_norm": 1.3494676351547241,
      "learning_rate": 5.911764705882353e-05,
      "loss": 1.3962,
      "step": 199000
    },
    {
      "epoch": 0.49875,
      "grad_norm": 1.0941671133041382,
      "learning_rate": 5.897058823529412e-05,
      "loss": 1.4072,
      "step": 199500
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2334924936294556,
      "learning_rate": 5.882352941176471e-05,
      "loss": 1.4098,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 400000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7357586038784e+18,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
