{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.25,
  "eval_steps": 500,
  "global_step": 100000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00125,
      "grad_norm": 0.864155650138855,
      "learning_rate": 8.333333333333333e-07,
      "loss": 2.0934,
      "step": 500
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.7021952271461487,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 2.0913,
      "step": 1000
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.7247902154922485,
      "learning_rate": 2.5e-06,
      "loss": 2.072,
      "step": 1500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.5956035256385803,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 2.0647,
      "step": 2000
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.6233073472976685,
      "learning_rate": 4.166666666666667e-06,
      "loss": 2.0743,
      "step": 2500
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.6304711103439331,
      "learning_rate": 5e-06,
      "loss": 2.0608,
      "step": 3000
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.6179541349411011,
      "learning_rate": 5.833333333333334e-06,
      "loss": 2.0557,
      "step": 3500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7056578993797302,
      "learning_rate": 6.666666666666667e-06,
      "loss": 2.0476,
      "step": 4000
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.7196956872940063,
      "learning_rate": 7.5e-06,
      "loss": 2.0499,
      "step": 4500
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.6280786395072937,
      "learning_rate": 8.333333333333334e-06,
      "loss": 2.0564,
      "step": 5000
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.6416502594947815,
      "learning_rate": 9.166666666666666e-06,
      "loss": 2.0461,
      "step": 5500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.568566083908081,
      "learning_rate": 1e-05,
      "loss": 2.0419,
      "step": 6000
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.5493419766426086,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 2.0404,
      "step": 6500
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.6433902978897095,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 2.0458,
      "step": 7000
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.5683876872062683,
      "learning_rate": 1.25e-05,
      "loss": 2.0438,
      "step": 7500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6052339673042297,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 2.0363,
      "step": 8000
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.5777627825737,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 2.0375,
      "step": 8500
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.6172158718109131,
      "learning_rate": 1.5e-05,
      "loss": 2.0297,
      "step": 9000
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.6084865927696228,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 2.0345,
      "step": 9500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.6073004007339478,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 2.0337,
      "step": 10000
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.6053885817527771,
      "learning_rate": 1.75e-05,
      "loss": 2.0259,
      "step": 10500
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.6602093577384949,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 2.0285,
      "step": 11000
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.6238638162612915,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 2.0267,
      "step": 11500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6253011226654053,
      "learning_rate": 2e-05,
      "loss": 2.0177,
      "step": 12000
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.5951969623565674,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 2.023,
      "step": 12500
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.6585981845855713,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 2.0196,
      "step": 13000
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.6671642065048218,
      "learning_rate": 2.25e-05,
      "loss": 2.0271,
      "step": 13500
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.708335280418396,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 2.0185,
      "step": 14000
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.668310284614563,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 2.0136,
      "step": 14500
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.6239287257194519,
      "learning_rate": 2.5e-05,
      "loss": 2.0176,
      "step": 15000
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.6692379117012024,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 2.0074,
      "step": 15500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6649496555328369,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 2.0113,
      "step": 16000
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.7117648720741272,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 2.0002,
      "step": 16500
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.6614023447036743,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 2.0064,
      "step": 17000
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.675977349281311,
      "learning_rate": 2.916666666666667e-05,
      "loss": 2.0036,
      "step": 17500
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.6832244396209717,
      "learning_rate": 3e-05,
      "loss": 2.0046,
      "step": 18000
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.6926181316375732,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 1.999,
      "step": 18500
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.7596989870071411,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 1.9992,
      "step": 19000
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.7731313109397888,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 2.0049,
      "step": 19500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7048933506011963,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.9748,
      "step": 20000
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.7708183526992798,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 1.9843,
      "step": 20500
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.8010103106498718,
      "learning_rate": 3.5e-05,
      "loss": 1.9855,
      "step": 21000
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.7820359468460083,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 1.9847,
      "step": 21500
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.7959474325180054,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 1.9877,
      "step": 22000
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.8328559398651123,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.9737,
      "step": 22500
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.8348504304885864,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 1.9715,
      "step": 23000
    },
    {
      "epoch": 0.05875,
      "grad_norm": 0.8890961408615112,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 1.969,
      "step": 23500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8386203646659851,
      "learning_rate": 4e-05,
      "loss": 1.9793,
      "step": 24000
    },
    {
      "epoch": 0.06125,
      "grad_norm": 0.8304561972618103,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 1.9767,
      "step": 24500
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.8839859962463379,
      "learning_rate": 4.166666666666667e-05,
      "loss": 1.9602,
      "step": 25000
    },
    {
      "epoch": 0.06375,
      "grad_norm": 0.8251996040344238,
      "learning_rate": 4.25e-05,
      "loss": 1.9653,
      "step": 25500
    },
    {
      "epoch": 0.065,
      "grad_norm": 1.0101752281188965,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 1.9575,
      "step": 26000
    },
    {
      "epoch": 0.06625,
      "grad_norm": 0.9769129753112793,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 1.9633,
      "step": 26500
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.9492970705032349,
      "learning_rate": 4.5e-05,
      "loss": 1.9598,
      "step": 27000
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.9648156762123108,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 1.9528,
      "step": 27500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.914553701877594,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.9512,
      "step": 28000
    },
    {
      "epoch": 0.07125,
      "grad_norm": 0.9479950070381165,
      "learning_rate": 4.75e-05,
      "loss": 1.9485,
      "step": 28500
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.9917711019515991,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 1.9436,
      "step": 29000
    },
    {
      "epoch": 0.07375,
      "grad_norm": 1.063467264175415,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 1.9449,
      "step": 29500
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.9776054620742798,
      "learning_rate": 5e-05,
      "loss": 1.936,
      "step": 30000
    },
    {
      "epoch": 0.07625,
      "grad_norm": 1.1549485921859741,
      "learning_rate": 5.0833333333333333e-05,
      "loss": 1.9379,
      "step": 30500
    },
    {
      "epoch": 0.0775,
      "grad_norm": 1.0316413640975952,
      "learning_rate": 5.166666666666667e-05,
      "loss": 1.9414,
      "step": 31000
    },
    {
      "epoch": 0.07875,
      "grad_norm": 1.0128039121627808,
      "learning_rate": 5.25e-05,
      "loss": 1.9222,
      "step": 31500
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2238264083862305,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.9253,
      "step": 32000
    },
    {
      "epoch": 0.08125,
      "grad_norm": 1.1280415058135986,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 1.9201,
      "step": 32500
    },
    {
      "epoch": 0.0825,
      "grad_norm": 1.1376125812530518,
      "learning_rate": 5.500000000000001e-05,
      "loss": 1.9192,
      "step": 33000
    },
    {
      "epoch": 0.08375,
      "grad_norm": 1.0999051332473755,
      "learning_rate": 5.583333333333334e-05,
      "loss": 1.9151,
      "step": 33500
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.9933043718338013,
      "learning_rate": 5.666666666666667e-05,
      "loss": 1.91,
      "step": 34000
    },
    {
      "epoch": 0.08625,
      "grad_norm": 1.2060508728027344,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 1.9097,
      "step": 34500
    },
    {
      "epoch": 0.0875,
      "grad_norm": 1.0517233610153198,
      "learning_rate": 5.833333333333334e-05,
      "loss": 1.9068,
      "step": 35000
    },
    {
      "epoch": 0.08875,
      "grad_norm": 1.151121735572815,
      "learning_rate": 5.916666666666667e-05,
      "loss": 1.8996,
      "step": 35500
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.071878433227539,
      "learning_rate": 6e-05,
      "loss": 1.898,
      "step": 36000
    },
    {
      "epoch": 0.09125,
      "grad_norm": 1.2146741151809692,
      "learning_rate": 6.083333333333333e-05,
      "loss": 1.8998,
      "step": 36500
    },
    {
      "epoch": 0.0925,
      "grad_norm": 1.2748982906341553,
      "learning_rate": 6.166666666666667e-05,
      "loss": 1.8844,
      "step": 37000
    },
    {
      "epoch": 0.09375,
      "grad_norm": 1.1616483926773071,
      "learning_rate": 6.25e-05,
      "loss": 1.8875,
      "step": 37500
    },
    {
      "epoch": 0.095,
      "grad_norm": 1.230504035949707,
      "learning_rate": 6.333333333333333e-05,
      "loss": 1.8871,
      "step": 38000
    },
    {
      "epoch": 0.09625,
      "grad_norm": 1.2021368741989136,
      "learning_rate": 6.416666666666668e-05,
      "loss": 1.8871,
      "step": 38500
    },
    {
      "epoch": 0.0975,
      "grad_norm": 1.2260793447494507,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.8799,
      "step": 39000
    },
    {
      "epoch": 0.09875,
      "grad_norm": 1.3143374919891357,
      "learning_rate": 6.583333333333334e-05,
      "loss": 1.8771,
      "step": 39500
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2593300342559814,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.8714,
      "step": 40000
    },
    {
      "epoch": 0.10125,
      "grad_norm": 1.40025794506073,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.865,
      "step": 40500
    },
    {
      "epoch": 0.1025,
      "grad_norm": 1.263132095336914,
      "learning_rate": 6.833333333333333e-05,
      "loss": 1.8626,
      "step": 41000
    },
    {
      "epoch": 0.10375,
      "grad_norm": 1.1864142417907715,
      "learning_rate": 6.916666666666666e-05,
      "loss": 1.8643,
      "step": 41500
    },
    {
      "epoch": 0.105,
      "grad_norm": 1.2174979448318481,
      "learning_rate": 7e-05,
      "loss": 1.8661,
      "step": 42000
    },
    {
      "epoch": 0.10625,
      "grad_norm": 1.5037810802459717,
      "learning_rate": 7.083333333333334e-05,
      "loss": 1.8588,
      "step": 42500
    },
    {
      "epoch": 0.1075,
      "grad_norm": 1.4078789949417114,
      "learning_rate": 7.166666666666667e-05,
      "loss": 1.8545,
      "step": 43000
    },
    {
      "epoch": 0.10875,
      "grad_norm": 1.2109127044677734,
      "learning_rate": 7.25e-05,
      "loss": 1.8453,
      "step": 43500
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.512188196182251,
      "learning_rate": 7.333333333333333e-05,
      "loss": 1.8476,
      "step": 44000
    },
    {
      "epoch": 0.11125,
      "grad_norm": 1.2102733850479126,
      "learning_rate": 7.416666666666668e-05,
      "loss": 1.8424,
      "step": 44500
    },
    {
      "epoch": 0.1125,
      "grad_norm": 1.3323529958724976,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.8446,
      "step": 45000
    },
    {
      "epoch": 0.11375,
      "grad_norm": 1.4106940031051636,
      "learning_rate": 7.583333333333334e-05,
      "loss": 1.8299,
      "step": 45500
    },
    {
      "epoch": 0.115,
      "grad_norm": 1.4618200063705444,
      "learning_rate": 7.666666666666667e-05,
      "loss": 1.8357,
      "step": 46000
    },
    {
      "epoch": 0.11625,
      "grad_norm": 1.424829125404358,
      "learning_rate": 7.75e-05,
      "loss": 1.8229,
      "step": 46500
    },
    {
      "epoch": 0.1175,
      "grad_norm": 1.5578261613845825,
      "learning_rate": 7.833333333333333e-05,
      "loss": 1.8266,
      "step": 47000
    },
    {
      "epoch": 0.11875,
      "grad_norm": 1.4147961139678955,
      "learning_rate": 7.916666666666666e-05,
      "loss": 1.8199,
      "step": 47500
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.450382113456726,
      "learning_rate": 8e-05,
      "loss": 1.8218,
      "step": 48000
    },
    {
      "epoch": 0.12125,
      "grad_norm": 1.5292165279388428,
      "learning_rate": 8.083333333333334e-05,
      "loss": 1.8175,
      "step": 48500
    },
    {
      "epoch": 0.1225,
      "grad_norm": 1.4269394874572754,
      "learning_rate": 8.166666666666667e-05,
      "loss": 1.8189,
      "step": 49000
    },
    {
      "epoch": 0.12375,
      "grad_norm": 1.3358274698257446,
      "learning_rate": 8.25e-05,
      "loss": 1.8126,
      "step": 49500
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.5615488290786743,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.8166,
      "step": 50000
    },
    {
      "epoch": 0.12625,
      "grad_norm": 1.5055317878723145,
      "learning_rate": 8.416666666666668e-05,
      "loss": 1.8015,
      "step": 50500
    },
    {
      "epoch": 0.1275,
      "grad_norm": 1.6018065214157104,
      "learning_rate": 8.5e-05,
      "loss": 1.7941,
      "step": 51000
    },
    {
      "epoch": 0.12875,
      "grad_norm": 1.4659924507141113,
      "learning_rate": 8.583333333333334e-05,
      "loss": 1.7903,
      "step": 51500
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.5612194538116455,
      "learning_rate": 8.666666666666667e-05,
      "loss": 1.7914,
      "step": 52000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 1.6428014039993286,
      "learning_rate": 8.75e-05,
      "loss": 1.7794,
      "step": 52500
    },
    {
      "epoch": 0.1325,
      "grad_norm": 1.446271300315857,
      "learning_rate": 8.833333333333333e-05,
      "loss": 1.7814,
      "step": 53000
    },
    {
      "epoch": 0.13375,
      "grad_norm": 1.5774890184402466,
      "learning_rate": 8.916666666666667e-05,
      "loss": 1.7816,
      "step": 53500
    },
    {
      "epoch": 0.135,
      "grad_norm": 1.9530143737792969,
      "learning_rate": 9e-05,
      "loss": 1.7856,
      "step": 54000
    },
    {
      "epoch": 0.13625,
      "grad_norm": 1.4705753326416016,
      "learning_rate": 9.083333333333334e-05,
      "loss": 1.7677,
      "step": 54500
    },
    {
      "epoch": 0.1375,
      "grad_norm": 1.5492900609970093,
      "learning_rate": 9.166666666666667e-05,
      "loss": 1.7709,
      "step": 55000
    },
    {
      "epoch": 0.13875,
      "grad_norm": 1.8654483556747437,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.7642,
      "step": 55500
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6102670431137085,
      "learning_rate": 9.333333333333334e-05,
      "loss": 1.7582,
      "step": 56000
    },
    {
      "epoch": 0.14125,
      "grad_norm": 1.7278226613998413,
      "learning_rate": 9.416666666666667e-05,
      "loss": 1.7594,
      "step": 56500
    },
    {
      "epoch": 0.1425,
      "grad_norm": 1.683935523033142,
      "learning_rate": 9.5e-05,
      "loss": 1.7553,
      "step": 57000
    },
    {
      "epoch": 0.14375,
      "grad_norm": 1.6363633871078491,
      "learning_rate": 9.583333333333334e-05,
      "loss": 1.7579,
      "step": 57500
    },
    {
      "epoch": 0.145,
      "grad_norm": 1.6941801309585571,
      "learning_rate": 9.666666666666667e-05,
      "loss": 1.7435,
      "step": 58000
    },
    {
      "epoch": 0.14625,
      "grad_norm": 1.4741714000701904,
      "learning_rate": 9.75e-05,
      "loss": 1.748,
      "step": 58500
    },
    {
      "epoch": 0.1475,
      "grad_norm": 1.6150779724121094,
      "learning_rate": 9.833333333333333e-05,
      "loss": 1.7397,
      "step": 59000
    },
    {
      "epoch": 0.14875,
      "grad_norm": 1.7995890378952026,
      "learning_rate": 9.916666666666667e-05,
      "loss": 1.7325,
      "step": 59500
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.6700972318649292,
      "learning_rate": 0.0001,
      "loss": 1.7503,
      "step": 60000
    },
    {
      "epoch": 0.15125,
      "grad_norm": 1.6452245712280273,
      "learning_rate": 9.98529411764706e-05,
      "loss": 1.7333,
      "step": 60500
    },
    {
      "epoch": 0.1525,
      "grad_norm": 1.4547799825668335,
      "learning_rate": 9.970588235294118e-05,
      "loss": 1.7318,
      "step": 61000
    },
    {
      "epoch": 0.15375,
      "grad_norm": 1.8347376585006714,
      "learning_rate": 9.955882352941178e-05,
      "loss": 1.7218,
      "step": 61500
    },
    {
      "epoch": 0.155,
      "grad_norm": 1.5920315980911255,
      "learning_rate": 9.941176470588236e-05,
      "loss": 1.7077,
      "step": 62000
    },
    {
      "epoch": 0.15625,
      "grad_norm": 1.7212966680526733,
      "learning_rate": 9.926470588235295e-05,
      "loss": 1.7167,
      "step": 62500
    },
    {
      "epoch": 0.1575,
      "grad_norm": 1.5742084980010986,
      "learning_rate": 9.911764705882353e-05,
      "loss": 1.7074,
      "step": 63000
    },
    {
      "epoch": 0.15875,
      "grad_norm": 1.7368007898330688,
      "learning_rate": 9.897058823529413e-05,
      "loss": 1.7071,
      "step": 63500
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7699558734893799,
      "learning_rate": 9.882352941176471e-05,
      "loss": 1.7013,
      "step": 64000
    },
    {
      "epoch": 0.16125,
      "grad_norm": 1.667356014251709,
      "learning_rate": 9.86764705882353e-05,
      "loss": 1.6978,
      "step": 64500
    },
    {
      "epoch": 0.1625,
      "grad_norm": 1.732240915298462,
      "learning_rate": 9.852941176470589e-05,
      "loss": 1.6916,
      "step": 65000
    },
    {
      "epoch": 0.16375,
      "grad_norm": 1.7115635871887207,
      "learning_rate": 9.838235294117647e-05,
      "loss": 1.6869,
      "step": 65500
    },
    {
      "epoch": 0.165,
      "grad_norm": 1.6621785163879395,
      "learning_rate": 9.823529411764706e-05,
      "loss": 1.6902,
      "step": 66000
    },
    {
      "epoch": 0.16625,
      "grad_norm": 1.8152867555618286,
      "learning_rate": 9.808823529411765e-05,
      "loss": 1.6819,
      "step": 66500
    },
    {
      "epoch": 0.1675,
      "grad_norm": 1.6894257068634033,
      "learning_rate": 9.794117647058824e-05,
      "loss": 1.6829,
      "step": 67000
    },
    {
      "epoch": 0.16875,
      "grad_norm": 1.6845656633377075,
      "learning_rate": 9.779411764705882e-05,
      "loss": 1.6774,
      "step": 67500
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0552570819854736,
      "learning_rate": 9.764705882352942e-05,
      "loss": 1.672,
      "step": 68000
    },
    {
      "epoch": 0.17125,
      "grad_norm": 1.8374886512756348,
      "learning_rate": 9.75e-05,
      "loss": 1.6637,
      "step": 68500
    },
    {
      "epoch": 0.1725,
      "grad_norm": 1.6825402975082397,
      "learning_rate": 9.73529411764706e-05,
      "loss": 1.663,
      "step": 69000
    },
    {
      "epoch": 0.17375,
      "grad_norm": 1.767700433731079,
      "learning_rate": 9.720588235294117e-05,
      "loss": 1.6681,
      "step": 69500
    },
    {
      "epoch": 0.175,
      "grad_norm": 1.8300673961639404,
      "learning_rate": 9.705882352941177e-05,
      "loss": 1.6564,
      "step": 70000
    },
    {
      "epoch": 0.17625,
      "grad_norm": 1.9486585855484009,
      "learning_rate": 9.691176470588235e-05,
      "loss": 1.6574,
      "step": 70500
    },
    {
      "epoch": 0.1775,
      "grad_norm": 1.8369641304016113,
      "learning_rate": 9.676470588235295e-05,
      "loss": 1.6532,
      "step": 71000
    },
    {
      "epoch": 0.17875,
      "grad_norm": 1.9165257215499878,
      "learning_rate": 9.661764705882354e-05,
      "loss": 1.65,
      "step": 71500
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.930983543395996,
      "learning_rate": 9.647058823529412e-05,
      "loss": 1.6558,
      "step": 72000
    },
    {
      "epoch": 0.18125,
      "grad_norm": 1.8403406143188477,
      "learning_rate": 9.632352941176472e-05,
      "loss": 1.6452,
      "step": 72500
    },
    {
      "epoch": 0.1825,
      "grad_norm": 1.7135121822357178,
      "learning_rate": 9.61764705882353e-05,
      "loss": 1.6527,
      "step": 73000
    },
    {
      "epoch": 0.18375,
      "grad_norm": 1.9882559776306152,
      "learning_rate": 9.60294117647059e-05,
      "loss": 1.6385,
      "step": 73500
    },
    {
      "epoch": 0.185,
      "grad_norm": 1.8998135328292847,
      "learning_rate": 9.588235294117648e-05,
      "loss": 1.6272,
      "step": 74000
    },
    {
      "epoch": 0.18625,
      "grad_norm": 1.9979103803634644,
      "learning_rate": 9.573529411764707e-05,
      "loss": 1.6335,
      "step": 74500
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.8253353834152222,
      "learning_rate": 9.558823529411765e-05,
      "loss": 1.6316,
      "step": 75000
    },
    {
      "epoch": 0.18875,
      "grad_norm": 1.8128278255462646,
      "learning_rate": 9.544117647058825e-05,
      "loss": 1.6282,
      "step": 75500
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9996551275253296,
      "learning_rate": 9.529411764705883e-05,
      "loss": 1.628,
      "step": 76000
    },
    {
      "epoch": 0.19125,
      "grad_norm": 1.9150238037109375,
      "learning_rate": 9.514705882352941e-05,
      "loss": 1.6188,
      "step": 76500
    },
    {
      "epoch": 0.1925,
      "grad_norm": 1.760855793952942,
      "learning_rate": 9.5e-05,
      "loss": 1.6163,
      "step": 77000
    },
    {
      "epoch": 0.19375,
      "grad_norm": 1.7863938808441162,
      "learning_rate": 9.485294117647059e-05,
      "loss": 1.605,
      "step": 77500
    },
    {
      "epoch": 0.195,
      "grad_norm": 1.878404140472412,
      "learning_rate": 9.470588235294118e-05,
      "loss": 1.5966,
      "step": 78000
    },
    {
      "epoch": 0.19625,
      "grad_norm": 1.847072720527649,
      "learning_rate": 9.455882352941176e-05,
      "loss": 1.6143,
      "step": 78500
    },
    {
      "epoch": 0.1975,
      "grad_norm": 1.704306960105896,
      "learning_rate": 9.441176470588236e-05,
      "loss": 1.6023,
      "step": 79000
    },
    {
      "epoch": 0.19875,
      "grad_norm": 1.692057490348816,
      "learning_rate": 9.426470588235294e-05,
      "loss": 1.5902,
      "step": 79500
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9751724004745483,
      "learning_rate": 9.411764705882353e-05,
      "loss": 1.5882,
      "step": 80000
    },
    {
      "epoch": 0.20125,
      "grad_norm": 1.9542534351348877,
      "learning_rate": 9.397058823529412e-05,
      "loss": 1.5928,
      "step": 80500
    },
    {
      "epoch": 0.2025,
      "grad_norm": 2.0423014163970947,
      "learning_rate": 9.382352941176471e-05,
      "loss": 1.5969,
      "step": 81000
    },
    {
      "epoch": 0.20375,
      "grad_norm": 1.8790979385375977,
      "learning_rate": 9.367647058823529e-05,
      "loss": 1.5861,
      "step": 81500
    },
    {
      "epoch": 0.205,
      "grad_norm": 1.8653647899627686,
      "learning_rate": 9.352941176470589e-05,
      "loss": 1.5845,
      "step": 82000
    },
    {
      "epoch": 0.20625,
      "grad_norm": 1.9019354581832886,
      "learning_rate": 9.338235294117648e-05,
      "loss": 1.5756,
      "step": 82500
    },
    {
      "epoch": 0.2075,
      "grad_norm": 1.9376120567321777,
      "learning_rate": 9.323529411764706e-05,
      "loss": 1.5763,
      "step": 83000
    },
    {
      "epoch": 0.20875,
      "grad_norm": 1.823911428451538,
      "learning_rate": 9.308823529411766e-05,
      "loss": 1.5775,
      "step": 83500
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.3817126750946045,
      "learning_rate": 9.294117647058824e-05,
      "loss": 1.5728,
      "step": 84000
    },
    {
      "epoch": 0.21125,
      "grad_norm": 1.9881726503372192,
      "learning_rate": 9.279411764705884e-05,
      "loss": 1.5702,
      "step": 84500
    },
    {
      "epoch": 0.2125,
      "grad_norm": 2.000735282897949,
      "learning_rate": 9.264705882352942e-05,
      "loss": 1.5583,
      "step": 85000
    },
    {
      "epoch": 0.21375,
      "grad_norm": 1.6832503080368042,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.5575,
      "step": 85500
    },
    {
      "epoch": 0.215,
      "grad_norm": 2.570873260498047,
      "learning_rate": 9.23529411764706e-05,
      "loss": 1.5641,
      "step": 86000
    },
    {
      "epoch": 0.21625,
      "grad_norm": 2.144967794418335,
      "learning_rate": 9.220588235294119e-05,
      "loss": 1.5614,
      "step": 86500
    },
    {
      "epoch": 0.2175,
      "grad_norm": 1.9306477308273315,
      "learning_rate": 9.205882352941177e-05,
      "loss": 1.5623,
      "step": 87000
    },
    {
      "epoch": 0.21875,
      "grad_norm": 1.929075837135315,
      "learning_rate": 9.191176470588235e-05,
      "loss": 1.5503,
      "step": 87500
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1191513538360596,
      "learning_rate": 9.176470588235295e-05,
      "loss": 1.549,
      "step": 88000
    },
    {
      "epoch": 0.22125,
      "grad_norm": 1.9515572786331177,
      "learning_rate": 9.161764705882353e-05,
      "loss": 1.5487,
      "step": 88500
    },
    {
      "epoch": 0.2225,
      "grad_norm": 2.0747973918914795,
      "learning_rate": 9.147058823529412e-05,
      "loss": 1.5458,
      "step": 89000
    },
    {
      "epoch": 0.22375,
      "grad_norm": 2.114978551864624,
      "learning_rate": 9.13235294117647e-05,
      "loss": 1.5428,
      "step": 89500
    },
    {
      "epoch": 0.225,
      "grad_norm": 2.0483994483947754,
      "learning_rate": 9.11764705882353e-05,
      "loss": 1.5419,
      "step": 90000
    },
    {
      "epoch": 0.22625,
      "grad_norm": 1.9456595182418823,
      "learning_rate": 9.102941176470588e-05,
      "loss": 1.5346,
      "step": 90500
    },
    {
      "epoch": 0.2275,
      "grad_norm": 2.0005695819854736,
      "learning_rate": 9.088235294117648e-05,
      "loss": 1.5296,
      "step": 91000
    },
    {
      "epoch": 0.22875,
      "grad_norm": 1.8668255805969238,
      "learning_rate": 9.073529411764706e-05,
      "loss": 1.5282,
      "step": 91500
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0259811878204346,
      "learning_rate": 9.058823529411765e-05,
      "loss": 1.5277,
      "step": 92000
    },
    {
      "epoch": 0.23125,
      "grad_norm": 2.109956741333008,
      "learning_rate": 9.044117647058823e-05,
      "loss": 1.5291,
      "step": 92500
    },
    {
      "epoch": 0.2325,
      "grad_norm": 2.011131763458252,
      "learning_rate": 9.029411764705883e-05,
      "loss": 1.5196,
      "step": 93000
    },
    {
      "epoch": 0.23375,
      "grad_norm": 2.0656349658966064,
      "learning_rate": 9.014705882352942e-05,
      "loss": 1.5191,
      "step": 93500
    },
    {
      "epoch": 0.235,
      "grad_norm": 1.9676610231399536,
      "learning_rate": 9e-05,
      "loss": 1.5296,
      "step": 94000
    },
    {
      "epoch": 0.23625,
      "grad_norm": 2.046384811401367,
      "learning_rate": 8.98529411764706e-05,
      "loss": 1.5208,
      "step": 94500
    },
    {
      "epoch": 0.2375,
      "grad_norm": 1.921543836593628,
      "learning_rate": 8.970588235294118e-05,
      "loss": 1.5139,
      "step": 95000
    },
    {
      "epoch": 0.23875,
      "grad_norm": 2.0970609188079834,
      "learning_rate": 8.955882352941178e-05,
      "loss": 1.5034,
      "step": 95500
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2860233783721924,
      "learning_rate": 8.941176470588236e-05,
      "loss": 1.5094,
      "step": 96000
    },
    {
      "epoch": 0.24125,
      "grad_norm": 2.231862783432007,
      "learning_rate": 8.926470588235295e-05,
      "loss": 1.5071,
      "step": 96500
    },
    {
      "epoch": 0.2425,
      "grad_norm": 2.1513900756835938,
      "learning_rate": 8.911764705882354e-05,
      "loss": 1.5047,
      "step": 97000
    },
    {
      "epoch": 0.24375,
      "grad_norm": 2.338294267654419,
      "learning_rate": 8.897058823529412e-05,
      "loss": 1.5019,
      "step": 97500
    },
    {
      "epoch": 0.245,
      "grad_norm": 1.898435115814209,
      "learning_rate": 8.882352941176471e-05,
      "loss": 1.4984,
      "step": 98000
    },
    {
      "epoch": 0.24625,
      "grad_norm": 2.1696417331695557,
      "learning_rate": 8.867647058823529e-05,
      "loss": 1.5009,
      "step": 98500
    },
    {
      "epoch": 0.2475,
      "grad_norm": 2.022007465362549,
      "learning_rate": 8.852941176470589e-05,
      "loss": 1.4996,
      "step": 99000
    },
    {
      "epoch": 0.24875,
      "grad_norm": 2.053650140762329,
      "learning_rate": 8.838235294117647e-05,
      "loss": 1.4999,
      "step": 99500
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.189403772354126,
      "learning_rate": 8.823529411764706e-05,
      "loss": 1.4964,
      "step": 100000
    }
  ],
  "logging_steps": 500,
  "max_steps": 400000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.678793019392e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
