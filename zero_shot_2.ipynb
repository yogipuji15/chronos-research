{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "MRRy4l-HtfJC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRRy4l-HtfJC",
    "outputId": "3f64e13a-dceb-4317-9024-d680121a8082"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yogi/miniconda3/envs/chronos-zero-shot/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Class to Create and Forecast time series using Amazon Chronos\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import transformers\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from chronos import ChronosPipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from gluonts.dataset.repository import get_dataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.ev.metrics import MASE, MeanWeightedSumQuantileLoss\n",
    "from gluonts.itertools import batcher\n",
    "from gluonts.model.evaluation import evaluate_forecasts\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class ChronosForecaster:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        transformers.set_seed(42)\n",
    "        self.limit_pred_len = True\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def is_gpu():\n",
    "        return torch.cuda.is_available()\n",
    "    \n",
    "    def get_series_decomposition(self, series, model='additive', period=12):\n",
    "        result = seasonal_decompose(series, model=model, period=period)\n",
    "        result.plot()\n",
    "        return result\n",
    "\n",
    "    def calculate_metrics(self, predicted, ground_truth):\n",
    "        mae = mean_absolute_error(ground_truth, predicted)\n",
    "        mse = mean_squared_error(ground_truth, predicted)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mape = mean_absolute_percentage_error(ground_truth, predicted)\n",
    "        r_squared = r2_score(ground_truth, predicted)\n",
    "\n",
    "        return {\n",
    "            'MAE': round(mae,2),\n",
    "            'MSE': round(mse,2),\n",
    "            'RMSE': round(rmse,2),\n",
    "            'MAPE': round(mape,2),\n",
    "            'R-squared': round(r_squared,2),\n",
    "        }\n",
    "    \n",
    "    # Split by percentage\n",
    "    def split_train_test(self, df, test_size=0.2, limit_pred_length=True):\n",
    "        self.df = df\n",
    "        _, _, self.y_train, self.y_test = train_test_split(df, df, test_size=test_size, random_state=42, shuffle=False)\n",
    "        clipped = False\n",
    "        self.limit_pred_len = limit_pred_length\n",
    "        if len(self.y_test) > 64 and self.limit_pred_len:\n",
    "            print(f\"[!] Test array size is {len(self.y_test)} which is > 64!\")\n",
    "            print(\"Clipping test data size to first 64 samples for acceptable accuracy\")\n",
    "            self.y_test = self.y_test[:64]\n",
    "            self.y_train = self.y_train[:-len(self.y_test)]\n",
    "            clipped = True\n",
    "        else:\n",
    "            print('[!] WARNING: limit_pred_length is disabled! Far future prediction will have low accuracy!')\n",
    "        return self.y_train, self.y_test, clipped\n",
    "    \n",
    "    # Split by number of samples to be predicted\n",
    "    def split_train_test_by_sample_size(self, df, target_column, test_sample_size=24):\n",
    "        self.df = df\n",
    "        self.y_test:pd.DataFrame = df.iloc[-test_sample_size:][target_column]\n",
    "        self.y_train:pd.DataFrame = df.iloc[:len(df)-test_sample_size][target_column]\n",
    "        self.limit_pred_len = False\n",
    "        return self.y_train, self.y_test\n",
    "\n",
    "    def predict(self, model_name=\"amazon/chronos-t5-small\", num_samples=20, temp=1, top_k=50, top_p=1, debug=True):\n",
    "        device = \"cuda\"\n",
    "        self.pipeline = ChronosPipeline.from_pretrained(\n",
    "            model_name,\n",
    "            device_map=device,\n",
    "            torch_dtype=torch.bfloat16\n",
    "        )\n",
    "        try:\n",
    "            context = torch.tensor(self.y_train)\n",
    "        except ValueError:\n",
    "            context = torch.tensor(self.y_train.astype(float).values)\n",
    "        prediction_length = len(self.y_test)\n",
    "        if debug:\n",
    "            print(f\"Using {device}\\nContext length = {len(self.y_train)}\\nForecast length = {prediction_length}\\nSample size = {num_samples}\")\n",
    "        self.forecast = self.pipeline.predict(\n",
    "            context,\n",
    "            prediction_length,\n",
    "            num_samples=num_samples,\n",
    "            temperature=temp,\n",
    "            top_k=int(top_k),\n",
    "            top_p=top_p,\n",
    "            limit_prediction_length=self.limit_pred_len\n",
    "        )\n",
    "\n",
    "        # self.forecast_index = range(len(self.y_train), len(self.y_train) + prediction_length)\n",
    "        self.forecast_index = range(self.y_test.index[0], self.y_test.index[-1] + 1)\n",
    "        self.low, self.median, self.high = np.quantile(self.forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "        # self.median = self.forecast[0].numpy().mean(axis=0)           # Mean instead of median\n",
    "        self.metrics = self.calculate_metrics(self.median, self.y_test)\n",
    "        self.params = json.dumps({\n",
    "                \"model\": model_name,\n",
    "                \"top_p\": top_p,\n",
    "                \"top_k\": top_k,\n",
    "                \"tempearature\": temp,\n",
    "                \"num_samples\": num_samples,\n",
    "                \"context_length\": len(self.y_train),\n",
    "                \"prediction_length\": prediction_length\n",
    "            },\n",
    "            indent=2)\n",
    "\n",
    "        return (self.forecast, self.metrics, self.median)\n",
    "    \n",
    "    def plot_forecast(self, series:pd.Series):\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(series, color=\"royalblue\", label=\"Historical Data\")\n",
    "        plt.plot(self.y_test, color=\"green\", label=\"Ground Truth\")\n",
    "        plt.plot(self.forecast_index, self.median, color=\"tomato\", label=\"Median Forecast\")\n",
    "        plt.fill_between(self.forecast_index, self.low, self.high, color=\"tomato\", alpha=0.3, label=\"80% Prediction Interval\")\n",
    "        plt.title('CHRONOS Forecasting')\n",
    "        plt.figtext(1, 0.55, \"Metrics:\\n\" + json.dumps(self.metrics, indent=2))\n",
    "        plt.figtext(1, 0.1, \"Params:\\n\" + self.params)\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        return plt\n",
    "\n",
    "    # Run tunning experiments for model param optimisation\n",
    "    def tune_model(self, num_iterations, series, metric_name='MSE'):\n",
    "        list_metrics = []\n",
    "\n",
    "        for i in range(num_iterations):\n",
    "            model_name = random.choice([\"amazon/chronos-t5-small\"])\n",
    "            top_p = random.randint(10, 100)\n",
    "            top_k = round(random.randrange(1,10,1)/10,1)\n",
    "            temp = round(random.randrange(1,10,1)/10,1)\n",
    "            num_samples = random.randint(9,51)\n",
    "\n",
    "            print(f'Running iteration {i} -> top_p = {top_p}, top_k = {top_k}, temp = {temp}, num_samples = {num_samples}')\n",
    "            \n",
    "            _, result, _ = self.predict(\n",
    "                model_name=model_name,\n",
    "                num_samples=num_samples,\n",
    "                temp=temp,\n",
    "                top_k=top_k,\n",
    "                top_p=top_p,\n",
    "                debug=False\n",
    "            )\n",
    "\n",
    "            plot = self.plot_forecast(series)\n",
    "            plot.savefig(f'results/{series.name}-{i}.png', bbox_inches='tight')\n",
    "            plot.close()\n",
    "\n",
    "            result['filename'] = f'results/{series.name}-{i}.png'\n",
    "\n",
    "            list_metrics.append(result | json.loads(self.params))\n",
    "\n",
    "        return pd.DataFrame(sorted(list_metrics, key=lambda x: x[metric_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa17f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with idx = 5350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "Context length = 1500\n",
      "Forecast length = 64\n",
      "Sample size = 3\n",
      "token=  tensor([[2132, 2128, 2127, 2126, 2128, 2127, 2126, 2126, 2125, 2125, 2125, 2126,\n",
      "         2125, 2126, 2126, 2125, 2124, 2125, 2124, 2121, 2119, 2119, 2122, 2121,\n",
      "         2122, 2124, 2124, 2126, 2126, 2126, 2126, 2128, 2129, 2129, 2126, 2126,\n",
      "         2126, 2126, 2126, 2126, 2127, 2126, 2127, 2127, 2127, 2127, 2128, 2131,\n",
      "         2130, 2133, 2131, 2131, 2130, 2128, 2126, 2127, 2127, 2123, 2123, 2120,\n",
      "         2121, 2122, 2119, 2119, 2119, 2118, 2116, 2115, 2117, 2116, 2117, 2117,\n",
      "         2116, 2116, 2115, 2112, 2112, 2112, 2113, 2114, 2115, 2114, 2113, 2110,\n",
      "         2107, 2105, 2102, 2103, 2106, 2107, 2107, 2106, 2100, 2102, 2099, 2094,\n",
      "         2094, 2094, 2088, 2085, 2083, 2084, 2081, 2083, 2083, 2088, 2092, 2089,\n",
      "         2091, 2089, 2091, 2092, 2099, 2100, 2097, 2097, 2097, 2099, 2100, 2098,\n",
      "         2096, 2097, 2095, 2094, 2095, 2095, 2095, 2096, 2095, 2095, 2096, 2096,\n",
      "         2095, 2095, 2095, 2095, 2099, 2098, 2097, 2099, 2097, 2097, 2098, 2098,\n",
      "         2097, 2097, 2097, 2097, 2098, 2097, 2098, 2099, 2099, 2100, 2100, 2102,\n",
      "         2104, 2107, 2106, 2104, 2103, 2103, 2101, 2106, 2108, 2107, 2106, 2105,\n",
      "         2104, 2105, 2105, 2105, 2104, 2105, 2105, 2106, 2105, 2108, 2109, 2110,\n",
      "         2109, 2109, 2112, 2110, 2110, 2109, 2110, 2109, 2113, 2113, 2113, 2113,\n",
      "         2116, 2116, 2117, 2117, 2117, 2114, 2114, 2119, 2126, 2127, 2126, 2123,\n",
      "         2120, 2120, 2122, 2122, 2124, 2123, 2123, 2123, 2121, 2122, 2122, 2123,\n",
      "         2125, 2125, 2127, 2128, 2126, 2126, 2126, 2126, 2123, 2118, 2121, 2123,\n",
      "         2124, 2123, 2121, 2122, 2120, 2117, 2119, 2116, 2117, 2116, 2115, 2114,\n",
      "         2117, 2116, 2116, 2116, 2115, 2116, 2120, 2121, 2120, 2138, 2136, 2136,\n",
      "         2147, 2145, 2151, 2150, 2150, 2147, 2147, 2147, 2147, 2147, 2151, 2152,\n",
      "         2151, 2153, 2153, 2164, 2160, 2160, 2158, 2158, 2159, 2159, 2164, 2164,\n",
      "         2161, 2165, 2164, 2161, 2161, 2163, 2155, 2156, 2164, 2165, 2164, 2168,\n",
      "         2170, 2170, 2178, 2183, 2190, 2194, 2217, 2217, 2230, 2231, 2219, 2215,\n",
      "         2215, 2215, 2235, 2229, 2228, 2228, 2228, 2252, 2256, 2255, 2290, 2290,\n",
      "         2288, 2306, 2338, 2344, 2338, 2319, 2300, 2345, 2336, 2316, 2315, 2297,\n",
      "         2286, 2270, 2255, 2290, 2273, 2265, 2272, 2296, 2311, 2302, 2321, 2315,\n",
      "         2315, 2318, 2315, 2304, 2307, 2316, 2323, 2322, 2319, 2324, 2312, 2312,\n",
      "         2302, 2299, 2283, 2273, 2260, 2256, 2256, 2256, 2273, 2266, 2260, 2262,\n",
      "         2261, 2258, 2259, 2260, 2250, 2251, 2274, 2259, 2254, 2258, 2257, 2257,\n",
      "         2253, 2265, 2268, 2278, 2266, 2258, 2260, 2265, 2264, 2271, 2266, 2267,\n",
      "         2269, 2267, 2264, 2271, 2271, 2274, 2282, 2280, 2283, 2292, 2293, 2292,\n",
      "         2292, 2298, 2297, 2297, 2297, 2297, 2282, 2290, 2286, 2273, 2265, 2260,\n",
      "         2265, 2265, 2271, 2277, 2276, 2276, 2286, 2283, 2274, 2270, 2267, 2277,\n",
      "         2273, 2279, 2273, 2268, 2264, 2265, 2256, 2253, 2259, 2258, 2258, 2262,\n",
      "         2257, 2255, 2262, 2256, 2255, 2257, 2279, 2277, 2286, 2289, 2286, 2285,\n",
      "         2289, 2291, 2292, 2294, 2294, 2286, 2287, 2292, 2293, 2284, 2283, 2289,\n",
      "         2283, 2282, 2278, 2273, 2269, 2265, 2259, 2266, 2266, 2272, 2270, 2271,\n",
      "         2271, 2272, 2260, 2260, 2261, 2260, 2262, 2260, 2259, 2263, 2271, 2271,\n",
      "         2264, 2267, 2270, 2267, 2264, 2275, 2289, 2283, 2278, 2280, 2273, 2272,\n",
      "         2267, 2268, 2266, 2261, 2261, 2261, 2260, 2263, 2261, 2255, 2263, 2262,\n",
      "         2262, 2265, 2266, 2273, 2269, 2266, 2273, 2278,    1]],\n",
      "       device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5195,  0.7617,  0.3633,  ...,  0.2109, -0.2080,  0.4102],\n",
      "         [ 0.0371, -0.0330, -0.3047,  ..., -0.6289,  0.7617,  0.4160],\n",
      "         [ 0.8359,  0.9688, -0.5000,  ...,  0.0233,  0.4082,  0.4160],\n",
      "         ...,\n",
      "         [-0.7344,  0.2002,  0.7148,  ..., -0.2080,  0.2773,  0.3340],\n",
      "         [-0.3594, -1.2422,  0.2695,  ..., -0.3145, -0.2148,  0.3242],\n",
      "         [ 0.3828, -0.2490, -0.0140,  ...,  3.0000, -1.0469, -2.5938]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([1, 513])\n",
      "testt2\n",
      "batch_size=  1\n",
      "seq_length=  513\n",
      "token=  tensor([[0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2282],\n",
      "        [2269],\n",
      "        [2272]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1406, -0.1318,  0.5547,  ...,  1.2422,  0.6133,  0.3027]],\n",
      "\n",
      "        [[-0.3320,  0.0070,  0.0776,  ..., -0.0435,  0.1035,  0.3262]],\n",
      "\n",
      "        [[ 0.0815,  0.3516,  0.7578,  ..., -0.1230,  0.5703,  0.3340]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2287],\n",
      "        [2266],\n",
      "        [2273]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3535, -0.8867,  0.4570,  ...,  0.5547,  0.7578,  0.2910]],\n",
      "\n",
      "        [[-0.8008, -1.0234, -0.1147,  ..., -0.2324,  1.1797,  0.3613]],\n",
      "\n",
      "        [[-0.7344,  0.2002,  0.7148,  ..., -0.2080,  0.2773,  0.3340]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2285],\n",
      "        [2270],\n",
      "        [2276]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 4.0430e-01, -7.9688e-01,  1.1377e-01,  ..., -9.6130e-04,\n",
      "           4.7461e-01,  3.0469e-01]],\n",
      "\n",
      "        [[-4.5703e-01, -1.8164e-01, -5.7129e-02,  ...,  5.8984e-01,\n",
      "           7.6953e-01,  3.3789e-01]],\n",
      "\n",
      "        [[ 9.4141e-01, -1.4844e+00,  5.4688e-01,  ..., -2.6489e-02,\n",
      "           8.7500e-01,  2.9102e-01]]], device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2310],\n",
      "        [2267],\n",
      "        [2276]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6992, -0.3828,  0.1641,  ...,  0.2891,  0.1357,  0.2754]],\n",
      "\n",
      "        [[-0.9961, -0.1240,  0.0026,  ..., -0.3008, -0.4219,  0.3574]],\n",
      "\n",
      "        [[ 0.9414, -1.4844,  0.5469,  ..., -0.0265,  0.8750,  0.2910]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2310],\n",
      "        [2271],\n",
      "        [2275]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6992, -0.3828,  0.1641,  ...,  0.2891,  0.1357,  0.2754]],\n",
      "\n",
      "        [[-0.9609,  0.3184, -0.3223,  ...,  0.5000,  0.4316,  0.3555]],\n",
      "\n",
      "        [[-0.6914, -1.5938,  0.1040,  ...,  0.5898,  0.6992,  0.3477]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2302],\n",
      "        [2273],\n",
      "        [2273]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4004,  0.1104,  0.3086,  ...,  0.5352,  0.7344,  0.2695]],\n",
      "\n",
      "        [[-0.7344,  0.2002,  0.7148,  ..., -0.2080,  0.2773,  0.3340]],\n",
      "\n",
      "        [[-0.7344,  0.2002,  0.7148,  ..., -0.2080,  0.2773,  0.3340]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2305],\n",
      "        [2276],\n",
      "        [2274]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7305, -1.5078,  0.3926,  ...,  0.5547, -0.1611,  0.2344]],\n",
      "\n",
      "        [[ 0.9414, -1.4844,  0.5469,  ..., -0.0265,  0.8750,  0.2910]],\n",
      "\n",
      "        [[-0.9453, -0.2334,  0.3867,  ...,  0.3438,  0.8711,  0.3301]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2304],\n",
      "        [2281],\n",
      "        [2275]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1250, -0.7852,  0.4883,  ...,  0.4531,  0.3965,  0.2832]],\n",
      "\n",
      "        [[-1.1719,  0.0835,  1.1641,  ...,  0.2598,  0.5508,  0.3105]],\n",
      "\n",
      "        [[-0.6914, -1.5938,  0.1040,  ...,  0.5898,  0.6992,  0.3477]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2314],\n",
      "        [2293],\n",
      "        [2280]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3828, -1.1484,  0.2119,  ...,  0.0552,  0.9727,  0.2383]],\n",
      "\n",
      "        [[-0.6953,  0.3809,  0.8203,  ...,  0.7852, -0.2324,  0.2949]],\n",
      "\n",
      "        [[ 0.1426, -1.1562,  0.1455,  ..., -0.8203,  0.2852,  0.3145]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2308],\n",
      "        [2293],\n",
      "        [2285]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0106, -0.8594, -0.2520,  ..., -0.1611,  0.6719,  0.3066]],\n",
      "\n",
      "        [[-0.6953,  0.3809,  0.8203,  ...,  0.7852, -0.2324,  0.2949]],\n",
      "\n",
      "        [[ 0.4043, -0.7969,  0.1138,  ..., -0.0010,  0.4746,  0.3047]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2308],\n",
      "        [2294],\n",
      "        [2286]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0106, -0.8594, -0.2520,  ..., -0.1611,  0.6719,  0.3066]],\n",
      "\n",
      "        [[-0.3027,  0.2617,  0.8555,  ...,  1.5156, -0.1719,  0.3027]],\n",
      "\n",
      "        [[-0.4648, -0.9805,  0.6016,  ..., -0.0525,  0.1348,  0.3125]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2307],\n",
      "        [2296],\n",
      "        [2288]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.9062, -1.1641, -0.3965,  ...,  1.3359, -0.2129,  0.2490]],\n",
      "\n",
      "        [[-0.3262, -0.0664,  0.5820,  ...,  0.8242,  0.7617,  0.3047]],\n",
      "\n",
      "        [[-0.8594, -0.2969,  0.4414,  ...,  0.6523,  0.1836,  0.2676]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2306],\n",
      "        [2298],\n",
      "        [2294]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.9297, -1.6328,  0.0796,  ...,  1.3203,  0.0240,  0.2490]],\n",
      "\n",
      "        [[-0.4844,  0.0157,  0.4199,  ...,  0.5898,  0.1396,  0.2695]],\n",
      "\n",
      "        [[-0.3027,  0.2617,  0.8555,  ...,  1.5156, -0.1719,  0.3027]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2314],\n",
      "        [2303],\n",
      "        [2293]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3828, -1.1484,  0.2119,  ...,  0.0552,  0.9727,  0.2383]],\n",
      "\n",
      "        [[-0.6914,  1.0156,  0.7656,  ..., -0.1875,  0.7070,  0.2949]],\n",
      "\n",
      "        [[-0.6953,  0.3809,  0.8203,  ...,  0.7852, -0.2324,  0.2949]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2313],\n",
      "        [2299],\n",
      "        [2295]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000, -0.9531,  0.3613,  ..., -0.0457,  0.5703,  0.2715]],\n",
      "\n",
      "        [[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]],\n",
      "\n",
      "        [[-0.2021,  0.3555,  0.5000,  ...,  0.8164, -0.2432,  0.2988]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2309],\n",
      "        [2295],\n",
      "        [2302]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2754,  0.0112,  0.2520,  ...,  0.0767,  0.6758,  0.2852]],\n",
      "\n",
      "        [[-0.2021,  0.3555,  0.5000,  ...,  0.8164, -0.2432,  0.2988]],\n",
      "\n",
      "        [[-0.4004,  0.1104,  0.3086,  ...,  0.5352,  0.7344,  0.2695]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2307],\n",
      "        [2289],\n",
      "        [2299]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.9062, -1.1641, -0.3965,  ...,  1.3359, -0.2129,  0.2490]],\n",
      "\n",
      "        [[-0.5156,  0.3594,  0.3672,  ...,  0.2305,  0.5469,  0.2891]],\n",
      "\n",
      "        [[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2307],\n",
      "        [2290],\n",
      "        [2299]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.9062, -1.1641, -0.3965,  ...,  1.3359, -0.2129,  0.2490]],\n",
      "\n",
      "        [[ 0.0359, -0.0466,  0.2461,  ...,  0.0649,  0.3398,  0.2637]],\n",
      "\n",
      "        [[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2300],\n",
      "        [2291],\n",
      "        [2299]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5273, -1.2734, -0.1221,  ...,  0.1729, -0.1943,  0.2539]],\n",
      "\n",
      "        [[-0.0232,  0.3105,  0.9883,  ..., -0.1035,  0.3008,  0.2910]],\n",
      "\n",
      "        [[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2298],\n",
      "        [2287],\n",
      "        [2297]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4844,  0.0157,  0.4199,  ...,  0.5898,  0.1396,  0.2695]],\n",
      "\n",
      "        [[-0.3535, -0.8867,  0.4570,  ...,  0.5547,  0.7578,  0.2910]],\n",
      "\n",
      "        [[-0.2227,  0.1416,  0.4414,  ...,  0.8984,  0.5117,  0.2656]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2295],\n",
      "        [2289],\n",
      "        [2299]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2021,  0.3555,  0.5000,  ...,  0.8164, -0.2432,  0.2988]],\n",
      "\n",
      "        [[-0.5156,  0.3594,  0.3672,  ...,  0.2305,  0.5469,  0.2891]],\n",
      "\n",
      "        [[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2298],\n",
      "        [2286],\n",
      "        [2299]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4844,  0.0157,  0.4199,  ...,  0.5898,  0.1396,  0.2695]],\n",
      "\n",
      "        [[-0.4648, -0.9805,  0.6016,  ..., -0.0525,  0.1348,  0.3125]],\n",
      "\n",
      "        [[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2304],\n",
      "        [2297],\n",
      "        [2300]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1250, -0.7852,  0.4883,  ...,  0.4531,  0.3965,  0.2832]],\n",
      "\n",
      "        [[-0.2227,  0.1416,  0.4414,  ...,  0.8984,  0.5117,  0.2656]],\n",
      "\n",
      "        [[-0.5273, -1.2734, -0.1221,  ...,  0.1729, -0.1943,  0.2539]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2303],\n",
      "        [2295],\n",
      "        [2301]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6914,  1.0156,  0.7656,  ..., -0.1875,  0.7070,  0.2949]],\n",
      "\n",
      "        [[-0.2021,  0.3555,  0.5000,  ...,  0.8164, -0.2432,  0.2988]],\n",
      "\n",
      "        [[-0.3418, -0.5742,  0.5391,  ...,  0.0923,  0.0535,  0.2471]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2301],\n",
      "        [2290],\n",
      "        [2312]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3418, -0.5742,  0.5391,  ...,  0.0923,  0.0535,  0.2471]],\n",
      "\n",
      "        [[ 0.0359, -0.0466,  0.2461,  ...,  0.0649,  0.3398,  0.2637]],\n",
      "\n",
      "        [[-1.1797, -0.6523,  0.1963,  ...,  0.9531,  0.0138,  0.2578]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2299],\n",
      "        [2289],\n",
      "        [2314]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]],\n",
      "\n",
      "        [[-0.5156,  0.3594,  0.3672,  ...,  0.2305,  0.5469,  0.2891]],\n",
      "\n",
      "        [[-0.3828, -1.1484,  0.2119,  ...,  0.0552,  0.9727,  0.2383]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2301],\n",
      "        [2288],\n",
      "        [2317]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3418, -0.5742,  0.5391,  ...,  0.0923,  0.0535,  0.2471]],\n",
      "\n",
      "        [[-0.8594, -0.2969,  0.4414,  ...,  0.6523,  0.1836,  0.2676]],\n",
      "\n",
      "        [[ 0.1914, -1.2578,  0.5781,  ...,  0.9180,  1.0547,  0.2832]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2293],\n",
      "        [2280],\n",
      "        [2318]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6953,  0.3809,  0.8203,  ...,  0.7852, -0.2324,  0.2949]],\n",
      "\n",
      "        [[ 0.1426, -1.1562,  0.1455,  ..., -0.8203,  0.2852,  0.3145]],\n",
      "\n",
      "        [[-0.5898, -1.6562,  0.8672,  ...,  0.7656,  0.1973,  0.2871]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2285],\n",
      "        [2280],\n",
      "        [2321]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 4.0430e-01, -7.9688e-01,  1.1377e-01,  ..., -9.6130e-04,\n",
      "           4.7461e-01,  3.0469e-01]],\n",
      "\n",
      "        [[ 1.4258e-01, -1.1562e+00,  1.4551e-01,  ..., -8.2031e-01,\n",
      "           2.8516e-01,  3.1445e-01]],\n",
      "\n",
      "        [[ 1.7578e-01, -5.2734e-01,  1.6895e-01,  ...,  2.5391e-01,\n",
      "           6.7188e-01,  2.4609e-01]]], device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2285],\n",
      "        [2279],\n",
      "        [2322]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 4.0430e-01, -7.9688e-01,  1.1377e-01,  ..., -9.6130e-04,\n",
      "           4.7461e-01,  3.0469e-01]],\n",
      "\n",
      "        [[ 8.1543e-02, -1.5547e+00, -1.3574e-01,  ...,  5.0781e-02,\n",
      "          -7.6172e-02,  2.9297e-01]],\n",
      "\n",
      "        [[ 4.2969e-01, -6.9531e-01,  1.7578e-01,  ...,  1.1406e+00,\n",
      "           7.9102e-02,  2.5586e-01]]], device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2286],\n",
      "        [2282],\n",
      "        [2322]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4648, -0.9805,  0.6016,  ..., -0.0525,  0.1348,  0.3125]],\n",
      "\n",
      "        [[ 0.1406, -0.1318,  0.5547,  ...,  1.2422,  0.6133,  0.3027]],\n",
      "\n",
      "        [[ 0.4297, -0.6953,  0.1758,  ...,  1.1406,  0.0791,  0.2559]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2292],\n",
      "        [2281],\n",
      "        [2322]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4922,  0.3438,  1.2578,  ...,  0.6016,  0.2295,  0.3223]],\n",
      "\n",
      "        [[-1.1719,  0.0835,  1.1641,  ...,  0.2598,  0.5508,  0.3105]],\n",
      "\n",
      "        [[ 0.4297, -0.6953,  0.1758,  ...,  1.1406,  0.0791,  0.2559]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2293],\n",
      "        [2278],\n",
      "        [2322]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6953,  0.3809,  0.8203,  ...,  0.7852, -0.2324,  0.2949]],\n",
      "\n",
      "        [[-0.3594, -1.2422,  0.2695,  ..., -0.3145, -0.2148,  0.3242]],\n",
      "\n",
      "        [[ 0.4297, -0.6953,  0.1758,  ...,  1.1406,  0.0791,  0.2559]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2297],\n",
      "        [2278],\n",
      "        [2322]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2227,  0.1416,  0.4414,  ...,  0.8984,  0.5117,  0.2656]],\n",
      "\n",
      "        [[-0.3594, -1.2422,  0.2695,  ..., -0.3145, -0.2148,  0.3242]],\n",
      "\n",
      "        [[ 0.4297, -0.6953,  0.1758,  ...,  1.1406,  0.0791,  0.2559]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2294],\n",
      "        [2269],\n",
      "        [2322]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3027,  0.2617,  0.8555,  ...,  1.5156, -0.1719,  0.3027]],\n",
      "\n",
      "        [[-0.3320,  0.0070,  0.0776,  ..., -0.0435,  0.1035,  0.3262]],\n",
      "\n",
      "        [[ 0.4297, -0.6953,  0.1758,  ...,  1.1406,  0.0791,  0.2559]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2288],\n",
      "        [2267],\n",
      "        [2319]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.8594, -0.2969,  0.4414,  ...,  0.6523,  0.1836,  0.2676]],\n",
      "\n",
      "        [[-0.9961, -0.1240,  0.0026,  ..., -0.3008, -0.4219,  0.3574]],\n",
      "\n",
      "        [[-0.8398, -1.2891,  0.5742,  ...,  0.6172,  0.0903,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2285],\n",
      "        [2268],\n",
      "        [2321]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4043, -0.7969,  0.1138,  ..., -0.0010,  0.4746,  0.3047]],\n",
      "\n",
      "        [[-0.2598, -0.1992,  0.0253,  ...,  0.6211, -0.3711,  0.3496]],\n",
      "\n",
      "        [[ 0.1758, -0.5273,  0.1689,  ...,  0.2539,  0.6719,  0.2461]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2290],\n",
      "        [2264],\n",
      "        [2318]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0359, -0.0466,  0.2461,  ...,  0.0649,  0.3398,  0.2637]],\n",
      "\n",
      "        [[-1.3359,  0.2188, -0.6172,  ..., -0.7422, -0.1064,  0.3398]],\n",
      "\n",
      "        [[-0.5898, -1.6562,  0.8672,  ...,  0.7656,  0.1973,  0.2871]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2290],\n",
      "        [2264],\n",
      "        [2321]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0359, -0.0466,  0.2461,  ...,  0.0649,  0.3398,  0.2637]],\n",
      "\n",
      "        [[-1.3359,  0.2188, -0.6172,  ..., -0.7422, -0.1064,  0.3398]],\n",
      "\n",
      "        [[ 0.1758, -0.5273,  0.1689,  ...,  0.2539,  0.6719,  0.2461]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2292],\n",
      "        [2267],\n",
      "        [2328]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4922,  0.3438,  1.2578,  ...,  0.6016,  0.2295,  0.3223]],\n",
      "\n",
      "        [[-0.9961, -0.1240,  0.0026,  ..., -0.3008, -0.4219,  0.3574]],\n",
      "\n",
      "        [[ 0.2061, -0.5234,  0.5820,  ...,  0.1226,  0.3047,  0.2334]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2291],\n",
      "        [2266],\n",
      "        [2321]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0232,  0.3105,  0.9883,  ..., -0.1035,  0.3008,  0.2910]],\n",
      "\n",
      "        [[-0.8008, -1.0234, -0.1147,  ..., -0.2324,  1.1797,  0.3613]],\n",
      "\n",
      "        [[ 0.1758, -0.5273,  0.1689,  ...,  0.2539,  0.6719,  0.2461]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2292],\n",
      "        [2250],\n",
      "        [2321]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4922,  0.3438,  1.2578,  ...,  0.6016,  0.2295,  0.3223]],\n",
      "\n",
      "        [[-0.3750, -0.8125, -0.2637,  ..., -0.3340,  0.9375,  0.3691]],\n",
      "\n",
      "        [[ 0.1758, -0.5273,  0.1689,  ...,  0.2539,  0.6719,  0.2461]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2295],\n",
      "        [2250],\n",
      "        [2319]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2021,  0.3555,  0.5000,  ...,  0.8164, -0.2432,  0.2988]],\n",
      "\n",
      "        [[-0.3750, -0.8125, -0.2637,  ..., -0.3340,  0.9375,  0.3691]],\n",
      "\n",
      "        [[-0.8398, -1.2891,  0.5742,  ...,  0.6172,  0.0903,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2296],\n",
      "        [2245],\n",
      "        [2319]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3262, -0.0664,  0.5820,  ...,  0.8242,  0.7617,  0.3047]],\n",
      "\n",
      "        [[-0.7031, -0.1245,  0.5977,  ..., -0.5742, -0.4043,  0.3438]],\n",
      "\n",
      "        [[-0.8398, -1.2891,  0.5742,  ...,  0.6172,  0.0903,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2292],\n",
      "        [2250],\n",
      "        [2320]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4922,  0.3438,  1.2578,  ...,  0.6016,  0.2295,  0.3223]],\n",
      "\n",
      "        [[-0.3750, -0.8125, -0.2637,  ..., -0.3340,  0.9375,  0.3691]],\n",
      "\n",
      "        [[-0.3008, -1.0469,  0.6836,  ...,  0.2695,  0.0277,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2292],\n",
      "        [2247],\n",
      "        [2317]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4922,  0.3438,  1.2578,  ...,  0.6016,  0.2295,  0.3223]],\n",
      "\n",
      "        [[-0.7461,  0.0500,  1.3125,  ..., -0.2793,  0.9453,  0.3066]],\n",
      "\n",
      "        [[ 0.1914, -1.2578,  0.5781,  ...,  0.9180,  1.0547,  0.2832]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2291],\n",
      "        [2239],\n",
      "        [2317]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0232,  0.3105,  0.9883,  ..., -0.1035,  0.3008,  0.2910]],\n",
      "\n",
      "        [[-0.6523,  0.0977,  0.4531,  ..., -0.4922,  0.3359,  0.2930]],\n",
      "\n",
      "        [[ 0.1914, -1.2578,  0.5781,  ...,  0.9180,  1.0547,  0.2832]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2286],\n",
      "        [2228],\n",
      "        [2318]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4648, -0.9805,  0.6016,  ..., -0.0525,  0.1348,  0.3125]],\n",
      "\n",
      "        [[ 0.2559,  0.1875,  0.1611,  ..., -0.0957,  0.0967,  0.3242]],\n",
      "\n",
      "        [[-0.5898, -1.6562,  0.8672,  ...,  0.7656,  0.1973,  0.2871]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2297],\n",
      "        [2218],\n",
      "        [2321]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2227,  0.1416,  0.4414,  ...,  0.8984,  0.5117,  0.2656]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[ 0.1758, -0.5273,  0.1689,  ...,  0.2539,  0.6719,  0.2461]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2294],\n",
      "        [2222],\n",
      "        [2325]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3027,  0.2617,  0.8555,  ...,  1.5156, -0.1719,  0.3027]],\n",
      "\n",
      "        [[-0.0188,  0.5039, -0.1069,  ...,  1.0781,  0.6055,  0.2773]],\n",
      "\n",
      "        [[-0.2480, -0.5195,  0.9180,  ...,  0.8359,  0.3828,  0.2490]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2293],\n",
      "        [2223],\n",
      "        [2324]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6953,  0.3809,  0.8203,  ...,  0.7852, -0.2324,  0.2949]],\n",
      "\n",
      "        [[-0.5234,  0.5273,  0.1689,  ...,  0.9102, -0.0820,  0.3008]],\n",
      "\n",
      "        [[-0.3672, -0.7422,  0.3301,  ...,  0.5156,  0.1758,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2294],\n",
      "        [2227],\n",
      "        [2316]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3027,  0.2617,  0.8555,  ...,  1.5156, -0.1719,  0.3027]],\n",
      "\n",
      "        [[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]],\n",
      "\n",
      "        [[-1.0156, -1.1562,  0.5703,  ...,  1.2812,  1.1484,  0.2969]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2299],\n",
      "        [2228],\n",
      "        [2318]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]],\n",
      "\n",
      "        [[ 0.2559,  0.1875,  0.1611,  ..., -0.0957,  0.0967,  0.3242]],\n",
      "\n",
      "        [[-0.5898, -1.6562,  0.8672,  ...,  0.7656,  0.1973,  0.2871]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2299],\n",
      "        [2235],\n",
      "        [2319]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]],\n",
      "\n",
      "        [[ 0.3125,  0.3262,  0.4824,  ...,  0.2070, -0.0295,  0.3105]],\n",
      "\n",
      "        [[-0.8398, -1.2891,  0.5742,  ...,  0.6172,  0.0903,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2295],\n",
      "        [2232],\n",
      "        [2316]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2021,  0.3555,  0.5000,  ...,  0.8164, -0.2432,  0.2988]],\n",
      "\n",
      "        [[-0.1748,  0.3457, -0.2500,  ..., -0.2490, -0.4785,  0.2871]],\n",
      "\n",
      "        [[-1.0156, -1.1562,  0.5703,  ...,  1.2812,  1.1484,  0.2969]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2300],\n",
      "        [2230],\n",
      "        [2316]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5273, -1.2734, -0.1221,  ...,  0.1729, -0.1943,  0.2539]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]],\n",
      "\n",
      "        [[-1.0156, -1.1562,  0.5703,  ...,  1.2812,  1.1484,  0.2969]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2298],\n",
      "        [2230],\n",
      "        [2316]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4844,  0.0157,  0.4199,  ...,  0.5898,  0.1396,  0.2695]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]],\n",
      "\n",
      "        [[-1.0156, -1.1562,  0.5703,  ...,  1.2812,  1.1484,  0.2969]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2300],\n",
      "        [2232],\n",
      "        [2316]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5273, -1.2734, -0.1221,  ...,  0.1729, -0.1943,  0.2539]],\n",
      "\n",
      "        [[-0.1748,  0.3457, -0.2500,  ..., -0.2490, -0.4785,  0.2871]],\n",
      "\n",
      "        [[-1.0156, -1.1562,  0.5703,  ...,  1.2812,  1.1484,  0.2969]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2306],\n",
      "        [2233],\n",
      "        [2315]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.9297, -1.6328,  0.0796,  ...,  1.3203,  0.0240,  0.2490]],\n",
      "\n",
      "        [[-0.0342,  0.3105,  0.5430,  ...,  0.4668, -0.2598,  0.2812]],\n",
      "\n",
      "        [[-0.8867, -0.9531, -0.0557,  ...,  0.4062,  0.8633,  0.2773]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2302],\n",
      "        [2228],\n",
      "        [2317]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4004,  0.1104,  0.3086,  ...,  0.5352,  0.7344,  0.2695]],\n",
      "\n",
      "        [[ 0.2559,  0.1875,  0.1611,  ..., -0.0957,  0.0967,  0.3242]],\n",
      "\n",
      "        [[ 0.1914, -1.2578,  0.5781,  ...,  0.9180,  1.0547,  0.2832]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2311],\n",
      "        [2229],\n",
      "        [2318]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.3047, -0.6797,  0.1289,  ...,  0.7812, -0.0405,  0.2334]],\n",
      "\n",
      "        [[ 0.0464,  0.5547, -0.4023,  ..., -0.4277, -0.2363,  0.3555]],\n",
      "\n",
      "        [[-0.5898, -1.6562,  0.8672,  ...,  0.7656,  0.1973,  0.2871]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2302],\n",
      "        [2234],\n",
      "        [2324]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4004,  0.1104,  0.3086,  ...,  0.5352,  0.7344,  0.2695]],\n",
      "\n",
      "        [[-0.4375,  0.4727,  0.4570,  ...,  0.2139,  1.0703,  0.2969]],\n",
      "\n",
      "        [[-0.3672, -0.7422,  0.3301,  ...,  0.5156,  0.1758,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2304],\n",
      "        [2249],\n",
      "        [2322]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1250, -0.7852,  0.4883,  ...,  0.4531,  0.3965,  0.2832]],\n",
      "\n",
      "        [[-1.1484, -0.3008,  0.5000,  ..., -0.3711, -0.0493,  0.3516]],\n",
      "\n",
      "        [[ 0.4297, -0.6953,  0.1758,  ...,  1.1406,  0.0791,  0.2559]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "Running with idx = 5414\n",
      "Using cuda\n",
      "Context length = 1500\n",
      "Forecast length = 64\n",
      "Sample size = 3\n",
      "token=  tensor([[2111, 2110, 2108, 2108, 2109, 2109, 2109, 2109, 2108, 2108, 2108, 2105,\n",
      "         2105, 2105, 2106, 2107, 2107, 2107, 2105, 2103, 2101, 2098, 2096, 2097,\n",
      "         2100, 2101, 2101, 2099, 2095, 2096, 2093, 2089, 2089, 2089, 2083, 2081,\n",
      "         2079, 2080, 2078, 2079, 2079, 2083, 2087, 2085, 2086, 2085, 2086, 2087,\n",
      "         2093, 2095, 2092, 2092, 2092, 2093, 2095, 2092, 2091, 2092, 2090, 2089,\n",
      "         2089, 2090, 2090, 2091, 2089, 2090, 2091, 2091, 2090, 2090, 2090, 2090,\n",
      "         2093, 2093, 2091, 2093, 2091, 2092, 2092, 2092, 2092, 2092, 2092, 2092,\n",
      "         2093, 2092, 2092, 2093, 2093, 2095, 2095, 2096, 2098, 2101, 2099, 2098,\n",
      "         2097, 2097, 2096, 2099, 2101, 2100, 2099, 2099, 2098, 2099, 2098, 2099,\n",
      "         2098, 2099, 2098, 2099, 2098, 2102, 2103, 2103, 2103, 2102, 2105, 2103,\n",
      "         2103, 2103, 2103, 2103, 2105, 2105, 2106, 2105, 2109, 2108, 2109, 2109,\n",
      "         2109, 2107, 2107, 2111, 2118, 2118, 2117, 2115, 2112, 2112, 2114, 2114,\n",
      "         2115, 2114, 2114, 2114, 2113, 2114, 2114, 2114, 2116, 2116, 2118, 2119,\n",
      "         2117, 2117, 2117, 2117, 2114, 2110, 2113, 2115, 2115, 2114, 2113, 2114,\n",
      "         2112, 2109, 2111, 2108, 2109, 2109, 2108, 2107, 2109, 2109, 2108, 2108,\n",
      "         2108, 2108, 2112, 2113, 2112, 2128, 2126, 2126, 2136, 2134, 2140, 2138,\n",
      "         2138, 2136, 2136, 2136, 2136, 2136, 2140, 2140, 2140, 2142, 2142, 2151,\n",
      "         2148, 2147, 2145, 2145, 2147, 2147, 2151, 2151, 2149, 2152, 2151, 2148,\n",
      "         2149, 2150, 2143, 2144, 2151, 2152, 2151, 2154, 2156, 2156, 2164, 2168,\n",
      "         2175, 2177, 2198, 2198, 2210, 2211, 2200, 2196, 2196, 2196, 2214, 2209,\n",
      "         2208, 2208, 2208, 2229, 2233, 2232, 2263, 2263, 2261, 2277, 2306, 2311,\n",
      "         2306, 2289, 2272, 2312, 2303, 2286, 2285, 2269, 2259, 2245, 2232, 2263,\n",
      "         2248, 2241, 2247, 2268, 2282, 2274, 2290, 2285, 2285, 2288, 2285, 2275,\n",
      "         2278, 2286, 2292, 2291, 2289, 2293, 2283, 2283, 2274, 2271, 2256, 2248,\n",
      "         2237, 2233, 2233, 2233, 2248, 2242, 2236, 2238, 2237, 2234, 2235, 2236,\n",
      "         2228, 2228, 2249, 2235, 2231, 2234, 2233, 2233, 2230, 2241, 2243, 2252,\n",
      "         2242, 2234, 2236, 2241, 2240, 2246, 2242, 2242, 2244, 2242, 2240, 2246,\n",
      "         2246, 2249, 2256, 2254, 2256, 2265, 2265, 2265, 2265, 2270, 2269, 2269,\n",
      "         2269, 2269, 2256, 2263, 2259, 2248, 2241, 2236, 2241, 2241, 2246, 2251,\n",
      "         2251, 2251, 2259, 2256, 2249, 2245, 2242, 2251, 2248, 2253, 2247, 2243,\n",
      "         2240, 2241, 2233, 2230, 2235, 2234, 2234, 2238, 2233, 2232, 2238, 2233,\n",
      "         2232, 2233, 2253, 2251, 2259, 2262, 2259, 2258, 2262, 2264, 2265, 2266,\n",
      "         2266, 2260, 2261, 2265, 2265, 2257, 2256, 2262, 2256, 2256, 2252, 2248,\n",
      "         2244, 2241, 2235, 2242, 2242, 2247, 2245, 2246, 2246, 2247, 2236, 2237,\n",
      "         2237, 2236, 2238, 2236, 2235, 2239, 2246, 2246, 2240, 2242, 2245, 2242,\n",
      "         2240, 2250, 2262, 2256, 2252, 2254, 2247, 2247, 2242, 2243, 2242, 2237,\n",
      "         2237, 2237, 2236, 2239, 2237, 2232, 2239, 2238, 2238, 2241, 2242, 2248,\n",
      "         2244, 2242, 2248, 2252, 2256, 2257, 2257, 2251, 2249, 2248, 2247, 2242,\n",
      "         2240, 2242, 2241, 2239, 2240, 2245, 2243, 2244, 2242, 2242, 2244, 2247,\n",
      "         2246, 2245, 2242, 2241, 2246, 2244, 2247, 2250, 2250, 2242, 2241, 2238,\n",
      "         2236, 2242, 2242, 2240, 2242, 2241, 2241, 2240, 2240, 2237, 2237, 2237,\n",
      "         2234, 2232, 2235, 2234, 2233, 2237, 2238, 2235, 2236, 2234, 2234, 2242,\n",
      "         2238, 2236, 2233, 2233, 2232, 2220, 2208, 2211,    1]],\n",
      "       device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4160,  0.7852,  0.5078,  ...,  0.7734, -0.4238,  0.4121],\n",
      "         [ 0.3496,  0.6094,  0.6641,  ...,  1.3984, -0.3398,  0.4141],\n",
      "         [-0.6914, -1.3438, -0.3965,  ...,  0.1719,  0.5977,  0.4160],\n",
      "         ...,\n",
      "         [-0.9375,  0.2246, -0.1240,  ...,  0.0221,  0.4922,  0.3262],\n",
      "         [-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281],\n",
      "         [ 0.3828, -0.2490, -0.0140,  ...,  3.0000, -1.0469, -2.5938]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([1, 513])\n",
      "testt2\n",
      "batch_size=  1\n",
      "seq_length=  513\n",
      "token=  tensor([[0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2211],\n",
      "        [2205],\n",
      "        [2213]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281]],\n",
      "\n",
      "        [[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2210],\n",
      "        [2212]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.2129, -0.0347,  ...,  0.0098,  0.6289,  0.3223]],\n",
      "\n",
      "        [[-0.3301,  0.6289, -0.3145,  ...,  0.8594,  0.5430,  0.3066]],\n",
      "\n",
      "        [[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2214],\n",
      "        [2212]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.2129, -0.0347,  ...,  0.0098,  0.6289,  0.3223]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]],\n",
      "\n",
      "        [[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2212],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.9375,  0.2246, -0.1240,  ...,  0.0221,  0.4922,  0.3262]],\n",
      "\n",
      "        [[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2207],\n",
      "        [2215],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6953,  0.2832, -0.3203,  ...,  1.1016,  0.6523,  0.3301]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2214],\n",
      "        [2213]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2209],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]],\n",
      "\n",
      "        [[-1.1328,  0.2129, -0.0347,  ...,  0.0098,  0.6289,  0.3223]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2209],\n",
      "        [2212]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.2129, -0.0347,  ...,  0.0098,  0.6289,  0.3223]],\n",
      "\n",
      "        [[-1.1328,  0.2129, -0.0347,  ...,  0.0098,  0.6289,  0.3223]],\n",
      "\n",
      "        [[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2215],\n",
      "        [2212]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.2129, -0.0347,  ...,  0.0098,  0.6289,  0.3223]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2214],\n",
      "        [2213]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.2129, -0.0347,  ...,  0.0098,  0.6289,  0.3223]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2212],\n",
      "        [2211],\n",
      "        [2212]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]],\n",
      "\n",
      "        [[-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281]],\n",
      "\n",
      "        [[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2212],\n",
      "        [2215],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2206],\n",
      "        [2213],\n",
      "        [2211]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0825,  0.5469, -0.3750,  ..., -0.5117,  0.9258,  0.3184]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]],\n",
      "\n",
      "        [[-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2206],\n",
      "        [2211],\n",
      "        [2208]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0825,  0.5469, -0.3750,  ..., -0.5117,  0.9258,  0.3184]],\n",
      "\n",
      "        [[-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281]],\n",
      "\n",
      "        [[-0.9375,  0.2246, -0.1240,  ...,  0.0221,  0.4922,  0.3262]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2199],\n",
      "        [2209],\n",
      "        [2212]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2383,  0.6250, -0.4219,  ...,  0.9609, -0.0469,  0.3535]],\n",
      "\n",
      "        [[-1.1328,  0.2129, -0.0347,  ...,  0.0098,  0.6289,  0.3223]],\n",
      "\n",
      "        [[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2194],\n",
      "        [2213],\n",
      "        [2211]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2275,  0.2891,  0.1089,  ..., -0.3164,  0.6641,  0.3730]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]],\n",
      "\n",
      "        [[-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2191],\n",
      "        [2216],\n",
      "        [2211]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0894,  0.5664,  0.6406,  ..., -0.4141, -0.1855,  0.3750]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2191],\n",
      "        [2218],\n",
      "        [2210]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0894,  0.5664,  0.6406,  ..., -0.4141, -0.1855,  0.3750]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.3301,  0.6289, -0.3145,  ...,  0.8594,  0.5430,  0.3066]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2203],\n",
      "        [2215],\n",
      "        [2210]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3262,  0.5234,  0.1865,  ...,  0.1357,  0.3242,  0.3398]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.3301,  0.6289, -0.3145,  ...,  0.8594,  0.5430,  0.3066]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2202],\n",
      "        [2215],\n",
      "        [2208]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5273,  0.6172,  0.6992,  ...,  0.3047, -0.3066,  0.3301]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.9375,  0.2246, -0.1240,  ...,  0.0221,  0.4922,  0.3262]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2203],\n",
      "        [2219],\n",
      "        [2210]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3262,  0.5234,  0.1865,  ...,  0.1357,  0.3242,  0.3398]],\n",
      "\n",
      "        [[-0.7656,  0.0679,  0.7500,  ..., -0.1045,  0.2432,  0.3105]],\n",
      "\n",
      "        [[-0.3301,  0.6289, -0.3145,  ...,  0.8594,  0.5430,  0.3066]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2202],\n",
      "        [2218],\n",
      "        [2211]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5273,  0.6172,  0.6992,  ...,  0.3047, -0.3066,  0.3301]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2202],\n",
      "        [2220],\n",
      "        [2206]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5273,  0.6172,  0.6992,  ...,  0.3047, -0.3066,  0.3301]],\n",
      "\n",
      "        [[-0.7070,  0.5508,  0.5117,  ...,  0.2178,  1.1484,  0.3066]],\n",
      "\n",
      "        [[ 0.0825,  0.5469, -0.3750,  ..., -0.5117,  0.9258,  0.3184]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2204],\n",
      "        [2218],\n",
      "        [2205]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3965,  0.2080,  0.5469,  ...,  1.1719,  0.1182,  0.3242]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2203],\n",
      "        [2218],\n",
      "        [2203]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3262,  0.5234,  0.1865,  ...,  0.1357,  0.3242,  0.3398]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.3262,  0.5234,  0.1865,  ...,  0.1357,  0.3242,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2218],\n",
      "        [2215]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2218],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2218],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2218],\n",
      "        [2211]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2216],\n",
      "        [2211]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2215],\n",
      "        [2212]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2214],\n",
      "        [2213]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.2129, -0.0347,  ...,  0.0098,  0.6289,  0.3223]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2211],\n",
      "        [2215]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.2129, -0.0347,  ...,  0.0098,  0.6289,  0.3223]],\n",
      "\n",
      "        [[-1.0156,  0.6523, -0.3008,  ...,  0.0386,  0.8906,  0.3281]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2215],\n",
      "        [2218],\n",
      "        [2215]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2218],\n",
      "        [2215],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2221],\n",
      "        [2216],\n",
      "        [2213]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3066,  0.4004,  0.2012,  ...,  1.3672,  0.5977,  0.3164]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2219],\n",
      "        [2216],\n",
      "        [2228]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7656,  0.0679,  0.7500,  ..., -0.1045,  0.2432,  0.3105]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[ 0.2559,  0.1875,  0.1611,  ..., -0.0957,  0.0967,  0.3242]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2220],\n",
      "        [2216],\n",
      "        [2230]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7070,  0.5508,  0.5117,  ...,  0.2178,  1.1484,  0.3066]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2221],\n",
      "        [2215],\n",
      "        [2221]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3066,  0.4004,  0.2012,  ...,  1.3672,  0.5977,  0.3164]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.3066,  0.4004,  0.2012,  ...,  1.3672,  0.5977,  0.3164]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2221],\n",
      "        [2214],\n",
      "        [2227]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3066,  0.4004,  0.2012,  ...,  1.3672,  0.5977,  0.3164]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]],\n",
      "\n",
      "        [[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2224],\n",
      "        [2216],\n",
      "        [2231]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0850,  0.6328, -0.1729,  ...,  0.9102, -0.1748,  0.2891]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-0.1816,  0.2393, -0.1387,  ...,  0.3906, -0.2617,  0.2832]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2230],\n",
      "        [2215],\n",
      "        [2224]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.0850,  0.6328, -0.1729,  ...,  0.9102, -0.1748,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2234],\n",
      "        [2217],\n",
      "        [2224]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4375,  0.4727,  0.4570,  ...,  0.2139,  1.0703,  0.2969]],\n",
      "\n",
      "        [[ 0.2637,  0.5430,  0.7656,  ..., -0.4629,  0.4609,  0.3535]],\n",
      "\n",
      "        [[-0.0850,  0.6328, -0.1729,  ...,  0.9102, -0.1748,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2238],\n",
      "        [2217],\n",
      "        [2222]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1953,  0.2422, -0.4316,  ..., -0.2178, -0.2754,  0.3086]],\n",
      "\n",
      "        [[ 0.2637,  0.5430,  0.7656,  ..., -0.4629,  0.4609,  0.3535]],\n",
      "\n",
      "        [[-0.0188,  0.5039, -0.1069,  ...,  1.0781,  0.6055,  0.2773]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2238],\n",
      "        [2216],\n",
      "        [2225]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1953,  0.2422, -0.4316,  ..., -0.2178, -0.2754,  0.3086]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-0.3438,  0.3594, -0.3320,  ...,  0.3672,  0.6367,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2245],\n",
      "        [2218],\n",
      "        [2224]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7031, -0.1245,  0.5977,  ..., -0.5742, -0.4043,  0.3438]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.0850,  0.6328, -0.1729,  ...,  0.9102, -0.1748,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2245],\n",
      "        [2216],\n",
      "        [2218]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7031, -0.1245,  0.5977,  ..., -0.5742, -0.4043,  0.3438]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2240],\n",
      "        [2217],\n",
      "        [2217]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.9414,  0.4180,  0.4043,  ..., -0.1069,  0.5000,  0.2754]],\n",
      "\n",
      "        [[ 0.2637,  0.5430,  0.7656,  ..., -0.4629,  0.4609,  0.3535]],\n",
      "\n",
      "        [[ 0.2637,  0.5430,  0.7656,  ..., -0.4629,  0.4609,  0.3535]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2261],\n",
      "        [2218],\n",
      "        [2219]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6914, -1.2891,  0.1523,  ..., -0.1855, -0.2246,  0.2891]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.7656,  0.0679,  0.7500,  ..., -0.1045,  0.2432,  0.3105]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2261],\n",
      "        [2218],\n",
      "        [2220]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6914, -1.2891,  0.1523,  ..., -0.1855, -0.2246,  0.2891]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.7070,  0.5508,  0.5117,  ...,  0.2178,  1.1484,  0.3066]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2259],\n",
      "        [2217],\n",
      "        [2220]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0312, -0.5391,  0.8672,  ..., -0.5273,  0.9141,  0.3477]],\n",
      "\n",
      "        [[ 0.2637,  0.5430,  0.7656,  ..., -0.4629,  0.4609,  0.3535]],\n",
      "\n",
      "        [[-0.7070,  0.5508,  0.5117,  ...,  0.2178,  1.1484,  0.3066]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2259],\n",
      "        [2216],\n",
      "        [2218]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0312, -0.5391,  0.8672,  ..., -0.5273,  0.9141,  0.3477]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2256],\n",
      "        [2216],\n",
      "        [2223]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2002, -0.8750,  1.1719,  ..., -0.2432,  0.5352,  0.3320]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-0.5234,  0.5273,  0.1689,  ...,  0.9102, -0.0820,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2271],\n",
      "        [2215],\n",
      "        [2233]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.9609,  0.3184, -0.3223,  ...,  0.5000,  0.4316,  0.3555]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.0342,  0.3105,  0.5430,  ...,  0.4668, -0.2598,  0.2812]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2276],\n",
      "        [2213],\n",
      "        [2235]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.9414, -1.4844,  0.5469,  ..., -0.0265,  0.8750,  0.2910]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]],\n",
      "\n",
      "        [[ 0.3125,  0.3262,  0.4824,  ...,  0.2070, -0.0295,  0.3105]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2276],\n",
      "        [2215],\n",
      "        [2230]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.9414, -1.4844,  0.5469,  ..., -0.0265,  0.8750,  0.2910]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2280],\n",
      "        [2214],\n",
      "        [2230]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1426, -1.1562,  0.1455,  ..., -0.8203,  0.2852,  0.3145]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2276],\n",
      "        [2215],\n",
      "        [2231]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.9414, -1.4844,  0.5469,  ..., -0.0265,  0.8750,  0.2910]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.1816,  0.2393, -0.1387,  ...,  0.3906, -0.2617,  0.2832]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2282],\n",
      "        [2215],\n",
      "        [2234]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1406, -0.1318,  0.5547,  ...,  1.2422,  0.6133,  0.3027]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.4375,  0.4727,  0.4570,  ...,  0.2139,  1.0703,  0.2969]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2302],\n",
      "        [2215],\n",
      "        [2232]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4004,  0.1104,  0.3086,  ...,  0.5352,  0.7344,  0.2695]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.1748,  0.3457, -0.2500,  ..., -0.2490, -0.4785,  0.2871]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2311],\n",
      "        [2217],\n",
      "        [2227]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.3047, -0.6797,  0.1289,  ...,  0.7812, -0.0405,  0.2334]],\n",
      "\n",
      "        [[ 0.2637,  0.5430,  0.7656,  ..., -0.4629,  0.4609,  0.3535]],\n",
      "\n",
      "        [[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2302],\n",
      "        [2217],\n",
      "        [2227]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4004,  0.1104,  0.3086,  ...,  0.5352,  0.7344,  0.2695]],\n",
      "\n",
      "        [[ 0.2637,  0.5430,  0.7656,  ..., -0.4629,  0.4609,  0.3535]],\n",
      "\n",
      "        [[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2296],\n",
      "        [2216],\n",
      "        [2226]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3262, -0.0664,  0.5820,  ...,  0.8242,  0.7617,  0.3047]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-0.1709,  0.2520, -0.3027,  ...,  0.4141,  0.7266,  0.2734]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "Running with idx = 5478\n",
      "Using cuda\n",
      "Context length = 1500\n",
      "Forecast length = 64\n",
      "Sample size = 3\n",
      "token=  tensor([[2085, 2085, 2086, 2086, 2085, 2086, 2086, 2086, 2088, 2088, 2087, 2088,\n",
      "         2087, 2087, 2087, 2087, 2087, 2087, 2087, 2087, 2088, 2087, 2087, 2088,\n",
      "         2088, 2090, 2090, 2091, 2092, 2095, 2094, 2093, 2091, 2091, 2090, 2094,\n",
      "         2095, 2094, 2094, 2093, 2093, 2093, 2093, 2093, 2093, 2093, 2093, 2094,\n",
      "         2093, 2096, 2097, 2097, 2097, 2096, 2098, 2097, 2097, 2097, 2097, 2097,\n",
      "         2099, 2099, 2099, 2099, 2102, 2102, 2102, 2102, 2102, 2100, 2101, 2104,\n",
      "         2110, 2110, 2109, 2108, 2105, 2105, 2106, 2106, 2108, 2107, 2107, 2107,\n",
      "         2106, 2107, 2106, 2107, 2109, 2109, 2110, 2111, 2110, 2109, 2109, 2109,\n",
      "         2107, 2103, 2106, 2108, 2108, 2107, 2106, 2107, 2105, 2103, 2104, 2102,\n",
      "         2102, 2102, 2101, 2101, 2103, 2102, 2102, 2102, 2101, 2102, 2105, 2106,\n",
      "         2105, 2119, 2117, 2118, 2126, 2125, 2129, 2128, 2128, 2127, 2126, 2126,\n",
      "         2126, 2126, 2129, 2130, 2130, 2131, 2131, 2140, 2137, 2136, 2135, 2135,\n",
      "         2136, 2136, 2140, 2139, 2137, 2141, 2139, 2137, 2137, 2139, 2133, 2133,\n",
      "         2140, 2141, 2140, 2143, 2144, 2144, 2151, 2155, 2161, 2163, 2182, 2182,\n",
      "         2192, 2193, 2183, 2180, 2180, 2180, 2195, 2191, 2191, 2191, 2191, 2209,\n",
      "         2212, 2211, 2239, 2239, 2238, 2252, 2277, 2282, 2277, 2262, 2247, 2282,\n",
      "         2275, 2260, 2259, 2244, 2235, 2223, 2211, 2239, 2226, 2219, 2225, 2244,\n",
      "         2256, 2249, 2263, 2259, 2259, 2261, 2259, 2250, 2252, 2260, 2265, 2264,\n",
      "         2262, 2265, 2257, 2257, 2249, 2246, 2233, 2226, 2216, 2212, 2212, 2212,\n",
      "         2226, 2220, 2215, 2217, 2216, 2214, 2214, 2215, 2208, 2208, 2227, 2214,\n",
      "         2211, 2214, 2213, 2213, 2210, 2219, 2222, 2230, 2220, 2214, 2215, 2219,\n",
      "         2219, 2224, 2220, 2221, 2222, 2221, 2219, 2224, 2224, 2227, 2233, 2231,\n",
      "         2233, 2241, 2241, 2241, 2241, 2245, 2244, 2244, 2244, 2244, 2233, 2239,\n",
      "         2235, 2226, 2219, 2215, 2219, 2219, 2224, 2229, 2228, 2228, 2235, 2233,\n",
      "         2227, 2223, 2221, 2229, 2226, 2230, 2225, 2222, 2219, 2219, 2212, 2210,\n",
      "         2214, 2214, 2214, 2217, 2213, 2211, 2217, 2212, 2211, 2213, 2230, 2229,\n",
      "         2235, 2238, 2235, 2235, 2238, 2240, 2241, 2242, 2242, 2236, 2237, 2241,\n",
      "         2241, 2234, 2233, 2238, 2233, 2233, 2230, 2226, 2222, 2219, 2214, 2220,\n",
      "         2220, 2225, 2223, 2224, 2224, 2225, 2215, 2216, 2216, 2215, 2217, 2215,\n",
      "         2214, 2218, 2224, 2224, 2219, 2221, 2223, 2221, 2219, 2227, 2238, 2233,\n",
      "         2230, 2231, 2225, 2225, 2221, 2222, 2220, 2216, 2216, 2216, 2215, 2218,\n",
      "         2216, 2211, 2218, 2217, 2217, 2219, 2220, 2226, 2222, 2220, 2226, 2230,\n",
      "         2233, 2234, 2234, 2228, 2227, 2226, 2225, 2221, 2219, 2220, 2219, 2218,\n",
      "         2219, 2223, 2222, 2222, 2220, 2220, 2222, 2225, 2224, 2223, 2221, 2219,\n",
      "         2224, 2222, 2225, 2227, 2227, 2220, 2219, 2217, 2215, 2220, 2220, 2219,\n",
      "         2220, 2219, 2219, 2219, 2219, 2216, 2216, 2216, 2214, 2211, 2214, 2214,\n",
      "         2213, 2216, 2217, 2214, 2215, 2214, 2214, 2220, 2217, 2215, 2212, 2212,\n",
      "         2211, 2201, 2191, 2193, 2192, 2185, 2179, 2175, 2191, 2191, 2187, 2178,\n",
      "         2181, 2178, 2178, 2178, 2178, 2179, 2184, 2181, 2181, 2180, 2179, 2186,\n",
      "         2184, 2187, 2186, 2186, 2191, 2202, 2208, 2208, 2210, 2211, 2211, 2211,\n",
      "         2214, 2216, 2216, 2228, 2255, 2257, 2243, 2237, 2233, 2225, 2222, 2224,\n",
      "         2221, 2224, 2222, 2235, 2232, 2242, 2244, 2241, 2234, 2233, 2227, 2233,\n",
      "         2242, 2244, 2243, 2251, 2254, 2241, 2244, 2253,    1]],\n",
      "       device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0378, -0.4766,  1.1719,  ..., -0.4980, -0.0164,  0.4199],\n",
      "         [ 0.0378, -0.4766,  1.1719,  ..., -0.4980, -0.0164,  0.4199],\n",
      "         [-0.7852,  0.3223,  0.0291,  ...,  0.7812,  0.0366,  0.4258],\n",
      "         ...,\n",
      "         [-0.7578, -0.8867, -0.8867,  ..., -0.3887,  0.1289,  0.3164],\n",
      "         [-1.0156, -1.0156,  0.7930,  ..., -0.5078,  0.4707,  0.3594],\n",
      "         [ 0.3828, -0.2490, -0.0140,  ...,  3.0000, -1.0469, -2.5938]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([1, 513])\n",
      "testt2\n",
      "batch_size=  1\n",
      "seq_length=  513\n",
      "token=  tensor([[0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2239],\n",
      "        [2250],\n",
      "        [2251]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6523,  0.0977,  0.4531,  ..., -0.4922,  0.3359,  0.2930]],\n",
      "\n",
      "        [[-0.3750, -0.8125, -0.2637,  ..., -0.3340,  0.9375,  0.3691]],\n",
      "\n",
      "        [[-0.5547, -1.1641,  0.0693,  ..., -0.3242,  1.1797,  0.3359]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2243],\n",
      "        [2245],\n",
      "        [2251]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0752, -0.0339, -0.3945,  ..., -0.7344, -0.2080,  0.3301]],\n",
      "\n",
      "        [[-0.7031, -0.1245,  0.5977,  ..., -0.5742, -0.4043,  0.3438]],\n",
      "\n",
      "        [[-0.5547, -1.1641,  0.0693,  ..., -0.3242,  1.1797,  0.3359]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2244],\n",
      "        [2248],\n",
      "        [2253]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7578, -0.8867, -0.8867,  ..., -0.3887,  0.1289,  0.3164]],\n",
      "\n",
      "        [[-0.8594, -0.5234,  0.4805,  ..., -0.4727,  0.6523,  0.3340]],\n",
      "\n",
      "        [[-1.0156, -1.0156,  0.7930,  ..., -0.5078,  0.4707,  0.3594]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2243],\n",
      "        [2248],\n",
      "        [2253]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0752, -0.0339, -0.3945,  ..., -0.7344, -0.2080,  0.3301]],\n",
      "\n",
      "        [[-0.8594, -0.5234,  0.4805,  ..., -0.4727,  0.6523,  0.3340]],\n",
      "\n",
      "        [[-1.0156, -1.0156,  0.7930,  ..., -0.5078,  0.4707,  0.3594]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2243],\n",
      "        [2251],\n",
      "        [2253]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0752, -0.0339, -0.3945,  ..., -0.7344, -0.2080,  0.3301]],\n",
      "\n",
      "        [[-0.5547, -1.1641,  0.0693,  ..., -0.3242,  1.1797,  0.3359]],\n",
      "\n",
      "        [[-1.0156, -1.0156,  0.7930,  ..., -0.5078,  0.4707,  0.3594]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2252],\n",
      "        [2248],\n",
      "        [2252]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1641, -1.3125,  0.7891,  ..., -0.4355,  0.2754,  0.3672]],\n",
      "\n",
      "        [[-0.8594, -0.5234,  0.4805,  ..., -0.4727,  0.6523,  0.3340]],\n",
      "\n",
      "        [[-1.1641, -1.3125,  0.7891,  ..., -0.4355,  0.2754,  0.3672]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2244],\n",
      "        [2246],\n",
      "        [2261]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7578, -0.8867, -0.8867,  ..., -0.3887,  0.1289,  0.3164]],\n",
      "\n",
      "        [[-0.9141,  0.4414,  1.0391,  ..., -0.0908,  0.1123,  0.3457]],\n",
      "\n",
      "        [[-0.6914, -1.2891,  0.1523,  ..., -0.1855, -0.2246,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2244],\n",
      "        [2252],\n",
      "        [2275]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7578, -0.8867, -0.8867,  ..., -0.3887,  0.1289,  0.3164]],\n",
      "\n",
      "        [[-1.1641, -1.3125,  0.7891,  ..., -0.4355,  0.2754,  0.3672]],\n",
      "\n",
      "        [[-0.6914, -1.5938,  0.1040,  ...,  0.5898,  0.6992,  0.3477]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2243],\n",
      "        [2255],\n",
      "        [2280]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0752, -0.0339, -0.3945,  ..., -0.7344, -0.2080,  0.3301]],\n",
      "\n",
      "        [[-1.2109, -1.1094,  0.8516,  ..., -0.6797, -0.0542,  0.3164]],\n",
      "\n",
      "        [[ 0.1426, -1.1562,  0.1455,  ..., -0.8203,  0.2852,  0.3145]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2246],\n",
      "        [2253],\n",
      "        [2285]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-9.1406e-01,  4.4141e-01,  1.0391e+00,  ..., -9.0820e-02,\n",
      "           1.1230e-01,  3.4570e-01]],\n",
      "\n",
      "        [[-1.0156e+00, -1.0156e+00,  7.9297e-01,  ..., -5.0781e-01,\n",
      "           4.7070e-01,  3.5938e-01]],\n",
      "\n",
      "        [[ 4.0430e-01, -7.9688e-01,  1.1377e-01,  ..., -9.6130e-04,\n",
      "           4.7461e-01,  3.0469e-01]]], device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2243],\n",
      "        [2258],\n",
      "        [2286]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0752, -0.0339, -0.3945,  ..., -0.7344, -0.2080,  0.3301]],\n",
      "\n",
      "        [[-0.2793, -1.5625,  0.5703,  ..., -0.3926,  1.0859,  0.3496]],\n",
      "\n",
      "        [[-0.4648, -0.9805,  0.6016,  ..., -0.0525,  0.1348,  0.3125]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2244],\n",
      "        [2257],\n",
      "        [2288]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7578, -0.8867, -0.8867,  ..., -0.3887,  0.1289,  0.3164]],\n",
      "\n",
      "        [[-0.9102, -1.0625,  1.0625,  ..., -0.1572,  1.0469,  0.3594]],\n",
      "\n",
      "        [[-0.8594, -0.2969,  0.4414,  ...,  0.6523,  0.1836,  0.2676]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2243],\n",
      "        [2251],\n",
      "        [2294]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0752, -0.0339, -0.3945,  ..., -0.7344, -0.2080,  0.3301]],\n",
      "\n",
      "        [[-0.5547, -1.1641,  0.0693,  ..., -0.3242,  1.1797,  0.3359]],\n",
      "\n",
      "        [[-0.3027,  0.2617,  0.8555,  ...,  1.5156, -0.1719,  0.3027]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2247],\n",
      "        [2252],\n",
      "        [2293]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7461,  0.0500,  1.3125,  ..., -0.2793,  0.9453,  0.3066]],\n",
      "\n",
      "        [[-1.1641, -1.3125,  0.7891,  ..., -0.4355,  0.2754,  0.3672]],\n",
      "\n",
      "        [[-0.6953,  0.3809,  0.8203,  ...,  0.7852, -0.2324,  0.2949]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2243],\n",
      "        [2252],\n",
      "        [2276]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0752, -0.0339, -0.3945,  ..., -0.7344, -0.2080,  0.3301]],\n",
      "\n",
      "        [[-1.1641, -1.3125,  0.7891,  ..., -0.4355,  0.2754,  0.3672]],\n",
      "\n",
      "        [[ 0.9414, -1.4844,  0.5469,  ..., -0.0265,  0.8750,  0.2910]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2238],\n",
      "        [2251],\n",
      "        [2283]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1953,  0.2422, -0.4316,  ..., -0.2178, -0.2754,  0.3086]],\n",
      "\n",
      "        [[-0.5547, -1.1641,  0.0693,  ..., -0.3242,  1.1797,  0.3359]],\n",
      "\n",
      "        [[-0.2559, -1.0938,  0.4941,  ...,  1.2891,  0.7031,  0.3105]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2243],\n",
      "        [2253],\n",
      "        [2297]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0752, -0.0339, -0.3945,  ..., -0.7344, -0.2080,  0.3301]],\n",
      "\n",
      "        [[-1.0156, -1.0156,  0.7930,  ..., -0.5078,  0.4707,  0.3594]],\n",
      "\n",
      "        [[-0.2227,  0.1416,  0.4414,  ...,  0.8984,  0.5117,  0.2656]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2245],\n",
      "        [2256],\n",
      "        [2299]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7031, -0.1245,  0.5977,  ..., -0.5742, -0.4043,  0.3438]],\n",
      "\n",
      "        [[ 0.2002, -0.8750,  1.1719,  ..., -0.2432,  0.5352,  0.3320]],\n",
      "\n",
      "        [[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2244],\n",
      "        [2255],\n",
      "        [2299]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7578, -0.8867, -0.8867,  ..., -0.3887,  0.1289,  0.3164]],\n",
      "\n",
      "        [[-1.2109, -1.1094,  0.8516,  ..., -0.6797, -0.0542,  0.3164]],\n",
      "\n",
      "        [[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2245],\n",
      "        [2256],\n",
      "        [2310]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7031, -0.1245,  0.5977,  ..., -0.5742, -0.4043,  0.3438]],\n",
      "\n",
      "        [[ 0.2002, -0.8750,  1.1719,  ..., -0.2432,  0.5352,  0.3320]],\n",
      "\n",
      "        [[-0.6992, -0.3828,  0.1641,  ...,  0.2891,  0.1357,  0.2754]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2245],\n",
      "        [2255],\n",
      "        [2310]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7031, -0.1245,  0.5977,  ..., -0.5742, -0.4043,  0.3438]],\n",
      "\n",
      "        [[-1.2109, -1.1094,  0.8516,  ..., -0.6797, -0.0542,  0.3164]],\n",
      "\n",
      "        [[-0.6992, -0.3828,  0.1641,  ...,  0.2891,  0.1357,  0.2754]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2237],\n",
      "        [2255],\n",
      "        [2314]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1211,  0.0874, -0.8633,  ..., -0.4414, -0.4062,  0.3203]],\n",
      "\n",
      "        [[-1.2109, -1.1094,  0.8516,  ..., -0.6797, -0.0542,  0.3164]],\n",
      "\n",
      "        [[-0.3828, -1.1484,  0.2119,  ...,  0.0552,  0.9727,  0.2383]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2246],\n",
      "        [2258],\n",
      "        [2332]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.9141,  0.4414,  1.0391,  ..., -0.0908,  0.1123,  0.3457]],\n",
      "\n",
      "        [[-0.2793, -1.5625,  0.5703,  ..., -0.3926,  1.0859,  0.3496]],\n",
      "\n",
      "        [[-0.2754, -0.5234,  0.2168,  ...,  0.1719,  0.1123,  0.2344]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2250],\n",
      "        [2266],\n",
      "        [2316]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3750, -0.8125, -0.2637,  ..., -0.3340,  0.9375,  0.3691]],\n",
      "\n",
      "        [[-0.8008, -1.0234, -0.1147,  ..., -0.2324,  1.1797,  0.3613]],\n",
      "\n",
      "        [[-1.0156, -1.1562,  0.5703,  ...,  1.2812,  1.1484,  0.2969]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2245],\n",
      "        [2252],\n",
      "        [2312]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7031, -0.1245,  0.5977,  ..., -0.5742, -0.4043,  0.3438]],\n",
      "\n",
      "        [[-1.1641, -1.3125,  0.7891,  ..., -0.4355,  0.2754,  0.3672]],\n",
      "\n",
      "        [[-1.1797, -0.6523,  0.1963,  ...,  0.9531,  0.0138,  0.2578]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2244],\n",
      "        [2249],\n",
      "        [2298]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7578, -0.8867, -0.8867,  ..., -0.3887,  0.1289,  0.3164]],\n",
      "\n",
      "        [[-1.1484, -0.3008,  0.5000,  ..., -0.3711, -0.0493,  0.3516]],\n",
      "\n",
      "        [[-0.4844,  0.0157,  0.4199,  ...,  0.5898,  0.1396,  0.2695]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2241],\n",
      "        [2250],\n",
      "        [2295]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3301,  0.0601,  0.6680,  ..., -0.5898, -0.5977,  0.3105]],\n",
      "\n",
      "        [[-0.3750, -0.8125, -0.2637,  ..., -0.3340,  0.9375,  0.3691]],\n",
      "\n",
      "        [[-0.2021,  0.3555,  0.5000,  ...,  0.8164, -0.2432,  0.2988]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2234],\n",
      "        [2250],\n",
      "        [2299]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4375,  0.4727,  0.4570,  ...,  0.2139,  1.0703,  0.2969]],\n",
      "\n",
      "        [[-0.3750, -0.8125, -0.2637,  ..., -0.3340,  0.9375,  0.3691]],\n",
      "\n",
      "        [[-0.2910,  0.4043,  0.4688,  ...,  0.3438, -0.0204,  0.2734]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2229],\n",
      "        [2254],\n",
      "        [2301]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0464,  0.5547, -0.4023,  ..., -0.4277, -0.2363,  0.3555]],\n",
      "\n",
      "        [[-0.4961, -0.8203,  0.9961,  ..., -0.6133,  0.2852,  0.3379]],\n",
      "\n",
      "        [[-0.3418, -0.5742,  0.5391,  ...,  0.0923,  0.0535,  0.2471]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2217],\n",
      "        [2254],\n",
      "        [2300]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2637,  0.5430,  0.7656,  ..., -0.4629,  0.4609,  0.3535]],\n",
      "\n",
      "        [[-0.4961, -0.8203,  0.9961,  ..., -0.6133,  0.2852,  0.3379]],\n",
      "\n",
      "        [[-0.5273, -1.2734, -0.1221,  ...,  0.1729, -0.1943,  0.2539]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2218],\n",
      "        [2253],\n",
      "        [2301]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-1.0156, -1.0156,  0.7930,  ..., -0.5078,  0.4707,  0.3594]],\n",
      "\n",
      "        [[-0.3418, -0.5742,  0.5391,  ...,  0.0923,  0.0535,  0.2471]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2218],\n",
      "        [2253],\n",
      "        [2304]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-1.0156, -1.0156,  0.7930,  ..., -0.5078,  0.4707,  0.3594]],\n",
      "\n",
      "        [[-1.1250, -0.7852,  0.4883,  ...,  0.4531,  0.3965,  0.2832]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2227],\n",
      "        [2261],\n",
      "        [2300]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]],\n",
      "\n",
      "        [[-0.6914, -1.2891,  0.1523,  ..., -0.1855, -0.2246,  0.2891]],\n",
      "\n",
      "        [[-0.5273, -1.2734, -0.1221,  ...,  0.1729, -0.1943,  0.2539]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2215],\n",
      "        [2268],\n",
      "        [2292]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]],\n",
      "\n",
      "        [[-0.2598, -0.1992,  0.0253,  ...,  0.6211, -0.3711,  0.3496]],\n",
      "\n",
      "        [[-0.4922,  0.3438,  1.2578,  ...,  0.6016,  0.2295,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2218],\n",
      "        [2269],\n",
      "        [2265]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.3320,  0.0070,  0.0776,  ..., -0.0435,  0.1035,  0.3262]],\n",
      "\n",
      "        [[-0.9219, -0.5859, -0.9727,  ..., -0.3379,  0.5234,  0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2221],\n",
      "        [2267],\n",
      "        [2284]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3066,  0.4004,  0.2012,  ...,  1.3672,  0.5977,  0.3164]],\n",
      "\n",
      "        [[-0.9961, -0.1240,  0.0026,  ..., -0.3008, -0.4219,  0.3574]],\n",
      "\n",
      "        [[-0.4941, -0.6328,  0.0718,  ...,  0.6445,  1.0078,  0.2695]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2219],\n",
      "        [2268],\n",
      "        [2303]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7656,  0.0679,  0.7500,  ..., -0.1045,  0.2432,  0.3105]],\n",
      "\n",
      "        [[-0.2598, -0.1992,  0.0253,  ...,  0.6211, -0.3711,  0.3496]],\n",
      "\n",
      "        [[-0.6914,  1.0156,  0.7656,  ..., -0.1875,  0.7070,  0.2949]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2220],\n",
      "        [2264],\n",
      "        [2301]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7070,  0.5508,  0.5117,  ...,  0.2178,  1.1484,  0.3066]],\n",
      "\n",
      "        [[-1.3359,  0.2188, -0.6172,  ..., -0.7422, -0.1064,  0.3398]],\n",
      "\n",
      "        [[-0.3418, -0.5742,  0.5391,  ...,  0.0923,  0.0535,  0.2471]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2221],\n",
      "        [2258],\n",
      "        [2298]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3066,  0.4004,  0.2012,  ...,  1.3672,  0.5977,  0.3164]],\n",
      "\n",
      "        [[-0.2793, -1.5625,  0.5703,  ..., -0.3926,  1.0859,  0.3496]],\n",
      "\n",
      "        [[-0.4844,  0.0157,  0.4199,  ...,  0.5898,  0.1396,  0.2695]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2221],\n",
      "        [2258],\n",
      "        [2296]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3066,  0.4004,  0.2012,  ...,  1.3672,  0.5977,  0.3164]],\n",
      "\n",
      "        [[-0.2793, -1.5625,  0.5703,  ..., -0.3926,  1.0859,  0.3496]],\n",
      "\n",
      "        [[-0.3262, -0.0664,  0.5820,  ...,  0.8242,  0.7617,  0.3047]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2219],\n",
      "        [2266],\n",
      "        [2300]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7656,  0.0679,  0.7500,  ..., -0.1045,  0.2432,  0.3105]],\n",
      "\n",
      "        [[-0.8008, -1.0234, -0.1147,  ..., -0.2324,  1.1797,  0.3613]],\n",
      "\n",
      "        [[-0.5273, -1.2734, -0.1221,  ...,  0.1729, -0.1943,  0.2539]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2230],\n",
      "        [2250],\n",
      "        [2298]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]],\n",
      "\n",
      "        [[-0.3750, -0.8125, -0.2637,  ..., -0.3340,  0.9375,  0.3691]],\n",
      "\n",
      "        [[-0.4844,  0.0157,  0.4199,  ...,  0.5898,  0.1396,  0.2695]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2234],\n",
      "        [2229],\n",
      "        [2298]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4375,  0.4727,  0.4570,  ...,  0.2139,  1.0703,  0.2969]],\n",
      "\n",
      "        [[ 0.0464,  0.5547, -0.4023,  ..., -0.4277, -0.2363,  0.3555]],\n",
      "\n",
      "        [[-0.4844,  0.0157,  0.4199,  ...,  0.5898,  0.1396,  0.2695]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2238],\n",
      "        [2228],\n",
      "        [2301]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1953,  0.2422, -0.4316,  ..., -0.2178, -0.2754,  0.3086]],\n",
      "\n",
      "        [[ 0.2559,  0.1875,  0.1611,  ..., -0.0957,  0.0967,  0.3242]],\n",
      "\n",
      "        [[-0.3418, -0.5742,  0.5391,  ...,  0.0923,  0.0535,  0.2471]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2238],\n",
      "        [2230],\n",
      "        [2298]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1953,  0.2422, -0.4316,  ..., -0.2178, -0.2754,  0.3086]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]],\n",
      "\n",
      "        [[-0.4844,  0.0157,  0.4199,  ...,  0.5898,  0.1396,  0.2695]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2245],\n",
      "        [2229],\n",
      "        [2293]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7031, -0.1245,  0.5977,  ..., -0.5742, -0.4043,  0.3438]],\n",
      "\n",
      "        [[ 0.0464,  0.5547, -0.4023,  ..., -0.4277, -0.2363,  0.3555]],\n",
      "\n",
      "        [[-0.6953,  0.3809,  0.8203,  ...,  0.7852, -0.2324,  0.2949]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2245],\n",
      "        [2232],\n",
      "        [2296]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7031, -0.1245,  0.5977,  ..., -0.5742, -0.4043,  0.3438]],\n",
      "\n",
      "        [[-0.1748,  0.3457, -0.2500,  ..., -0.2490, -0.4785,  0.2871]],\n",
      "\n",
      "        [[-0.3262, -0.0664,  0.5820,  ...,  0.8242,  0.7617,  0.3047]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2240],\n",
      "        [2228],\n",
      "        [2301]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.9414,  0.4180,  0.4043,  ..., -0.1069,  0.5000,  0.2754]],\n",
      "\n",
      "        [[ 0.2559,  0.1875,  0.1611,  ..., -0.0957,  0.0967,  0.3242]],\n",
      "\n",
      "        [[-0.3418, -0.5742,  0.5391,  ...,  0.0923,  0.0535,  0.2471]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2233],\n",
      "        [2218],\n",
      "        [2305]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0342,  0.3105,  0.5430,  ...,  0.4668, -0.2598,  0.2812]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.7305, -1.5078,  0.3926,  ...,  0.5547, -0.1611,  0.2344]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2233],\n",
      "        [2218],\n",
      "        [2303]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0342,  0.3105,  0.5430,  ...,  0.4668, -0.2598,  0.2812]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]],\n",
      "\n",
      "        [[-0.6914,  1.0156,  0.7656,  ..., -0.1875,  0.7070,  0.2949]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2232],\n",
      "        [2217],\n",
      "        [2305]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1748,  0.3457, -0.2500,  ..., -0.2490, -0.4785,  0.2871]],\n",
      "\n",
      "        [[ 0.2637,  0.5430,  0.7656,  ..., -0.4629,  0.4609,  0.3535]],\n",
      "\n",
      "        [[-0.7305, -1.5078,  0.3926,  ...,  0.5547, -0.1611,  0.2344]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2226],\n",
      "        [2216],\n",
      "        [2316]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1709,  0.2520, -0.3027,  ...,  0.4141,  0.7266,  0.2734]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[-1.0156, -1.1562,  0.5703,  ...,  1.2812,  1.1484,  0.2969]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2225],\n",
      "        [2216],\n",
      "        [2323]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3438,  0.3594, -0.3320,  ...,  0.3672,  0.6367,  0.3223]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]],\n",
      "\n",
      "        [[ 0.1348, -0.6719, -0.1396,  ...,  0.9219,  0.2363,  0.2617]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2226],\n",
      "        [2235],\n",
      "        [2331]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1709,  0.2520, -0.3027,  ...,  0.4141,  0.7266,  0.2734]],\n",
      "\n",
      "        [[ 0.3125,  0.3262,  0.4824,  ...,  0.2070, -0.0295,  0.3105]],\n",
      "\n",
      "        [[-0.1328, -0.5117,  0.0767,  ...,  0.1855,  0.1436,  0.2070]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2221],\n",
      "        [2232],\n",
      "        [2334]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3066,  0.4004,  0.2012,  ...,  1.3672,  0.5977,  0.3164]],\n",
      "\n",
      "        [[-0.1748,  0.3457, -0.2500,  ..., -0.2490, -0.4785,  0.2871]],\n",
      "\n",
      "        [[-0.6641, -0.2295,  0.6836,  ...,  0.1230,  0.5234,  0.2656]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2227],\n",
      "        [2230],\n",
      "        [2334]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]],\n",
      "\n",
      "        [[-0.6641, -0.2295,  0.6836,  ...,  0.1230,  0.5234,  0.2656]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2227],\n",
      "        [2230],\n",
      "        [2333]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]],\n",
      "\n",
      "        [[-0.3828,  0.0605,  0.3477,  ...,  0.2080,  0.5117,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2231],\n",
      "        [2229],\n",
      "        [2337]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1816,  0.2393, -0.1387,  ...,  0.3906, -0.2617,  0.2832]],\n",
      "\n",
      "        [[ 0.0464,  0.5547, -0.4023,  ..., -0.4277, -0.2363,  0.3555]],\n",
      "\n",
      "        [[-0.4766,  0.4434,  0.1504,  ..., -0.1357, -0.3594,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2230],\n",
      "        [2226],\n",
      "        [2337]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]],\n",
      "\n",
      "        [[-0.1709,  0.2520, -0.3027,  ...,  0.4141,  0.7266,  0.2734]],\n",
      "\n",
      "        [[-0.4766,  0.4434,  0.1504,  ..., -0.1357, -0.3594,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2227],\n",
      "        [2224],\n",
      "        [2337]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]],\n",
      "\n",
      "        [[-0.0850,  0.6328, -0.1729,  ...,  0.9102, -0.1748,  0.2891]],\n",
      "\n",
      "        [[-0.4766,  0.4434,  0.1504,  ..., -0.1357, -0.3594,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2229],\n",
      "        [2224],\n",
      "        [2339]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0464,  0.5547, -0.4023,  ..., -0.4277, -0.2363,  0.3555]],\n",
      "\n",
      "        [[-0.0850,  0.6328, -0.1729,  ...,  0.9102, -0.1748,  0.2891]],\n",
      "\n",
      "        [[-0.7891,  0.0442, -0.5000,  ...,  0.3574,  0.6602,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2229],\n",
      "        [2234],\n",
      "        [2342]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0464,  0.5547, -0.4023,  ..., -0.4277, -0.2363,  0.3555]],\n",
      "\n",
      "        [[-0.4375,  0.4727,  0.4570,  ...,  0.2139,  1.0703,  0.2969]],\n",
      "\n",
      "        [[-0.7109,  0.0366, -0.5977,  ...,  0.3809,  0.6172,  0.2676]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2237],\n",
      "        [2249],\n",
      "        [2343]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1211,  0.0874, -0.8633,  ..., -0.4414, -0.4062,  0.3203]],\n",
      "\n",
      "        [[-1.1484, -0.3008,  0.5000,  ..., -0.3711, -0.0493,  0.3516]],\n",
      "\n",
      "        [[-0.7500,  0.1387, -0.1094,  ...,  0.5430,  0.8164,  0.2393]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "Running with idx = 5542\n",
      "Using cuda\n",
      "Context length = 1500\n",
      "Forecast length = 64\n",
      "Sample size = 3\n",
      "token=  tensor([[2096, 2096, 2097, 2097, 2097, 2095, 2095, 2098, 2104, 2104, 2103, 2101,\n",
      "         2099, 2099, 2100, 2100, 2102, 2101, 2101, 2101, 2100, 2101, 2100, 2101,\n",
      "         2103, 2103, 2104, 2105, 2103, 2103, 2103, 2103, 2101, 2097, 2100, 2101,\n",
      "         2102, 2101, 2100, 2101, 2099, 2097, 2098, 2096, 2097, 2096, 2096, 2095,\n",
      "         2097, 2096, 2096, 2096, 2096, 2096, 2099, 2100, 2099, 2112, 2110, 2111,\n",
      "         2118, 2117, 2121, 2120, 2120, 2118, 2118, 2118, 2118, 2118, 2121, 2122,\n",
      "         2121, 2123, 2123, 2130, 2128, 2127, 2126, 2126, 2127, 2127, 2130, 2130,\n",
      "         2128, 2131, 2130, 2128, 2128, 2130, 2124, 2125, 2131, 2131, 2131, 2133,\n",
      "         2134, 2134, 2140, 2144, 2149, 2151, 2168, 2168, 2177, 2178, 2169, 2166,\n",
      "         2166, 2166, 2180, 2176, 2176, 2176, 2176, 2192, 2195, 2194, 2219, 2219,\n",
      "         2218, 2230, 2253, 2257, 2253, 2239, 2226, 2258, 2251, 2238, 2237, 2224,\n",
      "         2216, 2205, 2194, 2219, 2207, 2202, 2206, 2223, 2234, 2228, 2241, 2237,\n",
      "         2237, 2239, 2237, 2229, 2231, 2238, 2242, 2241, 2239, 2243, 2235, 2235,\n",
      "         2228, 2226, 2214, 2207, 2198, 2195, 2195, 2195, 2207, 2202, 2198, 2200,\n",
      "         2199, 2196, 2197, 2198, 2191, 2192, 2208, 2197, 2194, 2196, 2196, 2196,\n",
      "         2193, 2202, 2203, 2211, 2202, 2196, 2198, 2202, 2201, 2205, 2202, 2203,\n",
      "         2204, 2203, 2201, 2205, 2205, 2208, 2213, 2212, 2214, 2221, 2221, 2221,\n",
      "         2221, 2224, 2224, 2224, 2224, 2224, 2213, 2219, 2216, 2207, 2202, 2198,\n",
      "         2202, 2202, 2205, 2210, 2209, 2209, 2216, 2214, 2208, 2205, 2203, 2210,\n",
      "         2207, 2211, 2207, 2203, 2201, 2202, 2195, 2193, 2197, 2196, 2196, 2200,\n",
      "         2196, 2194, 2200, 2195, 2194, 2196, 2211, 2210, 2216, 2219, 2216, 2215,\n",
      "         2219, 2220, 2221, 2222, 2222, 2217, 2217, 2221, 2221, 2215, 2214, 2219,\n",
      "         2214, 2213, 2211, 2207, 2204, 2202, 2197, 2202, 2202, 2206, 2205, 2205,\n",
      "         2205, 2206, 2198, 2198, 2199, 2198, 2200, 2198, 2197, 2200, 2205, 2205,\n",
      "         2201, 2203, 2205, 2203, 2201, 2209, 2219, 2214, 2211, 2212, 2207, 2206,\n",
      "         2203, 2203, 2202, 2199, 2199, 2199, 2198, 2200, 2199, 2194, 2200, 2200,\n",
      "         2200, 2202, 2202, 2207, 2204, 2202, 2207, 2211, 2213, 2215, 2215, 2209,\n",
      "         2208, 2207, 2206, 2203, 2201, 2202, 2202, 2200, 2201, 2205, 2203, 2204,\n",
      "         2202, 2202, 2204, 2206, 2205, 2205, 2203, 2202, 2205, 2204, 2206, 2209,\n",
      "         2209, 2202, 2202, 2200, 2198, 2202, 2202, 2201, 2202, 2202, 2202, 2201,\n",
      "         2201, 2199, 2198, 2199, 2196, 2194, 2197, 2196, 2196, 2198, 2200, 2197,\n",
      "         2198, 2196, 2196, 2202, 2200, 2198, 2195, 2195, 2194, 2185, 2176, 2178,\n",
      "         2177, 2170, 2166, 2162, 2176, 2176, 2172, 2164, 2167, 2165, 2165, 2165,\n",
      "         2165, 2166, 2169, 2167, 2167, 2166, 2166, 2172, 2170, 2173, 2172, 2172,\n",
      "         2176, 2186, 2191, 2192, 2193, 2194, 2194, 2194, 2197, 2199, 2199, 2209,\n",
      "         2234, 2235, 2222, 2217, 2214, 2206, 2204, 2205, 2203, 2205, 2203, 2216,\n",
      "         2213, 2222, 2223, 2221, 2215, 2213, 2209, 2213, 2222, 2224, 2222, 2230,\n",
      "         2232, 2221, 2224, 2232, 2231, 2231, 2239, 2236, 2234, 2232, 2228, 2221,\n",
      "         2213, 2217, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2215, 2207, 2206,\n",
      "         2202, 2202, 2202, 2205, 2206, 2210, 2212, 2215, 2217, 2212, 2212, 2211,\n",
      "         2217, 2213, 2213, 2213, 2213, 2209, 2207, 2207, 2206, 2199, 2197, 2192,\n",
      "         2191, 2190, 2187, 2185, 2190, 2181, 2178, 2178, 2173, 2171, 2169, 2167,\n",
      "         2164, 2162, 2166, 2162, 2162, 2161, 2162, 2163,    1]],\n",
      "       device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6016,  0.0508,  0.2695,  ...,  0.3633, -0.6719,  0.4297],\n",
      "         [ 0.6016,  0.0508,  0.2695,  ...,  0.3633, -0.6719,  0.4297],\n",
      "         [ 0.5859, -0.4043,  0.6328,  ..., -0.2305,  0.9844,  0.4199],\n",
      "         ...,\n",
      "         [ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062],\n",
      "         [ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141],\n",
      "         [ 0.3828, -0.2490, -0.0140,  ...,  3.0000, -1.0469, -2.5938]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([1, 513])\n",
      "testt2\n",
      "batch_size=  1\n",
      "seq_length=  513\n",
      "token=  tensor([[0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2162],\n",
      "        [2163],\n",
      "        [2165]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2161],\n",
      "        [2166]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.1475,  0.7500,  0.8086,  ..., -0.3672,  0.1226,  0.4102]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2162],\n",
      "        [2161],\n",
      "        [2165]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[ 0.1475,  0.7500,  0.8086,  ..., -0.3672,  0.1226,  0.4102]],\n",
      "\n",
      "        [[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2160],\n",
      "        [2176]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2162],\n",
      "        [2162],\n",
      "        [2176]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2166],\n",
      "        [2173]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]],\n",
      "\n",
      "        [[ 0.6445,  0.6250,  0.7617,  ...,  0.2578,  0.6797,  0.3945]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2162],\n",
      "        [2175]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[ 0.7539, -0.2930,  0.5469,  ...,  0.2676,  0.3770,  0.3926]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2165],\n",
      "        [2162],\n",
      "        [2175]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]],\n",
      "\n",
      "        [[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[ 0.7539, -0.2930,  0.5469,  ...,  0.2676,  0.3770,  0.3926]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2164],\n",
      "        [2166],\n",
      "        [2176]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]],\n",
      "\n",
      "        [[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2165],\n",
      "        [2166],\n",
      "        [2179]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]],\n",
      "\n",
      "        [[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2166],\n",
      "        [2179]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]],\n",
      "\n",
      "        [[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2162],\n",
      "        [2179]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2158],\n",
      "        [2186]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2165],\n",
      "        [2165],\n",
      "        [2191]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]],\n",
      "\n",
      "        [[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]],\n",
      "\n",
      "        [[-0.0894,  0.5664,  0.6406,  ..., -0.4141, -0.1855,  0.3750]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2164],\n",
      "        [2160],\n",
      "        [2186]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2160],\n",
      "        [2160],\n",
      "        [2186]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2160],\n",
      "        [2193]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[-0.1660,  0.6797,  0.5352,  ..., -0.5156,  0.2129,  0.3750]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2164],\n",
      "        [2200]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]],\n",
      "\n",
      "        [[-0.3496,  0.3379, -0.0513,  ..., -1.0781,  0.3652,  0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2164],\n",
      "        [2196]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]],\n",
      "\n",
      "        [[-0.3535,  0.4551, -0.1582,  ...,  0.4199,  1.0625,  0.3555]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2168],\n",
      "        [2166],\n",
      "        [2200]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0732, -0.9609,  0.0762,  ..., -0.3477,  0.2754,  0.4043]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]],\n",
      "\n",
      "        [[-0.3496,  0.3379, -0.0513,  ..., -1.0781,  0.3652,  0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2171],\n",
      "        [2174],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4062,  0.5352,  1.0938,  ...,  0.6172,  0.2773,  0.4082]],\n",
      "\n",
      "        [[ 0.7227,  0.2715,  0.5547,  ..., -0.0623,  0.2500,  0.4023]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2170],\n",
      "        [2174],\n",
      "        [2215]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.8984,  0.4570,  0.4824,  ..., -0.6562,  0.4336,  0.4023]],\n",
      "\n",
      "        [[ 0.7227,  0.2715,  0.5547,  ..., -0.0623,  0.2500,  0.4023]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2171],\n",
      "        [2171],\n",
      "        [2206]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4062,  0.5352,  1.0938,  ...,  0.6172,  0.2773,  0.4082]],\n",
      "\n",
      "        [[ 0.4062,  0.5352,  1.0938,  ...,  0.6172,  0.2773,  0.4082]],\n",
      "\n",
      "        [[ 0.0825,  0.5469, -0.3750,  ..., -0.5117,  0.9258,  0.3184]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2175],\n",
      "        [2176],\n",
      "        [2205]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7539, -0.2930,  0.5469,  ...,  0.2676,  0.3770,  0.3926]],\n",
      "\n",
      "        [[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[-0.5000,  0.7695, -0.4121,  ...,  0.9688,  0.2812,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2178],\n",
      "        [2216]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]],\n",
      "\n",
      "        [[ 0.0913,  0.5273,  0.3086,  ...,  0.5469,  0.6133,  0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2176],\n",
      "        [2215]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[-0.5156,  0.5781,  0.1758,  ...,  0.9375,  0.6133,  0.3418]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2178],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2178],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2185],\n",
      "        [2179],\n",
      "        [2222]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]],\n",
      "\n",
      "        [[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]],\n",
      "\n",
      "        [[-0.0188,  0.5039, -0.1069,  ...,  1.0781,  0.6055,  0.2773]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2178],\n",
      "        [2213]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2176],\n",
      "        [2212]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[-0.2178,  0.5664, -0.2969,  ...,  0.3242,  0.3848,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2178],\n",
      "        [2213]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2178],\n",
      "        [2219]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]],\n",
      "\n",
      "        [[-0.7656,  0.0679,  0.7500,  ..., -0.1045,  0.2432,  0.3105]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2176],\n",
      "        [2213]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[-1.1172,  0.5039, -0.6484,  ...,  0.5898, -0.6367,  0.3438]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2187],\n",
      "        [2177],\n",
      "        [2222]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1318,  0.5938,  0.3418,  ...,  0.2559,  0.6250,  0.3867]],\n",
      "\n",
      "        [[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]],\n",
      "\n",
      "        [[-0.0188,  0.5039, -0.1069,  ...,  1.0781,  0.6055,  0.2773]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2186],\n",
      "        [2178],\n",
      "        [2222]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]],\n",
      "\n",
      "        [[-0.0188,  0.5039, -0.1069,  ...,  1.0781,  0.6055,  0.2773]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2186],\n",
      "        [2178],\n",
      "        [2228]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]],\n",
      "\n",
      "        [[ 0.2559,  0.1875,  0.1611,  ..., -0.0957,  0.0967,  0.3242]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2175],\n",
      "        [2230]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.7539, -0.2930,  0.5469,  ...,  0.2676,  0.3770,  0.3926]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2173],\n",
      "        [2221]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.6445,  0.6250,  0.7617,  ...,  0.2578,  0.6797,  0.3945]],\n",
      "\n",
      "        [[-0.3066,  0.4004,  0.2012,  ...,  1.3672,  0.5977,  0.3164]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2169],\n",
      "        [2227]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.5117,  0.3066, -0.3750,  ..., -0.3457,  0.7031,  0.4043]],\n",
      "\n",
      "        [[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2168],\n",
      "        [2231]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.0732, -0.9609,  0.0762,  ..., -0.3477,  0.2754,  0.4043]],\n",
      "\n",
      "        [[-0.1816,  0.2393, -0.1387,  ...,  0.3906, -0.2617,  0.2832]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2177],\n",
      "        [2187],\n",
      "        [2224]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]],\n",
      "\n",
      "        [[-0.1318,  0.5938,  0.3418,  ...,  0.2559,  0.6250,  0.3867]],\n",
      "\n",
      "        [[-0.0850,  0.6328, -0.1729,  ...,  0.9102, -0.1748,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2177],\n",
      "        [2185],\n",
      "        [2224]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]],\n",
      "\n",
      "        [[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]],\n",
      "\n",
      "        [[-0.0850,  0.6328, -0.1729,  ...,  0.9102, -0.1748,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2176],\n",
      "        [2182],\n",
      "        [2222]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[-0.0188,  0.5039, -0.1069,  ...,  1.0781,  0.6055,  0.2773]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2178],\n",
      "        [2184],\n",
      "        [2225]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]],\n",
      "\n",
      "        [[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[-0.3438,  0.3594, -0.3320,  ...,  0.3672,  0.6367,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2176],\n",
      "        [2185],\n",
      "        [2224]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]],\n",
      "\n",
      "        [[-0.0850,  0.6328, -0.1729,  ...,  0.9102, -0.1748,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2176],\n",
      "        [2183],\n",
      "        [2218]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[-0.6250,  0.5000,  0.6836,  ...,  0.2422,  0.8633,  0.3242]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2174],\n",
      "        [2180],\n",
      "        [2217]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7227,  0.2715,  0.5547,  ..., -0.0623,  0.2500,  0.4023]],\n",
      "\n",
      "        [[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.2637,  0.5430,  0.7656,  ..., -0.4629,  0.4609,  0.3535]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2176],\n",
      "        [2176],\n",
      "        [2219]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[-0.7656,  0.0679,  0.7500,  ..., -0.1045,  0.2432,  0.3105]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2177],\n",
      "        [2174],\n",
      "        [2220]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]],\n",
      "\n",
      "        [[ 0.7227,  0.2715,  0.5547,  ..., -0.0623,  0.2500,  0.4023]],\n",
      "\n",
      "        [[-0.7070,  0.5508,  0.5117,  ...,  0.2178,  1.1484,  0.3066]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2176],\n",
      "        [2170],\n",
      "        [2220]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[ 0.8984,  0.4570,  0.4824,  ..., -0.6562,  0.4336,  0.4023]],\n",
      "\n",
      "        [[-0.7070,  0.5508,  0.5117,  ...,  0.2178,  1.1484,  0.3066]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2176],\n",
      "        [2164],\n",
      "        [2214]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]],\n",
      "\n",
      "        [[ 0.2129,  0.6719, -0.0635,  ...,  0.4082,  0.5078,  0.3398]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2177],\n",
      "        [2162],\n",
      "        [2223]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]],\n",
      "\n",
      "        [[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[-0.5234,  0.5273,  0.1689,  ...,  0.9102, -0.0820,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2177],\n",
      "        [2162],\n",
      "        [2233]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]],\n",
      "\n",
      "        [[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[-0.0342,  0.3105,  0.5430,  ...,  0.4668, -0.2598,  0.2812]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2161],\n",
      "        [2235]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.1475,  0.7500,  0.8086,  ..., -0.3672,  0.1226,  0.4102]],\n",
      "\n",
      "        [[ 0.3125,  0.3262,  0.4824,  ...,  0.2070, -0.0295,  0.3105]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2164],\n",
      "        [2230]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2167],\n",
      "        [2230]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.4590, -0.7188, -0.3379,  ..., -0.8477,  0.5781,  0.4062]],\n",
      "\n",
      "        [[-0.3613,  0.1123, -0.4570,  ..., -0.1660,  0.7266,  0.2637]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2166],\n",
      "        [2231]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]],\n",
      "\n",
      "        [[-0.1816,  0.2393, -0.1387,  ...,  0.3906, -0.2617,  0.2832]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2164],\n",
      "        [2234]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]],\n",
      "\n",
      "        [[-0.4375,  0.4727,  0.4570,  ...,  0.2139,  1.0703,  0.2969]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2179],\n",
      "        [2163],\n",
      "        [2232]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]],\n",
      "\n",
      "        [[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[-0.1748,  0.3457, -0.2500,  ..., -0.2490, -0.4785,  0.2871]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2179],\n",
      "        [2162],\n",
      "        [2227]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]],\n",
      "\n",
      "        [[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2177],\n",
      "        [2164],\n",
      "        [2227]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]],\n",
      "\n",
      "        [[-0.5586,  0.4570, -0.1973,  ...,  0.4238,  0.5547,  0.3457]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2173],\n",
      "        [2165],\n",
      "        [2226]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6445,  0.6250,  0.7617,  ...,  0.2578,  0.6797,  0.3945]],\n",
      "\n",
      "        [[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]],\n",
      "\n",
      "        [[-0.1709,  0.2520, -0.3027,  ...,  0.4141,  0.7266,  0.2734]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "Running with idx = 5606\n",
      "Using cuda\n",
      "Context length = 1500\n",
      "Forecast length = 64\n",
      "Sample size = 3\n",
      "token=  tensor([[2115, 2114, 2114, 2114, 2114, 2114, 2116, 2117, 2117, 2118, 2118, 2125,\n",
      "         2122, 2122, 2121, 2121, 2122, 2122, 2125, 2125, 2123, 2126, 2125, 2123,\n",
      "         2123, 2124, 2119, 2120, 2125, 2126, 2125, 2127, 2129, 2129, 2134, 2138,\n",
      "         2142, 2144, 2160, 2160, 2168, 2169, 2161, 2159, 2159, 2159, 2171, 2168,\n",
      "         2167, 2167, 2167, 2183, 2186, 2185, 2208, 2208, 2207, 2219, 2240, 2244,\n",
      "         2240, 2227, 2215, 2244, 2238, 2225, 2225, 2212, 2205, 2195, 2185, 2208,\n",
      "         2197, 2192, 2196, 2212, 2222, 2216, 2228, 2225, 2225, 2227, 2225, 2217,\n",
      "         2219, 2225, 2230, 2229, 2227, 2230, 2223, 2223, 2216, 2214, 2203, 2197,\n",
      "         2189, 2186, 2186, 2186, 2197, 2192, 2188, 2190, 2189, 2187, 2187, 2188,\n",
      "         2182, 2182, 2198, 2187, 2184, 2187, 2186, 2186, 2184, 2192, 2193, 2200,\n",
      "         2192, 2187, 2188, 2192, 2191, 2195, 2192, 2193, 2194, 2193, 2191, 2195,\n",
      "         2195, 2198, 2203, 2201, 2203, 2209, 2210, 2209, 2209, 2213, 2212, 2212,\n",
      "         2212, 2212, 2203, 2208, 2205, 2197, 2192, 2188, 2192, 2192, 2195, 2200,\n",
      "         2199, 2199, 2205, 2203, 2198, 2195, 2193, 2200, 2197, 2201, 2197, 2193,\n",
      "         2191, 2192, 2186, 2184, 2187, 2187, 2187, 2190, 2186, 2185, 2190, 2186,\n",
      "         2185, 2186, 2201, 2200, 2205, 2208, 2205, 2204, 2208, 2209, 2209, 2211,\n",
      "         2211, 2206, 2206, 2209, 2210, 2204, 2203, 2208, 2203, 2203, 2200, 2197,\n",
      "         2194, 2192, 2187, 2192, 2192, 2196, 2195, 2195, 2195, 2196, 2188, 2189,\n",
      "         2189, 2188, 2190, 2188, 2187, 2190, 2195, 2195, 2191, 2193, 2195, 2193,\n",
      "         2191, 2198, 2208, 2203, 2200, 2201, 2197, 2196, 2193, 2193, 2192, 2189,\n",
      "         2189, 2189, 2188, 2190, 2189, 2185, 2190, 2190, 2190, 2192, 2192, 2197,\n",
      "         2194, 2192, 2197, 2200, 2203, 2204, 2204, 2199, 2198, 2197, 2196, 2193,\n",
      "         2191, 2192, 2192, 2190, 2191, 2195, 2193, 2194, 2192, 2192, 2194, 2196,\n",
      "         2195, 2195, 2193, 2192, 2195, 2194, 2196, 2198, 2198, 2192, 2192, 2190,\n",
      "         2188, 2192, 2192, 2191, 2192, 2192, 2192, 2191, 2191, 2189, 2189, 2189,\n",
      "         2187, 2185, 2187, 2187, 2186, 2189, 2190, 2187, 2188, 2187, 2187, 2192,\n",
      "         2190, 2188, 2186, 2186, 2185, 2176, 2167, 2169, 2168, 2163, 2158, 2155,\n",
      "         2167, 2168, 2164, 2157, 2159, 2157, 2157, 2157, 2157, 2158, 2162, 2160,\n",
      "         2160, 2159, 2158, 2164, 2162, 2165, 2164, 2164, 2168, 2177, 2182, 2182,\n",
      "         2184, 2185, 2185, 2185, 2187, 2189, 2189, 2199, 2222, 2223, 2211, 2206,\n",
      "         2203, 2196, 2194, 2195, 2193, 2195, 2193, 2205, 2202, 2211, 2212, 2210,\n",
      "         2204, 2203, 2198, 2203, 2211, 2212, 2211, 2218, 2220, 2210, 2212, 2220,\n",
      "         2219, 2219, 2227, 2223, 2222, 2220, 2217, 2209, 2202, 2206, 2208, 2208,\n",
      "         2208, 2208, 2208, 2208, 2208, 2204, 2197, 2196, 2192, 2192, 2192, 2195,\n",
      "         2196, 2200, 2201, 2204, 2206, 2201, 2201, 2200, 2206, 2203, 2203, 2203,\n",
      "         2202, 2199, 2197, 2197, 2196, 2189, 2187, 2182, 2182, 2181, 2178, 2176,\n",
      "         2181, 2173, 2169, 2170, 2165, 2163, 2161, 2159, 2156, 2154, 2159, 2154,\n",
      "         2154, 2154, 2154, 2156, 2154, 2150, 2143, 2144, 2150, 2153, 2152, 2158,\n",
      "         2156, 2159, 2158, 2171, 2169, 2176, 2171, 2170, 2170, 2173, 2175, 2182,\n",
      "         2179, 2186, 2185, 2179, 2176, 2176, 2174, 2175, 2171, 2173, 2172, 2171,\n",
      "         2169, 2165, 2171, 2171, 2167, 2165, 2170, 2171, 2168, 2167, 2170, 2170,\n",
      "         2176, 2179, 2176, 2174, 2174, 2174, 2176, 2176, 2174, 2170, 2169, 2167,\n",
      "         2167, 2168, 2165, 2167, 2168, 2167, 2167, 2166,    1]],\n",
      "       device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6484,  0.1934, -0.3945,  ..., -0.2500, -0.0552,  0.4199],\n",
      "         [ 0.9453,  0.3750, -0.3984,  ...,  0.0771, -0.3340,  0.4219],\n",
      "         [ 0.9453,  0.3750, -0.3984,  ...,  0.0771, -0.3340,  0.4219],\n",
      "         ...,\n",
      "         [ 0.4590, -0.7188, -0.3379,  ..., -0.8477,  0.5781,  0.4062],\n",
      "         [ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004],\n",
      "         [ 0.3828, -0.2490, -0.0140,  ...,  3.0000, -1.0469, -2.5938]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([1, 513])\n",
      "testt2\n",
      "batch_size=  1\n",
      "seq_length=  513\n",
      "token=  tensor([[0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2167],\n",
      "        [2168],\n",
      "        [2165]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4590, -0.7188, -0.3379,  ..., -0.8477,  0.5781,  0.4062]],\n",
      "\n",
      "        [[ 0.0732, -0.9609,  0.0762,  ..., -0.3477,  0.2754,  0.4043]],\n",
      "\n",
      "        [[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2166],\n",
      "        [2161],\n",
      "        [2166]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]],\n",
      "\n",
      "        [[ 0.1475,  0.7500,  0.8086,  ..., -0.3672,  0.1226,  0.4102]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2166],\n",
      "        [2161],\n",
      "        [2165]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]],\n",
      "\n",
      "        [[ 0.1475,  0.7500,  0.8086,  ..., -0.3672,  0.1226,  0.4102]],\n",
      "\n",
      "        [[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2160],\n",
      "        [2166]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2162],\n",
      "        [2158],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2153],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2153],\n",
      "        [2165]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2165],\n",
      "        [2154],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2164],\n",
      "        [2153],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2153],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2159],\n",
      "        [2163]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2155],\n",
      "        [2163]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.4160, -0.8789, -0.4453,  ...,  0.2832, -0.6914,  0.4121]],\n",
      "\n",
      "        [[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2158],\n",
      "        [2160]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2158],\n",
      "        [2159]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2160],\n",
      "        [2155]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[ 0.4160, -0.8789, -0.4453,  ...,  0.2832, -0.6914,  0.4121]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2160],\n",
      "        [2160],\n",
      "        [2156]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[ 0.8633,  0.5742,  0.3633,  ..., -0.6562,  0.1338,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2158],\n",
      "        [2155]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.4160, -0.8789, -0.4453,  ...,  0.2832, -0.6914,  0.4121]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2155],\n",
      "        [2154]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.4160, -0.8789, -0.4453,  ...,  0.2832, -0.6914,  0.4121]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2154],\n",
      "        [2154]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2168],\n",
      "        [2154],\n",
      "        [2153]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0732, -0.9609,  0.0762,  ..., -0.3477,  0.2754,  0.4043]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2171],\n",
      "        [2150],\n",
      "        [2154]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4062,  0.5352,  1.0938,  ...,  0.6172,  0.2773,  0.4082]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2170],\n",
      "        [2148],\n",
      "        [2152]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.8984,  0.4570,  0.4824,  ..., -0.6562,  0.4336,  0.4023]],\n",
      "\n",
      "        [[ 0.1738,  0.8516,  0.8516,  ..., -0.2520,  0.9414,  0.4062]],\n",
      "\n",
      "        [[ 0.5703, -0.1074,  0.1289,  ..., -0.2871, -0.3633,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2171],\n",
      "        [2147],\n",
      "        [2152]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4062,  0.5352,  1.0938,  ...,  0.6172,  0.2773,  0.4082]],\n",
      "\n",
      "        [[ 0.2109,  0.6172, -0.0294,  ..., -0.4004, -0.0264,  0.4180]],\n",
      "\n",
      "        [[ 0.5703, -0.1074,  0.1289,  ..., -0.2871, -0.3633,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2175],\n",
      "        [2149],\n",
      "        [2148]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7539, -0.2930,  0.5469,  ...,  0.2676,  0.3770,  0.3926]],\n",
      "\n",
      "        [[ 0.4238,  0.8125, -0.4883,  ..., -0.3652,  0.0364,  0.4121]],\n",
      "\n",
      "        [[ 0.1738,  0.8516,  0.8516,  ..., -0.2520,  0.9414,  0.4062]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2150],\n",
      "        [2148]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[ 0.1738,  0.8516,  0.8516,  ..., -0.2520,  0.9414,  0.4062]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2145],\n",
      "        [2150]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.5195,  0.4062,  0.6406,  ..., -0.4355,  0.4414,  0.4023]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2144],\n",
      "        [2150]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.3086,  0.7969,  0.6211,  ...,  0.0381,  0.6680,  0.4062]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2144],\n",
      "        [2153]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.3086,  0.7969,  0.6211,  ...,  0.0381,  0.6680,  0.4062]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2185],\n",
      "        [2142],\n",
      "        [2151]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]],\n",
      "\n",
      "        [[ 0.5078,  0.3086,  0.6758,  ...,  0.2695,  0.1699,  0.4023]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2143],\n",
      "        [2151]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.6289,  0.5664, -0.6055,  ..., -0.0173, -0.2695,  0.4219]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2144],\n",
      "        [2151]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.3086,  0.7969,  0.6211,  ...,  0.0381,  0.6680,  0.4062]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2144],\n",
      "        [2151]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.3086,  0.7969,  0.6211,  ...,  0.0381,  0.6680,  0.4062]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2145],\n",
      "        [2157]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.5195,  0.4062,  0.6406,  ..., -0.4355,  0.4414,  0.4023]],\n",
      "\n",
      "        [[ 0.4141,  0.0559, -0.5391,  ..., -0.1816,  0.4902,  0.4062]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2143],\n",
      "        [2158]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.6289,  0.5664, -0.6055,  ..., -0.0173, -0.2695,  0.4219]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2187],\n",
      "        [2146],\n",
      "        [2158]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1318,  0.5938,  0.3418,  ...,  0.2559,  0.6250,  0.3867]],\n",
      "\n",
      "        [[ 0.5859,  0.2158, -0.9727,  ..., -0.5469,  0.6016,  0.4141]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2186],\n",
      "        [2144],\n",
      "        [2161]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]],\n",
      "\n",
      "        [[ 0.3086,  0.7969,  0.6211,  ...,  0.0381,  0.6680,  0.4062]],\n",
      "\n",
      "        [[ 0.1475,  0.7500,  0.8086,  ..., -0.3672,  0.1226,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2186],\n",
      "        [2150],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2151],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2155],\n",
      "        [2170]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.4160, -0.8789, -0.4453,  ...,  0.2832, -0.6914,  0.4121]],\n",
      "\n",
      "        [[ 0.8984,  0.4570,  0.4824,  ..., -0.6562,  0.4336,  0.4023]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2154],\n",
      "        [2171]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]],\n",
      "\n",
      "        [[ 0.4062,  0.5352,  1.0938,  ...,  0.6172,  0.2773,  0.4082]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2153],\n",
      "        [2167]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.4590, -0.7188, -0.3379,  ..., -0.8477,  0.5781,  0.4062]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2153],\n",
      "        [2168]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.0732, -0.9609,  0.0762,  ..., -0.3477,  0.2754,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2149],\n",
      "        [2168]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.4238,  0.8125, -0.4883,  ..., -0.3652,  0.0364,  0.4121]],\n",
      "\n",
      "        [[ 0.0732, -0.9609,  0.0762,  ..., -0.3477,  0.2754,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2176],\n",
      "        [2149],\n",
      "        [2175]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[ 0.4238,  0.8125, -0.4883,  ..., -0.3652,  0.0364,  0.4121]],\n",
      "\n",
      "        [[ 0.7539, -0.2930,  0.5469,  ...,  0.2676,  0.3770,  0.3926]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2148],\n",
      "        [2179]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.1738,  0.8516,  0.8516,  ..., -0.2520,  0.9414,  0.4062]],\n",
      "\n",
      "        [[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2151],\n",
      "        [2178]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2150],\n",
      "        [2184]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2151],\n",
      "        [2184]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]],\n",
      "\n",
      "        [[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2150],\n",
      "        [2186]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2150],\n",
      "        [2187]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[-0.1318,  0.5938,  0.3418,  ...,  0.2559,  0.6250,  0.3867]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2149],\n",
      "        [2185]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.4238,  0.8125, -0.4883,  ..., -0.3652,  0.0364,  0.4121]],\n",
      "\n",
      "        [[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2187],\n",
      "        [2139],\n",
      "        [2182]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1318,  0.5938,  0.3418,  ...,  0.2559,  0.6250,  0.3867]],\n",
      "\n",
      "        [[ 0.7500,  0.6055, -0.4512,  ..., -0.8164, -0.1592,  0.4141]],\n",
      "\n",
      "        [[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2187],\n",
      "        [2138],\n",
      "        [2180]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1318,  0.5938,  0.3418,  ...,  0.2559,  0.6250,  0.3867]],\n",
      "\n",
      "        [[ 0.3555,  0.6094, -0.5117,  ..., -0.2891, -0.1709,  0.4180]],\n",
      "\n",
      "        [[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2185],\n",
      "        [2140],\n",
      "        [2175]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]],\n",
      "\n",
      "        [[ 0.6289,  0.5469, -0.5781,  ...,  0.0217, -0.2295,  0.4121]],\n",
      "\n",
      "        [[ 0.7539, -0.2930,  0.5469,  ...,  0.2676,  0.3770,  0.3926]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2137],\n",
      "        [2177]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.2578,  0.6016, -0.6875,  ..., -0.0674,  0.1807,  0.4121]],\n",
      "\n",
      "        [[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2136],\n",
      "        [2178]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.3828,  0.7461, -0.0123,  ...,  0.3359, -0.7070,  0.4023]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2136],\n",
      "        [2185]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.3828,  0.7461, -0.0123,  ...,  0.3359, -0.7070,  0.4023]],\n",
      "\n",
      "        [[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2139],\n",
      "        [2184]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.7500,  0.6055, -0.4512,  ..., -0.8164, -0.1592,  0.4141]],\n",
      "\n",
      "        [[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2139],\n",
      "        [2184]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.7500,  0.6055, -0.4512,  ..., -0.8164, -0.1592,  0.4141]],\n",
      "\n",
      "        [[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2179],\n",
      "        [2141],\n",
      "        [2186]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]],\n",
      "\n",
      "        [[ 0.2852,  0.5430,  0.3438,  ...,  0.0034, -0.2988,  0.4102]],\n",
      "\n",
      "        [[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2179],\n",
      "        [2139],\n",
      "        [2189]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]],\n",
      "\n",
      "        [[ 0.7500,  0.6055, -0.4512,  ..., -0.8164, -0.1592,  0.4141]],\n",
      "\n",
      "        [[-0.1777,  0.7734,  0.2363,  ..., -0.0928, -0.1099,  0.3730]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2177],\n",
      "        [2142],\n",
      "        [2192]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]],\n",
      "\n",
      "        [[ 0.5078,  0.3086,  0.6758,  ...,  0.2695,  0.1699,  0.4023]],\n",
      "\n",
      "        [[-0.3086,  0.1816,  0.6562,  ..., -0.5586,  0.8203,  0.3730]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2173],\n",
      "        [2147],\n",
      "        [2188]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6445,  0.6250,  0.7617,  ...,  0.2578,  0.6797,  0.3945]],\n",
      "\n",
      "        [[ 0.2109,  0.6172, -0.0294,  ..., -0.4004, -0.0264,  0.4180]],\n",
      "\n",
      "        [[ 0.0981,  0.5586,  0.2539,  ..., -0.5273,  1.1250,  0.3730]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "Running with idx = 5670\n",
      "Using cuda\n",
      "Context length = 1436\n",
      "Forecast length = 64\n",
      "Sample size = 3\n",
      "token=  tensor([[2115, 2114, 2114, 2114, 2114, 2114, 2116, 2117, 2117, 2118, 2118, 2125,\n",
      "         2122, 2122, 2121, 2121, 2122, 2122, 2125, 2125, 2123, 2126, 2125, 2123,\n",
      "         2123, 2124, 2119, 2120, 2125, 2126, 2125, 2127, 2129, 2129, 2134, 2138,\n",
      "         2142, 2144, 2160, 2160, 2168, 2169, 2161, 2159, 2159, 2159, 2171, 2168,\n",
      "         2167, 2167, 2167, 2183, 2186, 2185, 2208, 2208, 2207, 2219, 2240, 2244,\n",
      "         2240, 2227, 2215, 2244, 2238, 2225, 2225, 2212, 2205, 2195, 2185, 2208,\n",
      "         2197, 2192, 2196, 2212, 2222, 2216, 2228, 2225, 2225, 2227, 2225, 2217,\n",
      "         2219, 2225, 2230, 2229, 2227, 2230, 2223, 2223, 2216, 2214, 2203, 2197,\n",
      "         2189, 2186, 2186, 2186, 2197, 2192, 2188, 2190, 2189, 2187, 2187, 2188,\n",
      "         2182, 2182, 2198, 2187, 2184, 2187, 2186, 2186, 2184, 2192, 2193, 2200,\n",
      "         2192, 2187, 2188, 2192, 2191, 2195, 2192, 2193, 2194, 2193, 2191, 2195,\n",
      "         2195, 2198, 2203, 2201, 2203, 2209, 2210, 2209, 2209, 2213, 2212, 2212,\n",
      "         2212, 2212, 2203, 2208, 2205, 2197, 2192, 2188, 2192, 2192, 2195, 2200,\n",
      "         2199, 2199, 2205, 2203, 2198, 2195, 2193, 2200, 2197, 2201, 2197, 2193,\n",
      "         2191, 2192, 2186, 2184, 2187, 2187, 2187, 2190, 2186, 2185, 2190, 2186,\n",
      "         2185, 2186, 2201, 2200, 2205, 2208, 2205, 2204, 2208, 2209, 2209, 2211,\n",
      "         2211, 2206, 2206, 2209, 2210, 2204, 2203, 2208, 2203, 2203, 2200, 2197,\n",
      "         2194, 2192, 2187, 2192, 2192, 2196, 2195, 2195, 2195, 2196, 2188, 2189,\n",
      "         2189, 2188, 2190, 2188, 2187, 2190, 2195, 2195, 2191, 2193, 2195, 2193,\n",
      "         2191, 2198, 2208, 2203, 2200, 2201, 2197, 2196, 2193, 2193, 2192, 2189,\n",
      "         2189, 2189, 2188, 2190, 2189, 2185, 2190, 2190, 2190, 2192, 2192, 2197,\n",
      "         2194, 2192, 2197, 2200, 2203, 2204, 2204, 2199, 2198, 2197, 2196, 2193,\n",
      "         2191, 2192, 2192, 2190, 2191, 2195, 2193, 2194, 2192, 2192, 2194, 2196,\n",
      "         2195, 2195, 2193, 2192, 2195, 2194, 2196, 2198, 2198, 2192, 2192, 2190,\n",
      "         2188, 2192, 2192, 2191, 2192, 2192, 2192, 2191, 2191, 2189, 2189, 2189,\n",
      "         2187, 2185, 2187, 2187, 2186, 2189, 2190, 2187, 2188, 2187, 2187, 2192,\n",
      "         2190, 2188, 2186, 2186, 2185, 2176, 2167, 2169, 2168, 2163, 2158, 2155,\n",
      "         2167, 2168, 2164, 2157, 2159, 2157, 2157, 2157, 2157, 2158, 2162, 2160,\n",
      "         2160, 2159, 2158, 2164, 2162, 2165, 2164, 2164, 2168, 2177, 2182, 2182,\n",
      "         2184, 2185, 2185, 2185, 2187, 2189, 2189, 2199, 2222, 2223, 2211, 2206,\n",
      "         2203, 2196, 2194, 2195, 2193, 2195, 2193, 2205, 2202, 2211, 2212, 2210,\n",
      "         2204, 2203, 2198, 2203, 2211, 2212, 2211, 2218, 2220, 2210, 2212, 2220,\n",
      "         2219, 2219, 2227, 2223, 2222, 2220, 2217, 2209, 2202, 2206, 2208, 2208,\n",
      "         2208, 2208, 2208, 2208, 2208, 2204, 2197, 2196, 2192, 2192, 2192, 2195,\n",
      "         2196, 2200, 2201, 2204, 2206, 2201, 2201, 2200, 2206, 2203, 2203, 2203,\n",
      "         2202, 2199, 2197, 2197, 2196, 2189, 2187, 2182, 2182, 2181, 2178, 2176,\n",
      "         2181, 2173, 2169, 2170, 2165, 2163, 2161, 2159, 2156, 2154, 2159, 2154,\n",
      "         2154, 2154, 2154, 2156, 2154, 2150, 2143, 2144, 2150, 2153, 2152, 2158,\n",
      "         2156, 2159, 2158, 2171, 2169, 2176, 2171, 2170, 2170, 2173, 2175, 2182,\n",
      "         2179, 2186, 2185, 2179, 2176, 2176, 2174, 2175, 2171, 2173, 2172, 2171,\n",
      "         2169, 2165, 2171, 2171, 2167, 2165, 2170, 2171, 2168, 2167, 2170, 2170,\n",
      "         2176, 2179, 2176, 2174, 2174, 2174, 2176, 2176, 2174, 2170, 2169, 2167,\n",
      "         2167, 2168, 2165, 2167, 2168, 2167, 2167, 2166,    1]],\n",
      "       device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6484,  0.1934, -0.3945,  ..., -0.2500, -0.0552,  0.4199],\n",
      "         [ 0.9453,  0.3750, -0.3984,  ...,  0.0771, -0.3340,  0.4219],\n",
      "         [ 0.9453,  0.3750, -0.3984,  ...,  0.0771, -0.3340,  0.4219],\n",
      "         ...,\n",
      "         [ 0.4590, -0.7188, -0.3379,  ..., -0.8477,  0.5781,  0.4062],\n",
      "         [ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004],\n",
      "         [ 0.3828, -0.2490, -0.0140,  ...,  3.0000, -1.0469, -2.5938]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([1, 513])\n",
      "testt2\n",
      "batch_size=  1\n",
      "seq_length=  513\n",
      "token=  tensor([[0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]],\n",
      "\n",
      "        [[-0.0054, -0.0096,  0.1055,  ..., -0.3125,  0.0603,  1.6797]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2167],\n",
      "        [2168],\n",
      "        [2165]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4590, -0.7188, -0.3379,  ..., -0.8477,  0.5781,  0.4062]],\n",
      "\n",
      "        [[ 0.0732, -0.9609,  0.0762,  ..., -0.3477,  0.2754,  0.4043]],\n",
      "\n",
      "        [[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2166],\n",
      "        [2161],\n",
      "        [2166]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]],\n",
      "\n",
      "        [[ 0.1475,  0.7500,  0.8086,  ..., -0.3672,  0.1226,  0.4102]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2166],\n",
      "        [2161],\n",
      "        [2165]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]],\n",
      "\n",
      "        [[ 0.1475,  0.7500,  0.8086,  ..., -0.3672,  0.1226,  0.4102]],\n",
      "\n",
      "        [[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2160],\n",
      "        [2166]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[ 0.2949, -0.7852, -0.1221,  ...,  1.0859,  1.0078,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2162],\n",
      "        [2158],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6055, -0.8984,  0.2080,  ...,  1.2031,  0.6523,  0.4062]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2153],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2153],\n",
      "        [2165]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2165],\n",
      "        [2154],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0981, -0.0237,  0.3711,  ..., -0.2061,  0.0403,  0.3965]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2164],\n",
      "        [2153],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2153],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2159],\n",
      "        [2163]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2155],\n",
      "        [2163]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]],\n",
      "\n",
      "        [[ 0.4160, -0.8789, -0.4453,  ...,  0.2832, -0.6914,  0.4121]],\n",
      "\n",
      "        [[ 0.3301, -0.1719,  0.7930,  ..., -0.4082,  0.1621,  0.4141]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2158],\n",
      "        [2160]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2158],\n",
      "        [2159]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2160],\n",
      "        [2155]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[ 0.4160, -0.8789, -0.4453,  ...,  0.2832, -0.6914,  0.4121]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2160],\n",
      "        [2160],\n",
      "        [2156]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[ 0.5430,  0.6953,  0.0728,  ...,  0.8008,  0.1748,  0.4082]],\n",
      "\n",
      "        [[ 0.8633,  0.5742,  0.3633,  ..., -0.6562,  0.1338,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2158],\n",
      "        [2155]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.4160, -0.8789, -0.4453,  ...,  0.2832, -0.6914,  0.4121]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2155],\n",
      "        [2154]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]],\n",
      "\n",
      "        [[ 0.4160, -0.8789, -0.4453,  ...,  0.2832, -0.6914,  0.4121]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2154],\n",
      "        [2154]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5391,  0.6719,  0.3027,  ...,  0.9961,  0.0659,  0.4082]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2168],\n",
      "        [2154],\n",
      "        [2153]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0732, -0.9609,  0.0762,  ..., -0.3477,  0.2754,  0.4043]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2171],\n",
      "        [2150],\n",
      "        [2154]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4062,  0.5352,  1.0938,  ...,  0.6172,  0.2773,  0.4082]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2170],\n",
      "        [2148],\n",
      "        [2152]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.8984,  0.4570,  0.4824,  ..., -0.6562,  0.4336,  0.4023]],\n",
      "\n",
      "        [[ 0.1738,  0.8516,  0.8516,  ..., -0.2520,  0.9414,  0.4062]],\n",
      "\n",
      "        [[ 0.5703, -0.1074,  0.1289,  ..., -0.2871, -0.3633,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2171],\n",
      "        [2147],\n",
      "        [2152]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4062,  0.5352,  1.0938,  ...,  0.6172,  0.2773,  0.4082]],\n",
      "\n",
      "        [[ 0.2109,  0.6172, -0.0294,  ..., -0.4004, -0.0264,  0.4180]],\n",
      "\n",
      "        [[ 0.5703, -0.1074,  0.1289,  ..., -0.2871, -0.3633,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2175],\n",
      "        [2149],\n",
      "        [2148]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7539, -0.2930,  0.5469,  ...,  0.2676,  0.3770,  0.3926]],\n",
      "\n",
      "        [[ 0.4238,  0.8125, -0.4883,  ..., -0.3652,  0.0364,  0.4121]],\n",
      "\n",
      "        [[ 0.1738,  0.8516,  0.8516,  ..., -0.2520,  0.9414,  0.4062]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2150],\n",
      "        [2148]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[ 0.1738,  0.8516,  0.8516,  ..., -0.2520,  0.9414,  0.4062]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2145],\n",
      "        [2150]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.5195,  0.4062,  0.6406,  ..., -0.4355,  0.4414,  0.4023]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2144],\n",
      "        [2150]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.3086,  0.7969,  0.6211,  ...,  0.0381,  0.6680,  0.4062]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2144],\n",
      "        [2153]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.3086,  0.7969,  0.6211,  ...,  0.0381,  0.6680,  0.4062]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2185],\n",
      "        [2142],\n",
      "        [2151]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]],\n",
      "\n",
      "        [[ 0.5078,  0.3086,  0.6758,  ...,  0.2695,  0.1699,  0.4023]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2143],\n",
      "        [2151]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.6289,  0.5664, -0.6055,  ..., -0.0173, -0.2695,  0.4219]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2144],\n",
      "        [2151]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.3086,  0.7969,  0.6211,  ...,  0.0381,  0.6680,  0.4062]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2144],\n",
      "        [2151]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.3086,  0.7969,  0.6211,  ...,  0.0381,  0.6680,  0.4062]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2145],\n",
      "        [2157]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.5195,  0.4062,  0.6406,  ..., -0.4355,  0.4414,  0.4023]],\n",
      "\n",
      "        [[ 0.4141,  0.0559, -0.5391,  ..., -0.1816,  0.4902,  0.4062]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2143],\n",
      "        [2158]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.6289,  0.5664, -0.6055,  ..., -0.0173, -0.2695,  0.4219]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2187],\n",
      "        [2146],\n",
      "        [2158]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1318,  0.5938,  0.3418,  ...,  0.2559,  0.6250,  0.3867]],\n",
      "\n",
      "        [[ 0.5859,  0.2158, -0.9727,  ..., -0.5469,  0.6016,  0.4141]],\n",
      "\n",
      "        [[ 0.6992, -0.1533,  0.5156,  ...,  0.2012,  0.1943,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2186],\n",
      "        [2144],\n",
      "        [2161]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]],\n",
      "\n",
      "        [[ 0.3086,  0.7969,  0.6211,  ...,  0.0381,  0.6680,  0.4062]],\n",
      "\n",
      "        [[ 0.1475,  0.7500,  0.8086,  ..., -0.3672,  0.1226,  0.4102]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2186],\n",
      "        [2150],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2151],\n",
      "        [2164]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]],\n",
      "\n",
      "        [[ 0.8750, -1.7188, -0.3945,  ..., -0.3652, -0.3242,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2155],\n",
      "        [2170]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.4160, -0.8789, -0.4453,  ...,  0.2832, -0.6914,  0.4121]],\n",
      "\n",
      "        [[ 0.8984,  0.4570,  0.4824,  ..., -0.6562,  0.4336,  0.4023]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2154],\n",
      "        [2171]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.6328, -0.9648, -0.1426,  ..., -0.2197,  1.1172,  0.4141]],\n",
      "\n",
      "        [[ 0.4062,  0.5352,  1.0938,  ...,  0.6172,  0.2773,  0.4082]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2153],\n",
      "        [2167]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.4590, -0.7188, -0.3379,  ..., -0.8477,  0.5781,  0.4062]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2153],\n",
      "        [2168]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.8047, -1.0547,  0.3691,  ...,  0.3711,  0.6133,  0.4043]],\n",
      "\n",
      "        [[ 0.0732, -0.9609,  0.0762,  ..., -0.3477,  0.2754,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2149],\n",
      "        [2168]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.4238,  0.8125, -0.4883,  ..., -0.3652,  0.0364,  0.4121]],\n",
      "\n",
      "        [[ 0.0732, -0.9609,  0.0762,  ..., -0.3477,  0.2754,  0.4043]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2176],\n",
      "        [2149],\n",
      "        [2175]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6719,  1.1250,  0.6719,  ..., -0.1973,  1.0312,  0.3965]],\n",
      "\n",
      "        [[ 0.4238,  0.8125, -0.4883,  ..., -0.3652,  0.0364,  0.4121]],\n",
      "\n",
      "        [[ 0.7539, -0.2930,  0.5469,  ...,  0.2676,  0.3770,  0.3926]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2148],\n",
      "        [2179]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.1738,  0.8516,  0.8516,  ..., -0.2520,  0.9414,  0.4062]],\n",
      "\n",
      "        [[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2151],\n",
      "        [2178]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2150],\n",
      "        [2184]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2183],\n",
      "        [2151],\n",
      "        [2184]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2715, -0.2002,  0.3262,  ...,  0.9844,  0.9219,  0.4082]],\n",
      "\n",
      "        [[ 0.0791,  0.2559,  0.2266,  ..., -0.1064,  0.1953,  0.4102]],\n",
      "\n",
      "        [[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2180],\n",
      "        [2150],\n",
      "        [2186]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2150],\n",
      "        [2187]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.4512,  0.3438, -0.4043,  ...,  0.0383,  0.4961,  0.4199]],\n",
      "\n",
      "        [[-0.1318,  0.5938,  0.3418,  ...,  0.2559,  0.6250,  0.3867]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2149],\n",
      "        [2185]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.4238,  0.8125, -0.4883,  ..., -0.3652,  0.0364,  0.4121]],\n",
      "\n",
      "        [[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2187],\n",
      "        [2139],\n",
      "        [2182]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1318,  0.5938,  0.3418,  ...,  0.2559,  0.6250,  0.3867]],\n",
      "\n",
      "        [[ 0.7500,  0.6055, -0.4512,  ..., -0.8164, -0.1592,  0.4141]],\n",
      "\n",
      "        [[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2187],\n",
      "        [2138],\n",
      "        [2180]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1318,  0.5938,  0.3418,  ...,  0.2559,  0.6250,  0.3867]],\n",
      "\n",
      "        [[ 0.3555,  0.6094, -0.5117,  ..., -0.2891, -0.1709,  0.4180]],\n",
      "\n",
      "        [[-0.5000,  0.4492, -0.4453,  ...,  0.7578, -0.1377,  0.4023]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2185],\n",
      "        [2140],\n",
      "        [2175]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]],\n",
      "\n",
      "        [[ 0.6289,  0.5469, -0.5781,  ...,  0.0217, -0.2295,  0.4121]],\n",
      "\n",
      "        [[ 0.7539, -0.2930,  0.5469,  ...,  0.2676,  0.3770,  0.3926]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2182],\n",
      "        [2137],\n",
      "        [2177]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3359,  0.1235, -0.4941,  ...,  0.1709,  0.8750,  0.4062]],\n",
      "\n",
      "        [[ 0.2578,  0.6016, -0.6875,  ..., -0.0674,  0.1807,  0.4121]],\n",
      "\n",
      "        [[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2136],\n",
      "        [2178]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.3828,  0.7461, -0.0123,  ...,  0.3359, -0.7070,  0.4023]],\n",
      "\n",
      "        [[ 0.3984, -0.2793, -0.2041,  ...,  0.8086,  0.0728,  0.4004]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2184],\n",
      "        [2136],\n",
      "        [2185]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]],\n",
      "\n",
      "        [[ 0.3828,  0.7461, -0.0123,  ...,  0.3359, -0.7070,  0.4023]],\n",
      "\n",
      "        [[ 0.6641,  0.4688,  0.1289,  ...,  0.7070,  0.1602,  0.3789]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2139],\n",
      "        [2184]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.7500,  0.6055, -0.4512,  ..., -0.8164, -0.1592,  0.4141]],\n",
      "\n",
      "        [[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2181],\n",
      "        [2139],\n",
      "        [2184]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1396,  0.2676,  0.0021,  ..., -0.5000,  0.5820,  0.3945]],\n",
      "\n",
      "        [[ 0.7500,  0.6055, -0.4512,  ..., -0.8164, -0.1592,  0.4141]],\n",
      "\n",
      "        [[-0.7188, -0.4922,  0.4297,  ...,  0.6250, -0.1826,  0.3984]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2179],\n",
      "        [2141],\n",
      "        [2186]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]],\n",
      "\n",
      "        [[ 0.2852,  0.5430,  0.3438,  ...,  0.0034, -0.2988,  0.4102]],\n",
      "\n",
      "        [[-0.1113,  0.5469, -0.2578,  ...,  0.8984,  0.2617,  0.3906]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2179],\n",
      "        [2139],\n",
      "        [2189]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 1.2266,  0.5547, -0.2100,  ..., -0.5703,  0.8594,  0.4023]],\n",
      "\n",
      "        [[ 0.7500,  0.6055, -0.4512,  ..., -0.8164, -0.1592,  0.4141]],\n",
      "\n",
      "        [[-0.1777,  0.7734,  0.2363,  ..., -0.0928, -0.1099,  0.3730]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2177],\n",
      "        [2142],\n",
      "        [2192]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4766, -0.9102,  0.6836,  ...,  0.9141,  0.2539,  0.3965]],\n",
      "\n",
      "        [[ 0.5078,  0.3086,  0.6758,  ...,  0.2695,  0.1699,  0.4023]],\n",
      "\n",
      "        [[-0.3086,  0.1816,  0.6562,  ..., -0.5586,  0.8203,  0.3730]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n",
      "token=  tensor([[2173],\n",
      "        [2147],\n",
      "        [2188]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6445,  0.6250,  0.7617,  ...,  0.2578,  0.6797,  0.3945]],\n",
      "\n",
      "        [[ 0.2109,  0.6172, -0.0294,  ..., -0.4004, -0.0264,  0.4180]],\n",
      "\n",
      "        [[ 0.0981,  0.5586,  0.2539,  ..., -0.5273,  1.1250,  0.3730]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([3, 1])\n",
      "testt2\n",
      "batch_size=  3\n",
      "seq_length=  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/yogi/chronos-research/dataset/LQ45-daily/ANTM.csv')\n",
    "\n",
    "PRED_DURATION = 365 * 1 # A multiplier of 24 as I was working with hourly dataset\n",
    "FORECAST_LEN = 64 # Trying to keep this less than 64 data points for best chronos performance\n",
    "PRED_START = len(df) - PRED_DURATION # The index where to split context and test data from your df\n",
    "CONTEXT_LEN = 1500 # Choose this wisely from above hyperparameter tuning experiment\n",
    "\n",
    "agg_metrics = []\n",
    "pred_indices = [i for i in range(len(df), PRED_START, -FORECAST_LEN)][::-1]\n",
    "\n",
    "\n",
    "og_df = df.copy()\n",
    "TARGET_COLUMN = 'close'\n",
    "\n",
    "for idx in pred_indices:\n",
    "    print(f'Running with idx = {idx}')\n",
    "    fc = ChronosForecaster()\n",
    "    \n",
    "    df = og_df[(idx-CONTEXT_LEN):(idx+FORECAST_LEN)].copy()\n",
    "\n",
    "    if idx > len(og_df):\n",
    "        continue\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    context, test = fc.split_train_test_by_sample_size(df, target_column=TARGET_COLUMN, test_sample_size=FORECAST_LEN)\n",
    "\n",
    "    forecast, metrics, median = fc.predict( model_name=\"amazon/chronos-t5-small\", num_samples=3)\n",
    "\n",
    "    metrics['idx_context_start'] = idx - CONTEXT_LEN\n",
    "    metrics['idx_context_end'] = idx\n",
    "    metrics['idx_forecast_start'] = idx + 1\n",
    "    metrics['idx_forecast_end'] = idx + FORECAST_LEN\n",
    "\n",
    "    agg_metrics.append(metrics | json.loads(fc.params))\n",
    "\n",
    "    fc.plot_forecast(df[TARGET_COLUMN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322a7fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil mean scaling= tensor([[0.6936, 0.6989, 0.6910, 0.6910, 0.6910, 0.6910, 0.6752, 0.6804, 0.6804,\n",
      "         0.7305, 0.7464, 0.7596, 0.7543, 0.8123, 0.8018, 0.7886, 0.8097, 0.8492,\n",
      "         0.8387, 0.8360, 0.8492, 0.8756, 0.8835, 0.8650, 0.9152, 0.9125, 0.8519,\n",
      "         0.8545, 0.8782, 0.8703, 0.8571, 0.8782, 0.8703, 0.8703, 0.8598, 0.8650,\n",
      "         0.8756, 0.9099, 0.9521, 0.9336, 0.9257, 0.9283, 0.8861, 0.8756, 0.8756,\n",
      "         0.8756, 0.9046, 0.9020, 0.8730, 0.8730, 0.8730, 0.9204, 0.9152, 0.8888,\n",
      "         0.8941, 0.9415, 0.9494, 0.9257, 0.9178, 0.9231, 0.9178, 0.9099, 0.8993,\n",
      "         0.9152, 0.9178, 0.8941, 0.8888, 0.8598, 0.8914, 0.8545, 0.8202, 0.8519,\n",
      "         0.8624, 0.8545, 0.8677, 0.8677, 0.8650, 0.8439, 0.8413, 0.8413, 0.8413,\n",
      "         0.8492, 0.8466, 0.8308, 0.8387, 0.8466, 0.8360, 0.9152, 0.9178, 0.9204,\n",
      "         0.9204, 0.9204, 0.9125, 0.9072, 0.8861, 0.8756, 0.8809, 0.8677, 0.8967,\n",
      "         0.8967, 0.9099, 0.8914, 0.8861, 0.8941, 0.9099, 0.9072, 0.8914, 0.8861,\n",
      "         0.8888, 0.8993, 0.9204, 0.8993, 0.8914, 0.9020, 0.8941, 0.8941, 0.8914,\n",
      "         0.8888, 0.8967, 0.8941, 0.8861, 0.8730, 0.8782, 0.8809, 0.8861, 0.8861,\n",
      "         0.8809, 0.8756, 0.8650, 0.8782, 0.8730, 0.8571, 0.8334, 0.8281, 0.8439,\n",
      "         0.8439, 0.8360, 0.8466, 0.8439, 0.8413, 0.8413, 0.8360, 0.8387, 0.8387,\n",
      "         0.8387, 0.8387, 0.8413, 0.8387, 0.8334, 0.8730, 0.8624, 0.8598, 0.8703,\n",
      "         0.8703, 0.8914, 0.8624, 0.9072, 0.9072, 0.9099, 0.9204, 0.9231, 0.9363,\n",
      "         0.9231, 0.8941, 0.9178, 0.9152, 0.8993, 0.9072, 0.8993, 0.8835, 0.8835,\n",
      "         0.8703, 0.8703, 0.8888, 0.8571, 0.8571, 0.8360, 0.8334, 0.8308, 0.8202,\n",
      "         0.8097, 0.8018, 0.7938, 0.7991, 0.7938, 0.8334, 0.8255, 0.8097, 0.8070,\n",
      "         0.8255, 0.8360, 0.8492, 0.8492, 0.8466, 0.8598, 0.8360, 0.8413, 0.8624,\n",
      "         0.8413, 0.8519, 0.8545, 0.8730, 0.8782, 0.8888, 0.8809, 0.8756, 0.8571,\n",
      "         0.8519, 0.8519, 0.8835, 0.8703, 0.8809, 0.8809, 0.9020, 0.8941, 0.8967,\n",
      "         0.9072, 0.8967, 0.8888, 0.8861, 0.8756, 0.8967, 0.8967, 0.8809, 0.8888,\n",
      "         0.8941, 0.8941, 0.8914, 0.8782, 0.8941, 0.8782, 0.8835, 0.9072, 0.9099,\n",
      "         0.9072, 0.9310, 0.9283, 0.9310, 0.9468, 0.9389, 0.9389, 0.9283, 0.9310,\n",
      "         0.9310, 0.9732, 0.9653, 0.9679, 0.9679, 0.9916, 0.9811, 1.0022, 1.0048,\n",
      "         0.9969, 0.9943, 1.0101, 1.0048, 0.9996, 0.9864, 0.9864, 1.0154, 1.0207,\n",
      "         0.9969, 1.0022, 0.9996, 0.9890, 1.0022, 0.9758, 0.9653, 0.9811, 0.9943,\n",
      "         0.9943, 0.9890, 0.9785, 0.9758, 0.9626, 0.9494, 0.9494, 0.9679, 0.9574,\n",
      "         0.9574, 1.0286, 1.0022, 1.0022, 1.0022, 1.0549, 1.0576, 1.0919, 1.0523,\n",
      "         1.0760, 1.0971, 1.0734, 1.0998, 1.0945, 1.0787, 1.0945, 1.0945, 1.0760,\n",
      "         1.0813, 1.0760, 1.0813, 1.0813, 1.0760, 1.0971, 1.0839, 1.0971, 1.0839,\n",
      "         1.0760, 1.0787, 1.0760, 1.0655, 1.0655, 1.1024, 1.0998, 1.0681, 1.0866,\n",
      "         1.0998, 1.0813, 1.0787, 1.0839, 1.1024, 1.1050, 1.1024, 1.1209, 1.1209,\n",
      "         1.1130, 1.1420, 1.1341, 1.1314, 1.1578, 1.1261, 1.1235, 1.1050, 1.1050,\n",
      "         1.0998, 1.1077, 1.1156, 1.1314, 1.1156, 1.1288, 1.1763, 1.1736, 1.1604,\n",
      "         1.1631, 1.1604, 1.1631, 1.1604, 1.1525, 1.1341, 1.1472, 1.1182, 1.1446,\n",
      "         1.1446, 1.1472, 1.1314, 1.1314, 1.1604, 1.1894, 1.2185, 1.1710, 1.1631,\n",
      "         1.2105, 1.2079, 1.2185, 1.2211, 1.1815, 1.1974, 1.2000, 1.2000, 1.2000,\n",
      "         1.2026, 1.1921, 1.2132, 1.2026, 1.2079, 1.2079, 1.2079, 1.1974, 1.1921,\n",
      "         1.1683, 1.1974, 1.2079, 1.2105, 1.2211, 1.2369, 1.2343, 1.2343, 1.2422,\n",
      "         1.2343, 1.2211, 1.2185, 1.2185, 1.2422, 1.2554, 1.2580, 1.2185, 1.2185,\n",
      "         1.2185, 1.2185, 1.2185, 1.2185, 1.2185, 1.1367, 1.1446, 1.1420, 1.1341,\n",
      "         1.1235, 1.1235, 1.1024, 1.1209, 1.1103, 1.0998, 1.0839, 1.0945, 1.1077,\n",
      "         1.1077, 1.1077, 1.1209, 1.1367, 1.1367, 1.1314, 1.1367, 1.1446, 1.1209,\n",
      "         1.0813, 1.0681, 1.0602, 1.0760, 1.0839, 1.0708, 1.0655, 1.0866, 1.0655,\n",
      "         1.0839, 1.0681, 1.0971, 1.0945, 1.0734, 1.0628, 1.0655, 1.0549, 1.0602,\n",
      "         1.0523, 1.0523, 1.0602, 1.0655, 1.0576, 1.0655, 1.0576, 1.0391, 1.0602,\n",
      "         1.0945, 1.1050, 1.0971, 1.1103, 1.1235, 1.1156, 1.1182, 1.1209, 1.1341,\n",
      "         1.1182, 1.1156, 1.1341, 1.1736, 1.1868, 1.2000, 1.2264, 1.2395, 1.2237,\n",
      "         1.2026, 1.2053, 1.2000, 1.1736, 1.1631, 1.1631, 1.2000, 1.2132, 1.2264,\n",
      "         1.2290, 1.2527, 1.2053, 1.1842, 1.1921, 1.1815, 1.2026, 1.2079, 1.2132,\n",
      "         1.2185, 1.1894, 1.1842, 1.2026, 1.2132, 1.1974, 1.1921, 1.1815, 1.1868,\n",
      "         1.1631, 1.1868, 1.1815, 1.1683, 1.1683, 1.1552, 1.1763, 1.1710, 1.1789,\n",
      "         1.1710, 1.1763, 1.1763, 1.1710, 1.1763, 1.1683, 1.1472, 1.1657]])\n",
      "token=  tensor([[2144, 2144, 2143, 2143, 2143, 2143, 2141, 2142, 2142, 2149, 2151, 2153,\n",
      "         2152, 2160, 2158, 2157, 2159, 2165, 2163, 2163, 2165, 2168, 2170, 2167,\n",
      "         2174, 2173, 2165, 2166, 2169, 2168, 2166, 2169, 2168, 2168, 2166, 2167,\n",
      "         2168, 2173, 2179, 2176, 2175, 2176, 2170, 2168, 2168, 2168, 2172, 2172,\n",
      "         2168, 2168, 2168, 2175, 2174, 2170, 2171, 2177, 2179, 2175, 2174, 2175,\n",
      "         2174, 2173, 2172, 2174, 2174, 2171, 2170, 2166, 2171, 2166, 2161, 2165,\n",
      "         2167, 2166, 2167, 2167, 2167, 2164, 2164, 2164, 2164, 2165, 2164, 2162,\n",
      "         2163, 2164, 2163, 2174, 2174, 2175, 2175, 2175, 2173, 2173, 2170, 2168,\n",
      "         2169, 2167, 2171, 2171, 2173, 2171, 2170, 2171, 2173, 2173, 2171, 2170,\n",
      "         2170, 2172, 2175, 2172, 2171, 2172, 2171, 2171, 2171, 2170, 2171, 2171,\n",
      "         2170, 2168, 2169, 2169, 2170, 2170, 2169, 2168, 2167, 2169, 2168, 2166,\n",
      "         2163, 2162, 2164, 2164, 2163, 2164, 2164, 2164, 2164, 2163, 2163, 2163,\n",
      "         2163, 2163, 2164, 2163, 2163, 2168, 2167, 2166, 2168, 2168, 2171, 2167,\n",
      "         2173, 2173, 2173, 2175, 2175, 2177, 2175, 2171, 2174, 2174, 2172, 2173,\n",
      "         2172, 2170, 2170, 2168, 2168, 2170, 2166, 2166, 2163, 2163, 2162, 2161,\n",
      "         2159, 2158, 2157, 2158, 2157, 2163, 2162, 2159, 2159, 2162, 2163, 2165,\n",
      "         2165, 2164, 2166, 2163, 2164, 2167, 2164, 2165, 2166, 2168, 2169, 2170,\n",
      "         2169, 2168, 2166, 2165, 2165, 2170, 2168, 2169, 2169, 2172, 2171, 2171,\n",
      "         2173, 2171, 2170, 2170, 2168, 2171, 2171, 2169, 2170, 2171, 2171, 2171,\n",
      "         2169, 2171, 2169, 2170, 2173, 2173, 2173, 2176, 2176, 2176, 2178, 2177,\n",
      "         2177, 2176, 2176, 2176, 2182, 2181, 2181, 2181, 2184, 2183, 2186, 2186,\n",
      "         2185, 2185, 2187, 2186, 2185, 2184, 2184, 2187, 2188, 2185, 2186, 2185,\n",
      "         2184, 2186, 2182, 2181, 2183, 2185, 2185, 2184, 2182, 2182, 2180, 2179,\n",
      "         2179, 2181, 2180, 2180, 2189, 2186, 2186, 2186, 2193, 2193, 2198, 2193,\n",
      "         2196, 2199, 2195, 2199, 2198, 2196, 2198, 2198, 2196, 2196, 2196, 2196,\n",
      "         2196, 2196, 2199, 2197, 2199, 2197, 2196, 2196, 2196, 2194, 2194, 2199,\n",
      "         2199, 2195, 2197, 2199, 2196, 2196, 2197, 2199, 2200, 2199, 2202, 2202,\n",
      "         2201, 2205, 2204, 2203, 2207, 2203, 2202, 2200, 2200, 2199, 2200, 2201,\n",
      "         2203, 2201, 2203, 2209, 2209, 2207, 2208, 2207, 2208, 2207, 2206, 2204,\n",
      "         2205, 2202, 2205, 2205, 2205, 2203, 2203, 2207, 2211, 2215, 2209, 2208,\n",
      "         2214, 2214, 2215, 2216, 2210, 2212, 2213, 2213, 2213, 2213, 2212, 2214,\n",
      "         2213, 2214, 2214, 2214, 2212, 2212, 2208, 2212, 2214, 2214, 2216, 2218,\n",
      "         2217, 2217, 2218, 2217, 2216, 2215, 2215, 2218, 2220, 2221, 2215, 2215,\n",
      "         2215, 2215, 2215, 2215, 2215, 2204, 2205, 2205, 2204, 2202, 2202, 2199,\n",
      "         2202, 2200, 2199, 2197, 2198, 2200, 2200, 2200, 2202, 2204, 2204, 2203,\n",
      "         2204, 2205, 2202, 2196, 2195, 2194, 2196, 2197, 2195, 2194, 2197, 2194,\n",
      "         2197, 2195, 2199, 2198, 2195, 2194, 2194, 2193, 2194, 2193, 2193, 2194,\n",
      "         2194, 2193, 2194, 2193, 2191, 2194, 2198, 2200, 2199, 2200, 2202, 2201,\n",
      "         2202, 2202, 2204, 2202, 2201, 2204, 2209, 2211, 2213, 2216, 2218, 2216,\n",
      "         2213, 2213, 2213, 2209, 2208, 2208, 2213, 2214, 2216, 2217, 2220, 2213,\n",
      "         2211, 2212, 2210, 2213, 2214, 2214, 2215, 2211, 2211, 2213, 2214, 2212,\n",
      "         2212, 2210, 2211, 2208, 2211, 2210, 2208, 2208, 2207, 2209, 2209, 2210,\n",
      "         2209, 2209, 2209, 2209, 2209, 2208, 2205, 2208,    1]],\n",
      "       device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4785,  0.8438,  0.5977,  ..., -0.1216,  0.6367,  0.3652],\n",
      "         [ 0.4785,  0.8438,  0.5977,  ..., -0.1216,  0.6367,  0.3652],\n",
      "         [ 0.7070,  0.6602, -0.3691,  ..., -0.0659, -0.2539,  0.3770],\n",
      "         ...,\n",
      "         [-0.3730,  0.6562, -0.4492,  ...,  0.9922,  0.4961,  0.2305],\n",
      "         [-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656],\n",
      "         [ 0.3203, -0.2871,  0.0153,  ...,  3.2031, -1.1797, -2.8438]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([1, 513])\n",
      "testt2\n",
      "batch_size=  1\n",
      "seq_length=  513\n",
      "token=  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0640,  0.0267,  0.0284,  ..., -0.2061,  0.0195,  2.0469]],\n",
      "\n",
      "        [[ 0.0640,  0.0267,  0.0284,  ..., -0.2061,  0.0195,  2.0469]],\n",
      "\n",
      "        [[ 0.0640,  0.0267,  0.0284,  ..., -0.2061,  0.0195,  2.0469]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0640,  0.0267,  0.0284,  ..., -0.2061,  0.0195,  2.0469]],\n",
      "\n",
      "        [[ 0.0640,  0.0267,  0.0284,  ..., -0.2061,  0.0195,  2.0469]],\n",
      "\n",
      "        [[ 0.0640,  0.0267,  0.0284,  ..., -0.2061,  0.0195,  2.0469]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2207],\n",
      "        [2208],\n",
      "        [2209],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2209],\n",
      "        [2206],\n",
      "        [2209],\n",
      "        [2206],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2206],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2208]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2208],\n",
      "        [2209],\n",
      "        [2207],\n",
      "        [2209],\n",
      "        [2203],\n",
      "        [2206],\n",
      "        [2209],\n",
      "        [2206],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2209],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2207]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2207],\n",
      "        [2211],\n",
      "        [2206],\n",
      "        [2206],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2204],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2205],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2207],\n",
      "        [2209],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2207]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        [[-1.0234,  0.6445, -0.3828,  ...,  0.0061,  0.7148,  0.4434]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3730,  0.6562, -0.4492,  ...,  0.9922,  0.4961,  0.2305]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2204],\n",
      "        [2202],\n",
      "        [2206],\n",
      "        [2203],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2204],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2204],\n",
      "        [2204],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2206],\n",
      "        [2205],\n",
      "        [2204],\n",
      "        [2206],\n",
      "        [2209]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5625,  0.2227,  0.4238,  ...,  1.2656,  0.1787,  0.1768]],\n",
      "\n",
      "        [[-0.4727,  0.5938,  0.7070,  ...,  0.4727, -0.3359,  0.1768]],\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5625,  0.2227,  0.4238,  ...,  1.2656,  0.1787,  0.1768]],\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2203],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2202],\n",
      "        [2205],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2204],\n",
      "        [2203],\n",
      "        [2206],\n",
      "        [2204],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2205],\n",
      "        [2204],\n",
      "        [2208],\n",
      "        [2208]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3281,  0.5742,  0.2539,  ...,  0.1133,  0.1484,  0.1787]],\n",
      "\n",
      "        [[-0.3730,  0.6562, -0.4492,  ...,  0.9922,  0.4961,  0.2305]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5625,  0.2227,  0.4238,  ...,  1.2656,  0.1787,  0.1768]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2207],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2209],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2205],\n",
      "        [2204],\n",
      "        [2204],\n",
      "        [2207],\n",
      "        [2204],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2204],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2207]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        [[-0.3730,  0.6562, -0.4492,  ...,  0.9922,  0.4961,  0.2305]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2207],\n",
      "        [2203],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2204],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2206],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2203],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2207]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        [[-0.3281,  0.5742,  0.2539,  ...,  0.1133,  0.1484,  0.1787]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2203],\n",
      "        [2206],\n",
      "        [2206],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2210],\n",
      "        [2213],\n",
      "        [2208],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2206],\n",
      "        [2207],\n",
      "        [2206],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2208]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-0.3281,  0.5742,  0.2539,  ...,  0.1133,  0.1484,  0.1787]],\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2205],\n",
      "        [2204],\n",
      "        [2206],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2209],\n",
      "        [2210],\n",
      "        [2209],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2209],\n",
      "        [2209],\n",
      "        [2207],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2210]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-0.3730,  0.6562, -0.4492,  ...,  0.9922,  0.4961,  0.2305]],\n",
      "\n",
      "        [[ 0.5625,  0.2227,  0.4238,  ...,  1.2656,  0.1787,  0.1768]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        [[-0.4375,  0.5625, -0.3887,  ...,  0.7422,  0.6445,  0.3594]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2207],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2209],\n",
      "        [2205],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2206],\n",
      "        [2211],\n",
      "        [2209],\n",
      "        [2209],\n",
      "        [2209],\n",
      "        [2211],\n",
      "        [2205],\n",
      "        [2213],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2206],\n",
      "        [2211]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        [[-1.0234,  0.6445, -0.3828,  ...,  0.0061,  0.7148,  0.4434]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2203],\n",
      "        [2206],\n",
      "        [2211],\n",
      "        [2203],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2204],\n",
      "        [2211],\n",
      "        [2206],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2211]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3281,  0.5742,  0.2539,  ...,  0.1133,  0.1484,  0.1787]],\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        [[-1.0234,  0.6445, -0.3828,  ...,  0.0061,  0.7148,  0.4434]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-1.0234,  0.6445, -0.3828,  ...,  0.0061,  0.7148,  0.4434]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2202],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2199],\n",
      "        [2203],\n",
      "        [2204],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2206],\n",
      "        [2203],\n",
      "        [2210],\n",
      "        [2203],\n",
      "        [2204],\n",
      "        [2213],\n",
      "        [2207]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4727,  0.5938,  0.7070,  ...,  0.4727, -0.3359,  0.1768]],\n",
      "\n",
      "        [[-0.3730,  0.6562, -0.4492,  ...,  0.9922,  0.4961,  0.2305]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5625,  0.2227,  0.4238,  ...,  1.2656,  0.1787,  0.1768]],\n",
      "\n",
      "        [[-0.8945,  0.6094, -0.5586,  ...,  0.7148, -0.7773,  0.3008]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2199],\n",
      "        [2202],\n",
      "        [2207],\n",
      "        [2195],\n",
      "        [2203],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2208],\n",
      "        [2204],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2203],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2209],\n",
      "        [2202],\n",
      "        [2206],\n",
      "        [2209],\n",
      "        [2207]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        [[-0.4727,  0.5938,  0.7070,  ...,  0.4727, -0.3359,  0.1768]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1855,  0.5273, -0.5312,  ..., -0.4160,  0.6953,  0.1309]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2198],\n",
      "        [2200],\n",
      "        [2207],\n",
      "        [2195],\n",
      "        [2200],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2207],\n",
      "        [2202],\n",
      "        [2200],\n",
      "        [2205],\n",
      "        [2200],\n",
      "        [2205],\n",
      "        [2200],\n",
      "        [2207],\n",
      "        [2206],\n",
      "        [2198],\n",
      "        [2208],\n",
      "        [2210],\n",
      "        [2207]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-0.3691,  0.3398, -0.1118,  ..., -0.8789,  0.3320,  0.2598]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-0.4375,  0.5625, -0.3887,  ...,  0.7422,  0.6445,  0.3594]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2199],\n",
      "        [2194],\n",
      "        [2204],\n",
      "        [2197],\n",
      "        [2198],\n",
      "        [2207],\n",
      "        [2206],\n",
      "        [2207],\n",
      "        [2202],\n",
      "        [2201],\n",
      "        [2205],\n",
      "        [2197],\n",
      "        [2202],\n",
      "        [2199],\n",
      "        [2208],\n",
      "        [2202],\n",
      "        [2198],\n",
      "        [2209],\n",
      "        [2208],\n",
      "        [2208]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]],\n",
      "\n",
      "        [[ 0.5625,  0.2227,  0.4238,  ...,  1.2656,  0.1787,  0.1768]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2202],\n",
      "        [2195],\n",
      "        [2200],\n",
      "        [2199],\n",
      "        [2198],\n",
      "        [2204],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2202],\n",
      "        [2198],\n",
      "        [2207],\n",
      "        [2197],\n",
      "        [2199],\n",
      "        [2197],\n",
      "        [2207],\n",
      "        [2202],\n",
      "        [2201],\n",
      "        [2207],\n",
      "        [2209],\n",
      "        [2205]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4727,  0.5938,  0.7070,  ...,  0.4727, -0.3359,  0.1768]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.3691,  0.3398, -0.1118,  ..., -0.8789,  0.3320,  0.2598]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        [[-0.3730,  0.6562, -0.4492,  ...,  0.9922,  0.4961,  0.2305]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2204],\n",
      "        [2198],\n",
      "        [2200],\n",
      "        [2202],\n",
      "        [2203],\n",
      "        [2202],\n",
      "        [2204],\n",
      "        [2210],\n",
      "        [2204],\n",
      "        [2199],\n",
      "        [2208],\n",
      "        [2199],\n",
      "        [2202],\n",
      "        [2199],\n",
      "        [2205],\n",
      "        [2201],\n",
      "        [2202],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2203]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5625,  0.2227,  0.4238,  ...,  1.2656,  0.1787,  0.1768]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-0.3691,  0.3398, -0.1118,  ..., -0.8789,  0.3320,  0.2598]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-0.3281,  0.5742,  0.2539,  ...,  0.1133,  0.1484,  0.1787]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2201],\n",
      "        [2200],\n",
      "        [2205],\n",
      "        [2203],\n",
      "        [2199],\n",
      "        [2199],\n",
      "        [2209],\n",
      "        [2207],\n",
      "        [2201],\n",
      "        [2206],\n",
      "        [2202],\n",
      "        [2204],\n",
      "        [2202],\n",
      "        [2203],\n",
      "        [2202],\n",
      "        [2205],\n",
      "        [2203],\n",
      "        [2208],\n",
      "        [2204]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3730,  0.6562, -0.4492,  ...,  0.9922,  0.4961,  0.2305]],\n",
      "\n",
      "        [[ 0.0030,  0.2139,  0.1001,  ...,  0.4961,  0.6602,  0.2158]],\n",
      "\n",
      "        [[-0.3691,  0.3398, -0.1118,  ..., -0.8789,  0.3320,  0.2598]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3281,  0.5742,  0.2539,  ...,  0.1133,  0.1484,  0.1787]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[ 0.5625,  0.2227,  0.4238,  ...,  1.2656,  0.1787,  0.1768]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2201],\n",
      "        [2205],\n",
      "        [2204],\n",
      "        [2205],\n",
      "        [2195],\n",
      "        [2198],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2202],\n",
      "        [2204],\n",
      "        [2202],\n",
      "        [2205],\n",
      "        [2202],\n",
      "        [2200],\n",
      "        [2203],\n",
      "        [2208],\n",
      "        [2200],\n",
      "        [2209],\n",
      "        [2203]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3730,  0.6562, -0.4492,  ...,  0.9922,  0.4961,  0.2305]],\n",
      "\n",
      "        [[ 0.0030,  0.2139,  0.1001,  ...,  0.4961,  0.6602,  0.2158]],\n",
      "\n",
      "        [[-0.3730,  0.6562, -0.4492,  ...,  0.9922,  0.4961,  0.2305]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3691,  0.3398, -0.1118,  ..., -0.8789,  0.3320,  0.2598]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        [[-0.3281,  0.5742,  0.2539,  ...,  0.1133,  0.1484,  0.1787]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2202],\n",
      "        [2202],\n",
      "        [2207],\n",
      "        [2201],\n",
      "        [2205],\n",
      "        [2196],\n",
      "        [2198],\n",
      "        [2206],\n",
      "        [2204],\n",
      "        [2202],\n",
      "        [2201],\n",
      "        [2199],\n",
      "        [2203],\n",
      "        [2202],\n",
      "        [2200],\n",
      "        [2206],\n",
      "        [2205],\n",
      "        [2198],\n",
      "        [2210],\n",
      "        [2199]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4727,  0.5938,  0.7070,  ...,  0.4727, -0.3359,  0.1768]],\n",
      "\n",
      "        [[-0.4727,  0.5938,  0.7070,  ...,  0.4727, -0.3359,  0.1768]],\n",
      "\n",
      "        [[-0.7734,  0.2598, -0.2949,  ...,  1.0469,  0.7148,  0.2178]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-0.4375,  0.5625, -0.3887,  ...,  0.7422,  0.6445,  0.3594]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2195],\n",
      "        [2198],\n",
      "        [2208],\n",
      "        [2199],\n",
      "        [2202],\n",
      "        [2197],\n",
      "        [2200],\n",
      "        [2205],\n",
      "        [2202],\n",
      "        [2199],\n",
      "        [2201],\n",
      "        [2196],\n",
      "        [2200],\n",
      "        [2199],\n",
      "        [2202],\n",
      "        [2205],\n",
      "        [2203],\n",
      "        [2198],\n",
      "        [2211],\n",
      "        [2199]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-1.0234,  0.6445, -0.3828,  ...,  0.0061,  0.7148,  0.4434]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2193],\n",
      "        [2195],\n",
      "        [2203],\n",
      "        [2198],\n",
      "        [2200],\n",
      "        [2199],\n",
      "        [2201],\n",
      "        [2204],\n",
      "        [2201],\n",
      "        [2196],\n",
      "        [2200],\n",
      "        [2195],\n",
      "        [2197],\n",
      "        [2195],\n",
      "        [2204],\n",
      "        [2201],\n",
      "        [2201],\n",
      "        [2198],\n",
      "        [2209],\n",
      "        [2198]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.3281,  0.5742,  0.2539,  ...,  0.1133,  0.1484,  0.1787]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2195],\n",
      "        [2192],\n",
      "        [2202],\n",
      "        [2195],\n",
      "        [2196],\n",
      "        [2202],\n",
      "        [2204],\n",
      "        [2204],\n",
      "        [2198],\n",
      "        [2193],\n",
      "        [2202],\n",
      "        [2190],\n",
      "        [2194],\n",
      "        [2195],\n",
      "        [2204],\n",
      "        [2198],\n",
      "        [2197],\n",
      "        [2200],\n",
      "        [2209],\n",
      "        [2198]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.3711,  0.2217,  0.7305,  ..., -0.6211,  0.7070,  0.3750]],\n",
      "\n",
      "        [[-0.4727,  0.5938,  0.7070,  ...,  0.4727, -0.3359,  0.1768]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3691,  0.3398, -0.1118,  ..., -0.8789,  0.3320,  0.2598]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2196],\n",
      "        [2193],\n",
      "        [2199],\n",
      "        [2197],\n",
      "        [2196],\n",
      "        [2202],\n",
      "        [2203],\n",
      "        [2207],\n",
      "        [2198],\n",
      "        [2196],\n",
      "        [2202],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2189],\n",
      "        [2204],\n",
      "        [2196],\n",
      "        [2197],\n",
      "        [2202],\n",
      "        [2208],\n",
      "        [2191]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        [[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4727,  0.5938,  0.7070,  ...,  0.4727, -0.3359,  0.1768]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2195],\n",
      "        [2196],\n",
      "        [2196],\n",
      "        [2197],\n",
      "        [2198],\n",
      "        [2197],\n",
      "        [2201],\n",
      "        [2208],\n",
      "        [2200],\n",
      "        [2196],\n",
      "        [2203],\n",
      "        [2196],\n",
      "        [2194],\n",
      "        [2195],\n",
      "        [2201],\n",
      "        [2196],\n",
      "        [2199],\n",
      "        [2203],\n",
      "        [2209],\n",
      "        [2194]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3281,  0.5742,  0.2539,  ...,  0.1133,  0.1484,  0.1787]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2198],\n",
      "        [2195],\n",
      "        [2197],\n",
      "        [2197],\n",
      "        [2200],\n",
      "        [2193],\n",
      "        [2197],\n",
      "        [2207],\n",
      "        [2202],\n",
      "        [2198],\n",
      "        [2202],\n",
      "        [2197],\n",
      "        [2198],\n",
      "        [2197],\n",
      "        [2199],\n",
      "        [2198],\n",
      "        [2199],\n",
      "        [2202],\n",
      "        [2209],\n",
      "        [2196]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4727,  0.5938,  0.7070,  ...,  0.4727, -0.3359,  0.1768]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2199],\n",
      "        [2197],\n",
      "        [2199],\n",
      "        [2197],\n",
      "        [2199],\n",
      "        [2190],\n",
      "        [2196],\n",
      "        [2207],\n",
      "        [2201],\n",
      "        [2200],\n",
      "        [2199],\n",
      "        [2199],\n",
      "        [2199],\n",
      "        [2198],\n",
      "        [2198],\n",
      "        [2199],\n",
      "        [2197],\n",
      "        [2198],\n",
      "        [2209],\n",
      "        [2199]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-1.1172,  0.2617, -0.2559,  ..., -0.0308,  0.5625,  0.3555]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2197],\n",
      "        [2197],\n",
      "        [2199],\n",
      "        [2196],\n",
      "        [2197],\n",
      "        [2194],\n",
      "        [2195],\n",
      "        [2204],\n",
      "        [2199],\n",
      "        [2198],\n",
      "        [2197],\n",
      "        [2198],\n",
      "        [2201],\n",
      "        [2196],\n",
      "        [2199],\n",
      "        [2199],\n",
      "        [2197],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2201]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]],\n",
      "\n",
      "        [[-1.1328,  0.1523, -0.2910,  ...,  0.2168,  0.7539,  0.2656]],\n",
      "\n",
      "        [[ 0.0030,  0.2139,  0.1001,  ...,  0.4961,  0.6602,  0.2158]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2196],\n",
      "        [2197],\n",
      "        [2199],\n",
      "        [2191],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2198],\n",
      "        [2200],\n",
      "        [2197],\n",
      "        [2196],\n",
      "        [2195],\n",
      "        [2195],\n",
      "        [2197],\n",
      "        [2191],\n",
      "        [2199],\n",
      "        [2197],\n",
      "        [2197],\n",
      "        [2195],\n",
      "        [2210],\n",
      "        [2199]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.4375,  0.5625, -0.3887,  ...,  0.7422,  0.6445,  0.3594]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2196],\n",
      "        [2195],\n",
      "        [2196],\n",
      "        [2193],\n",
      "        [2189],\n",
      "        [2197],\n",
      "        [2198],\n",
      "        [2200],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2197],\n",
      "        [2192],\n",
      "        [2195],\n",
      "        [2188],\n",
      "        [2199],\n",
      "        [2193],\n",
      "        [2198],\n",
      "        [2197],\n",
      "        [2211],\n",
      "        [2197]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-1.0234,  0.6445, -0.3828,  ...,  0.0061,  0.7148,  0.4434]],\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2199],\n",
      "        [2196],\n",
      "        [2195],\n",
      "        [2196],\n",
      "        [2193],\n",
      "        [2198],\n",
      "        [2198],\n",
      "        [2199],\n",
      "        [2197],\n",
      "        [2191],\n",
      "        [2198],\n",
      "        [2192],\n",
      "        [2193],\n",
      "        [2190],\n",
      "        [2201],\n",
      "        [2188],\n",
      "        [2198],\n",
      "        [2197],\n",
      "        [2210],\n",
      "        [2194]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-0.4375,  0.5625, -0.3887,  ...,  0.7422,  0.6445,  0.3594]],\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2196],\n",
      "        [2198],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2193],\n",
      "        [2197],\n",
      "        [2197],\n",
      "        [2199],\n",
      "        [2195],\n",
      "        [2193],\n",
      "        [2200],\n",
      "        [2192],\n",
      "        [2197],\n",
      "        [2191],\n",
      "        [2199],\n",
      "        [2190],\n",
      "        [2193],\n",
      "        [2197],\n",
      "        [2212],\n",
      "        [2193]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-0.5000,  0.6016, -0.3906,  ...,  0.3828,  0.1699,  0.3418]],\n",
      "\n",
      "        [[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2197],\n",
      "        [2198],\n",
      "        [2191],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2198],\n",
      "        [2202],\n",
      "        [2198],\n",
      "        [2193],\n",
      "        [2201],\n",
      "        [2194],\n",
      "        [2195],\n",
      "        [2188],\n",
      "        [2198],\n",
      "        [2192],\n",
      "        [2195],\n",
      "        [2196],\n",
      "        [2211],\n",
      "        [2196]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        [[-1.0234,  0.6445, -0.3828,  ...,  0.0061,  0.7148,  0.4434]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2197],\n",
      "        [2199],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2195],\n",
      "        [2192],\n",
      "        [2195],\n",
      "        [2202],\n",
      "        [2198],\n",
      "        [2193],\n",
      "        [2199],\n",
      "        [2193],\n",
      "        [2195],\n",
      "        [2190],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2195],\n",
      "        [2197],\n",
      "        [2214],\n",
      "        [2195]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        [[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2199],\n",
      "        [2199],\n",
      "        [2194],\n",
      "        [2191],\n",
      "        [2195],\n",
      "        [2193],\n",
      "        [2196],\n",
      "        [2202],\n",
      "        [2198],\n",
      "        [2194],\n",
      "        [2198],\n",
      "        [2193],\n",
      "        [2195],\n",
      "        [2191],\n",
      "        [2191],\n",
      "        [2196],\n",
      "        [2197],\n",
      "        [2194],\n",
      "        [2212],\n",
      "        [2195]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]],\n",
      "\n",
      "        [[-0.5000,  0.6016, -0.3906,  ...,  0.3828,  0.1699,  0.3418]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2197],\n",
      "        [2200],\n",
      "        [2194],\n",
      "        [2189],\n",
      "        [2192],\n",
      "        [2191],\n",
      "        [2198],\n",
      "        [2199],\n",
      "        [2196],\n",
      "        [2192],\n",
      "        [2194],\n",
      "        [2191],\n",
      "        [2196],\n",
      "        [2189],\n",
      "        [2194],\n",
      "        [2197],\n",
      "        [2196],\n",
      "        [2190],\n",
      "        [2212],\n",
      "        [2195]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-0.3691,  0.3398, -0.1118,  ..., -0.8789,  0.3320,  0.2598]],\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]],\n",
      "\n",
      "        [[-0.5000,  0.6016, -0.3906,  ...,  0.3828,  0.1699,  0.3418]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2196],\n",
      "        [2198],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2191],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2195],\n",
      "        [2192],\n",
      "        [2191],\n",
      "        [2194],\n",
      "        [2191],\n",
      "        [2193],\n",
      "        [2190],\n",
      "        [2195],\n",
      "        [2195],\n",
      "        [2195],\n",
      "        [2193],\n",
      "        [2214],\n",
      "        [2196]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2194],\n",
      "        [2195],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2191],\n",
      "        [2196],\n",
      "        [2194],\n",
      "        [2192],\n",
      "        [2188],\n",
      "        [2198],\n",
      "        [2189],\n",
      "        [2191],\n",
      "        [2189],\n",
      "        [2196],\n",
      "        [2191],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2214],\n",
      "        [2194]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2193],\n",
      "        [2194],\n",
      "        [2190],\n",
      "        [2191],\n",
      "        [2191],\n",
      "        [2191],\n",
      "        [2196],\n",
      "        [2197],\n",
      "        [2195],\n",
      "        [2188],\n",
      "        [2196],\n",
      "        [2189],\n",
      "        [2191],\n",
      "        [2191],\n",
      "        [2195],\n",
      "        [2190],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2214],\n",
      "        [2191]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2193],\n",
      "        [2195],\n",
      "        [2187],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2191],\n",
      "        [2195],\n",
      "        [2195],\n",
      "        [2194],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2193],\n",
      "        [2189],\n",
      "        [2193],\n",
      "        [2189],\n",
      "        [2213],\n",
      "        [2193]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.0635,  0.5742,  0.2656,  ...,  0.2559,  0.5664,  0.3359]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.8945,  0.6094, -0.5586,  ...,  0.7148, -0.7773,  0.3008]],\n",
      "\n",
      "        [[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2193],\n",
      "        [2195],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2191],\n",
      "        [2193],\n",
      "        [2196],\n",
      "        [2192],\n",
      "        [2191],\n",
      "        [2194],\n",
      "        [2190],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2190],\n",
      "        [2187],\n",
      "        [2189],\n",
      "        [2214],\n",
      "        [2191]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2190],\n",
      "        [2194],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2198],\n",
      "        [2194],\n",
      "        [2191],\n",
      "        [2191],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2214],\n",
      "        [2193]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]],\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2191],\n",
      "        [2186],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2192],\n",
      "        [2197],\n",
      "        [2192],\n",
      "        [2191],\n",
      "        [2191],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2187],\n",
      "        [2214],\n",
      "        [2191]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]],\n",
      "\n",
      "        [[-0.1001,  0.5977, -0.2334,  ...,  0.8008,  0.1309,  0.3730]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0635,  0.5742,  0.2656,  ...,  0.2559,  0.5664,  0.3359]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2190],\n",
      "        [2191],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2191],\n",
      "        [2192],\n",
      "        [2194],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2187],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2186],\n",
      "        [2189],\n",
      "        [2214],\n",
      "        [2191]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2191],\n",
      "        [2188],\n",
      "        [2191],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2187],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2188],\n",
      "        [2190],\n",
      "        [2188],\n",
      "        [2188],\n",
      "        [2189],\n",
      "        [2214],\n",
      "        [2191]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2185],\n",
      "        [2185],\n",
      "        [2189],\n",
      "        [2194],\n",
      "        [2188],\n",
      "        [2191],\n",
      "        [2188],\n",
      "        [2192],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2188],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2189],\n",
      "        [2214],\n",
      "        [2189]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5742,  0.2773,  0.1084,  ...,  0.8164, -0.0029,  0.3789]],\n",
      "\n",
      "        [[ 0.5742,  0.2773,  0.1084,  ...,  0.8164, -0.0029,  0.3789]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2188],\n",
      "        [2188],\n",
      "        [2189],\n",
      "        [2197],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2193],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2187],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2186],\n",
      "        [2191],\n",
      "        [2214],\n",
      "        [2190]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2198],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2186],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2190],\n",
      "        [2190],\n",
      "        [2188],\n",
      "        [2188],\n",
      "        [2190],\n",
      "        [2187],\n",
      "        [2187],\n",
      "        [2189],\n",
      "        [2213],\n",
      "        [2188]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.8945,  0.6094, -0.5586,  ...,  0.7148, -0.7773,  0.3008]],\n",
      "\n",
      "        [[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2198],\n",
      "        [2193],\n",
      "        [2189],\n",
      "        [2187],\n",
      "        [2191],\n",
      "        [2192],\n",
      "        [2190],\n",
      "        [2186],\n",
      "        [2194],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2213],\n",
      "        [2190]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.8945,  0.6094, -0.5586,  ...,  0.7148, -0.7773,  0.3008]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token=  tensor([[2191],\n",
      "        [2191],\n",
      "        [2195],\n",
      "        [2197],\n",
      "        [2196],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2191],\n",
      "        [2190],\n",
      "        [2190],\n",
      "        [2187],\n",
      "        [2197],\n",
      "        [2190],\n",
      "        [2188],\n",
      "        [2187],\n",
      "        [2191],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2214],\n",
      "        [2190]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.0066,  0.7070, -0.0209,  ...,  0.5195,  0.4180,  0.3574]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2190],\n",
      "        [2188],\n",
      "        [2196],\n",
      "        [2197],\n",
      "        [2195],\n",
      "        [2186],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2190],\n",
      "        [2190],\n",
      "        [2187],\n",
      "        [2198],\n",
      "        [2190],\n",
      "        [2187],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2215],\n",
      "        [2191]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]],\n",
      "\n",
      "        [[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.3203,  0.7266,  0.2969,  ...,  0.9961,  0.6133,  0.3906]],\n",
      "\n",
      "        [[-0.1318,  0.5469,  0.6914,  ..., -0.5234, -0.1484,  0.3535]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2186],\n",
      "        [2199],\n",
      "        [2195],\n",
      "        [2196],\n",
      "        [2190],\n",
      "        [2187],\n",
      "        [2187],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2186],\n",
      "        [2198],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2195],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2222],\n",
      "        [2190]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.1001,  0.5977, -0.2334,  ...,  0.8008,  0.1309,  0.3730]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.0093,  0.4746, -0.3125,  ...,  0.8594,  0.8047,  0.1768]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2187],\n",
      "        [2198],\n",
      "        [2196],\n",
      "        [2194],\n",
      "        [2190],\n",
      "        [2190],\n",
      "        [2188],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2189],\n",
      "        [2197],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2197],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2221],\n",
      "        [2190]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.0635,  0.5742,  0.2656,  ...,  0.2559,  0.5664,  0.3359]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.3633,  0.2471,  0.0297,  ...,  1.3750,  0.6289,  0.3398]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2188],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2195],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2188],\n",
      "        [2188],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2196],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2190],\n",
      "        [2194],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2218],\n",
      "        [2190]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[-0.2207,  0.3359,  0.1807,  ..., -0.4219,  0.6055,  0.4121]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.7930,  0.5234,  0.6484,  ...,  0.2812,  0.8398,  0.2559]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2186],\n",
      "        [2195],\n",
      "        [2196],\n",
      "        [2196],\n",
      "        [2187],\n",
      "        [2196],\n",
      "        [2184],\n",
      "        [2189],\n",
      "        [2191],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2189],\n",
      "        [2191],\n",
      "        [2189],\n",
      "        [2196],\n",
      "        [2188],\n",
      "        [2196],\n",
      "        [2215],\n",
      "        [2190]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[-0.1001,  0.5977, -0.2334,  ...,  0.8008,  0.1309,  0.3730]],\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        [[-0.3203,  0.7266,  0.2969,  ...,  0.9961,  0.6133,  0.3906]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2188],\n",
      "        [2196],\n",
      "        [2197],\n",
      "        [2197],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2186],\n",
      "        [2192],\n",
      "        [2194],\n",
      "        [2187],\n",
      "        [2197],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2190],\n",
      "        [2196],\n",
      "        [2187],\n",
      "        [2195],\n",
      "        [2215],\n",
      "        [2192]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[-0.3203,  0.7266,  0.2969,  ...,  0.9961,  0.6133,  0.3906]],\n",
      "\n",
      "        [[-0.3711,  0.2217,  0.7305,  ..., -0.6211,  0.7070,  0.3750]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2188],\n",
      "        [2197],\n",
      "        [2201],\n",
      "        [2199],\n",
      "        [2189],\n",
      "        [2196],\n",
      "        [2190],\n",
      "        [2191],\n",
      "        [2196],\n",
      "        [2188],\n",
      "        [2199],\n",
      "        [2189],\n",
      "        [2195],\n",
      "        [2190],\n",
      "        [2195],\n",
      "        [2188],\n",
      "        [2195],\n",
      "        [2216],\n",
      "        [2196]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3633,  0.5430, -0.4375,  ..., -0.0208,  0.4512,  0.3711]],\n",
      "\n",
      "        [[ 0.1855,  0.6484,  0.4102,  ...,  0.5039,  0.6211,  0.3457]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2189],\n",
      "        [2188],\n",
      "        [2198],\n",
      "        [2198],\n",
      "        [2199],\n",
      "        [2190],\n",
      "        [2197],\n",
      "        [2190],\n",
      "        [2189],\n",
      "        [2198],\n",
      "        [2188],\n",
      "        [2198],\n",
      "        [2193],\n",
      "        [2196],\n",
      "        [2190],\n",
      "        [2196],\n",
      "        [2188],\n",
      "        [2196],\n",
      "        [2215],\n",
      "        [2196]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0413,  0.6484,  0.2285,  ..., -0.1157, -0.1250,  0.3066]],\n",
      "\n",
      "        [[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]],\n",
      "\n",
      "        [[-0.3203,  0.7266,  0.2969,  ...,  0.9961,  0.6133,  0.3906]],\n",
      "\n",
      "        [[-0.4102,  0.4961, -0.2305,  ...,  0.4609,  0.8867,  0.2754]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2187],\n",
      "        [2187],\n",
      "        [2198],\n",
      "        [2199],\n",
      "        [2198],\n",
      "        [2189],\n",
      "        [2197],\n",
      "        [2189],\n",
      "        [2188],\n",
      "        [2197],\n",
      "        [2189],\n",
      "        [2199],\n",
      "        [2198],\n",
      "        [2196],\n",
      "        [2190],\n",
      "        [2197],\n",
      "        [2186],\n",
      "        [2193],\n",
      "        [2217],\n",
      "        [2199]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0635,  0.5742,  0.2656,  ...,  0.2559,  0.5664,  0.3359]],\n",
      "\n",
      "        [[-0.0635,  0.5742,  0.2656,  ...,  0.2559,  0.5664,  0.3359]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        [[ 0.1553,  0.6367,  0.8477,  ..., -0.4824,  0.5625,  0.3691]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2188],\n",
      "        [2188],\n",
      "        [2198],\n",
      "        [2199],\n",
      "        [2199],\n",
      "        [2192],\n",
      "        [2195],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2200],\n",
      "        [2187],\n",
      "        [2198],\n",
      "        [2197],\n",
      "        [2195],\n",
      "        [2194],\n",
      "        [2198],\n",
      "        [2187],\n",
      "        [2193],\n",
      "        [2223],\n",
      "        [2199]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1582,  0.6211,  0.5703,  ..., -0.6875,  0.2207,  0.3965]],\n",
      "\n",
      "        [[-0.5586,  0.6289,  0.0258,  ...,  1.0781, -0.0112,  0.2305]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2188],\n",
      "        [2187],\n",
      "        [2199],\n",
      "        [2199],\n",
      "        [2200],\n",
      "        [2195],\n",
      "        [2195],\n",
      "        [2189],\n",
      "        [2189],\n",
      "        [2198],\n",
      "        [2195],\n",
      "        [2199],\n",
      "        [2200],\n",
      "        [2195],\n",
      "        [2195],\n",
      "        [2197],\n",
      "        [2189],\n",
      "        [2198],\n",
      "        [2221],\n",
      "        [2197]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[-0.0635,  0.5742,  0.2656,  ...,  0.2559,  0.5664,  0.3359]],\n",
      "\n",
      "        [[-0.3691,  0.6445, -0.4688,  ...,  0.8594,  0.0074,  0.3008]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]],\n",
      "\n",
      "        [[-0.3633,  0.2471,  0.0297,  ...,  1.3750,  0.6289,  0.3398]],\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2190],\n",
      "        [2188],\n",
      "        [2200],\n",
      "        [2197],\n",
      "        [2200],\n",
      "        [2196],\n",
      "        [2197],\n",
      "        [2190],\n",
      "        [2188],\n",
      "        [2196],\n",
      "        [2195],\n",
      "        [2200],\n",
      "        [2199],\n",
      "        [2195],\n",
      "        [2197],\n",
      "        [2198],\n",
      "        [2190],\n",
      "        [2197],\n",
      "        [2218],\n",
      "        [2200]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]],\n",
      "\n",
      "        [[ 0.1035,  0.5508,  0.3379,  ..., -0.4746,  1.1875,  0.3223]],\n",
      "\n",
      "        [[-0.3691,  0.3398, -0.1118,  ..., -0.8789,  0.3320,  0.2598]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6484,  0.5586, -0.1787,  ...,  0.2969,  0.1846,  0.2891]],\n",
      "\n",
      "        [[-0.7930,  0.5234,  0.6484,  ...,  0.2812,  0.8398,  0.2559]],\n",
      "\n",
      "        [[-0.3691,  0.3398, -0.1118,  ..., -0.8789,  0.3320,  0.2598]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2190],\n",
      "        [2190],\n",
      "        [2201],\n",
      "        [2193],\n",
      "        [2197],\n",
      "        [2195],\n",
      "        [2197],\n",
      "        [2189],\n",
      "        [2190],\n",
      "        [2195],\n",
      "        [2198],\n",
      "        [2202],\n",
      "        [2198],\n",
      "        [2198],\n",
      "        [2196],\n",
      "        [2199],\n",
      "        [2189],\n",
      "        [2201],\n",
      "        [2217],\n",
      "        [2198]], device='cuda:0')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]],\n",
      "\n",
      "        [[-0.3125,  0.1543,  0.1260,  ..., -0.4805,  0.0493,  0.3359]],\n",
      "\n",
      "        [[ 0.0030,  0.2139,  0.1001,  ...,  0.4961,  0.6602,  0.2158]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0030,  0.2139,  0.1001,  ...,  0.4961,  0.6602,  0.2158]],\n",
      "\n",
      "        [[ 0.1553,  0.6367,  0.8477,  ..., -0.4824,  0.5625,  0.3691]],\n",
      "\n",
      "        [[-0.4844,  0.6875,  0.6992,  ...,  0.9805, -0.3594,  0.2910]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 248.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MASE[0.5]</th>\n",
       "      <th>mean_weighted_sum_quantile_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>4.990018</td>\n",
       "      <td>0.027283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MASE[0.5]  mean_weighted_sum_quantile_loss\n",
       "None   4.990018                         0.027283"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gluonts.dataset.repository import get_dataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.ev.metrics import MASE, MeanWeightedSumQuantileLoss\n",
    "from gluonts.itertools import batcher\n",
    "from gluonts.model.evaluation import evaluate_forecasts\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "from tqdm.auto import tqdm\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "# Load dataset\n",
    "batch_size = 32\n",
    "num_samples = 20\n",
    "df = pd.read_csv('/home/yogi/chronos-research/dataset/daily-all/TLKM.csv')\n",
    "\n",
    "# Ensure the date column is in datetime format and sort by date\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(by='timestamp')\n",
    "\n",
    "# Prepare ListDataset for GluonTS\n",
    "prediction_length = 64\n",
    "freq = \"D\"  # Daily frequency\n",
    "# dataset = ListDataset(\n",
    "#     [{\"start\": df['timestamp'].iloc[0], \"target\": df['close'].values}],  # Assuming 'close' is the target column\n",
    "#     freq=freq\n",
    "# )\n",
    "dataset = [\n",
    "    {\n",
    "        \"start\": pd.Period(df['timestamp'].iloc[0], freq=freq),\n",
    "        \"target\": df[\"close\"].values\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load Chronos\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"/home/yogi/chronos-research/chronos-forecasting/scripts/output/run-6/checkpoint-300000\",\n",
    "    device_map=\"cuda:0\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Split dataset for evaluation\n",
    "train_data, test_data = split(dataset, offset=-prediction_length)\n",
    "test_data = test_data.generate_instances(prediction_length)\n",
    "\n",
    "\n",
    "# Generate forecast samples\n",
    "forecast_samples = []\n",
    "for batch in tqdm(batcher(test_data.input, batch_size=32)):\n",
    "    context = [torch.tensor(entry[\"target\"]) for entry in batch]\n",
    "    forecast_samples.append(\n",
    "        pipeline.predict(\n",
    "            context,\n",
    "            prediction_length=prediction_length,\n",
    "            num_samples=num_samples,\n",
    "        ).numpy()\n",
    "    )\n",
    "forecast_samples = np.concatenate(forecast_samples)\n",
    "\n",
    "# Convert forecast samples into gluonts SampleForecast objects\n",
    "sample_forecasts = []\n",
    "for item, ts in zip(forecast_samples, test_data.input):\n",
    "    forecast_start_date = ts[\"start\"] + len(ts[\"target\"])\n",
    "    sample_forecasts.append(\n",
    "        SampleForecast(samples=item, start_date=forecast_start_date)\n",
    "    )\n",
    "\n",
    "# Evaluate\n",
    "metrics_df = evaluate_forecasts(\n",
    "    sample_forecasts,\n",
    "    test_data=test_data,\n",
    "    metrics=[\n",
    "        MASE(),\n",
    "        MeanWeightedSumQuantileLoss(np.arange(0.1, 1.0, 0.1)),\n",
    "    ],\n",
    ")\n",
    "\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c23da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token=  tensor([[2115, 2114, 2114, 2114, 2114, 2114, 2116, 2117, 2117, 2118, 2118, 2125,\n",
      "         2122, 2122, 2121, 2121, 2122, 2122, 2125, 2125, 2123, 2126, 2125, 2123,\n",
      "         2123, 2124, 2119, 2120, 2125, 2126, 2125, 2127, 2129, 2129, 2134, 2138,\n",
      "         2142, 2144, 2160, 2160, 2168, 2169, 2161, 2159, 2159, 2159, 2171, 2168,\n",
      "         2167, 2167, 2167, 2183, 2186, 2185, 2208, 2208, 2207, 2219, 2240, 2244,\n",
      "         2240, 2227, 2215, 2244, 2238, 2225, 2225, 2212, 2205, 2195, 2185, 2208,\n",
      "         2197, 2192, 2196, 2212, 2222, 2216, 2228, 2225, 2225, 2227, 2225, 2217,\n",
      "         2219, 2225, 2230, 2229, 2227, 2230, 2223, 2223, 2216, 2214, 2203, 2197,\n",
      "         2189, 2186, 2186, 2186, 2197, 2192, 2188, 2190, 2189, 2187, 2187, 2188,\n",
      "         2182, 2182, 2198, 2187, 2184, 2187, 2186, 2186, 2184, 2192, 2193, 2200,\n",
      "         2192, 2187, 2188, 2192, 2191, 2195, 2192, 2193, 2194, 2193, 2191, 2195,\n",
      "         2195, 2198, 2203, 2201, 2203, 2209, 2210, 2209, 2209, 2213, 2212, 2212,\n",
      "         2212, 2212, 2203, 2208, 2205, 2197, 2192, 2188, 2192, 2192, 2195, 2200,\n",
      "         2199, 2199, 2205, 2203, 2198, 2195, 2193, 2200, 2197, 2201, 2197, 2193,\n",
      "         2191, 2192, 2186, 2184, 2187, 2187, 2187, 2190, 2186, 2185, 2190, 2186,\n",
      "         2185, 2186, 2201, 2200, 2205, 2208, 2205, 2204, 2208, 2209, 2209, 2211,\n",
      "         2211, 2206, 2206, 2209, 2210, 2204, 2203, 2208, 2203, 2203, 2200, 2197,\n",
      "         2194, 2192, 2187, 2192, 2192, 2196, 2195, 2195, 2195, 2196, 2188, 2189,\n",
      "         2189, 2188, 2190, 2188, 2187, 2190, 2195, 2195, 2191, 2193, 2195, 2193,\n",
      "         2191, 2198, 2208, 2203, 2200, 2201, 2197, 2196, 2193, 2193, 2192, 2189,\n",
      "         2189, 2189, 2188, 2190, 2189, 2185, 2190, 2190, 2190, 2192, 2192, 2197,\n",
      "         2194, 2192, 2197, 2200, 2203, 2204, 2204, 2199, 2198, 2197, 2196, 2193,\n",
      "         2191, 2192, 2192, 2190, 2191, 2195, 2193, 2194, 2192, 2192, 2194, 2196,\n",
      "         2195, 2195, 2193, 2192, 2195, 2194, 2196, 2198, 2198, 2192, 2192, 2190,\n",
      "         2188, 2192, 2192, 2191, 2192, 2192, 2192, 2191, 2191, 2189, 2189, 2189,\n",
      "         2187, 2185, 2187, 2187, 2186, 2189, 2190, 2187, 2188, 2187, 2187, 2192,\n",
      "         2190, 2188, 2186, 2186, 2185, 2176, 2167, 2169, 2168, 2163, 2158, 2155,\n",
      "         2167, 2168, 2164, 2157, 2159, 2157, 2157, 2157, 2157, 2158, 2162, 2160,\n",
      "         2160, 2159, 2158, 2164, 2162, 2165, 2164, 2164, 2168, 2177, 2182, 2182,\n",
      "         2184, 2185, 2185, 2185, 2187, 2189, 2189, 2199, 2222, 2223, 2211, 2206,\n",
      "         2203, 2196, 2194, 2195, 2193, 2195, 2193, 2205, 2202, 2211, 2212, 2210,\n",
      "         2204, 2203, 2198, 2203, 2211, 2212, 2211, 2218, 2220, 2210, 2212, 2220,\n",
      "         2219, 2219, 2227, 2223, 2222, 2220, 2217, 2209, 2202, 2206, 2208, 2208,\n",
      "         2208, 2208, 2208, 2208, 2208, 2204, 2197, 2196, 2192, 2192, 2192, 2195,\n",
      "         2196, 2200, 2201, 2204, 2206, 2201, 2201, 2200, 2206, 2203, 2203, 2203,\n",
      "         2202, 2199, 2197, 2197, 2196, 2189, 2187, 2182, 2182, 2181, 2178, 2176,\n",
      "         2181, 2173, 2169, 2170, 2165, 2163, 2161, 2159, 2156, 2154, 2159, 2154,\n",
      "         2154, 2154, 2154, 2156, 2154, 2150, 2143, 2144, 2150, 2153, 2152, 2158,\n",
      "         2156, 2159, 2158, 2171, 2169, 2176, 2171, 2170, 2170, 2173, 2175, 2182,\n",
      "         2179, 2186, 2185, 2179, 2176, 2176, 2174, 2175, 2171, 2173, 2172, 2171,\n",
      "         2169, 2165, 2171, 2171, 2167, 2165, 2170, 2171, 2168, 2167, 2170, 2170,\n",
      "         2176, 2179, 2176, 2174, 2174, 2174, 2176, 2176, 2174, 2170, 2169, 2167,\n",
      "         2167, 2168, 2165, 2167, 2168, 2167, 2167, 2166,    1]],\n",
      "       device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.5273, -0.1924, -0.5625,  ...,  0.0967, -0.0103,  0.5000],\n",
      "         [ 0.7422,  0.3477, -0.5898,  ...,  0.2012, -0.6641,  0.6172],\n",
      "         [ 0.7422,  0.3477, -0.5898,  ...,  0.2012, -0.6641,  0.6172],\n",
      "         ...,\n",
      "         [ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082],\n",
      "         [ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039],\n",
      "         [ 0.3438, -0.4199,  0.0796,  ...,  4.2188, -1.4453, -3.1094]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([1, 513])\n",
      "testt2\n",
      "batch_size=  1\n",
      "seq_length=  513\n",
      "token=  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1406, -0.0349, -0.1060,  ..., -0.3535,  0.0947,  3.1719]],\n",
      "\n",
      "        [[ 0.1406, -0.0349, -0.1060,  ..., -0.3535,  0.0947,  3.1719]],\n",
      "\n",
      "        [[ 0.1406, -0.0349, -0.1060,  ..., -0.3535,  0.0947,  3.1719]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1406, -0.0349, -0.1060,  ..., -0.3535,  0.0947,  3.1719]],\n",
      "\n",
      "        [[ 0.1406, -0.0349, -0.1060,  ..., -0.3535,  0.0947,  3.1719]],\n",
      "\n",
      "        [[ 0.1406, -0.0349, -0.1060,  ..., -0.3535,  0.0947,  3.1719]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2166],\n",
      "        [2167],\n",
      "        [2166],\n",
      "        [2165],\n",
      "        [2166],\n",
      "        [2167],\n",
      "        [2166],\n",
      "        [2166],\n",
      "        [2162],\n",
      "        [2164],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2167],\n",
      "        [2168],\n",
      "        [2167],\n",
      "        [2164],\n",
      "        [2166],\n",
      "        [2164],\n",
      "        [2166],\n",
      "        [2166]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2168],\n",
      "        [2166],\n",
      "        [2168],\n",
      "        [2166],\n",
      "        [2167],\n",
      "        [2167],\n",
      "        [2168],\n",
      "        [2167],\n",
      "        [2163],\n",
      "        [2161],\n",
      "        [2164],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2167],\n",
      "        [2167],\n",
      "        [2162],\n",
      "        [2169],\n",
      "        [2162],\n",
      "        [2167],\n",
      "        [2168]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]],\n",
      "\n",
      "        [[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2165],\n",
      "        [2168],\n",
      "        [2164],\n",
      "        [2167],\n",
      "        [2164],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2167],\n",
      "        [2163],\n",
      "        [2163],\n",
      "        [2164],\n",
      "        [2164],\n",
      "        [2168],\n",
      "        [2164],\n",
      "        [2170],\n",
      "        [2163],\n",
      "        [2167],\n",
      "        [2164],\n",
      "        [2170],\n",
      "        [2167]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        [[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2162],\n",
      "        [2165],\n",
      "        [2159],\n",
      "        [2172],\n",
      "        [2160],\n",
      "        [2170],\n",
      "        [2162],\n",
      "        [2170],\n",
      "        [2158],\n",
      "        [2162],\n",
      "        [2167],\n",
      "        [2163],\n",
      "        [2166],\n",
      "        [2163],\n",
      "        [2166],\n",
      "        [2163],\n",
      "        [2169],\n",
      "        [2162],\n",
      "        [2167],\n",
      "        [2164]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2162],\n",
      "        [2163],\n",
      "        [2161],\n",
      "        [2170],\n",
      "        [2161],\n",
      "        [2167],\n",
      "        [2162],\n",
      "        [2169],\n",
      "        [2159],\n",
      "        [2160],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2163],\n",
      "        [2165],\n",
      "        [2169],\n",
      "        [2160],\n",
      "        [2170],\n",
      "        [2162],\n",
      "        [2169],\n",
      "        [2162]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        [[ 0.3770,  0.5352,  0.9219,  ...,  0.1572,  0.1484,  0.5547]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2159],\n",
      "        [2160],\n",
      "        [2168],\n",
      "        [2161],\n",
      "        [2165],\n",
      "        [2162],\n",
      "        [2167],\n",
      "        [2159],\n",
      "        [2159],\n",
      "        [2162],\n",
      "        [2165],\n",
      "        [2164],\n",
      "        [2163],\n",
      "        [2169],\n",
      "        [2160],\n",
      "        [2170],\n",
      "        [2159],\n",
      "        [2169],\n",
      "        [2162]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2161],\n",
      "        [2160],\n",
      "        [2158],\n",
      "        [2169],\n",
      "        [2158],\n",
      "        [2168],\n",
      "        [2161],\n",
      "        [2169],\n",
      "        [2159],\n",
      "        [2160],\n",
      "        [2162],\n",
      "        [2162],\n",
      "        [2166],\n",
      "        [2160],\n",
      "        [2170],\n",
      "        [2160],\n",
      "        [2170],\n",
      "        [2159],\n",
      "        [2169],\n",
      "        [2162]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3770,  0.5352,  0.9219,  ...,  0.1572,  0.1484,  0.5547]],\n",
      "\n",
      "        [[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        [[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2161],\n",
      "        [2160],\n",
      "        [2158],\n",
      "        [2168],\n",
      "        [2158],\n",
      "        [2167],\n",
      "        [2158],\n",
      "        [2168],\n",
      "        [2158],\n",
      "        [2160],\n",
      "        [2160],\n",
      "        [2161],\n",
      "        [2165],\n",
      "        [2161],\n",
      "        [2170],\n",
      "        [2159],\n",
      "        [2173],\n",
      "        [2161],\n",
      "        [2170],\n",
      "        [2160]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3770,  0.5352,  0.9219,  ...,  0.1572,  0.1484,  0.5547]],\n",
      "\n",
      "        [[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        [[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3770,  0.5352,  0.9219,  ...,  0.1572,  0.1484,  0.5547]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]],\n",
      "\n",
      "        [[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2161],\n",
      "        [2160],\n",
      "        [2159],\n",
      "        [2168],\n",
      "        [2158],\n",
      "        [2163],\n",
      "        [2161],\n",
      "        [2170],\n",
      "        [2158],\n",
      "        [2159],\n",
      "        [2162],\n",
      "        [2161],\n",
      "        [2161],\n",
      "        [2159],\n",
      "        [2167],\n",
      "        [2158],\n",
      "        [2171],\n",
      "        [2157],\n",
      "        [2170],\n",
      "        [2159]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3770,  0.5352,  0.9219,  ...,  0.1572,  0.1484,  0.5547]],\n",
      "\n",
      "        [[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2160],\n",
      "        [2159],\n",
      "        [2164],\n",
      "        [2158],\n",
      "        [2159],\n",
      "        [2161],\n",
      "        [2170],\n",
      "        [2158],\n",
      "        [2156],\n",
      "        [2161],\n",
      "        [2161],\n",
      "        [2161],\n",
      "        [2157],\n",
      "        [2169],\n",
      "        [2158],\n",
      "        [2166],\n",
      "        [2157],\n",
      "        [2170],\n",
      "        [2159]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2156],\n",
      "        [2160],\n",
      "        [2159],\n",
      "        [2162],\n",
      "        [2158],\n",
      "        [2159],\n",
      "        [2159],\n",
      "        [2165],\n",
      "        [2158],\n",
      "        [2156],\n",
      "        [2161],\n",
      "        [2161],\n",
      "        [2157],\n",
      "        [2157],\n",
      "        [2163],\n",
      "        [2158],\n",
      "        [2169],\n",
      "        [2157],\n",
      "        [2167],\n",
      "        [2157]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2156],\n",
      "        [2162],\n",
      "        [2159],\n",
      "        [2162],\n",
      "        [2160],\n",
      "        [2161],\n",
      "        [2159],\n",
      "        [2169],\n",
      "        [2158],\n",
      "        [2156],\n",
      "        [2158],\n",
      "        [2169],\n",
      "        [2157],\n",
      "        [2157],\n",
      "        [2164],\n",
      "        [2158],\n",
      "        [2169],\n",
      "        [2154],\n",
      "        [2169],\n",
      "        [2157]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2156],\n",
      "        [2162],\n",
      "        [2159],\n",
      "        [2163],\n",
      "        [2159],\n",
      "        [2158],\n",
      "        [2159],\n",
      "        [2169],\n",
      "        [2158],\n",
      "        [2154],\n",
      "        [2158],\n",
      "        [2167],\n",
      "        [2157],\n",
      "        [2157],\n",
      "        [2164],\n",
      "        [2158],\n",
      "        [2170],\n",
      "        [2156],\n",
      "        [2167],\n",
      "        [2157]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2155],\n",
      "        [2159],\n",
      "        [2163],\n",
      "        [2158],\n",
      "        [2155],\n",
      "        [2158],\n",
      "        [2159],\n",
      "        [2169],\n",
      "        [2162],\n",
      "        [2154],\n",
      "        [2157],\n",
      "        [2166],\n",
      "        [2157],\n",
      "        [2158],\n",
      "        [2159],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2154],\n",
      "        [2167],\n",
      "        [2157]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6758, -1.1484, -0.6055,  ..., -0.3867, -0.6367,  0.2852]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2156],\n",
      "        [2156],\n",
      "        [2167],\n",
      "        [2161],\n",
      "        [2155],\n",
      "        [2158],\n",
      "        [2159],\n",
      "        [2165],\n",
      "        [2161],\n",
      "        [2154],\n",
      "        [2157],\n",
      "        [2167],\n",
      "        [2159],\n",
      "        [2159],\n",
      "        [2162],\n",
      "        [2165],\n",
      "        [2160],\n",
      "        [2154],\n",
      "        [2164],\n",
      "        [2161]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        [[ 0.3770,  0.5352,  0.9219,  ...,  0.1572,  0.1484,  0.5547]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2161],\n",
      "        [2155],\n",
      "        [2165],\n",
      "        [2161],\n",
      "        [2152],\n",
      "        [2162],\n",
      "        [2167],\n",
      "        [2168],\n",
      "        [2156],\n",
      "        [2154],\n",
      "        [2157],\n",
      "        [2167],\n",
      "        [2159],\n",
      "        [2159],\n",
      "        [2159],\n",
      "        [2163],\n",
      "        [2160],\n",
      "        [2154],\n",
      "        [2159],\n",
      "        [2166]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3770,  0.5352,  0.9219,  ...,  0.1572,  0.1484,  0.5547]],\n",
      "\n",
      "        [[ 0.6758, -1.1484, -0.6055,  ..., -0.3867, -0.6367,  0.2852]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2162],\n",
      "        [2154],\n",
      "        [2164],\n",
      "        [2162],\n",
      "        [2152],\n",
      "        [2159],\n",
      "        [2165],\n",
      "        [2167],\n",
      "        [2156],\n",
      "        [2158],\n",
      "        [2156],\n",
      "        [2169],\n",
      "        [2158],\n",
      "        [2157],\n",
      "        [2159],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2154],\n",
      "        [2159],\n",
      "        [2165]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2156],\n",
      "        [2167],\n",
      "        [2164],\n",
      "        [2154],\n",
      "        [2157],\n",
      "        [2164],\n",
      "        [2167],\n",
      "        [2155],\n",
      "        [2157],\n",
      "        [2160],\n",
      "        [2168],\n",
      "        [2158],\n",
      "        [2156],\n",
      "        [2167],\n",
      "        [2167],\n",
      "        [2164],\n",
      "        [2159],\n",
      "        [2164],\n",
      "        [2163]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        [[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2157],\n",
      "        [2167],\n",
      "        [2167],\n",
      "        [2154],\n",
      "        [2157],\n",
      "        [2165],\n",
      "        [2168],\n",
      "        [2155],\n",
      "        [2160],\n",
      "        [2157],\n",
      "        [2165],\n",
      "        [2158],\n",
      "        [2156],\n",
      "        [2165],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2159],\n",
      "        [2160],\n",
      "        [2165]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2156],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2157],\n",
      "        [2156],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2152],\n",
      "        [2159],\n",
      "        [2157],\n",
      "        [2165],\n",
      "        [2158],\n",
      "        [2155],\n",
      "        [2166],\n",
      "        [2166],\n",
      "        [2167],\n",
      "        [2157],\n",
      "        [2163],\n",
      "        [2165]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2157],\n",
      "        [2165],\n",
      "        [2164],\n",
      "        [2156],\n",
      "        [2156],\n",
      "        [2165],\n",
      "        [2167],\n",
      "        [2151],\n",
      "        [2159],\n",
      "        [2157],\n",
      "        [2165],\n",
      "        [2158],\n",
      "        [2154],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2167],\n",
      "        [2157],\n",
      "        [2163],\n",
      "        [2164]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2160],\n",
      "        [2157],\n",
      "        [2164],\n",
      "        [2165],\n",
      "        [2155],\n",
      "        [2154],\n",
      "        [2164],\n",
      "        [2167],\n",
      "        [2152],\n",
      "        [2159],\n",
      "        [2157],\n",
      "        [2167],\n",
      "        [2156],\n",
      "        [2155],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2159],\n",
      "        [2166],\n",
      "        [2163]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]],\n",
      "\n",
      "        [[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2157],\n",
      "        [2164],\n",
      "        [2165],\n",
      "        [2156],\n",
      "        [2157],\n",
      "        [2164],\n",
      "        [2165],\n",
      "        [2151],\n",
      "        [2157],\n",
      "        [2157],\n",
      "        [2165],\n",
      "        [2153],\n",
      "        [2154],\n",
      "        [2168],\n",
      "        [2165],\n",
      "        [2166],\n",
      "        [2159],\n",
      "        [2165],\n",
      "        [2162]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2157],\n",
      "        [2165],\n",
      "        [2164],\n",
      "        [2156],\n",
      "        [2156],\n",
      "        [2161],\n",
      "        [2165],\n",
      "        [2151],\n",
      "        [2157],\n",
      "        [2157],\n",
      "        [2167],\n",
      "        [2153],\n",
      "        [2155],\n",
      "        [2167],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2158],\n",
      "        [2164],\n",
      "        [2162]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2157],\n",
      "        [2167],\n",
      "        [2164],\n",
      "        [2155],\n",
      "        [2156],\n",
      "        [2161],\n",
      "        [2165],\n",
      "        [2151],\n",
      "        [2155],\n",
      "        [2155],\n",
      "        [2164],\n",
      "        [2154],\n",
      "        [2154],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2157],\n",
      "        [2164],\n",
      "        [2161]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        [[ 0.3770,  0.5352,  0.9219,  ...,  0.1572,  0.1484,  0.5547]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2156],\n",
      "        [2165],\n",
      "        [2162],\n",
      "        [2154],\n",
      "        [2157],\n",
      "        [2162],\n",
      "        [2162],\n",
      "        [2151],\n",
      "        [2155],\n",
      "        [2154],\n",
      "        [2167],\n",
      "        [2153],\n",
      "        [2154],\n",
      "        [2164],\n",
      "        [2168],\n",
      "        [2164],\n",
      "        [2154],\n",
      "        [2164],\n",
      "        [2162]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2153],\n",
      "        [2162],\n",
      "        [2162],\n",
      "        [2152],\n",
      "        [2157],\n",
      "        [2161],\n",
      "        [2163],\n",
      "        [2151],\n",
      "        [2155],\n",
      "        [2154],\n",
      "        [2167],\n",
      "        [2154],\n",
      "        [2154],\n",
      "        [2164],\n",
      "        [2167],\n",
      "        [2164],\n",
      "        [2154],\n",
      "        [2163],\n",
      "        [2162]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 1.3906, -1.4297,  0.6602,  ...,  0.1836,  0.8008,  0.6133]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2164],\n",
      "        [2153],\n",
      "        [2167],\n",
      "        [2162],\n",
      "        [2151],\n",
      "        [2157],\n",
      "        [2163],\n",
      "        [2162],\n",
      "        [2150],\n",
      "        [2157],\n",
      "        [2154],\n",
      "        [2170],\n",
      "        [2158],\n",
      "        [2153],\n",
      "        [2160],\n",
      "        [2169],\n",
      "        [2164],\n",
      "        [2155],\n",
      "        [2163],\n",
      "        [2162]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        [[ 1.3906, -1.4297,  0.6602,  ...,  0.1836,  0.8008,  0.6133]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6758, -1.1484, -0.6055,  ..., -0.3867, -0.6367,  0.2852]],\n",
      "\n",
      "        [[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2160],\n",
      "        [2150],\n",
      "        [2167],\n",
      "        [2159],\n",
      "        [2151],\n",
      "        [2157],\n",
      "        [2162],\n",
      "        [2159],\n",
      "        [2150],\n",
      "        [2160],\n",
      "        [2151],\n",
      "        [2170],\n",
      "        [2159],\n",
      "        [2151],\n",
      "        [2162],\n",
      "        [2170],\n",
      "        [2165],\n",
      "        [2154],\n",
      "        [2162],\n",
      "        [2162]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        [[ 0.0069,  0.3984, -0.3691,  ..., -0.5391,  0.7188,  0.3086]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2160],\n",
      "        [2151],\n",
      "        [2169],\n",
      "        [2160],\n",
      "        [2151],\n",
      "        [2154],\n",
      "        [2163],\n",
      "        [2159],\n",
      "        [2150],\n",
      "        [2159],\n",
      "        [2152],\n",
      "        [2168],\n",
      "        [2159],\n",
      "        [2151],\n",
      "        [2161],\n",
      "        [2168],\n",
      "        [2166],\n",
      "        [2151],\n",
      "        [2162],\n",
      "        [2167]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        [[-0.0679,  0.1396,  0.5703,  ..., -0.3340, -0.1689,  0.5586]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0679,  0.1396,  0.5703,  ..., -0.3340, -0.1689,  0.5586]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2161],\n",
      "        [2152],\n",
      "        [2171],\n",
      "        [2160],\n",
      "        [2157],\n",
      "        [2154],\n",
      "        [2166],\n",
      "        [2161],\n",
      "        [2150],\n",
      "        [2159],\n",
      "        [2157],\n",
      "        [2171],\n",
      "        [2159],\n",
      "        [2151],\n",
      "        [2161],\n",
      "        [2171],\n",
      "        [2164],\n",
      "        [2151],\n",
      "        [2162],\n",
      "        [2166]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3770,  0.5352,  0.9219,  ...,  0.1572,  0.1484,  0.5547]],\n",
      "\n",
      "        [[ 0.7109, -0.4336,  0.3555,  ..., -0.1396, -0.4961,  0.5781]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0679,  0.1396,  0.5703,  ..., -0.3340, -0.1689,  0.5586]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2157],\n",
      "        [2171],\n",
      "        [2160],\n",
      "        [2157],\n",
      "        [2154],\n",
      "        [2166],\n",
      "        [2161],\n",
      "        [2150],\n",
      "        [2162],\n",
      "        [2154],\n",
      "        [2171],\n",
      "        [2160],\n",
      "        [2150],\n",
      "        [2159],\n",
      "        [2169],\n",
      "        [2160],\n",
      "        [2151],\n",
      "        [2162],\n",
      "        [2170]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0679,  0.1396,  0.5703,  ..., -0.3340, -0.1689,  0.5586]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2157],\n",
      "        [2171],\n",
      "        [2159],\n",
      "        [2158],\n",
      "        [2154],\n",
      "        [2168],\n",
      "        [2159],\n",
      "        [2149],\n",
      "        [2162],\n",
      "        [2156],\n",
      "        [2171],\n",
      "        [2159],\n",
      "        [2150],\n",
      "        [2159],\n",
      "        [2171],\n",
      "        [2161],\n",
      "        [2150],\n",
      "        [2162],\n",
      "        [2170]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0069,  0.3984, -0.3691,  ..., -0.5391,  0.7188,  0.3086]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2167],\n",
      "        [2159],\n",
      "        [2171],\n",
      "        [2159],\n",
      "        [2159],\n",
      "        [2158],\n",
      "        [2168],\n",
      "        [2159],\n",
      "        [2144],\n",
      "        [2165],\n",
      "        [2159],\n",
      "        [2171],\n",
      "        [2164],\n",
      "        [2150],\n",
      "        [2159],\n",
      "        [2171],\n",
      "        [2161],\n",
      "        [2150],\n",
      "        [2158],\n",
      "        [2171]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0069,  0.3984, -0.3691,  ..., -0.5391,  0.7188,  0.3086]],\n",
      "\n",
      "        [[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2170],\n",
      "        [2159],\n",
      "        [2170],\n",
      "        [2163],\n",
      "        [2159],\n",
      "        [2160],\n",
      "        [2171],\n",
      "        [2159],\n",
      "        [2144],\n",
      "        [2168],\n",
      "        [2159],\n",
      "        [2167],\n",
      "        [2161],\n",
      "        [2140],\n",
      "        [2155],\n",
      "        [2168],\n",
      "        [2162],\n",
      "        [2150],\n",
      "        [2154],\n",
      "        [2170]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0069,  0.3984, -0.3691,  ..., -0.5391,  0.7188,  0.3086]],\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2169],\n",
      "        [2159],\n",
      "        [2171],\n",
      "        [2164],\n",
      "        [2159],\n",
      "        [2159],\n",
      "        [2171],\n",
      "        [2159],\n",
      "        [2144],\n",
      "        [2165],\n",
      "        [2159],\n",
      "        [2168],\n",
      "        [2161],\n",
      "        [2134],\n",
      "        [2155],\n",
      "        [2171],\n",
      "        [2162],\n",
      "        [2150],\n",
      "        [2154],\n",
      "        [2170]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0069,  0.3984, -0.3691,  ..., -0.5391,  0.7188,  0.3086]],\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2169],\n",
      "        [2159],\n",
      "        [2167],\n",
      "        [2166],\n",
      "        [2158],\n",
      "        [2159],\n",
      "        [2170],\n",
      "        [2159],\n",
      "        [2143],\n",
      "        [2162],\n",
      "        [2159],\n",
      "        [2167],\n",
      "        [2162],\n",
      "        [2138],\n",
      "        [2155],\n",
      "        [2168],\n",
      "        [2159],\n",
      "        [2150],\n",
      "        [2154],\n",
      "        [2173]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0069,  0.3984, -0.3691,  ..., -0.5391,  0.7188,  0.3086]],\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 0.9492,  0.8125,  1.0625,  ...,  0.3691,  0.6797,  0.5273]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2169],\n",
      "        [2157],\n",
      "        [2170],\n",
      "        [2167],\n",
      "        [2154],\n",
      "        [2159],\n",
      "        [2170],\n",
      "        [2159],\n",
      "        [2141],\n",
      "        [2164],\n",
      "        [2162],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2138],\n",
      "        [2155],\n",
      "        [2169],\n",
      "        [2159],\n",
      "        [2146],\n",
      "        [2154],\n",
      "        [2170]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4668,  0.4883, -1.2188,  ..., -0.6562,  0.7344,  0.5234]],\n",
      "\n",
      "        [[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2170],\n",
      "        [2157],\n",
      "        [2169],\n",
      "        [2170],\n",
      "        [2154],\n",
      "        [2159],\n",
      "        [2169],\n",
      "        [2154],\n",
      "        [2141],\n",
      "        [2164],\n",
      "        [2166],\n",
      "        [2162],\n",
      "        [2165],\n",
      "        [2138],\n",
      "        [2157],\n",
      "        [2165],\n",
      "        [2160],\n",
      "        [2140],\n",
      "        [2158],\n",
      "        [2171]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]],\n",
      "\n",
      "        [[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2168],\n",
      "        [2155],\n",
      "        [2166],\n",
      "        [2170],\n",
      "        [2154],\n",
      "        [2159],\n",
      "        [2171],\n",
      "        [2154],\n",
      "        [2141],\n",
      "        [2164],\n",
      "        [2164],\n",
      "        [2165],\n",
      "        [2163],\n",
      "        [2140],\n",
      "        [2157],\n",
      "        [2165],\n",
      "        [2159],\n",
      "        [2142],\n",
      "        [2159],\n",
      "        [2168]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        [[ 0.6758, -1.1484, -0.6055,  ..., -0.3867, -0.6367,  0.2852]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8047,  0.7031,  0.6133,  ...,  0.5234, -0.3906,  0.2734]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2171],\n",
      "        [2155],\n",
      "        [2170],\n",
      "        [2170],\n",
      "        [2154],\n",
      "        [2163],\n",
      "        [2169],\n",
      "        [2155],\n",
      "        [2141],\n",
      "        [2169],\n",
      "        [2163],\n",
      "        [2165],\n",
      "        [2163],\n",
      "        [2139],\n",
      "        [2157],\n",
      "        [2167],\n",
      "        [2163],\n",
      "        [2142],\n",
      "        [2158],\n",
      "        [2168]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]],\n",
      "\n",
      "        [[ 0.6758, -1.1484, -0.6055,  ..., -0.3867, -0.6367,  0.2852]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8047,  0.7031,  0.6133,  ...,  0.5234, -0.3906,  0.2734]],\n",
      "\n",
      "        [[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2168],\n",
      "        [2156],\n",
      "        [2168],\n",
      "        [2170],\n",
      "        [2156],\n",
      "        [2164],\n",
      "        [2165],\n",
      "        [2154],\n",
      "        [2144],\n",
      "        [2165],\n",
      "        [2164],\n",
      "        [2160],\n",
      "        [2162],\n",
      "        [2140],\n",
      "        [2157],\n",
      "        [2165],\n",
      "        [2163],\n",
      "        [2142],\n",
      "        [2158],\n",
      "        [2169]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        [[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8047,  0.7031,  0.6133,  ...,  0.5234, -0.3906,  0.2734]],\n",
      "\n",
      "        [[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2165],\n",
      "        [2155],\n",
      "        [2169],\n",
      "        [2170],\n",
      "        [2159],\n",
      "        [2163],\n",
      "        [2165],\n",
      "        [2154],\n",
      "        [2142],\n",
      "        [2166],\n",
      "        [2165],\n",
      "        [2161],\n",
      "        [2162],\n",
      "        [2139],\n",
      "        [2156],\n",
      "        [2166],\n",
      "        [2164],\n",
      "        [2140],\n",
      "        [2158],\n",
      "        [2169]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        [[ 0.6758, -1.1484, -0.6055,  ..., -0.3867, -0.6367,  0.2852]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2167],\n",
      "        [2161],\n",
      "        [2170],\n",
      "        [2167],\n",
      "        [2164],\n",
      "        [2163],\n",
      "        [2167],\n",
      "        [2158],\n",
      "        [2143],\n",
      "        [2169],\n",
      "        [2164],\n",
      "        [2162],\n",
      "        [2161],\n",
      "        [2139],\n",
      "        [2156],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2141],\n",
      "        [2158],\n",
      "        [2165]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.3770,  0.5352,  0.9219,  ...,  0.1572,  0.1484,  0.5547]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7812,  0.7695,  0.2217,  ...,  0.3906, -0.5039,  0.4551]],\n",
      "\n",
      "        [[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2167],\n",
      "        [2166],\n",
      "        [2165],\n",
      "        [2168],\n",
      "        [2164],\n",
      "        [2163],\n",
      "        [2166],\n",
      "        [2157],\n",
      "        [2143],\n",
      "        [2167],\n",
      "        [2169],\n",
      "        [2162],\n",
      "        [2169],\n",
      "        [2142],\n",
      "        [2156],\n",
      "        [2167],\n",
      "        [2164],\n",
      "        [2142],\n",
      "        [2156],\n",
      "        [2166]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8047,  0.7031,  0.6133,  ...,  0.5234, -0.3906,  0.2734]],\n",
      "\n",
      "        [[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2169],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2168],\n",
      "        [2165],\n",
      "        [2170],\n",
      "        [2156],\n",
      "        [2143],\n",
      "        [2170],\n",
      "        [2166],\n",
      "        [2163],\n",
      "        [2168],\n",
      "        [2140],\n",
      "        [2155],\n",
      "        [2170],\n",
      "        [2164],\n",
      "        [2140],\n",
      "        [2156],\n",
      "        [2167]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2168],\n",
      "        [2169],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2168],\n",
      "        [2163],\n",
      "        [2170],\n",
      "        [2157],\n",
      "        [2143],\n",
      "        [2169],\n",
      "        [2165],\n",
      "        [2163],\n",
      "        [2168],\n",
      "        [2140],\n",
      "        [2154],\n",
      "        [2171],\n",
      "        [2163],\n",
      "        [2140],\n",
      "        [2155],\n",
      "        [2167]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.6758, -1.1484, -0.6055,  ..., -0.3867, -0.6367,  0.2852]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2168],\n",
      "        [2169],\n",
      "        [2165],\n",
      "        [2167],\n",
      "        [2169],\n",
      "        [2169],\n",
      "        [2171],\n",
      "        [2156],\n",
      "        [2141],\n",
      "        [2168],\n",
      "        [2167],\n",
      "        [2162],\n",
      "        [2169],\n",
      "        [2139],\n",
      "        [2151],\n",
      "        [2171],\n",
      "        [2162],\n",
      "        [2140],\n",
      "        [2153],\n",
      "        [2170]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 1.3906, -1.4297,  0.6602,  ...,  0.1836,  0.8008,  0.6133]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2168],\n",
      "        [2169],\n",
      "        [2164],\n",
      "        [2166],\n",
      "        [2168],\n",
      "        [2166],\n",
      "        [2172],\n",
      "        [2156],\n",
      "        [2140],\n",
      "        [2168],\n",
      "        [2166],\n",
      "        [2162],\n",
      "        [2169],\n",
      "        [2139],\n",
      "        [2151],\n",
      "        [2171],\n",
      "        [2162],\n",
      "        [2139],\n",
      "        [2151],\n",
      "        [2170]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8203,  0.6641, -0.9141,  ..., -0.9727, -0.4238,  0.5586]],\n",
      "\n",
      "        [[-0.0679,  0.1396,  0.5703,  ..., -0.3340, -0.1689,  0.5586]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2168],\n",
      "        [2168],\n",
      "        [2166],\n",
      "        [2169],\n",
      "        [2168],\n",
      "        [2167],\n",
      "        [2170],\n",
      "        [2155],\n",
      "        [2141],\n",
      "        [2168],\n",
      "        [2169],\n",
      "        [2161],\n",
      "        [2168],\n",
      "        [2139],\n",
      "        [2149],\n",
      "        [2171],\n",
      "        [2162],\n",
      "        [2139],\n",
      "        [2150],\n",
      "        [2171]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        [[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8203,  0.6641, -0.9141,  ..., -0.9727, -0.4238,  0.5586]],\n",
      "\n",
      "        [[ 0.0069,  0.3984, -0.3691,  ..., -0.5391,  0.7188,  0.3086]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2167],\n",
      "        [2169],\n",
      "        [2167],\n",
      "        [2170],\n",
      "        [2166],\n",
      "        [2167],\n",
      "        [2170],\n",
      "        [2154],\n",
      "        [2141],\n",
      "        [2168],\n",
      "        [2167],\n",
      "        [2160],\n",
      "        [2168],\n",
      "        [2143],\n",
      "        [2150],\n",
      "        [2170],\n",
      "        [2161],\n",
      "        [2139],\n",
      "        [2150],\n",
      "        [2171]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8203,  0.6641, -0.9141,  ..., -0.9727, -0.4238,  0.5586]],\n",
      "\n",
      "        [[ 0.0069,  0.3984, -0.3691,  ..., -0.5391,  0.7188,  0.3086]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2167],\n",
      "        [2167],\n",
      "        [2167],\n",
      "        [2171],\n",
      "        [2166],\n",
      "        [2169],\n",
      "        [2168],\n",
      "        [2152],\n",
      "        [2141],\n",
      "        [2167],\n",
      "        [2165],\n",
      "        [2160],\n",
      "        [2165],\n",
      "        [2141],\n",
      "        [2150],\n",
      "        [2176],\n",
      "        [2161],\n",
      "        [2137],\n",
      "        [2149],\n",
      "        [2170]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2832,  0.7773, -0.8242,  ..., -0.3262,  0.0757,  0.4023]],\n",
      "\n",
      "        [[ 0.3164,  0.9102, -0.7266,  ..., -0.5625,  0.2344,  0.4648]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2163],\n",
      "        [2167],\n",
      "        [2167],\n",
      "        [2169],\n",
      "        [2167],\n",
      "        [2168],\n",
      "        [2169],\n",
      "        [2151],\n",
      "        [2139],\n",
      "        [2168],\n",
      "        [2165],\n",
      "        [2159],\n",
      "        [2165],\n",
      "        [2139],\n",
      "        [2150],\n",
      "        [2173],\n",
      "        [2161],\n",
      "        [2137],\n",
      "        [2149],\n",
      "        [2170]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2832,  0.7773, -0.8242,  ..., -0.3262,  0.0757,  0.4023]],\n",
      "\n",
      "        [[ 0.3164,  0.9102, -0.7266,  ..., -0.5625,  0.2344,  0.4648]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2165],\n",
      "        [2167],\n",
      "        [2170],\n",
      "        [2168],\n",
      "        [2165],\n",
      "        [2169],\n",
      "        [2151],\n",
      "        [2139],\n",
      "        [2164],\n",
      "        [2165],\n",
      "        [2159],\n",
      "        [2166],\n",
      "        [2139],\n",
      "        [2150],\n",
      "        [2170],\n",
      "        [2161],\n",
      "        [2138],\n",
      "        [2144],\n",
      "        [2170]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1641,  0.7070, -1.0078,  ..., -0.7695, -0.1543,  0.4922]],\n",
      "\n",
      "        [[ 0.4258,  0.8750,  0.6172,  ..., -0.5156,  0.1602,  0.4473]],\n",
      "\n",
      "        [[ 0.8945,  0.5000,  0.4609,  ..., -0.8164,  0.7148,  0.4238]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2160],\n",
      "        [2168],\n",
      "        [2164],\n",
      "        [2169],\n",
      "        [2168],\n",
      "        [2165],\n",
      "        [2170],\n",
      "        [2150],\n",
      "        [2137],\n",
      "        [2167],\n",
      "        [2168],\n",
      "        [2159],\n",
      "        [2167],\n",
      "        [2139],\n",
      "        [2150],\n",
      "        [2172],\n",
      "        [2159],\n",
      "        [2141],\n",
      "        [2144],\n",
      "        [2176]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.5195,  0.8281,  0.2676,  ...,  0.9844,  0.2910,  0.6172]],\n",
      "\n",
      "        [[-0.0762, -1.2656, -0.6133,  ..., -0.6094,  0.1973,  0.3770]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7812,  0.7695,  0.2217,  ...,  0.3906, -0.5039,  0.4551]],\n",
      "\n",
      "        [[ 0.4258,  0.8750,  0.6172,  ..., -0.5156,  0.1602,  0.4473]],\n",
      "\n",
      "        [[ 0.9531,  0.5625,  1.0234,  ..., -0.4863,  1.1562,  0.4043]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2159],\n",
      "        [2167],\n",
      "        [2164],\n",
      "        [2169],\n",
      "        [2167],\n",
      "        [2167],\n",
      "        [2168],\n",
      "        [2150],\n",
      "        [2137],\n",
      "        [2167],\n",
      "        [2167],\n",
      "        [2158],\n",
      "        [2169],\n",
      "        [2139],\n",
      "        [2150],\n",
      "        [2171],\n",
      "        [2159],\n",
      "        [2141],\n",
      "        [2144],\n",
      "        [2173]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7812,  0.7695,  0.2217,  ...,  0.3906, -0.5039,  0.4551]],\n",
      "\n",
      "        [[ 0.4258,  0.8750,  0.6172,  ..., -0.5156,  0.1602,  0.4473]],\n",
      "\n",
      "        [[ 0.9492,  0.8125,  1.0625,  ...,  0.3691,  0.6797,  0.5273]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2169],\n",
      "        [2162],\n",
      "        [2168],\n",
      "        [2166],\n",
      "        [2167],\n",
      "        [2168],\n",
      "        [2145],\n",
      "        [2139],\n",
      "        [2170],\n",
      "        [2168],\n",
      "        [2158],\n",
      "        [2169],\n",
      "        [2138],\n",
      "        [2148],\n",
      "        [2173],\n",
      "        [2159],\n",
      "        [2140],\n",
      "        [2141],\n",
      "        [2171]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]],\n",
      "\n",
      "        [[ 0.4141, -0.7344,  0.4570,  ...,  0.6602,  0.3887,  0.5508]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.7812,  0.7695,  0.2217,  ...,  0.3906, -0.5039,  0.4551]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2158],\n",
      "        [2167],\n",
      "        [2159],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2169],\n",
      "        [2167],\n",
      "        [2140],\n",
      "        [2143],\n",
      "        [2170],\n",
      "        [2168],\n",
      "        [2154],\n",
      "        [2170],\n",
      "        [2142],\n",
      "        [2144],\n",
      "        [2172],\n",
      "        [2163],\n",
      "        [2140],\n",
      "        [2141],\n",
      "        [2172]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7070,  0.1387,  0.0330,  ...,  0.6016, -0.1289,  0.3789]],\n",
      "\n",
      "        [[ 0.0574, -1.3359, -0.7109,  ..., -0.8203,  0.8555,  0.4082]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.7812,  0.7695,  0.2217,  ...,  0.3906, -0.5039,  0.4551]],\n",
      "\n",
      "        [[ 0.8789,  0.7930,  1.2734,  ...,  1.0234,  0.7148,  0.5156]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2157],\n",
      "        [2166],\n",
      "        [2159],\n",
      "        [2165],\n",
      "        [2165],\n",
      "        [2169],\n",
      "        [2165],\n",
      "        [2141],\n",
      "        [2142],\n",
      "        [2168],\n",
      "        [2165],\n",
      "        [2153],\n",
      "        [2167],\n",
      "        [2143],\n",
      "        [2143],\n",
      "        [2170],\n",
      "        [2163],\n",
      "        [2140],\n",
      "        [2142],\n",
      "        [2171]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.4258, -0.1348, -0.7188,  ..., -0.7148,  0.2715,  0.5508]],\n",
      "\n",
      "        [[ 0.3125, -0.9727, -0.4590,  ...,  1.0078,  1.3125,  0.5039]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.8047,  0.7031,  0.6133,  ...,  0.5234, -0.3906,  0.2734]],\n",
      "\n",
      "        [[ 0.5859,  0.7695,  1.4141,  ...,  0.3145,  0.1021,  0.3926]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2156],\n",
      "        [2165],\n",
      "        [2159],\n",
      "        [2165],\n",
      "        [2168],\n",
      "        [2166],\n",
      "        [2164],\n",
      "        [2140],\n",
      "        [2142],\n",
      "        [2170],\n",
      "        [2167],\n",
      "        [2150],\n",
      "        [2169],\n",
      "        [2140],\n",
      "        [2144],\n",
      "        [2170],\n",
      "        [2162],\n",
      "        [2138],\n",
      "        [2140],\n",
      "        [2173]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1641,  0.7070, -1.0078,  ..., -0.7695, -0.1543,  0.4922]],\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.9492,  0.8125,  1.0625,  ...,  0.3691,  0.6797,  0.5273]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2156],\n",
      "        [2163],\n",
      "        [2159],\n",
      "        [2162],\n",
      "        [2163],\n",
      "        [2168],\n",
      "        [2163],\n",
      "        [2140],\n",
      "        [2143],\n",
      "        [2169],\n",
      "        [2165],\n",
      "        [2153],\n",
      "        [2167],\n",
      "        [2139],\n",
      "        [2144],\n",
      "        [2170],\n",
      "        [2163],\n",
      "        [2134],\n",
      "        [2140],\n",
      "        [2172]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6797, -0.2256, -0.4609,  ..., -0.9141, -0.1582,  0.4199]],\n",
      "\n",
      "        [[ 0.6133, -0.9805,  0.9570,  ..., -0.4121, -0.1514,  0.3906]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2910,  0.6406,  1.1016,  ..., -0.7852, -0.6055,  0.2891]],\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.8789,  0.7930,  1.2734,  ...,  1.0234,  0.7148,  0.5156]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2154],\n",
      "        [2164],\n",
      "        [2159],\n",
      "        [2159],\n",
      "        [2163],\n",
      "        [2167],\n",
      "        [2161],\n",
      "        [2142],\n",
      "        [2143],\n",
      "        [2169],\n",
      "        [2158],\n",
      "        [2151],\n",
      "        [2165],\n",
      "        [2139],\n",
      "        [2142],\n",
      "        [2171],\n",
      "        [2165],\n",
      "        [2132],\n",
      "        [2140],\n",
      "        [2169]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 1.1719, -1.5469, -0.2480,  ..., -0.4980,  1.1797,  0.4395]],\n",
      "\n",
      "        [[ 1.1016, -1.7344, -0.0933,  ..., -0.1914, -0.6680,  0.5156]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5039,  0.9609,  0.3008,  ...,  0.6016, -0.5742,  0.2246]],\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token=  tensor([[2153],\n",
      "        [2165],\n",
      "        [2159],\n",
      "        [2159],\n",
      "        [2167],\n",
      "        [2168],\n",
      "        [2160],\n",
      "        [2141],\n",
      "        [2143],\n",
      "        [2169],\n",
      "        [2160],\n",
      "        [2151],\n",
      "        [2165],\n",
      "        [2137],\n",
      "        [2142],\n",
      "        [2169],\n",
      "        [2165],\n",
      "        [2136],\n",
      "        [2140],\n",
      "        [2169]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 1.3906, -1.4297,  0.6602,  ...,  0.1836,  0.8008,  0.6133]],\n",
      "\n",
      "        [[ 0.4980, -0.7891, -0.0320,  ..., -0.2070,  0.1523,  0.5547]],\n",
      "\n",
      "        [[ 0.1357,  0.7500, -0.0928,  ...,  1.4453, -0.3301,  0.4160]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2871,  0.7617, -0.3848,  ...,  0.3164, -0.8594,  0.5391]],\n",
      "\n",
      "        [[ 0.8672,  0.6367, -0.8281,  ...,  0.2812, -0.8516,  0.5547]],\n",
      "\n",
      "        [[ 0.4453,  0.1533, -0.6133,  ..., -0.9219,  0.3730,  0.5078]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 244.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MASE[0.5]</th>\n",
       "      <th>mean_weighted_sum_quantile_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>4.910444</td>\n",
       "      <td>0.048781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MASE[0.5]  mean_weighted_sum_quantile_loss\n",
       "None   4.910444                         0.048781"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gluonts.dataset.repository import get_dataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.ev.metrics import MASE, MeanWeightedSumQuantileLoss\n",
    "from gluonts.itertools import batcher\n",
    "from gluonts.model.evaluation import evaluate_forecasts\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "from tqdm.auto import tqdm\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "# Load dataset\n",
    "batch_size = 32\n",
    "num_samples = 20\n",
    "df = pd.read_csv('/home/yogi/chronos-research/dataset/daily-all/ANTM.csv')\n",
    "\n",
    "# Hitung jumlah total baris\n",
    "# total_rows = len(df)\n",
    "\n",
    "# Hitung jumlah baris yang mencakup 30% terakhir\n",
    "# rows_to_take = int(0.3 * total_rows)\n",
    "\n",
    "# # Ambil 30% baris terakhir\n",
    "# df = df.tail(rows_to_take)\n",
    "\n",
    "# # Hitung 70% dari total baris\n",
    "# rows_to_take = int(0.7 * total_rows)\n",
    "\n",
    "# # Ambil 70% pertama dari data\n",
    "# df = df.head(rows_to_take)\n",
    "\n",
    "# Ensure the date column is in datetime format and sort by date\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(by='timestamp')\n",
    "\n",
    "# Prepare ListDataset for GluonTS\n",
    "prediction_length = 64\n",
    "freq = \"D\"  # Daily frequency\n",
    "# dataset = ListDataset(\n",
    "#     [{\"start\": df['timestamp'].iloc[0], \"target\": df['close'].values}],  # Assuming 'close' is the target column\n",
    "#     freq=freq\n",
    "# )\n",
    "dataset = [\n",
    "    {\n",
    "        \"start\": pd.Period(df['timestamp'].iloc[0], freq=freq),\n",
    "        \"target\": df[\"close\"].values\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load Chronos\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"/home/yogi/chronos-research/chronos-forecasting/scripts/output/run-4/checkpoint-100000\",\n",
    "    device_map=\"cuda:1\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Split dataset for evaluation\n",
    "train_data, test_data = split(dataset, offset=-prediction_length)\n",
    "test_data = test_data.generate_instances(prediction_length)\n",
    "\n",
    "\n",
    "# Generate forecast samples\n",
    "forecast_samples = []\n",
    "for batch in tqdm(batcher(test_data.input, batch_size=32)):\n",
    "    context = [torch.tensor(entry[\"target\"]) for entry in batch]\n",
    "    forecast_samples.append(\n",
    "        pipeline.predict(\n",
    "            context,\n",
    "            prediction_length=prediction_length,\n",
    "            num_samples=num_samples,\n",
    "        ).numpy()\n",
    "    )\n",
    "forecast_samples = np.concatenate(forecast_samples)\n",
    "\n",
    "# Convert forecast samples into gluonts SampleForecast objects\n",
    "sample_forecasts = []\n",
    "for item, ts in zip(forecast_samples, test_data.input):\n",
    "    forecast_start_date = ts[\"start\"] + len(ts[\"target\"])\n",
    "    sample_forecasts.append(\n",
    "        SampleForecast(samples=item, start_date=forecast_start_date)\n",
    "    )\n",
    "\n",
    "# Evaluate\n",
    "metrics_df = evaluate_forecasts(\n",
    "    sample_forecasts,\n",
    "    test_data=test_data,\n",
    "    metrics=[\n",
    "        MASE(),\n",
    "        MeanWeightedSumQuantileLoss(np.arange(0.1, 1.0, 0.1)),\n",
    "    ],\n",
    ")\n",
    "\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25708d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yogi/miniconda3/envs/chronos-zero-shot/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token=  tensor([[2144, 2144, 2143, 2143, 2143, 2143, 2141, 2142, 2142, 2149, 2151, 2153,\n",
      "         2152, 2160, 2158, 2157, 2159, 2165, 2163, 2163, 2165, 2168, 2170, 2167,\n",
      "         2174, 2173, 2165, 2166, 2169, 2168, 2166, 2169, 2168, 2168, 2166, 2167,\n",
      "         2168, 2173, 2179, 2176, 2175, 2176, 2170, 2168, 2168, 2168, 2172, 2172,\n",
      "         2168, 2168, 2168, 2175, 2174, 2170, 2171, 2177, 2179, 2175, 2174, 2175,\n",
      "         2174, 2173, 2172, 2174, 2174, 2171, 2170, 2166, 2171, 2166, 2161, 2165,\n",
      "         2167, 2166, 2167, 2167, 2167, 2164, 2164, 2164, 2164, 2165, 2164, 2162,\n",
      "         2163, 2164, 2163, 2174, 2174, 2175, 2175, 2175, 2173, 2173, 2170, 2168,\n",
      "         2169, 2167, 2171, 2171, 2173, 2171, 2170, 2171, 2173, 2173, 2171, 2170,\n",
      "         2170, 2172, 2175, 2172, 2171, 2172, 2171, 2171, 2171, 2170, 2171, 2171,\n",
      "         2170, 2168, 2169, 2169, 2170, 2170, 2169, 2168, 2167, 2169, 2168, 2166,\n",
      "         2163, 2162, 2164, 2164, 2163, 2164, 2164, 2164, 2164, 2163, 2163, 2163,\n",
      "         2163, 2163, 2164, 2163, 2163, 2168, 2167, 2166, 2168, 2168, 2171, 2167,\n",
      "         2173, 2173, 2173, 2175, 2175, 2177, 2175, 2171, 2174, 2174, 2172, 2173,\n",
      "         2172, 2170, 2170, 2168, 2168, 2170, 2166, 2166, 2163, 2163, 2162, 2161,\n",
      "         2159, 2158, 2157, 2158, 2157, 2163, 2162, 2159, 2159, 2162, 2163, 2165,\n",
      "         2165, 2164, 2166, 2163, 2164, 2167, 2164, 2165, 2166, 2168, 2169, 2170,\n",
      "         2169, 2168, 2166, 2165, 2165, 2170, 2168, 2169, 2169, 2172, 2171, 2171,\n",
      "         2173, 2171, 2170, 2170, 2168, 2171, 2171, 2169, 2170, 2171, 2171, 2171,\n",
      "         2169, 2171, 2169, 2170, 2173, 2173, 2173, 2176, 2176, 2176, 2178, 2177,\n",
      "         2177, 2176, 2176, 2176, 2182, 2181, 2181, 2181, 2184, 2183, 2186, 2186,\n",
      "         2185, 2185, 2187, 2186, 2185, 2184, 2184, 2187, 2188, 2185, 2186, 2185,\n",
      "         2184, 2186, 2182, 2181, 2183, 2185, 2185, 2184, 2182, 2182, 2180, 2179,\n",
      "         2179, 2181, 2180, 2180, 2189, 2186, 2186, 2186, 2193, 2193, 2198, 2193,\n",
      "         2196, 2199, 2195, 2199, 2198, 2196, 2198, 2198, 2196, 2196, 2196, 2196,\n",
      "         2196, 2196, 2199, 2197, 2199, 2197, 2196, 2196, 2196, 2194, 2194, 2199,\n",
      "         2199, 2195, 2197, 2199, 2196, 2196, 2197, 2199, 2200, 2199, 2202, 2202,\n",
      "         2201, 2205, 2204, 2203, 2207, 2203, 2202, 2200, 2200, 2199, 2200, 2201,\n",
      "         2203, 2201, 2203, 2209, 2209, 2207, 2208, 2207, 2208, 2207, 2206, 2204,\n",
      "         2205, 2202, 2205, 2205, 2205, 2203, 2203, 2207, 2211, 2215, 2209, 2208,\n",
      "         2214, 2214, 2215, 2216, 2210, 2212, 2213, 2213, 2213, 2213, 2212, 2214,\n",
      "         2213, 2214, 2214, 2214, 2212, 2212, 2208, 2212, 2214, 2214, 2216, 2218,\n",
      "         2217, 2217, 2218, 2217, 2216, 2215, 2215, 2218, 2220, 2221, 2215, 2215,\n",
      "         2215, 2215, 2215, 2215, 2215, 2204, 2205, 2205, 2204, 2202, 2202, 2199,\n",
      "         2202, 2200, 2199, 2197, 2198, 2200, 2200, 2200, 2202, 2204, 2204, 2203,\n",
      "         2204, 2205, 2202, 2196, 2195, 2194, 2196, 2197, 2195, 2194, 2197, 2194,\n",
      "         2197, 2195, 2199, 2198, 2195, 2194, 2194, 2193, 2194, 2193, 2193, 2194,\n",
      "         2194, 2193, 2194, 2193, 2191, 2194, 2198, 2200, 2199, 2200, 2202, 2201,\n",
      "         2202, 2202, 2204, 2202, 2201, 2204, 2209, 2211, 2213, 2216, 2218, 2216,\n",
      "         2213, 2213, 2213, 2209, 2208, 2208, 2213, 2214, 2216, 2217, 2220, 2213,\n",
      "         2211, 2212, 2210, 2213, 2214, 2214, 2215, 2211, 2211, 2213, 2214, 2212,\n",
      "         2212, 2210, 2211, 2208, 2211, 2210, 2208, 2208, 2207, 2209, 2209, 2210,\n",
      "         2209, 2209, 2209, 2209, 2209, 2208, 2205, 2208,    1]],\n",
      "       device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.6758,  0.7344,  0.7148,  ..., -0.4355,  0.4922,  0.4590],\n",
      "         [ 0.6758,  0.7344,  0.7148,  ..., -0.4355,  0.4922,  0.4590],\n",
      "         [ 1.0156,  0.7539, -0.0096,  ..., -0.2021, -0.3457,  0.3320],\n",
      "         ...,\n",
      "         [-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342],\n",
      "         [-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737],\n",
      "         [ 0.4180, -0.3164, -0.0654,  ...,  4.8750, -1.2969, -2.7188]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([1, 513])\n",
      "testt2\n",
      "batch_size=  1\n",
      "seq_length=  513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 06:52:12.290606: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-13 06:52:12.319003: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-13 06:52:12.347377: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-13 06:52:12.481310: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-13 06:52:18.953180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token=  tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.1484,  0.0210, -0.0693,  ..., -0.3477,  0.0432,  3.0156]],\n",
      "\n",
      "        [[ 0.1484,  0.0210, -0.0693,  ..., -0.3477,  0.0432,  3.0156]],\n",
      "\n",
      "        [[ 0.1484,  0.0210, -0.0693,  ..., -0.3477,  0.0432,  3.0156]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1484,  0.0210, -0.0693,  ..., -0.3477,  0.0432,  3.0156]],\n",
      "\n",
      "        [[ 0.1484,  0.0210, -0.0693,  ..., -0.3477,  0.0432,  3.0156]],\n",
      "\n",
      "        [[ 0.1484,  0.0210, -0.0693,  ..., -0.3477,  0.0432,  3.0156]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2211],\n",
      "        [2210],\n",
      "        [2212],\n",
      "        [2203],\n",
      "        [2211],\n",
      "        [2205],\n",
      "        [2199],\n",
      "        [2211],\n",
      "        [2211],\n",
      "        [2205],\n",
      "        [2211],\n",
      "        [2210],\n",
      "        [2208],\n",
      "        [2203],\n",
      "        [2203],\n",
      "        [2212],\n",
      "        [2203],\n",
      "        [2213],\n",
      "        [2204],\n",
      "        [2205]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        [[-0.8828,  0.6406, -0.6133,  ...,  0.5742,  0.6250, -0.0378]],\n",
      "\n",
      "        [[-0.6602,  0.7969, -0.5352,  ...,  0.5430, -0.2061,  0.1875]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[ 0.7734,  0.4277,  0.5039,  ...,  1.7344,  0.3184, -0.0210]],\n",
      "\n",
      "        [[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2210],\n",
      "        [2208],\n",
      "        [2200],\n",
      "        [2210],\n",
      "        [2208],\n",
      "        [2200],\n",
      "        [2209],\n",
      "        [2209],\n",
      "        [2206],\n",
      "        [2213],\n",
      "        [2212],\n",
      "        [2210],\n",
      "        [2203],\n",
      "        [2202],\n",
      "        [2209],\n",
      "        [2202],\n",
      "        [2211],\n",
      "        [2199],\n",
      "        [2201]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        [[-0.8828,  0.6406, -0.6133,  ...,  0.5742,  0.6250, -0.0378]],\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        [[-0.3965,  0.7344, -0.5234,  ...,  1.1562, -0.1602,  0.5234]],\n",
      "\n",
      "        [[-0.1035,  0.2100,  0.1494,  ...,  0.3047,  0.8086,  0.5664]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2207],\n",
      "        [2206],\n",
      "        [2197],\n",
      "        [2208],\n",
      "        [2204],\n",
      "        [2197],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2204],\n",
      "        [2211],\n",
      "        [2210],\n",
      "        [2209],\n",
      "        [2203],\n",
      "        [2206],\n",
      "        [2209],\n",
      "        [2198],\n",
      "        [2208],\n",
      "        [2196],\n",
      "        [2205]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-1.2344,  0.0981, -0.7500,  ...,  0.7695,  0.9844,  0.0398]],\n",
      "\n",
      "        [[ 0.2227,  0.5352, -0.8750,  ..., -0.1973,  0.5430,  0.0444]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]],\n",
      "\n",
      "        [[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2207],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2196],\n",
      "        [2209],\n",
      "        [2207],\n",
      "        [2196],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2204],\n",
      "        [2211],\n",
      "        [2211],\n",
      "        [2206],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2212],\n",
      "        [2196],\n",
      "        [2208],\n",
      "        [2196],\n",
      "        [2196]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.2344,  0.0981, -0.7500,  ...,  0.7695,  0.9844,  0.0398]],\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2214],\n",
      "        [2216],\n",
      "        [2196],\n",
      "        [2207],\n",
      "        [2206],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2206],\n",
      "        [2213],\n",
      "        [2213],\n",
      "        [2205],\n",
      "        [2196],\n",
      "        [2207],\n",
      "        [2214],\n",
      "        [2196],\n",
      "        [2209],\n",
      "        [2196],\n",
      "        [2197]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]],\n",
      "\n",
      "        [[-0.9219,  0.6289, -0.2637,  ...,  0.8789,  0.0569,  0.2871]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2206],\n",
      "        [2214],\n",
      "        [2211],\n",
      "        [2199],\n",
      "        [2208],\n",
      "        [2216],\n",
      "        [2197],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2211],\n",
      "        [2212],\n",
      "        [2203],\n",
      "        [2196],\n",
      "        [2208],\n",
      "        [2213],\n",
      "        [2195],\n",
      "        [2209],\n",
      "        [2198],\n",
      "        [2197]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2227,  0.5352, -0.8750,  ..., -0.1973,  0.5430,  0.0444]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        [[-0.5820,  0.7148,  0.7344,  ...,  1.1016, -0.9336,  0.3613]],\n",
      "\n",
      "        [[-0.9219,  0.6289, -0.2637,  ...,  0.8789,  0.0569,  0.2871]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2212],\n",
      "        [2212],\n",
      "        [2199],\n",
      "        [2208],\n",
      "        [2212],\n",
      "        [2198],\n",
      "        [2208],\n",
      "        [2209],\n",
      "        [2210],\n",
      "        [2212],\n",
      "        [2213],\n",
      "        [2205],\n",
      "        [2197],\n",
      "        [2209],\n",
      "        [2214],\n",
      "        [2197],\n",
      "        [2210],\n",
      "        [2198],\n",
      "        [2198]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.6602,  0.7969, -0.5352,  ...,  0.5430, -0.2061,  0.1875]],\n",
      "\n",
      "        [[-0.6602,  0.7969, -0.5352,  ...,  0.5430, -0.2061,  0.1875]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8828,  0.6406, -0.6133,  ...,  0.5742,  0.6250, -0.0378]],\n",
      "\n",
      "        [[-0.5820,  0.7148,  0.7344,  ...,  1.1016, -0.9336,  0.3613]],\n",
      "\n",
      "        [[-0.5820,  0.7148,  0.7344,  ...,  1.1016, -0.9336,  0.3613]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2213],\n",
      "        [2213],\n",
      "        [2200],\n",
      "        [2210],\n",
      "        [2212],\n",
      "        [2199],\n",
      "        [2209],\n",
      "        [2209],\n",
      "        [2208],\n",
      "        [2213],\n",
      "        [2214],\n",
      "        [2206],\n",
      "        [2199],\n",
      "        [2207],\n",
      "        [2215],\n",
      "        [2198],\n",
      "        [2211],\n",
      "        [2200],\n",
      "        [2200]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        [[-0.4668,  0.4082, -0.7031,  ..., -0.9844,  0.6133,  0.2539]],\n",
      "\n",
      "        [[-0.4668,  0.4082, -0.7031,  ..., -0.9844,  0.6133,  0.2539]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2211],\n",
      "        [2214],\n",
      "        [2214],\n",
      "        [2200],\n",
      "        [2212],\n",
      "        [2212],\n",
      "        [2200],\n",
      "        [2211],\n",
      "        [2212],\n",
      "        [2209],\n",
      "        [2215],\n",
      "        [2217],\n",
      "        [2206],\n",
      "        [2200],\n",
      "        [2208],\n",
      "        [2213],\n",
      "        [2198],\n",
      "        [2213],\n",
      "        [2200],\n",
      "        [2201]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[-0.4668,  0.4082, -0.7031,  ..., -0.9844,  0.6133,  0.2539]],\n",
      "\n",
      "        [[-0.1035,  0.2100,  0.1494,  ...,  0.3047,  0.8086,  0.5664]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2213],\n",
      "        [2215],\n",
      "        [2196],\n",
      "        [2214],\n",
      "        [2213],\n",
      "        [2199],\n",
      "        [2213],\n",
      "        [2214],\n",
      "        [2207],\n",
      "        [2216],\n",
      "        [2213],\n",
      "        [2205],\n",
      "        [2202],\n",
      "        [2208],\n",
      "        [2214],\n",
      "        [2200],\n",
      "        [2216],\n",
      "        [2199],\n",
      "        [2199]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        [[-0.3965,  0.7344, -0.5234,  ...,  1.1562, -0.1602,  0.5234]],\n",
      "\n",
      "        [[-0.3965,  0.7344, -0.5234,  ...,  1.1562, -0.1602,  0.5234]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2209],\n",
      "        [2214],\n",
      "        [2216],\n",
      "        [2191],\n",
      "        [2213],\n",
      "        [2213],\n",
      "        [2196],\n",
      "        [2211],\n",
      "        [2213],\n",
      "        [2208],\n",
      "        [2216],\n",
      "        [2214],\n",
      "        [2203],\n",
      "        [2199],\n",
      "        [2210],\n",
      "        [2214],\n",
      "        [2200],\n",
      "        [2215],\n",
      "        [2193],\n",
      "        [2196]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2210],\n",
      "        [2214],\n",
      "        [2216],\n",
      "        [2193],\n",
      "        [2212],\n",
      "        [2214],\n",
      "        [2193],\n",
      "        [2211],\n",
      "        [2212],\n",
      "        [2207],\n",
      "        [2215],\n",
      "        [2214],\n",
      "        [2203],\n",
      "        [2199],\n",
      "        [2208],\n",
      "        [2215],\n",
      "        [2198],\n",
      "        [2214],\n",
      "        [2190],\n",
      "        [2191]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.8828,  0.6406, -0.6133,  ...,  0.5742,  0.6250, -0.0378]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[-0.1670,  0.1167, -0.0952,  ..., -1.0547, -0.1768,  0.3262]],\n",
      "\n",
      "        [[-0.1021,  0.2578,  0.9297,  ..., -0.8906,  0.0410,  0.4414]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2216],\n",
      "        [2217],\n",
      "        [2195],\n",
      "        [2213],\n",
      "        [2213],\n",
      "        [2194],\n",
      "        [2211],\n",
      "        [2213],\n",
      "        [2210],\n",
      "        [2215],\n",
      "        [2214],\n",
      "        [2199],\n",
      "        [2193],\n",
      "        [2205],\n",
      "        [2214],\n",
      "        [2199],\n",
      "        [2215],\n",
      "        [2193],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        [[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2210],\n",
      "        [2213],\n",
      "        [2216],\n",
      "        [2196],\n",
      "        [2210],\n",
      "        [2216],\n",
      "        [2197],\n",
      "        [2209],\n",
      "        [2211],\n",
      "        [2208],\n",
      "        [2214],\n",
      "        [2213],\n",
      "        [2200],\n",
      "        [2195],\n",
      "        [2205],\n",
      "        [2217],\n",
      "        [2196],\n",
      "        [2213],\n",
      "        [2195],\n",
      "        [2196]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.8828,  0.6406, -0.6133,  ...,  0.5742,  0.6250, -0.0378]],\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2214],\n",
      "        [2216],\n",
      "        [2196],\n",
      "        [2212],\n",
      "        [2214],\n",
      "        [2199],\n",
      "        [2212],\n",
      "        [2213],\n",
      "        [2205],\n",
      "        [2213],\n",
      "        [2212],\n",
      "        [2201],\n",
      "        [2193],\n",
      "        [2205],\n",
      "        [2216],\n",
      "        [2197],\n",
      "        [2215],\n",
      "        [2196],\n",
      "        [2196]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2214],\n",
      "        [2217],\n",
      "        [2195],\n",
      "        [2210],\n",
      "        [2214],\n",
      "        [2198],\n",
      "        [2210],\n",
      "        [2211],\n",
      "        [2205],\n",
      "        [2212],\n",
      "        [2217],\n",
      "        [2201],\n",
      "        [2196],\n",
      "        [2207],\n",
      "        [2215],\n",
      "        [2200],\n",
      "        [2214],\n",
      "        [2194],\n",
      "        [2197]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.9219,  0.6289, -0.2637,  ...,  0.8789,  0.0569,  0.2871]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2213],\n",
      "        [2216],\n",
      "        [2195],\n",
      "        [2213],\n",
      "        [2214],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2215],\n",
      "        [2205],\n",
      "        [2215],\n",
      "        [2216],\n",
      "        [2201],\n",
      "        [2196],\n",
      "        [2206],\n",
      "        [2215],\n",
      "        [2199],\n",
      "        [2217],\n",
      "        [2196],\n",
      "        [2195]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2212],\n",
      "        [2215],\n",
      "        [2193],\n",
      "        [2212],\n",
      "        [2214],\n",
      "        [2196],\n",
      "        [2208],\n",
      "        [2213],\n",
      "        [2205],\n",
      "        [2216],\n",
      "        [2216],\n",
      "        [2199],\n",
      "        [2196],\n",
      "        [2204],\n",
      "        [2214],\n",
      "        [2199],\n",
      "        [2216],\n",
      "        [2196],\n",
      "        [2195]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-0.6602,  0.7969, -0.5352,  ...,  0.5430, -0.2061,  0.1875]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2206],\n",
      "        [2210],\n",
      "        [2213],\n",
      "        [2194],\n",
      "        [2211],\n",
      "        [2212],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2211],\n",
      "        [2204],\n",
      "        [2216],\n",
      "        [2215],\n",
      "        [2199],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2213],\n",
      "        [2196],\n",
      "        [2214],\n",
      "        [2197],\n",
      "        [2194]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2227,  0.5352, -0.8750,  ..., -0.1973,  0.5430,  0.0444]],\n",
      "\n",
      "        [[-0.8828,  0.6406, -0.6133,  ...,  0.5742,  0.6250, -0.0378]],\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[-0.9219,  0.6289, -0.2637,  ...,  0.8789,  0.0569,  0.2871]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2206],\n",
      "        [2208],\n",
      "        [2212],\n",
      "        [2192],\n",
      "        [2211],\n",
      "        [2211],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2212],\n",
      "        [2206],\n",
      "        [2213],\n",
      "        [2215],\n",
      "        [2196],\n",
      "        [2196],\n",
      "        [2204],\n",
      "        [2211],\n",
      "        [2194],\n",
      "        [2214],\n",
      "        [2194],\n",
      "        [2194]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2227,  0.5352, -0.8750,  ..., -0.1973,  0.5430,  0.0444]],\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.6602,  0.7969, -0.5352,  ...,  0.5430, -0.2061,  0.1875]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2204],\n",
      "        [2208],\n",
      "        [2212],\n",
      "        [2195],\n",
      "        [2211],\n",
      "        [2210],\n",
      "        [2193],\n",
      "        [2204],\n",
      "        [2212],\n",
      "        [2206],\n",
      "        [2213],\n",
      "        [2214],\n",
      "        [2196],\n",
      "        [2194],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2214],\n",
      "        [2196],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7734,  0.4277,  0.5039,  ...,  1.7344,  0.3184, -0.0210]],\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.6602,  0.7969, -0.5352,  ...,  0.5430, -0.2061,  0.1875]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2209],\n",
      "        [2213],\n",
      "        [2195],\n",
      "        [2210],\n",
      "        [2211],\n",
      "        [2195],\n",
      "        [2207],\n",
      "        [2211],\n",
      "        [2205],\n",
      "        [2212],\n",
      "        [2212],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2213],\n",
      "        [2195],\n",
      "        [2195]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2204],\n",
      "        [2212],\n",
      "        [2214],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2212],\n",
      "        [2195],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2206],\n",
      "        [2211],\n",
      "        [2211],\n",
      "        [2196],\n",
      "        [2193],\n",
      "        [2207],\n",
      "        [2210],\n",
      "        [2193],\n",
      "        [2212],\n",
      "        [2193],\n",
      "        [2195]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7734,  0.4277,  0.5039,  ...,  1.7344,  0.3184, -0.0210]],\n",
      "\n",
      "        [[-0.6602,  0.7969, -0.5352,  ...,  0.5430, -0.2061,  0.1875]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6602,  0.7969, -0.5352,  ...,  0.5430, -0.2061,  0.1875]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2206],\n",
      "        [2211],\n",
      "        [2212],\n",
      "        [2193],\n",
      "        [2209],\n",
      "        [2209],\n",
      "        [2195],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2206],\n",
      "        [2209],\n",
      "        [2211],\n",
      "        [2194],\n",
      "        [2196],\n",
      "        [2208],\n",
      "        [2212],\n",
      "        [2196],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2194]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2227,  0.5352, -0.8750,  ..., -0.1973,  0.5430,  0.0444]],\n",
      "\n",
      "        [[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        [[-0.6602,  0.7969, -0.5352,  ...,  0.5430, -0.2061,  0.1875]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2211],\n",
      "        [2215],\n",
      "        [2193],\n",
      "        [2207],\n",
      "        [2211],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2212],\n",
      "        [2196],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2195],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2215],\n",
      "        [2216],\n",
      "        [2194],\n",
      "        [2209],\n",
      "        [2214],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2207],\n",
      "        [2213],\n",
      "        [2196],\n",
      "        [2199],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2195],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2207],\n",
      "        [2214],\n",
      "        [2215],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2211],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2210],\n",
      "        [2205],\n",
      "        [2208],\n",
      "        [2210],\n",
      "        [2196],\n",
      "        [2200],\n",
      "        [2205],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2211],\n",
      "        [2194],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.2344,  0.0981, -0.7500,  ...,  0.7695,  0.9844,  0.0398]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2215],\n",
      "        [2216],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2207],\n",
      "        [2210],\n",
      "        [2205],\n",
      "        [2210],\n",
      "        [2207],\n",
      "        [2196],\n",
      "        [2199],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2210],\n",
      "        [2194],\n",
      "        [2194]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8828,  0.6406, -0.6133,  ...,  0.5742,  0.6250, -0.0378]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2214],\n",
      "        [2215],\n",
      "        [2194],\n",
      "        [2205],\n",
      "        [2210],\n",
      "        [2194],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2211],\n",
      "        [2207],\n",
      "        [2194],\n",
      "        [2200],\n",
      "        [2205],\n",
      "        [2210],\n",
      "        [2195],\n",
      "        [2207],\n",
      "        [2192],\n",
      "        [2192]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2344,  0.0981, -0.7500,  ...,  0.7695,  0.9844,  0.0398]],\n",
      "\n",
      "        [[-0.3984,  0.3965,  1.0312,  ..., -1.1328,  0.4473,  0.4512]],\n",
      "\n",
      "        [[-0.3984,  0.3965,  1.0312,  ..., -1.1328,  0.4473,  0.4512]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2207],\n",
      "        [2215],\n",
      "        [2216],\n",
      "        [2193],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2207],\n",
      "        [2194],\n",
      "        [2199],\n",
      "        [2204],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2192],\n",
      "        [2195]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.2344,  0.0981, -0.7500,  ...,  0.7695,  0.9844,  0.0398]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2344,  0.0981, -0.7500,  ...,  0.7695,  0.9844,  0.0398]],\n",
      "\n",
      "        [[-0.3984,  0.3965,  1.0312,  ..., -1.1328,  0.4473,  0.4512]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2213],\n",
      "        [2214],\n",
      "        [2193],\n",
      "        [2204],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2206],\n",
      "        [2206],\n",
      "        [2206],\n",
      "        [2208],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2197],\n",
      "        [2205],\n",
      "        [2210],\n",
      "        [2196],\n",
      "        [2208],\n",
      "        [2191],\n",
      "        [2195]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.1021,  0.2578,  0.9297,  ..., -0.8906,  0.0410,  0.4414]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2204],\n",
      "        [2215],\n",
      "        [2215],\n",
      "        [2193],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2207],\n",
      "        [2196],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2203],\n",
      "        [2193],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.7734,  0.4277,  0.5039,  ...,  1.7344,  0.3184, -0.0210]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0364,  0.4902,  0.6797,  ...,  0.2852, -0.1240, -0.0186]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2215],\n",
      "        [2215],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2205],\n",
      "        [2202],\n",
      "        [2204],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2196],\n",
      "        [2193],\n",
      "        [2207],\n",
      "        [2209],\n",
      "        [2195],\n",
      "        [2202],\n",
      "        [2194],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3926,  0.6367,  0.9766,  ...,  0.3242, -0.6953,  0.2324]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2216],\n",
      "        [2216],\n",
      "        [2196],\n",
      "        [2208],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2202],\n",
      "        [2211],\n",
      "        [2195],\n",
      "        [2193],\n",
      "        [2206],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2202],\n",
      "        [2195],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3926,  0.6367,  0.9766,  ...,  0.3242, -0.6953,  0.2324]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2218],\n",
      "        [2216],\n",
      "        [2194],\n",
      "        [2209],\n",
      "        [2211],\n",
      "        [2195],\n",
      "        [2212],\n",
      "        [2205],\n",
      "        [2206],\n",
      "        [2205],\n",
      "        [2207],\n",
      "        [2195],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2210],\n",
      "        [2194],\n",
      "        [2204],\n",
      "        [2195],\n",
      "        [2195]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-0.7344,  0.3477,  1.1641,  ...,  0.0527,  0.9297,  0.1118]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7734,  0.4277,  0.5039,  ...,  1.7344,  0.3184, -0.0210]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2206],\n",
      "        [2218],\n",
      "        [2216],\n",
      "        [2193],\n",
      "        [2205],\n",
      "        [2208],\n",
      "        [2195],\n",
      "        [2212],\n",
      "        [2207],\n",
      "        [2203],\n",
      "        [2205],\n",
      "        [2208],\n",
      "        [2195],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2204],\n",
      "        [2195],\n",
      "        [2200],\n",
      "        [2195],\n",
      "        [2194]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2227,  0.5352, -0.8750,  ..., -0.1973,  0.5430,  0.0444]],\n",
      "\n",
      "        [[-0.7344,  0.3477,  1.1641,  ...,  0.0527,  0.9297,  0.1118]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4668,  0.4082, -0.7031,  ..., -0.9844,  0.6133,  0.2539]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2206],\n",
      "        [2218],\n",
      "        [2216],\n",
      "        [2193],\n",
      "        [2204],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2210],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2199],\n",
      "        [2195],\n",
      "        [2204],\n",
      "        [2194],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2227,  0.5352, -0.8750,  ..., -0.1973,  0.5430,  0.0444]],\n",
      "\n",
      "        [[-0.7344,  0.3477,  1.1641,  ...,  0.0527,  0.9297,  0.1118]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7734,  0.4277,  0.5039,  ...,  1.7344,  0.3184, -0.0210]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2217],\n",
      "        [2216],\n",
      "        [2193],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2211],\n",
      "        [2206],\n",
      "        [2205],\n",
      "        [2205],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2199],\n",
      "        [2194],\n",
      "        [2204],\n",
      "        [2194],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7734,  0.4277,  0.5039,  ...,  1.7344,  0.3184, -0.0210]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2217],\n",
      "        [2215],\n",
      "        [2193],\n",
      "        [2207],\n",
      "        [2205],\n",
      "        [2193],\n",
      "        [2211],\n",
      "        [2206],\n",
      "        [2207],\n",
      "        [2208],\n",
      "        [2204],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2205],\n",
      "        [2196],\n",
      "        [2193],\n",
      "        [2199],\n",
      "        [2194],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3965,  0.7344, -0.5234,  ...,  1.1562, -0.1602,  0.5234]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2217],\n",
      "        [2215],\n",
      "        [2194],\n",
      "        [2200],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2211],\n",
      "        [2199],\n",
      "        [2208],\n",
      "        [2208],\n",
      "        [2205],\n",
      "        [2191],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2198],\n",
      "        [2192],\n",
      "        [2196],\n",
      "        [2193],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2215],\n",
      "        [2216],\n",
      "        [2196],\n",
      "        [2202],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2210],\n",
      "        [2196],\n",
      "        [2207],\n",
      "        [2203],\n",
      "        [2205],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2205],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2206],\n",
      "        [2214],\n",
      "        [2215],\n",
      "        [2196],\n",
      "        [2199],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2210],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2196],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2205],\n",
      "        [2196],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2227,  0.5352, -0.8750,  ..., -0.1973,  0.5430,  0.0444]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2214],\n",
      "        [2217],\n",
      "        [2194],\n",
      "        [2198],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2210],\n",
      "        [2196],\n",
      "        [2199],\n",
      "        [2192],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2190],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2200],\n",
      "        [2192]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.4668,  0.4082, -0.7031,  ..., -0.9844,  0.6133,  0.2539]],\n",
      "\n",
      "        [[-0.3984,  0.3965,  1.0312,  ..., -1.1328,  0.4473,  0.4512]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2203],\n",
      "        [2214],\n",
      "        [2219],\n",
      "        [2194],\n",
      "        [2196],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2198],\n",
      "        [2196],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2193],\n",
      "        [2196],\n",
      "        [2207],\n",
      "        [2197],\n",
      "        [2193],\n",
      "        [2196],\n",
      "        [2199],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.0364,  0.4902,  0.6797,  ...,  0.2852, -0.1240, -0.0186]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[-0.6523,  0.3340,  1.1875,  ..., -0.2852,  0.5391,  0.0119]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4785,  0.4160, -0.4570,  ...,  0.8516,  0.9609,  0.3164]],\n",
      "\n",
      "        [[-0.3965,  0.7344, -0.5234,  ...,  1.1562, -0.1602,  0.5234]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2215],\n",
      "        [2219],\n",
      "        [2194],\n",
      "        [2196],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2199],\n",
      "        [2196],\n",
      "        [2192],\n",
      "        [2208],\n",
      "        [2192],\n",
      "        [2200],\n",
      "        [2205],\n",
      "        [2192],\n",
      "        [2195],\n",
      "        [2193],\n",
      "        [2199],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[-0.6523,  0.3340,  1.1875,  ..., -0.2852,  0.5391,  0.0119]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.3965,  0.7344, -0.5234,  ...,  1.1562, -0.1602,  0.5234]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2217],\n",
      "        [2218],\n",
      "        [2193],\n",
      "        [2196],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2198],\n",
      "        [2197],\n",
      "        [2196],\n",
      "        [2208],\n",
      "        [2192],\n",
      "        [2200],\n",
      "        [2203],\n",
      "        [2193],\n",
      "        [2195],\n",
      "        [2197],\n",
      "        [2198],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        [[-0.7344,  0.3477,  1.1641,  ...,  0.0527,  0.9297,  0.1118]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9219,  0.6289, -0.2637,  ...,  0.8789,  0.0569,  0.2871]],\n",
      "\n",
      "        [[-0.5820,  0.7148,  0.7344,  ...,  1.1016, -0.9336,  0.3613]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2216],\n",
      "        [2218],\n",
      "        [2193],\n",
      "        [2197],\n",
      "        [2210],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2195],\n",
      "        [2198],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2199],\n",
      "        [2200],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2195],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        [[-0.7344,  0.3477,  1.1641,  ...,  0.0527,  0.9297,  0.1118]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2206],\n",
      "        [2222],\n",
      "        [2217],\n",
      "        [2191],\n",
      "        [2193],\n",
      "        [2207],\n",
      "        [2192],\n",
      "        [2199],\n",
      "        [2195],\n",
      "        [2199],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2198],\n",
      "        [2205],\n",
      "        [2196],\n",
      "        [2195],\n",
      "        [2194],\n",
      "        [2193],\n",
      "        [2197]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.2227,  0.5352, -0.8750,  ..., -0.1973,  0.5430,  0.0444]],\n",
      "\n",
      "        [[-0.0708,  0.4375, -0.3340,  ...,  0.7891,  0.9336, -0.1484]],\n",
      "\n",
      "        [[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.9219,  0.6289, -0.2637,  ...,  0.8789,  0.0569,  0.2871]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2221],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2190],\n",
      "        [2197],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2196],\n",
      "        [2210],\n",
      "        [2194],\n",
      "        [2192],\n",
      "        [2194],\n",
      "        [2193],\n",
      "        [2197]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.4727,  0.0669,  0.2070,  ...,  1.4062,  0.7539,  0.0347]],\n",
      "\n",
      "        [[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.9219,  0.6289, -0.2637,  ...,  0.8789,  0.0569,  0.2871]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2220],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2191],\n",
      "        [2196],\n",
      "        [2193],\n",
      "        [2205],\n",
      "        [2196],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2209],\n",
      "        [2200],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2191],\n",
      "        [2197]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-1.0547,  0.4434,  1.1172,  ...,  0.0559,  0.6016,  0.1729]],\n",
      "\n",
      "        [[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.1021,  0.2578,  0.9297,  ..., -0.8906,  0.0410,  0.4414]],\n",
      "\n",
      "        [[-0.9219,  0.6289, -0.2637,  ...,  0.8789,  0.0569,  0.2871]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2207],\n",
      "        [2221],\n",
      "        [2209],\n",
      "        [2193],\n",
      "        [2197],\n",
      "        [2208],\n",
      "        [2191],\n",
      "        [2197],\n",
      "        [2195],\n",
      "        [2205],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2190],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2200],\n",
      "        [2192],\n",
      "        [2195],\n",
      "        [2193],\n",
      "        [2199]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.2344,  0.0981, -0.7500,  ...,  0.7695,  0.9844,  0.0398]],\n",
      "\n",
      "        [[-0.4727,  0.0669,  0.2070,  ...,  1.4062,  0.7539,  0.0347]],\n",
      "\n",
      "        [[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.3965,  0.7344, -0.5234,  ...,  1.1562, -0.1602,  0.5234]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2205],\n",
      "        [2219],\n",
      "        [2211],\n",
      "        [2194],\n",
      "        [2198],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2199],\n",
      "        [2193],\n",
      "        [2206],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2192],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2199],\n",
      "        [2193],\n",
      "        [2195],\n",
      "        [2189],\n",
      "        [2195]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.1523,  0.4219, -0.7305,  ...,  1.5625,  0.1650, -0.0342]],\n",
      "\n",
      "        [[-0.6523,  0.3340,  1.1875,  ..., -0.2852,  0.5391,  0.0119]],\n",
      "\n",
      "        [[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[ 0.0134,  0.6055,  0.2002,  ..., -0.5156, -0.2988,  0.3750]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2217],\n",
      "        [2214],\n",
      "        [2194],\n",
      "        [2200],\n",
      "        [2213],\n",
      "        [2193],\n",
      "        [2200],\n",
      "        [2196],\n",
      "        [2204],\n",
      "        [2196],\n",
      "        [2207],\n",
      "        [2192],\n",
      "        [2191],\n",
      "        [2208],\n",
      "        [2200],\n",
      "        [2193],\n",
      "        [2195],\n",
      "        [2185],\n",
      "        [2194]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[ 0.5430,  0.0471,  0.1953,  ...,  0.8906, -0.2256,  0.6328]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2214],\n",
      "        [2210],\n",
      "        [2194],\n",
      "        [2196],\n",
      "        [2211],\n",
      "        [2199],\n",
      "        [2198],\n",
      "        [2195],\n",
      "        [2205],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2209],\n",
      "        [2200],\n",
      "        [2193],\n",
      "        [2195],\n",
      "        [2185],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[-0.8828,  0.6406, -0.6133,  ...,  0.5742,  0.6250, -0.0378]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[ 0.5430,  0.0471,  0.1953,  ...,  0.8906, -0.2256,  0.6328]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2208],\n",
      "        [2218],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2195],\n",
      "        [2208],\n",
      "        [2199],\n",
      "        [2200],\n",
      "        [2195],\n",
      "        [2205],\n",
      "        [2195],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2209],\n",
      "        [2196],\n",
      "        [2205],\n",
      "        [2195],\n",
      "        [2186],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        [[-0.7344,  0.3477,  1.1641,  ...,  0.0527,  0.9297,  0.1118]],\n",
      "\n",
      "        [[-1.5703,  0.0145, -0.5781,  ..., -0.2080,  0.5430, -0.1660]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[ 0.1025,  0.5859, -0.1699,  ...,  0.9375, -0.0811,  0.6289]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2213],\n",
      "        [2218],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2197],\n",
      "        [2193],\n",
      "        [2195],\n",
      "        [2205],\n",
      "        [2195],\n",
      "        [2205],\n",
      "        [2191],\n",
      "        [2193],\n",
      "        [2210],\n",
      "        [2195],\n",
      "        [2205],\n",
      "        [2195],\n",
      "        [2187],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[-0.7344,  0.3477,  1.1641,  ...,  0.0527,  0.9297,  0.1118]],\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[ 0.1348,  0.6680,  0.1621,  ...,  0.4121,  0.9375,  0.6328]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2218],\n",
      "        [2213],\n",
      "        [2208],\n",
      "        [2190],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2198],\n",
      "        [2196],\n",
      "        [2195],\n",
      "        [2208],\n",
      "        [2195],\n",
      "        [2205],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2195],\n",
      "        [2205],\n",
      "        [2195],\n",
      "        [2185],\n",
      "        [2193]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.7344,  0.3477,  1.1641,  ...,  0.0527,  0.9297,  0.1118]],\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[-1.7500, -0.1855, -0.6562,  ...,  0.1592,  0.9375, -0.0737]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[ 0.5430,  0.0471,  0.1953,  ...,  0.8906, -0.2256,  0.6328]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2210],\n",
      "        [2213],\n",
      "        [2199],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2189],\n",
      "        [2193],\n",
      "        [2195],\n",
      "        [2207],\n",
      "        [2195],\n",
      "        [2207],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2203],\n",
      "        [2194],\n",
      "        [2184],\n",
      "        [2195]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.8828,  0.6406, -0.6133,  ...,  0.5742,  0.6250, -0.0378]],\n",
      "\n",
      "        [[-0.7578,  0.8828, -0.4746,  ...,  0.9297, -1.0781,  0.6289]],\n",
      "\n",
      "        [[-0.3965,  0.7344, -0.5234,  ...,  1.1562, -0.1602,  0.5234]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[-0.3789, -0.8125,  0.3398,  ...,  0.9219,  0.0359,  0.6172]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2211],\n",
      "        [2214],\n",
      "        [2194],\n",
      "        [2192],\n",
      "        [2194],\n",
      "        [2210],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2203],\n",
      "        [2193],\n",
      "        [2178],\n",
      "        [2195]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        [[-0.0302,  1.0156, -0.0189,  ...,  0.8203,  0.3691,  0.5352]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[ 0.8203, -0.6094,  0.0635,  ...,  1.0000,  0.0400,  0.6875]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2211],\n",
      "        [2215],\n",
      "        [2197],\n",
      "        [2193],\n",
      "        [2195],\n",
      "        [2207],\n",
      "        [2191],\n",
      "        [2195],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2210],\n",
      "        [2200],\n",
      "        [2200],\n",
      "        [2193],\n",
      "        [2181],\n",
      "        [2194]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[-0.9219,  0.6289, -0.2637,  ...,  0.8789,  0.0569,  0.2871]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[-0.4336,  0.2061, -0.3203,  ..., -0.2236,  0.9453,  0.5898]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2211],\n",
      "        [2216],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2209],\n",
      "        [2190],\n",
      "        [2193],\n",
      "        [2194],\n",
      "        [2208],\n",
      "        [2194],\n",
      "        [2209],\n",
      "        [2192],\n",
      "        [2196],\n",
      "        [2210],\n",
      "        [2200],\n",
      "        [2210],\n",
      "        [2193],\n",
      "        [2185],\n",
      "        [2194]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-1.1953,  0.7266, -0.5781,  ...,  0.0417,  0.7773,  0.2676]],\n",
      "\n",
      "        [[ 0.2773,  0.8672,  0.7656,  ...,  0.7070,  0.7578,  0.4043]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        [[ 0.5430,  0.0471,  0.1953,  ...,  0.8906, -0.2256,  0.6328]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:25, 25.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2219],\n",
      "        [2215],\n",
      "        [2195],\n",
      "        [2200],\n",
      "        [2194],\n",
      "        [2215],\n",
      "        [2190],\n",
      "        [2195],\n",
      "        [2194],\n",
      "        [2199],\n",
      "        [2194],\n",
      "        [2207],\n",
      "        [2192],\n",
      "        [2193],\n",
      "        [2209],\n",
      "        [2199],\n",
      "        [2209],\n",
      "        [2194],\n",
      "        [2186],\n",
      "        [2194]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[-0.6523,  0.3340,  1.1875,  ..., -0.2852,  0.5391,  0.0119]],\n",
      "\n",
      "        [[ 0.1963,  0.9883,  0.6602,  ...,  1.2422,  0.9922,  0.4297]],\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]],\n",
      "\n",
      "        [[ 0.1025,  0.5859, -0.1699,  ...,  0.9375, -0.0811,  0.6289]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n",
      "token=  tensor([[2217],\n",
      "        [2225],\n",
      "        [2193],\n",
      "        [2200],\n",
      "        [2194],\n",
      "        [2219],\n",
      "        [2188],\n",
      "        [2195],\n",
      "        [2194],\n",
      "        [2199],\n",
      "        [2200],\n",
      "        [2211],\n",
      "        [2193],\n",
      "        [2193],\n",
      "        [2208],\n",
      "        [2199],\n",
      "        [2208],\n",
      "        [2195],\n",
      "        [2183],\n",
      "        [2194]], device='cuda:1')\n",
      "Ukuran Tabel Embedding: Embedding(4096, 512)\n",
      "inputs_embeds=  tensor([[[ 0.3086,  0.5742,  1.1562,  ..., -0.4609,  0.6484,  0.2793]],\n",
      "\n",
      "        [[-0.3926,  0.3242, -0.6172,  ...,  0.5469,  0.9844, -0.0105]],\n",
      "\n",
      "        [[-0.1924,  0.5625,  0.6367,  ..., -0.9297,  0.0703,  0.5898]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3652,  0.4727, -0.4941,  ...,  0.0723,  0.5508,  0.2695]],\n",
      "\n",
      "        [[ 0.0977, -0.7617,  0.1758,  ...,  1.2578,  1.1094,  0.6797]],\n",
      "\n",
      "        [[-0.2793,  0.2441,  0.0811,  ..., -0.6289,  0.7695,  0.5859]]],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "testt1\n",
      "torch.Size([20, 1])\n",
      "testt2\n",
      "batch_size=  20\n",
      "seq_length=  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 26.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MASE[0.5]</th>\n",
       "      <th>mean_weighted_sum_quantile_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>10.348085</td>\n",
       "      <td>0.053441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MASE[0.5]  mean_weighted_sum_quantile_loss\n",
       "None  10.348085                         0.053441"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gluonts.dataset.repository import get_dataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.ev.metrics import MASE, MeanWeightedSumQuantileLoss\n",
    "from gluonts.itertools import batcher\n",
    "from gluonts.model.evaluation import evaluate_forecasts\n",
    "from gluonts.model.forecast import SampleForecast\n",
    "from tqdm.auto import tqdm\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "# Load dataset\n",
    "batch_size = 32\n",
    "num_samples = 20\n",
    "df = pd.read_csv('/home/yogi/chronos-research/dataset/daily-all/TLKM.csv')\n",
    "\n",
    "# # Hitung jumlah total baris\n",
    "# total_rows = len(df)\n",
    "\n",
    "# # Hitung 70% dari total baris\n",
    "# rows_to_take = int(0.7 * total_rows)\n",
    "\n",
    "# # Ambil 70% pertama dari data\n",
    "# df = df.head(rows_to_take)\n",
    "\n",
    "# Ensure the date column is in datetime format and sort by date\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(by='timestamp')\n",
    "\n",
    "# Prepare ListDataset for GluonTS\n",
    "prediction_length = 64\n",
    "freq = \"D\"  # Daily frequency\n",
    "# dataset = ListDataset(\n",
    "#     [{\"start\": df['timestamp'].iloc[0], \"target\": df['close'].values}],  # Assuming 'close' is the target column\n",
    "#     freq=freq\n",
    "# )\n",
    "dataset = [\n",
    "    {\n",
    "        \"start\": pd.Period(df['timestamp'].iloc[0], freq=freq),\n",
    "        \"target\": df[\"close\"].values\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load Chronos\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"/home/yogi/chronos-research/chronos-forecasting/scripts/output/42-dataset/checkpoint-final\",\n",
    "    device_map=\"cuda:1\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Split dataset for evaluation\n",
    "train_data, test_data = split(dataset, offset=-prediction_length)\n",
    "test_data = test_data.generate_instances(prediction_length)\n",
    "\n",
    "\n",
    "# Generate forecast samples\n",
    "forecast_samples = []\n",
    "for batch in tqdm(batcher(test_data.input, batch_size=32)):\n",
    "    context = [torch.tensor(entry[\"target\"]) for entry in batch]\n",
    "    forecast_samples.append(\n",
    "        pipeline.predict(\n",
    "            context,\n",
    "            prediction_length=prediction_length,\n",
    "            num_samples=num_samples,\n",
    "        ).numpy()\n",
    "    )\n",
    "forecast_samples = np.concatenate(forecast_samples)\n",
    "\n",
    "# Convert forecast samples into gluonts SampleForecast objects\n",
    "sample_forecasts = []\n",
    "for item, ts in zip(forecast_samples, test_data.input):\n",
    "    forecast_start_date = ts[\"start\"] + len(ts[\"target\"])\n",
    "    sample_forecasts.append(\n",
    "        SampleForecast(samples=item, start_date=forecast_start_date)\n",
    "    )\n",
    "\n",
    "# Evaluate\n",
    "metrics_df = evaluate_forecasts(\n",
    "    sample_forecasts,\n",
    "    test_data=test_data,\n",
    "    metrics=[\n",
    "        MASE(),\n",
    "        MeanWeightedSumQuantileLoss(np.arange(0.1, 1.0, 0.1)),\n",
    "    ],\n",
    ")\n",
    "\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %tensorboard --logdir=/home/yogi/chronos-research/chronos-forecasting/scripts/output/42-dataset/logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42dfc1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2016-06-20 00:00:00'),\n",
       " Timestamp('2006-08-03 00:00:00'),\n",
       " Timestamp('2019-02-14 00:00:00'),\n",
       " Timestamp('2006-10-27 00:00:00'),\n",
       " Timestamp('2018-07-24 00:00:00'),\n",
       " Timestamp('2009-11-12 00:00:00'),\n",
       " Timestamp('2020-08-13 00:00:00'),\n",
       " Timestamp('2012-02-20 00:00:00'),\n",
       " Timestamp('2010-05-05 00:00:00'),\n",
       " Timestamp('2008-05-21 00:00:00'),\n",
       " Timestamp('2004-01-15 00:00:00'),\n",
       " Timestamp('2021-11-19 00:00:00'),\n",
       " Timestamp('2018-05-03 00:00:00'),\n",
       " Timestamp('2016-07-28 00:00:00'),\n",
       " Timestamp('2021-01-11 00:00:00'),\n",
       " Timestamp('2002-12-24 00:00:00'),\n",
       " Timestamp('2022-05-31 00:00:00'),\n",
       " Timestamp('2001-06-18 00:00:00'),\n",
       " Timestamp('2018-08-21 00:00:00'),\n",
       " Timestamp('2012-08-14 00:00:00'),\n",
       " Timestamp('2008-04-11 00:00:00'),\n",
       " Timestamp('2001-08-31 00:00:00'),\n",
       " Timestamp('2022-08-08 00:00:00'),\n",
       " Timestamp('2016-01-05 00:00:00'),\n",
       " Timestamp('2006-05-08 00:00:00'),\n",
       " Timestamp('2021-01-18 00:00:00'),\n",
       " Timestamp('2018-03-20 00:00:00'),\n",
       " Timestamp('2004-12-30 00:00:00'),\n",
       " Timestamp('2003-02-13 00:00:00'),\n",
       " Timestamp('2003-09-23 00:00:00'),\n",
       " Timestamp('2019-01-31 00:00:00'),\n",
       " Timestamp('2008-03-10 00:00:00'),\n",
       " Timestamp('2017-08-07 00:00:00'),\n",
       " Timestamp('2009-03-25 00:00:00'),\n",
       " Timestamp('2017-03-17 00:00:00'),\n",
       " Timestamp('2020-02-12 00:00:00'),\n",
       " Timestamp('2016-09-05 00:00:00'),\n",
       " Timestamp('2022-07-11 00:00:00'),\n",
       " Timestamp('2020-06-01 00:00:00'),\n",
       " Timestamp('2014-01-22 00:00:00'),\n",
       " Timestamp('2013-06-06 00:00:00'),\n",
       " Timestamp('2017-07-14 00:00:00'),\n",
       " Timestamp('2001-07-30 00:00:00'),\n",
       " Timestamp('2018-10-17 00:00:00'),\n",
       " Timestamp('2004-09-15 00:00:00'),\n",
       " Timestamp('2010-02-05 00:00:00'),\n",
       " Timestamp('2018-11-09 00:00:00'),\n",
       " Timestamp('2006-06-26 00:00:00'),\n",
       " Timestamp('2020-04-01 00:00:00'),\n",
       " Timestamp('2012-10-08 00:00:00'),\n",
       " Timestamp('2015-01-22 00:00:00'),\n",
       " Timestamp('2013-06-24 00:00:00'),\n",
       " Timestamp('2017-02-03 00:00:00'),\n",
       " Timestamp('2014-10-03 00:00:00'),\n",
       " Timestamp('2017-08-18 00:00:00'),\n",
       " Timestamp('2005-03-07 00:00:00'),\n",
       " Timestamp('2008-03-07 00:00:00'),\n",
       " Timestamp('2008-03-25 00:00:00'),\n",
       " Timestamp('2001-07-04 00:00:00'),\n",
       " Timestamp('2007-04-16 00:00:00'),\n",
       " Timestamp('2007-02-01 00:00:00'),\n",
       " Timestamp('2018-08-09 00:00:00'),\n",
       " Timestamp('2014-01-15 00:00:00'),\n",
       " Timestamp('2014-05-01 00:00:00'),\n",
       " Timestamp('2006-08-25 00:00:00'),\n",
       " Timestamp('2014-08-22 00:00:00'),\n",
       " Timestamp('2011-04-04 00:00:00'),\n",
       " Timestamp('2017-05-16 00:00:00'),\n",
       " Timestamp('2007-09-07 00:00:00'),\n",
       " Timestamp('2007-01-16 00:00:00'),\n",
       " Timestamp('2007-12-19 00:00:00'),\n",
       " Timestamp('2008-07-14 00:00:00'),\n",
       " Timestamp('2021-04-01 00:00:00'),\n",
       " Timestamp('2021-12-16 00:00:00'),\n",
       " Timestamp('2010-11-08 00:00:00'),\n",
       " Timestamp('2001-07-27 00:00:00'),\n",
       " Timestamp('2013-07-03 00:00:00'),\n",
       " Timestamp('2015-09-30 00:00:00'),\n",
       " Timestamp('2007-11-12 00:00:00'),\n",
       " Timestamp('2013-10-23 00:00:00'),\n",
       " Timestamp('2003-05-29 00:00:00'),\n",
       " Timestamp('2022-12-19 00:00:00'),\n",
       " Timestamp('2007-09-17 00:00:00'),\n",
       " Timestamp('2013-01-09 00:00:00'),\n",
       " Timestamp('2001-10-10 00:00:00'),\n",
       " Timestamp('2016-10-05 00:00:00'),\n",
       " Timestamp('2012-05-16 00:00:00'),\n",
       " Timestamp('2018-11-12 00:00:00'),\n",
       " Timestamp('2017-01-09 00:00:00'),\n",
       " Timestamp('2017-04-21 00:00:00'),\n",
       " Timestamp('2008-09-30 00:00:00'),\n",
       " Timestamp('2002-08-02 00:00:00'),\n",
       " Timestamp('2009-07-14 00:00:00'),\n",
       " Timestamp('2015-05-14 00:00:00'),\n",
       " Timestamp('2003-10-16 00:00:00'),\n",
       " Timestamp('2018-10-24 00:00:00'),\n",
       " Timestamp('2021-02-18 00:00:00'),\n",
       " Timestamp('2019-07-08 00:00:00'),\n",
       " Timestamp('2022-11-22 00:00:00'),\n",
       " Timestamp('2011-10-10 00:00:00'),\n",
       " Timestamp('2013-12-02 00:00:00'),\n",
       " Timestamp('2019-02-04 00:00:00'),\n",
       " Timestamp('2009-08-04 00:00:00'),\n",
       " Timestamp('2017-08-01 00:00:00'),\n",
       " Timestamp('2005-08-31 00:00:00'),\n",
       " Timestamp('2011-03-04 00:00:00'),\n",
       " Timestamp('2006-12-29 00:00:00'),\n",
       " Timestamp('2006-04-27 00:00:00'),\n",
       " Timestamp('2011-02-02 00:00:00'),\n",
       " Timestamp('2015-10-28 00:00:00'),\n",
       " Timestamp('2013-10-08 00:00:00'),\n",
       " Timestamp('2002-04-29 00:00:00'),\n",
       " Timestamp('2008-12-31 00:00:00'),\n",
       " Timestamp('2004-07-02 00:00:00'),\n",
       " Timestamp('2001-11-27 00:00:00'),\n",
       " Timestamp('2010-10-08 00:00:00'),\n",
       " Timestamp('2021-02-23 00:00:00'),\n",
       " Timestamp('2002-01-29 00:00:00'),\n",
       " Timestamp('2008-03-03 00:00:00'),\n",
       " Timestamp('2010-02-25 00:00:00'),\n",
       " Timestamp('2021-01-29 00:00:00'),\n",
       " Timestamp('2006-06-09 00:00:00'),\n",
       " Timestamp('2017-02-10 00:00:00'),\n",
       " Timestamp('2017-07-06 00:00:00'),\n",
       " Timestamp('2003-05-07 00:00:00'),\n",
       " Timestamp('2011-02-17 00:00:00'),\n",
       " Timestamp('2002-05-01 00:00:00'),\n",
       " Timestamp('2009-04-10 00:00:00'),\n",
       " Timestamp('2012-03-09 00:00:00'),\n",
       " Timestamp('2015-12-21 00:00:00'),\n",
       " Timestamp('2013-02-20 00:00:00'),\n",
       " Timestamp('2009-09-04 00:00:00'),\n",
       " Timestamp('2015-05-27 00:00:00'),\n",
       " Timestamp('2013-11-11 00:00:00'),\n",
       " Timestamp('2001-09-20 00:00:00'),\n",
       " Timestamp('2007-08-30 00:00:00'),\n",
       " Timestamp('2003-01-15 00:00:00'),\n",
       " Timestamp('2013-12-26 00:00:00'),\n",
       " Timestamp('2005-06-14 00:00:00'),\n",
       " Timestamp('2017-04-11 00:00:00'),\n",
       " Timestamp('2015-12-11 00:00:00'),\n",
       " Timestamp('2002-03-11 00:00:00'),\n",
       " Timestamp('2011-04-21 00:00:00'),\n",
       " Timestamp('2002-06-21 00:00:00'),\n",
       " Timestamp('2007-05-15 00:00:00'),\n",
       " Timestamp('2010-04-12 00:00:00'),\n",
       " Timestamp('2016-01-26 00:00:00'),\n",
       " Timestamp('2006-05-31 00:00:00'),\n",
       " Timestamp('2012-06-13 00:00:00'),\n",
       " Timestamp('2006-08-11 00:00:00'),\n",
       " Timestamp('2022-09-15 00:00:00'),\n",
       " Timestamp('2008-04-30 00:00:00'),\n",
       " Timestamp('2014-02-04 00:00:00'),\n",
       " Timestamp('2005-05-06 00:00:00'),\n",
       " Timestamp('2015-02-17 00:00:00'),\n",
       " Timestamp('2004-12-13 00:00:00'),\n",
       " Timestamp('2005-07-05 00:00:00'),\n",
       " Timestamp('2007-02-20 00:00:00'),\n",
       " Timestamp('2010-09-06 00:00:00'),\n",
       " Timestamp('2008-12-11 00:00:00'),\n",
       " Timestamp('2016-06-07 00:00:00'),\n",
       " Timestamp('2005-10-24 00:00:00'),\n",
       " Timestamp('2015-03-20 00:00:00'),\n",
       " Timestamp('2010-03-15 00:00:00'),\n",
       " Timestamp('2009-12-21 00:00:00'),\n",
       " Timestamp('2011-12-19 00:00:00'),\n",
       " Timestamp('2009-03-03 00:00:00'),\n",
       " Timestamp('2005-09-27 00:00:00'),\n",
       " Timestamp('2021-08-05 00:00:00'),\n",
       " Timestamp('2009-05-08 00:00:00'),\n",
       " Timestamp('2010-12-29 00:00:00'),\n",
       " Timestamp('2014-08-14 00:00:00'),\n",
       " Timestamp('2020-01-27 00:00:00'),\n",
       " Timestamp('2019-05-22 00:00:00'),\n",
       " Timestamp('2008-10-01 00:00:00'),\n",
       " Timestamp('2014-06-13 00:00:00'),\n",
       " Timestamp('2014-10-01 00:00:00'),\n",
       " Timestamp('2006-11-07 00:00:00'),\n",
       " Timestamp('2021-04-29 00:00:00'),\n",
       " Timestamp('2021-02-24 00:00:00'),\n",
       " Timestamp('2005-05-12 00:00:00'),\n",
       " Timestamp('2016-11-03 00:00:00'),\n",
       " Timestamp('2020-01-22 00:00:00'),\n",
       " Timestamp('2012-01-03 00:00:00'),\n",
       " Timestamp('2001-06-14 00:00:00'),\n",
       " Timestamp('2004-09-29 00:00:00'),\n",
       " Timestamp('2018-03-07 00:00:00'),\n",
       " Timestamp('2015-11-04 00:00:00'),\n",
       " Timestamp('2004-05-18 00:00:00'),\n",
       " Timestamp('2004-03-19 00:00:00'),\n",
       " Timestamp('2014-09-11 00:00:00'),\n",
       " Timestamp('2003-04-22 00:00:00'),\n",
       " Timestamp('2017-04-06 00:00:00'),\n",
       " Timestamp('2019-07-23 00:00:00'),\n",
       " Timestamp('2003-08-19 00:00:00'),\n",
       " Timestamp('2011-09-06 00:00:00'),\n",
       " Timestamp('2014-06-10 00:00:00'),\n",
       " Timestamp('2018-08-15 00:00:00'),\n",
       " Timestamp('2006-01-26 00:00:00'),\n",
       " Timestamp('2005-02-21 00:00:00'),\n",
       " Timestamp('2007-06-25 00:00:00'),\n",
       " Timestamp('2004-11-16 00:00:00'),\n",
       " Timestamp('2015-06-11 00:00:00'),\n",
       " Timestamp('2015-06-05 00:00:00'),\n",
       " Timestamp('2020-11-23 00:00:00'),\n",
       " Timestamp('2005-09-07 00:00:00'),\n",
       " Timestamp('2019-03-25 00:00:00'),\n",
       " Timestamp('2012-12-19 00:00:00'),\n",
       " Timestamp('2011-07-27 00:00:00'),\n",
       " Timestamp('2009-07-01 00:00:00'),\n",
       " Timestamp('2014-03-04 00:00:00'),\n",
       " Timestamp('2020-01-09 00:00:00'),\n",
       " Timestamp('2006-06-06 00:00:00'),\n",
       " Timestamp('2021-01-15 00:00:00'),\n",
       " Timestamp('2005-12-22 00:00:00'),\n",
       " Timestamp('2021-09-02 00:00:00'),\n",
       " Timestamp('2005-01-03 00:00:00'),\n",
       " Timestamp('2007-07-27 00:00:00'),\n",
       " Timestamp('2022-11-28 00:00:00'),\n",
       " Timestamp('2011-05-02 00:00:00'),\n",
       " Timestamp('2009-05-04 00:00:00'),\n",
       " Timestamp('2009-11-11 00:00:00'),\n",
       " Timestamp('2018-05-28 00:00:00'),\n",
       " Timestamp('2014-03-18 00:00:00'),\n",
       " Timestamp('2002-12-26 00:00:00'),\n",
       " Timestamp('2004-05-25 00:00:00'),\n",
       " Timestamp('2017-09-04 00:00:00'),\n",
       " Timestamp('2003-03-18 00:00:00'),\n",
       " Timestamp('2004-03-30 00:00:00'),\n",
       " Timestamp('2005-10-20 00:00:00'),\n",
       " Timestamp('2003-04-16 00:00:00'),\n",
       " Timestamp('2009-01-02 00:00:00'),\n",
       " Timestamp('2018-01-25 00:00:00'),\n",
       " Timestamp('2018-01-22 00:00:00'),\n",
       " Timestamp('2006-06-14 00:00:00'),\n",
       " Timestamp('2020-05-22 00:00:00'),\n",
       " Timestamp('2015-04-23 00:00:00'),\n",
       " Timestamp('2018-06-22 00:00:00'),\n",
       " Timestamp('2021-07-27 00:00:00'),\n",
       " Timestamp('2007-09-11 00:00:00'),\n",
       " Timestamp('2019-05-02 00:00:00'),\n",
       " Timestamp('2014-02-07 00:00:00'),\n",
       " Timestamp('2014-03-17 00:00:00'),\n",
       " Timestamp('2007-08-10 00:00:00'),\n",
       " Timestamp('2016-08-18 00:00:00'),\n",
       " Timestamp('2021-06-29 00:00:00'),\n",
       " Timestamp('2022-02-24 00:00:00'),\n",
       " Timestamp('2007-07-06 00:00:00'),\n",
       " Timestamp('2021-04-19 00:00:00'),\n",
       " Timestamp('2014-01-27 00:00:00'),\n",
       " Timestamp('2002-11-04 00:00:00'),\n",
       " Timestamp('2005-01-21 00:00:00'),\n",
       " Timestamp('2007-06-07 00:00:00'),\n",
       " Timestamp('2008-12-15 00:00:00'),\n",
       " Timestamp('2009-02-10 00:00:00'),\n",
       " Timestamp('2014-03-26 00:00:00'),\n",
       " Timestamp('2003-10-30 00:00:00'),\n",
       " Timestamp('2009-08-21 00:00:00'),\n",
       " Timestamp('2013-03-07 00:00:00'),\n",
       " Timestamp('2010-01-25 00:00:00'),\n",
       " Timestamp('2014-10-16 00:00:00'),\n",
       " Timestamp('2010-04-08 00:00:00'),\n",
       " Timestamp('2021-08-10 00:00:00'),\n",
       " Timestamp('2003-09-01 00:00:00'),\n",
       " Timestamp('2011-04-22 00:00:00'),\n",
       " Timestamp('2022-07-06 00:00:00'),\n",
       " Timestamp('2005-01-27 00:00:00'),\n",
       " Timestamp('2009-05-18 00:00:00'),\n",
       " Timestamp('2012-06-25 00:00:00'),\n",
       " Timestamp('2021-04-12 00:00:00'),\n",
       " Timestamp('2011-08-04 00:00:00'),\n",
       " Timestamp('2007-05-22 00:00:00'),\n",
       " Timestamp('2022-08-25 00:00:00'),\n",
       " Timestamp('2015-04-30 00:00:00'),\n",
       " Timestamp('2010-08-24 00:00:00'),\n",
       " Timestamp('2008-07-10 00:00:00'),\n",
       " Timestamp('2009-08-11 00:00:00'),\n",
       " Timestamp('2007-08-23 00:00:00'),\n",
       " Timestamp('2014-02-14 00:00:00'),\n",
       " Timestamp('2009-10-12 00:00:00'),\n",
       " Timestamp('2019-02-05 00:00:00'),\n",
       " Timestamp('2017-03-14 00:00:00'),\n",
       " Timestamp('2012-01-05 00:00:00'),\n",
       " Timestamp('2016-03-28 00:00:00'),\n",
       " Timestamp('2022-06-01 00:00:00'),\n",
       " Timestamp('2014-10-09 00:00:00'),\n",
       " Timestamp('2022-12-05 00:00:00'),\n",
       " Timestamp('2015-12-10 00:00:00'),\n",
       " Timestamp('2003-04-10 00:00:00'),\n",
       " Timestamp('2010-02-18 00:00:00'),\n",
       " Timestamp('2017-02-24 00:00:00'),\n",
       " Timestamp('2022-04-27 00:00:00'),\n",
       " Timestamp('2019-08-20 00:00:00'),\n",
       " Timestamp('2016-10-04 00:00:00'),\n",
       " Timestamp('2005-11-23 00:00:00'),\n",
       " Timestamp('2005-11-09 00:00:00'),\n",
       " Timestamp('2002-05-27 00:00:00'),\n",
       " Timestamp('2006-03-08 00:00:00'),\n",
       " Timestamp('2019-11-28 00:00:00'),\n",
       " Timestamp('2003-04-25 00:00:00'),\n",
       " Timestamp('2002-08-01 00:00:00'),\n",
       " Timestamp('2010-09-17 00:00:00'),\n",
       " Timestamp('2007-05-04 00:00:00'),\n",
       " Timestamp('2013-09-03 00:00:00'),\n",
       " Timestamp('2010-12-10 00:00:00'),\n",
       " Timestamp('2004-02-25 00:00:00'),\n",
       " Timestamp('2020-03-05 00:00:00'),\n",
       " Timestamp('2020-04-06 00:00:00'),\n",
       " Timestamp('2020-10-28 00:00:00'),\n",
       " Timestamp('2018-04-27 00:00:00'),\n",
       " Timestamp('2005-02-25 00:00:00'),\n",
       " Timestamp('2009-10-16 00:00:00'),\n",
       " Timestamp('2018-10-26 00:00:00'),\n",
       " Timestamp('2012-09-12 00:00:00'),\n",
       " Timestamp('2022-08-24 00:00:00'),\n",
       " Timestamp('2022-05-13 00:00:00'),\n",
       " Timestamp('2018-04-19 00:00:00'),\n",
       " Timestamp('2014-07-03 00:00:00'),\n",
       " Timestamp('2009-12-11 00:00:00'),\n",
       " Timestamp('2022-04-11 00:00:00'),\n",
       " Timestamp('2022-06-28 00:00:00'),\n",
       " Timestamp('2004-02-09 00:00:00'),\n",
       " Timestamp('2003-03-04 00:00:00'),\n",
       " Timestamp('2003-06-26 00:00:00'),\n",
       " Timestamp('2021-05-12 00:00:00'),\n",
       " Timestamp('2017-12-27 00:00:00'),\n",
       " Timestamp('2020-01-17 00:00:00'),\n",
       " Timestamp('2016-07-08 00:00:00'),\n",
       " Timestamp('2009-04-24 00:00:00'),\n",
       " Timestamp('2004-12-23 00:00:00'),\n",
       " Timestamp('2007-06-28 00:00:00'),\n",
       " Timestamp('2010-10-28 00:00:00'),\n",
       " Timestamp('2001-10-12 00:00:00'),\n",
       " Timestamp('2011-02-24 00:00:00'),\n",
       " Timestamp('2002-06-28 00:00:00'),\n",
       " Timestamp('2006-11-16 00:00:00'),\n",
       " Timestamp('2003-07-01 00:00:00'),\n",
       " Timestamp('2017-09-28 00:00:00'),\n",
       " Timestamp('2001-08-07 00:00:00'),\n",
       " Timestamp('2006-08-29 00:00:00'),\n",
       " Timestamp('2005-04-06 00:00:00'),\n",
       " Timestamp('2005-10-06 00:00:00'),\n",
       " Timestamp('2005-11-29 00:00:00'),\n",
       " Timestamp('2013-11-07 00:00:00'),\n",
       " Timestamp('2006-01-18 00:00:00'),\n",
       " Timestamp('2006-10-03 00:00:00'),\n",
       " Timestamp('2003-09-22 00:00:00'),\n",
       " Timestamp('2020-04-15 00:00:00'),\n",
       " Timestamp('2012-02-22 00:00:00'),\n",
       " Timestamp('2003-09-30 00:00:00'),\n",
       " Timestamp('2019-03-28 00:00:00'),\n",
       " Timestamp('2013-02-12 00:00:00'),\n",
       " Timestamp('2008-07-04 00:00:00'),\n",
       " Timestamp('2015-03-23 00:00:00'),\n",
       " Timestamp('2008-06-11 00:00:00'),\n",
       " Timestamp('2004-12-20 00:00:00'),\n",
       " Timestamp('2005-03-18 00:00:00'),\n",
       " Timestamp('2008-06-17 00:00:00'),\n",
       " Timestamp('2017-08-21 00:00:00'),\n",
       " Timestamp('2019-05-14 00:00:00'),\n",
       " Timestamp('2007-06-21 00:00:00'),\n",
       " Timestamp('2014-02-11 00:00:00'),\n",
       " Timestamp('2006-08-28 00:00:00'),\n",
       " Timestamp('2004-04-09 00:00:00'),\n",
       " Timestamp('2007-10-23 00:00:00'),\n",
       " Timestamp('2002-06-06 00:00:00'),\n",
       " Timestamp('2014-04-09 00:00:00'),\n",
       " Timestamp('2003-06-25 00:00:00'),\n",
       " Timestamp('2009-04-02 00:00:00'),\n",
       " Timestamp('2007-03-26 00:00:00'),\n",
       " Timestamp('2004-05-06 00:00:00'),\n",
       " Timestamp('2008-05-05 00:00:00'),\n",
       " Timestamp('2017-09-18 00:00:00'),\n",
       " Timestamp('2017-10-16 00:00:00'),\n",
       " Timestamp('2011-03-21 00:00:00'),\n",
       " Timestamp('2001-10-17 00:00:00'),\n",
       " Timestamp('2014-05-06 00:00:00'),\n",
       " Timestamp('2004-12-06 00:00:00'),\n",
       " Timestamp('2003-03-24 00:00:00'),\n",
       " Timestamp('2020-03-17 00:00:00'),\n",
       " Timestamp('2021-07-23 00:00:00'),\n",
       " Timestamp('2017-07-07 00:00:00'),\n",
       " Timestamp('2018-07-11 00:00:00'),\n",
       " Timestamp('2003-12-24 00:00:00'),\n",
       " Timestamp('2011-07-22 00:00:00'),\n",
       " Timestamp('2007-01-30 00:00:00'),\n",
       " Timestamp('2010-04-26 00:00:00'),\n",
       " Timestamp('2013-09-16 00:00:00'),\n",
       " Timestamp('2022-10-28 00:00:00'),\n",
       " Timestamp('2010-10-22 00:00:00'),\n",
       " Timestamp('2003-02-17 00:00:00'),\n",
       " Timestamp('2015-03-16 00:00:00'),\n",
       " Timestamp('2020-10-19 00:00:00'),\n",
       " Timestamp('2005-12-15 00:00:00'),\n",
       " Timestamp('2022-12-29 00:00:00'),\n",
       " Timestamp('2009-01-20 00:00:00'),\n",
       " Timestamp('2012-06-04 00:00:00'),\n",
       " Timestamp('2021-06-11 00:00:00'),\n",
       " Timestamp('2005-08-04 00:00:00'),\n",
       " Timestamp('2006-07-25 00:00:00'),\n",
       " Timestamp('2014-08-29 00:00:00'),\n",
       " Timestamp('2010-12-16 00:00:00'),\n",
       " Timestamp('2013-05-27 00:00:00'),\n",
       " Timestamp('2009-05-22 00:00:00'),\n",
       " Timestamp('2004-01-13 00:00:00'),\n",
       " Timestamp('2007-01-17 00:00:00'),\n",
       " Timestamp('2018-01-30 00:00:00'),\n",
       " Timestamp('2006-10-13 00:00:00'),\n",
       " Timestamp('2014-05-07 00:00:00'),\n",
       " Timestamp('2004-11-18 00:00:00'),\n",
       " Timestamp('2017-12-26 00:00:00'),\n",
       " Timestamp('2004-10-07 00:00:00'),\n",
       " Timestamp('2006-01-24 00:00:00'),\n",
       " Timestamp('2022-12-22 00:00:00'),\n",
       " Timestamp('2011-06-10 00:00:00'),\n",
       " Timestamp('2015-02-10 00:00:00'),\n",
       " Timestamp('2005-11-01 00:00:00'),\n",
       " Timestamp('2018-11-13 00:00:00'),\n",
       " Timestamp('2017-11-14 00:00:00'),\n",
       " Timestamp('2002-01-14 00:00:00'),\n",
       " Timestamp('2015-05-21 00:00:00'),\n",
       " Timestamp('2002-05-13 00:00:00'),\n",
       " Timestamp('2019-02-12 00:00:00'),\n",
       " Timestamp('2001-04-16 00:00:00'),\n",
       " Timestamp('2012-06-29 00:00:00'),\n",
       " Timestamp('2021-06-23 00:00:00'),\n",
       " Timestamp('2019-06-17 00:00:00'),\n",
       " Timestamp('2005-01-13 00:00:00'),\n",
       " Timestamp('2004-05-26 00:00:00'),\n",
       " Timestamp('2011-11-22 00:00:00'),\n",
       " Timestamp('2007-10-31 00:00:00'),\n",
       " Timestamp('2021-06-28 00:00:00'),\n",
       " Timestamp('2017-01-18 00:00:00'),\n",
       " Timestamp('2014-12-15 00:00:00'),\n",
       " Timestamp('2006-08-23 00:00:00'),\n",
       " Timestamp('2020-06-23 00:00:00'),\n",
       " Timestamp('2020-07-20 00:00:00'),\n",
       " Timestamp('2016-04-13 00:00:00'),\n",
       " Timestamp('2019-03-11 00:00:00'),\n",
       " Timestamp('2008-04-29 00:00:00'),\n",
       " Timestamp('2003-11-28 00:00:00'),\n",
       " Timestamp('2012-10-17 00:00:00'),\n",
       " Timestamp('2017-10-02 00:00:00'),\n",
       " Timestamp('2002-10-04 00:00:00'),\n",
       " Timestamp('2013-11-01 00:00:00'),\n",
       " Timestamp('2011-07-06 00:00:00'),\n",
       " Timestamp('2017-10-11 00:00:00'),\n",
       " Timestamp('2017-12-15 00:00:00'),\n",
       " Timestamp('2006-11-21 00:00:00'),\n",
       " Timestamp('2002-11-19 00:00:00'),\n",
       " Timestamp('2009-09-30 00:00:00'),\n",
       " Timestamp('2009-12-03 00:00:00'),\n",
       " Timestamp('2016-07-22 00:00:00'),\n",
       " Timestamp('2007-03-22 00:00:00'),\n",
       " Timestamp('2012-04-27 00:00:00'),\n",
       " Timestamp('2008-09-12 00:00:00'),\n",
       " Timestamp('2001-08-16 00:00:00'),\n",
       " Timestamp('2015-08-05 00:00:00'),\n",
       " Timestamp('2007-11-30 00:00:00'),\n",
       " Timestamp('2020-06-04 00:00:00'),\n",
       " Timestamp('2020-09-16 00:00:00'),\n",
       " Timestamp('2012-09-04 00:00:00'),\n",
       " Timestamp('2020-12-23 00:00:00'),\n",
       " Timestamp('2002-11-05 00:00:00'),\n",
       " Timestamp('2020-06-12 00:00:00'),\n",
       " Timestamp('2007-09-06 00:00:00'),\n",
       " Timestamp('2006-11-03 00:00:00'),\n",
       " Timestamp('2005-07-07 00:00:00'),\n",
       " Timestamp('2021-12-20 00:00:00'),\n",
       " Timestamp('2020-10-21 00:00:00'),\n",
       " Timestamp('2011-10-07 00:00:00'),\n",
       " Timestamp('2009-01-08 00:00:00'),\n",
       " Timestamp('2006-08-18 00:00:00'),\n",
       " Timestamp('2021-01-26 00:00:00'),\n",
       " Timestamp('2004-04-29 00:00:00'),\n",
       " Timestamp('2013-12-23 00:00:00'),\n",
       " Timestamp('2011-03-15 00:00:00'),\n",
       " Timestamp('2013-01-03 00:00:00'),\n",
       " Timestamp('2012-01-02 00:00:00'),\n",
       " Timestamp('2006-05-26 00:00:00'),\n",
       " Timestamp('2015-02-11 00:00:00'),\n",
       " Timestamp('2011-07-20 00:00:00'),\n",
       " Timestamp('2006-06-16 00:00:00'),\n",
       " Timestamp('2002-01-21 00:00:00'),\n",
       " Timestamp('2020-05-13 00:00:00'),\n",
       " Timestamp('2017-06-28 00:00:00'),\n",
       " Timestamp('2005-05-24 00:00:00'),\n",
       " Timestamp('2010-09-13 00:00:00'),\n",
       " Timestamp('2007-07-17 00:00:00'),\n",
       " Timestamp('2020-05-26 00:00:00'),\n",
       " Timestamp('2011-05-11 00:00:00'),\n",
       " Timestamp('2005-12-23 00:00:00'),\n",
       " Timestamp('2013-07-12 00:00:00'),\n",
       " Timestamp('2019-03-29 00:00:00'),\n",
       " Timestamp('2005-05-10 00:00:00'),\n",
       " Timestamp('2018-06-11 00:00:00'),\n",
       " Timestamp('2009-06-10 00:00:00'),\n",
       " Timestamp('2022-06-10 00:00:00'),\n",
       " Timestamp('2004-12-03 00:00:00'),\n",
       " Timestamp('2006-04-25 00:00:00'),\n",
       " Timestamp('2022-01-28 00:00:00'),\n",
       " Timestamp('2012-02-01 00:00:00'),\n",
       " Timestamp('2022-02-17 00:00:00'),\n",
       " Timestamp('2016-12-14 00:00:00'),\n",
       " Timestamp('2017-11-28 00:00:00'),\n",
       " Timestamp('2001-07-16 00:00:00'),\n",
       " Timestamp('2009-05-25 00:00:00'),\n",
       " Timestamp('2002-09-17 00:00:00'),\n",
       " Timestamp('2020-08-14 00:00:00'),\n",
       " Timestamp('2007-05-16 00:00:00'),\n",
       " Timestamp('2012-05-15 00:00:00'),\n",
       " Timestamp('2007-12-12 00:00:00'),\n",
       " Timestamp('2014-09-16 00:00:00'),\n",
       " Timestamp('2001-11-13 00:00:00'),\n",
       " Timestamp('2015-06-09 00:00:00'),\n",
       " Timestamp('2021-01-14 00:00:00'),\n",
       " Timestamp('2006-02-21 00:00:00'),\n",
       " Timestamp('2011-08-03 00:00:00'),\n",
       " Timestamp('2021-03-10 00:00:00'),\n",
       " Timestamp('2012-03-15 00:00:00'),\n",
       " Timestamp('2012-10-12 00:00:00'),\n",
       " Timestamp('2021-05-14 00:00:00'),\n",
       " Timestamp('2013-03-05 00:00:00'),\n",
       " Timestamp('2021-11-25 00:00:00'),\n",
       " Timestamp('2004-04-13 00:00:00'),\n",
       " Timestamp('2002-10-14 00:00:00'),\n",
       " Timestamp('2021-06-15 00:00:00'),\n",
       " Timestamp('2020-04-03 00:00:00'),\n",
       " Timestamp('2016-10-14 00:00:00'),\n",
       " Timestamp('2020-05-29 00:00:00'),\n",
       " Timestamp('2009-01-16 00:00:00'),\n",
       " Timestamp('2008-08-29 00:00:00'),\n",
       " Timestamp('2003-01-27 00:00:00'),\n",
       " Timestamp('2007-01-12 00:00:00'),\n",
       " Timestamp('2018-03-27 00:00:00'),\n",
       " Timestamp('2011-02-23 00:00:00'),\n",
       " Timestamp('2020-02-14 00:00:00'),\n",
       " Timestamp('2022-11-07 00:00:00'),\n",
       " Timestamp('2015-03-09 00:00:00'),\n",
       " Timestamp('2018-09-28 00:00:00'),\n",
       " Timestamp('2018-07-19 00:00:00'),\n",
       " Timestamp('2010-04-06 00:00:00'),\n",
       " Timestamp('2004-12-24 00:00:00'),\n",
       " Timestamp('2013-12-04 00:00:00'),\n",
       " Timestamp('2010-04-20 00:00:00'),\n",
       " Timestamp('2007-03-13 00:00:00'),\n",
       " Timestamp('2002-09-04 00:00:00'),\n",
       " Timestamp('2015-04-20 00:00:00'),\n",
       " Timestamp('2004-05-07 00:00:00'),\n",
       " Timestamp('2007-08-01 00:00:00'),\n",
       " Timestamp('2006-03-17 00:00:00'),\n",
       " Timestamp('2009-09-10 00:00:00'),\n",
       " Timestamp('2018-03-19 00:00:00'),\n",
       " Timestamp('2010-01-28 00:00:00'),\n",
       " Timestamp('2003-12-05 00:00:00'),\n",
       " Timestamp('2002-12-19 00:00:00'),\n",
       " Timestamp('2012-08-30 00:00:00'),\n",
       " Timestamp('2002-07-04 00:00:00'),\n",
       " Timestamp('2011-09-09 00:00:00'),\n",
       " Timestamp('2009-11-26 00:00:00'),\n",
       " Timestamp('2007-11-07 00:00:00'),\n",
       " Timestamp('2015-02-23 00:00:00'),\n",
       " Timestamp('2002-12-27 00:00:00'),\n",
       " Timestamp('2022-06-14 00:00:00'),\n",
       " Timestamp('2014-05-15 00:00:00'),\n",
       " Timestamp('2018-07-04 00:00:00'),\n",
       " Timestamp('2006-06-07 00:00:00'),\n",
       " Timestamp('2012-06-22 00:00:00'),\n",
       " Timestamp('2017-08-14 00:00:00'),\n",
       " Timestamp('2016-12-05 00:00:00'),\n",
       " Timestamp('2020-03-16 00:00:00'),\n",
       " Timestamp('2019-02-22 00:00:00'),\n",
       " Timestamp('2016-08-22 00:00:00'),\n",
       " Timestamp('2001-09-24 00:00:00'),\n",
       " Timestamp('2015-02-20 00:00:00'),\n",
       " Timestamp('2018-04-12 00:00:00'),\n",
       " Timestamp('2009-01-12 00:00:00'),\n",
       " Timestamp('2015-09-18 00:00:00'),\n",
       " Timestamp('2014-11-18 00:00:00'),\n",
       " Timestamp('2018-10-10 00:00:00'),\n",
       " Timestamp('2002-02-15 00:00:00'),\n",
       " Timestamp('2010-09-14 00:00:00'),\n",
       " Timestamp('2006-04-21 00:00:00'),\n",
       " Timestamp('2009-07-29 00:00:00'),\n",
       " Timestamp('2008-05-16 00:00:00'),\n",
       " Timestamp('2002-08-09 00:00:00'),\n",
       " Timestamp('2002-05-14 00:00:00'),\n",
       " Timestamp('2019-01-01 00:00:00'),\n",
       " Timestamp('2018-10-29 00:00:00'),\n",
       " Timestamp('2020-02-26 00:00:00'),\n",
       " Timestamp('2005-08-23 00:00:00'),\n",
       " Timestamp('2012-03-19 00:00:00'),\n",
       " Timestamp('2013-05-28 00:00:00'),\n",
       " Timestamp('2019-10-28 00:00:00'),\n",
       " Timestamp('2008-08-11 00:00:00'),\n",
       " Timestamp('2008-11-06 00:00:00'),\n",
       " Timestamp('2005-09-21 00:00:00'),\n",
       " Timestamp('2020-10-20 00:00:00'),\n",
       " Timestamp('2011-09-15 00:00:00'),\n",
       " Timestamp('2009-04-21 00:00:00'),\n",
       " Timestamp('2010-11-24 00:00:00'),\n",
       " Timestamp('2004-05-19 00:00:00'),\n",
       " Timestamp('2010-09-30 00:00:00'),\n",
       " Timestamp('2021-01-20 00:00:00'),\n",
       " Timestamp('2008-12-24 00:00:00'),\n",
       " Timestamp('2021-08-11 00:00:00'),\n",
       " Timestamp('2019-07-09 00:00:00'),\n",
       " Timestamp('2005-07-15 00:00:00'),\n",
       " Timestamp('2004-02-17 00:00:00'),\n",
       " Timestamp('2007-04-24 00:00:00'),\n",
       " Timestamp('2014-12-12 00:00:00'),\n",
       " Timestamp('2017-03-30 00:00:00'),\n",
       " Timestamp('2012-02-14 00:00:00'),\n",
       " Timestamp('2013-11-15 00:00:00'),\n",
       " Timestamp('2005-06-28 00:00:00'),\n",
       " Timestamp('2019-07-15 00:00:00'),\n",
       " Timestamp('2017-06-02 00:00:00'),\n",
       " Timestamp('2021-12-08 00:00:00'),\n",
       " Timestamp('2021-01-21 00:00:00'),\n",
       " Timestamp('2022-11-25 00:00:00'),\n",
       " Timestamp('2021-10-14 00:00:00'),\n",
       " Timestamp('2015-06-18 00:00:00'),\n",
       " Timestamp('2013-10-25 00:00:00'),\n",
       " Timestamp('2015-02-05 00:00:00'),\n",
       " Timestamp('2010-12-27 00:00:00'),\n",
       " Timestamp('2004-03-22 00:00:00'),\n",
       " Timestamp('2010-06-09 00:00:00'),\n",
       " Timestamp('2002-03-15 00:00:00'),\n",
       " Timestamp('2016-07-25 00:00:00'),\n",
       " Timestamp('2019-07-11 00:00:00'),\n",
       " Timestamp('2015-02-13 00:00:00'),\n",
       " Timestamp('2021-10-07 00:00:00'),\n",
       " Timestamp('2019-06-12 00:00:00'),\n",
       " Timestamp('2010-12-20 00:00:00'),\n",
       " Timestamp('2012-11-13 00:00:00'),\n",
       " Timestamp('2021-09-10 00:00:00'),\n",
       " Timestamp('2016-04-19 00:00:00'),\n",
       " Timestamp('2011-01-05 00:00:00'),\n",
       " Timestamp('2006-03-21 00:00:00'),\n",
       " Timestamp('2022-09-29 00:00:00'),\n",
       " Timestamp('2002-07-25 00:00:00'),\n",
       " Timestamp('2022-03-02 00:00:00'),\n",
       " Timestamp('2013-10-03 00:00:00'),\n",
       " Timestamp('2001-05-16 00:00:00'),\n",
       " Timestamp('2022-06-17 00:00:00'),\n",
       " Timestamp('2009-02-06 00:00:00'),\n",
       " Timestamp('2017-09-08 00:00:00'),\n",
       " Timestamp('2021-08-31 00:00:00'),\n",
       " Timestamp('2006-04-18 00:00:00'),\n",
       " Timestamp('2006-05-05 00:00:00'),\n",
       " Timestamp('2014-09-17 00:00:00'),\n",
       " Timestamp('2003-11-11 00:00:00'),\n",
       " Timestamp('2021-02-05 00:00:00'),\n",
       " Timestamp('2010-08-25 00:00:00'),\n",
       " Timestamp('2001-08-03 00:00:00'),\n",
       " Timestamp('2021-09-20 00:00:00'),\n",
       " Timestamp('2017-05-18 00:00:00'),\n",
       " Timestamp('2010-12-08 00:00:00'),\n",
       " Timestamp('2002-12-25 00:00:00'),\n",
       " Timestamp('2006-09-11 00:00:00'),\n",
       " Timestamp('2012-12-03 00:00:00'),\n",
       " Timestamp('2021-10-11 00:00:00'),\n",
       " Timestamp('2003-09-04 00:00:00'),\n",
       " Timestamp('2018-09-03 00:00:00'),\n",
       " Timestamp('2003-06-20 00:00:00'),\n",
       " Timestamp('2003-01-13 00:00:00'),\n",
       " Timestamp('2016-09-07 00:00:00'),\n",
       " Timestamp('2010-06-01 00:00:00'),\n",
       " Timestamp('2012-05-07 00:00:00'),\n",
       " Timestamp('2003-03-27 00:00:00'),\n",
       " Timestamp('2007-02-12 00:00:00'),\n",
       " Timestamp('2009-11-18 00:00:00'),\n",
       " Timestamp('2003-10-07 00:00:00'),\n",
       " Timestamp('2020-01-10 00:00:00'),\n",
       " Timestamp('2006-06-22 00:00:00'),\n",
       " Timestamp('2017-11-15 00:00:00'),\n",
       " Timestamp('2008-11-18 00:00:00'),\n",
       " Timestamp('2015-04-14 00:00:00'),\n",
       " Timestamp('2018-09-10 00:00:00'),\n",
       " Timestamp('2020-01-03 00:00:00'),\n",
       " Timestamp('2020-08-24 00:00:00'),\n",
       " Timestamp('2014-02-18 00:00:00'),\n",
       " Timestamp('2004-07-22 00:00:00'),\n",
       " Timestamp('2019-11-15 00:00:00'),\n",
       " Timestamp('2022-10-05 00:00:00'),\n",
       " Timestamp('2004-04-20 00:00:00'),\n",
       " Timestamp('2014-07-29 00:00:00'),\n",
       " Timestamp('2008-02-12 00:00:00'),\n",
       " Timestamp('2006-03-20 00:00:00'),\n",
       " Timestamp('2003-03-20 00:00:00'),\n",
       " Timestamp('2006-01-04 00:00:00'),\n",
       " Timestamp('2010-01-01 00:00:00'),\n",
       " Timestamp('2001-09-19 00:00:00'),\n",
       " Timestamp('2015-04-03 00:00:00'),\n",
       " Timestamp('2013-02-18 00:00:00'),\n",
       " Timestamp('2022-08-10 00:00:00'),\n",
       " Timestamp('2010-01-08 00:00:00'),\n",
       " Timestamp('2001-05-07 00:00:00'),\n",
       " Timestamp('2015-05-18 00:00:00'),\n",
       " Timestamp('2008-02-04 00:00:00'),\n",
       " Timestamp('2007-11-29 00:00:00'),\n",
       " Timestamp('2016-07-21 00:00:00'),\n",
       " Timestamp('2014-12-30 00:00:00'),\n",
       " Timestamp('2018-07-10 00:00:00'),\n",
       " Timestamp('2005-12-27 00:00:00'),\n",
       " Timestamp('2016-03-04 00:00:00'),\n",
       " Timestamp('2011-05-30 00:00:00'),\n",
       " Timestamp('2008-08-19 00:00:00'),\n",
       " Timestamp('2011-06-08 00:00:00'),\n",
       " Timestamp('2020-07-08 00:00:00'),\n",
       " Timestamp('2017-08-04 00:00:00'),\n",
       " Timestamp('2023-01-03 00:00:00'),\n",
       " Timestamp('2009-11-03 00:00:00'),\n",
       " Timestamp('2011-10-26 00:00:00'),\n",
       " Timestamp('2005-08-15 00:00:00'),\n",
       " Timestamp('2016-01-28 00:00:00'),\n",
       " Timestamp('2017-04-20 00:00:00'),\n",
       " Timestamp('2005-07-14 00:00:00'),\n",
       " Timestamp('2003-09-18 00:00:00'),\n",
       " Timestamp('2008-02-28 00:00:00'),\n",
       " Timestamp('2004-12-02 00:00:00'),\n",
       " Timestamp('2014-04-25 00:00:00'),\n",
       " Timestamp('2005-02-17 00:00:00'),\n",
       " Timestamp('2012-03-21 00:00:00'),\n",
       " Timestamp('2007-07-05 00:00:00'),\n",
       " Timestamp('2006-08-15 00:00:00'),\n",
       " Timestamp('2017-03-15 00:00:00'),\n",
       " Timestamp('2012-02-24 00:00:00'),\n",
       " Timestamp('2001-05-11 00:00:00'),\n",
       " Timestamp('2016-06-08 00:00:00'),\n",
       " Timestamp('2012-08-10 00:00:00'),\n",
       " Timestamp('2021-03-30 00:00:00'),\n",
       " Timestamp('2007-08-27 00:00:00'),\n",
       " Timestamp('2008-05-15 00:00:00'),\n",
       " Timestamp('2016-05-25 00:00:00'),\n",
       " Timestamp('2022-03-11 00:00:00'),\n",
       " Timestamp('2018-01-02 00:00:00'),\n",
       " Timestamp('2015-04-13 00:00:00'),\n",
       " Timestamp('2002-06-17 00:00:00'),\n",
       " Timestamp('2013-10-17 00:00:00'),\n",
       " Timestamp('2017-11-24 00:00:00'),\n",
       " Timestamp('2012-07-26 00:00:00'),\n",
       " Timestamp('2013-07-23 00:00:00'),\n",
       " Timestamp('2003-02-04 00:00:00'),\n",
       " Timestamp('2005-07-01 00:00:00'),\n",
       " Timestamp('2022-10-17 00:00:00'),\n",
       " Timestamp('2013-11-13 00:00:00'),\n",
       " Timestamp('2002-08-19 00:00:00'),\n",
       " Timestamp('2022-12-16 00:00:00'),\n",
       " Timestamp('2020-04-02 00:00:00'),\n",
       " Timestamp('2013-08-27 00:00:00'),\n",
       " Timestamp('2003-08-07 00:00:00'),\n",
       " Timestamp('2014-11-03 00:00:00'),\n",
       " Timestamp('2012-07-18 00:00:00'),\n",
       " Timestamp('2011-09-20 00:00:00'),\n",
       " Timestamp('2013-01-08 00:00:00'),\n",
       " Timestamp('2017-09-14 00:00:00'),\n",
       " Timestamp('2016-04-14 00:00:00'),\n",
       " Timestamp('2001-06-07 00:00:00'),\n",
       " Timestamp('2021-02-19 00:00:00'),\n",
       " Timestamp('2014-09-08 00:00:00'),\n",
       " Timestamp('2003-09-11 00:00:00'),\n",
       " Timestamp('2006-05-03 00:00:00'),\n",
       " Timestamp('2004-02-19 00:00:00'),\n",
       " Timestamp('2001-04-18 00:00:00'),\n",
       " Timestamp('2010-12-22 00:00:00'),\n",
       " Timestamp('2015-07-16 00:00:00'),\n",
       " Timestamp('2004-08-26 00:00:00'),\n",
       " Timestamp('2014-07-23 00:00:00'),\n",
       " Timestamp('2017-08-24 00:00:00'),\n",
       " Timestamp('2021-07-19 00:00:00'),\n",
       " Timestamp('2006-01-05 00:00:00'),\n",
       " Timestamp('2008-07-28 00:00:00'),\n",
       " Timestamp('2017-03-23 00:00:00'),\n",
       " Timestamp('2008-06-19 00:00:00'),\n",
       " Timestamp('2009-03-24 00:00:00'),\n",
       " Timestamp('2017-12-12 00:00:00'),\n",
       " Timestamp('2008-01-23 00:00:00'),\n",
       " Timestamp('2009-06-25 00:00:00'),\n",
       " Timestamp('2007-11-05 00:00:00'),\n",
       " Timestamp('2013-08-29 00:00:00'),\n",
       " Timestamp('2013-05-07 00:00:00'),\n",
       " Timestamp('2009-11-06 00:00:00'),\n",
       " Timestamp('2010-04-29 00:00:00'),\n",
       " Timestamp('2010-05-04 00:00:00'),\n",
       " Timestamp('2005-02-22 00:00:00'),\n",
       " Timestamp('2001-11-16 00:00:00'),\n",
       " Timestamp('2020-06-09 00:00:00'),\n",
       " Timestamp('2015-06-16 00:00:00'),\n",
       " Timestamp('2010-08-10 00:00:00'),\n",
       " Timestamp('2020-01-20 00:00:00'),\n",
       " Timestamp('2008-07-01 00:00:00'),\n",
       " Timestamp('2010-05-24 00:00:00'),\n",
       " Timestamp('2010-08-31 00:00:00'),\n",
       " Timestamp('2013-02-19 00:00:00'),\n",
       " Timestamp('2011-07-26 00:00:00'),\n",
       " Timestamp('2005-01-07 00:00:00'),\n",
       " Timestamp('2009-04-03 00:00:00'),\n",
       " Timestamp('2001-06-22 00:00:00'),\n",
       " Timestamp('2007-06-11 00:00:00'),\n",
       " Timestamp('2001-04-26 00:00:00'),\n",
       " Timestamp('2011-06-27 00:00:00'),\n",
       " Timestamp('2007-07-23 00:00:00'),\n",
       " Timestamp('2002-06-26 00:00:00'),\n",
       " Timestamp('2014-12-18 00:00:00'),\n",
       " Timestamp('2006-01-17 00:00:00'),\n",
       " Timestamp('2021-03-16 00:00:00'),\n",
       " Timestamp('2004-01-01 00:00:00'),\n",
       " Timestamp('2010-09-16 00:00:00'),\n",
       " Timestamp('2011-02-15 00:00:00'),\n",
       " Timestamp('2017-10-09 00:00:00'),\n",
       " Timestamp('2009-08-13 00:00:00'),\n",
       " Timestamp('2009-07-28 00:00:00'),\n",
       " Timestamp('2010-04-05 00:00:00'),\n",
       " Timestamp('2022-02-28 00:00:00'),\n",
       " Timestamp('2015-12-04 00:00:00'),\n",
       " Timestamp('2012-11-06 00:00:00'),\n",
       " Timestamp('2006-12-13 00:00:00'),\n",
       " Timestamp('2005-02-08 00:00:00'),\n",
       " Timestamp('2003-04-03 00:00:00'),\n",
       " Timestamp('2005-08-24 00:00:00'),\n",
       " Timestamp('2013-08-14 00:00:00'),\n",
       " Timestamp('2009-12-28 00:00:00'),\n",
       " Timestamp('2006-09-08 00:00:00'),\n",
       " Timestamp('2003-09-24 00:00:00'),\n",
       " Timestamp('2022-04-14 00:00:00'),\n",
       " Timestamp('2021-10-22 00:00:00'),\n",
       " Timestamp('2020-04-14 00:00:00'),\n",
       " Timestamp('2002-12-12 00:00:00'),\n",
       " Timestamp('2015-12-29 00:00:00'),\n",
       " Timestamp('2005-03-10 00:00:00'),\n",
       " Timestamp('2002-01-31 00:00:00'),\n",
       " Timestamp('2013-07-29 00:00:00'),\n",
       " Timestamp('2014-12-25 00:00:00'),\n",
       " Timestamp('2004-12-28 00:00:00'),\n",
       " Timestamp('2015-01-02 00:00:00'),\n",
       " Timestamp('2012-09-06 00:00:00'),\n",
       " Timestamp('2014-10-22 00:00:00'),\n",
       " Timestamp('2002-06-14 00:00:00'),\n",
       " Timestamp('2009-10-05 00:00:00'),\n",
       " Timestamp('2006-12-20 00:00:00'),\n",
       " Timestamp('2009-11-05 00:00:00'),\n",
       " Timestamp('2015-04-15 00:00:00'),\n",
       " Timestamp('2021-11-10 00:00:00'),\n",
       " Timestamp('2016-02-15 00:00:00'),\n",
       " Timestamp('2018-02-06 00:00:00'),\n",
       " Timestamp('2008-07-02 00:00:00'),\n",
       " Timestamp('2002-11-29 00:00:00'),\n",
       " Timestamp('2007-12-05 00:00:00'),\n",
       " Timestamp('2013-05-14 00:00:00'),\n",
       " Timestamp('2007-01-23 00:00:00'),\n",
       " Timestamp('2006-06-29 00:00:00'),\n",
       " Timestamp('2015-01-14 00:00:00'),\n",
       " Timestamp('2010-06-28 00:00:00'),\n",
       " Timestamp('2020-07-02 00:00:00'),\n",
       " Timestamp('2018-12-13 00:00:00'),\n",
       " Timestamp('2012-12-14 00:00:00'),\n",
       " Timestamp('2019-03-21 00:00:00'),\n",
       " Timestamp('2013-12-19 00:00:00'),\n",
       " Timestamp('2008-03-19 00:00:00'),\n",
       " Timestamp('2006-10-26 00:00:00'),\n",
       " Timestamp('2005-02-28 00:00:00'),\n",
       " Timestamp('2005-01-05 00:00:00'),\n",
       " Timestamp('2003-08-21 00:00:00'),\n",
       " Timestamp('2008-01-04 00:00:00'),\n",
       " Timestamp('2017-10-24 00:00:00'),\n",
       " Timestamp('2009-12-09 00:00:00'),\n",
       " Timestamp('2020-11-05 00:00:00'),\n",
       " Timestamp('2002-05-08 00:00:00'),\n",
       " Timestamp('2011-06-29 00:00:00'),\n",
       " Timestamp('2013-04-17 00:00:00'),\n",
       " Timestamp('2011-06-30 00:00:00'),\n",
       " Timestamp('2002-05-21 00:00:00'),\n",
       " Timestamp('2007-08-06 00:00:00'),\n",
       " Timestamp('2006-04-04 00:00:00'),\n",
       " Timestamp('2020-03-13 00:00:00'),\n",
       " Timestamp('2021-08-03 00:00:00'),\n",
       " Timestamp('2009-03-02 00:00:00'),\n",
       " Timestamp('2018-05-25 00:00:00'),\n",
       " Timestamp('2013-07-26 00:00:00'),\n",
       " Timestamp('2008-07-22 00:00:00'),\n",
       " Timestamp('2015-04-07 00:00:00'),\n",
       " Timestamp('2006-01-20 00:00:00'),\n",
       " Timestamp('2001-06-08 00:00:00'),\n",
       " Timestamp('2014-05-12 00:00:00'),\n",
       " Timestamp('2007-04-09 00:00:00'),\n",
       " Timestamp('2015-07-20 00:00:00'),\n",
       " Timestamp('2015-06-04 00:00:00'),\n",
       " Timestamp('2008-04-08 00:00:00'),\n",
       " Timestamp('2019-11-19 00:00:00'),\n",
       " Timestamp('2003-02-21 00:00:00'),\n",
       " Timestamp('2019-10-11 00:00:00'),\n",
       " Timestamp('2003-11-20 00:00:00'),\n",
       " Timestamp('2021-05-06 00:00:00'),\n",
       " Timestamp('2008-10-20 00:00:00'),\n",
       " Timestamp('2011-05-04 00:00:00'),\n",
       " Timestamp('2010-08-20 00:00:00'),\n",
       " Timestamp('2016-03-09 00:00:00'),\n",
       " Timestamp('2010-05-10 00:00:00'),\n",
       " Timestamp('2012-08-31 00:00:00'),\n",
       " Timestamp('2016-01-14 00:00:00'),\n",
       " Timestamp('2020-02-21 00:00:00'),\n",
       " Timestamp('2020-10-13 00:00:00'),\n",
       " Timestamp('2016-05-04 00:00:00'),\n",
       " Timestamp('2020-07-06 00:00:00'),\n",
       " Timestamp('2015-06-03 00:00:00'),\n",
       " Timestamp('2021-07-20 00:00:00'),\n",
       " Timestamp('2003-06-03 00:00:00'),\n",
       " Timestamp('2005-07-20 00:00:00'),\n",
       " Timestamp('2005-04-14 00:00:00'),\n",
       " Timestamp('2012-08-16 00:00:00'),\n",
       " Timestamp('2021-12-31 00:00:00'),\n",
       " Timestamp('2004-08-04 00:00:00'),\n",
       " Timestamp('2003-03-25 00:00:00'),\n",
       " Timestamp('2011-06-14 00:00:00'),\n",
       " Timestamp('2010-05-17 00:00:00'),\n",
       " Timestamp('2017-05-11 00:00:00'),\n",
       " Timestamp('2009-04-15 00:00:00'),\n",
       " Timestamp('2007-04-12 00:00:00'),\n",
       " Timestamp('2008-11-10 00:00:00'),\n",
       " Timestamp('2017-08-25 00:00:00'),\n",
       " Timestamp('2021-07-07 00:00:00'),\n",
       " Timestamp('2013-07-09 00:00:00'),\n",
       " Timestamp('2011-11-07 00:00:00'),\n",
       " Timestamp('2010-05-25 00:00:00'),\n",
       " Timestamp('2004-09-24 00:00:00'),\n",
       " Timestamp('2018-06-19 00:00:00'),\n",
       " Timestamp('2005-08-02 00:00:00'),\n",
       " Timestamp('2017-01-16 00:00:00'),\n",
       " Timestamp('2006-06-27 00:00:00'),\n",
       " Timestamp('2014-06-03 00:00:00'),\n",
       " Timestamp('2001-07-05 00:00:00'),\n",
       " Timestamp('2009-02-11 00:00:00'),\n",
       " Timestamp('2018-01-16 00:00:00'),\n",
       " Timestamp('2009-01-13 00:00:00'),\n",
       " Timestamp('2003-01-21 00:00:00'),\n",
       " Timestamp('2011-11-04 00:00:00'),\n",
       " Timestamp('2008-01-28 00:00:00'),\n",
       " Timestamp('2011-01-14 00:00:00'),\n",
       " Timestamp('2007-09-10 00:00:00'),\n",
       " Timestamp('2005-07-22 00:00:00'),\n",
       " Timestamp('2022-10-21 00:00:00'),\n",
       " Timestamp('2002-10-16 00:00:00'),\n",
       " Timestamp('2020-11-25 00:00:00'),\n",
       " Timestamp('2019-03-07 00:00:00'),\n",
       " Timestamp('2003-07-16 00:00:00'),\n",
       " Timestamp('2020-12-03 00:00:00'),\n",
       " Timestamp('2010-09-28 00:00:00'),\n",
       " Timestamp('2004-09-10 00:00:00'),\n",
       " Timestamp('2011-04-01 00:00:00'),\n",
       " Timestamp('2012-02-21 00:00:00'),\n",
       " Timestamp('2018-12-03 00:00:00'),\n",
       " Timestamp('2022-10-13 00:00:00'),\n",
       " Timestamp('2019-07-04 00:00:00'),\n",
       " Timestamp('2018-10-04 00:00:00'),\n",
       " Timestamp('2011-06-20 00:00:00'),\n",
       " Timestamp('2021-07-02 00:00:00'),\n",
       " Timestamp('2017-01-23 00:00:00'),\n",
       " Timestamp('2022-03-30 00:00:00'),\n",
       " Timestamp('2021-10-15 00:00:00'),\n",
       " Timestamp('2007-12-24 00:00:00'),\n",
       " Timestamp('2003-02-07 00:00:00'),\n",
       " Timestamp('2014-10-20 00:00:00'),\n",
       " Timestamp('2011-08-05 00:00:00'),\n",
       " Timestamp('2003-07-15 00:00:00'),\n",
       " Timestamp('2013-11-25 00:00:00'),\n",
       " Timestamp('2022-06-29 00:00:00'),\n",
       " Timestamp('2012-07-17 00:00:00'),\n",
       " Timestamp('2017-05-08 00:00:00'),\n",
       " Timestamp('2015-07-01 00:00:00'),\n",
       " Timestamp('2019-06-04 00:00:00'),\n",
       " Timestamp('2020-07-17 00:00:00'),\n",
       " Timestamp('2010-10-07 00:00:00'),\n",
       " Timestamp('2014-04-14 00:00:00'),\n",
       " Timestamp('2011-12-23 00:00:00'),\n",
       " Timestamp('2004-07-21 00:00:00'),\n",
       " Timestamp('2016-02-26 00:00:00'),\n",
       " Timestamp('2020-03-27 00:00:00'),\n",
       " Timestamp('2013-08-08 00:00:00'),\n",
       " Timestamp('2022-08-12 00:00:00'),\n",
       " Timestamp('2002-07-10 00:00:00'),\n",
       " Timestamp('2002-11-20 00:00:00'),\n",
       " Timestamp('2008-09-15 00:00:00'),\n",
       " Timestamp('2007-06-20 00:00:00'),\n",
       " Timestamp('2010-06-16 00:00:00'),\n",
       " Timestamp('2007-11-09 00:00:00'),\n",
       " Timestamp('2018-11-20 00:00:00'),\n",
       " Timestamp('2010-01-12 00:00:00'),\n",
       " Timestamp('2014-01-06 00:00:00'),\n",
       " Timestamp('2008-01-25 00:00:00'),\n",
       " Timestamp('2014-08-07 00:00:00'),\n",
       " Timestamp('2018-04-17 00:00:00'),\n",
       " Timestamp('2014-01-31 00:00:00'),\n",
       " Timestamp('2012-11-22 00:00:00'),\n",
       " Timestamp('2009-11-04 00:00:00'),\n",
       " Timestamp('2008-08-14 00:00:00'),\n",
       " Timestamp('2013-04-03 00:00:00'),\n",
       " Timestamp('2012-11-19 00:00:00'),\n",
       " Timestamp('2019-07-05 00:00:00'),\n",
       " Timestamp('2022-05-19 00:00:00'),\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file_path = f\"/home/yogi/chronos-research/dataset/daily-all/ANTM.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = pd.DataFrame(df)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(by='timestamp')\n",
    "data = Dataset.from_pandas(df).train_test_split(test_size=0.2)\n",
    "\n",
    "train_ds=Dataset.from_pandas(pd.DataFrame(data['train']).sort_values(by='timestamp'))\n",
    "test_ds=Dataset.from_pandas(pd.DataFrame(data['test']).sort_values(by='timestamp'))\n",
    "\n",
    "combined_data = {}\n",
    "\n",
    "# Iterate through the columns of train and test, and combine them\n",
    "for column in data['train'].column_names:\n",
    "    combined_data[column] = [train_ds[column], test_ds[column]]\n",
    "\n",
    "# Create the combined dataset\n",
    "combined_dataset = Dataset.from_dict(combined_data)\n",
    "\n",
    "# combined_data['timestamp'][0][len(data['train']-1)]\n",
    "combined_data['timestamp'][0][len(data['train'])-1]\n",
    "combined_data['close'][1]\n",
    "data['train']['timestamp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8f74a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2001-04-16T00:00:00.000000', '2001-04-17T00:00:00.000000',\n",
       "       '2001-04-18T00:00:00.000000', ..., '2023-01-02T00:00:00.000000',\n",
       "       '2023-01-04T00:00:00.000000', '2023-01-06T00:00:00.000000'],\n",
       "      dtype='datetime64[us]')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset[0]['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db066199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf_entry= {'timestamp': array(['2001-04-18T00:00:00.000000', '2001-04-19T00:00:00.000000',\n",
      "       '2001-04-23T00:00:00.000000', ..., '2023-01-03T00:00:00.000000',\n",
      "       '2023-01-04T00:00:00.000000', '2023-01-06T00:00:00.000000'],\n",
      "      dtype='datetime64[us]'), 'close': array([ 432,  432,  432, ..., 2000, 2050, 1985])}\n",
      "field= close\n",
      "hf_entry= {'timestamp': array(['2001-04-16T00:00:00.000000', '2001-04-17T00:00:00.000000',\n",
      "       '2001-04-20T00:00:00.000000', ..., '2022-12-28T00:00:00.000000',\n",
      "       '2022-12-30T00:00:00.000000', '2023-01-05T00:00:00.000000'],\n",
      "      dtype='datetime64[us]'), 'close': array([ 432,  432,  432, ..., 2010, 1985, 1965])}\n",
      "field= close\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'start': Period('2001-04-18', 'D'),\n",
       "  'target': array([ 432,  432,  432, ..., 2000, 2050, 1985])},\n",
       " {'start': Period('2001-04-16', 'D'),\n",
       "  'target': array([ 432,  432,  432, ..., 2010, 1985, 1965])}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset.set_format(\"numpy\")\n",
    "series_fields = [\n",
    "    col\n",
    "    for col in combined_dataset.features\n",
    "    if isinstance(combined_dataset.features[col], datasets.Sequence)\n",
    "]\n",
    "series_fields.remove(\"timestamp\")\n",
    "dataset_freq = \"D\"\n",
    "\n",
    "gts_dataset = []\n",
    "for hf_entry in combined_dataset:\n",
    "    print(\"hf_entry=\", hf_entry)\n",
    "    for field in series_fields:\n",
    "        print(\"field=\", field)\n",
    "        gts_dataset.append(\n",
    "            {\n",
    "                \"start\": pd.Period(\n",
    "                    hf_entry[\"timestamp\"][0],\n",
    "                    freq=dataset_freq,\n",
    "                ),\n",
    "                \"target\": hf_entry[field],\n",
    "            }\n",
    "        )\n",
    "# assert len(gts_dataset) == dataset_length\n",
    "\n",
    "gts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50f9da04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df, remaining_df = train_test_split(gts_dataset, train_size=0.7, random_state=42)\n",
    "print(len(remaining_df))  # Untuk mengecek panjang remaining_df\n",
    "\n",
    "# valid_df, test_df = train_test_split(remaining_df, test_size=0.2 / (0.1 + 0.2), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "273e7098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4536 examples [00:00, 833166.76 examples/s]\n",
      "Generating test split: 1134 examples [00:00, 555777.14 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['timestamp', 'open', 'low', 'high', 'close', 'volume'],\n",
       "    num_rows: 4536\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "\n",
    "# Membaca file CSV\n",
    "file_path = \"/home/yogi/chronos-research/dataset/daily-all/ANTM.csv\"  # Ganti dengan path file CSV Anda\n",
    "df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
    "\n",
    "# Membagi data menjadi train dan test (80% train, 20% test)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Menyimpan data train dan test ke dalam file CSV baru\n",
    "train_df.to_csv('/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/temp/train.csv', index=False)\n",
    "test_df.to_csv('/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/temp/test.csv', index=False)\n",
    "\n",
    "data_files = {'train': '/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/temp/train.csv', \n",
    "              'test': '/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/temp/test.csv'}\n",
    "ds = datasets.load_dataset('csv', data_files=data_files, split=\"train\")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b008b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'timestamp', 'HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL', 'OT'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"autogluon/chronos_datasets_extra\", \"ETTh\", split=\"train\", trust_remote_code=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "602643de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.827000141143799,\n",
       " 5.692999839782715,\n",
       " 5.1570000648498535,\n",
       " 5.090000152587892,\n",
       " 5.357999801635742,\n",
       " 5.625999927520752,\n",
       " 7.166999816894531,\n",
       " 7.434999942779541,\n",
       " 5.559000015258789,\n",
       " 4.554999828338623,\n",
       " 4.956999778747559,\n",
       " 5.760000228881836,\n",
       " 4.689000129699707,\n",
       " 4.689000129699707,\n",
       " 5.090000152587892,\n",
       " 5.090000152587892,\n",
       " 4.2199997901916495,\n",
       " 4.75600004196167,\n",
       " 5.625999927520752,\n",
       " 5.492000102996826,\n",
       " 5.357999801635742,\n",
       " 5.090000152587892,\n",
       " 4.822999954223633,\n",
       " 4.622000217437744,\n",
       " 5.223999977111816,\n",
       " 5.1570000648498535,\n",
       " 5.1570000648498535,\n",
       " 5.1570000648498535,\n",
       " 4.554999828338623,\n",
       " 5.425000190734863,\n",
       " 5.492000102996826,\n",
       " 5.625999927520752,\n",
       " 5.559000015258789,\n",
       " 5.223999977111816,\n",
       " 9.913000106811523,\n",
       " 11.788000106811523,\n",
       " 9.645000457763672,\n",
       " 10.381999969482422,\n",
       " 8.77400016784668,\n",
       " 10.449000358581545,\n",
       " 9.845999717712402,\n",
       " 9.913000106811523,\n",
       " 10.649999618530272,\n",
       " 10.11400032043457,\n",
       " 9.979999542236328,\n",
       " 9.3100004196167,\n",
       " 9.444000244140623,\n",
       " 9.444000244140623,\n",
       " 10.381999969482422,\n",
       " 9.779000282287598,\n",
       " 10.381999969482422,\n",
       " 9.779000282287598,\n",
       " 10.717000007629396,\n",
       " 10.3149995803833,\n",
       " 12.592000007629396,\n",
       " 11.119000434875488,\n",
       " 10.649999618530272,\n",
       " 10.04699993133545,\n",
       " 11.720999717712402,\n",
       " 12.123000144958494,\n",
       " 9.979999542236328,\n",
       " 9.243000030517578,\n",
       " 10.180999755859377,\n",
       " 9.645000457763672,\n",
       " 9.779000282287598,\n",
       " 11.119000434875488,\n",
       " 11.052000045776367,\n",
       " 10.784000396728516,\n",
       " 11.185999870300291,\n",
       " 10.449000358581545,\n",
       " 9.57800006866455,\n",
       " 9.3100004196167,\n",
       " 9.913000106811523,\n",
       " 8.975000381469727,\n",
       " 8.640000343322754,\n",
       " 9.175999641418455,\n",
       " 9.109000205993652,\n",
       " 9.845999717712402,\n",
       " 11.588000297546388,\n",
       " 11.788000106811523,\n",
       " 10.583000183105469,\n",
       " 11.588000297546388,\n",
       " 11.92199993133545,\n",
       " 12.324000358581545,\n",
       " 10.381999969482422,\n",
       " 10.04699993133545,\n",
       " 10.515999794006348,\n",
       " 10.717000007629396,\n",
       " 9.979999542236328,\n",
       " 11.31999969482422,\n",
       " 11.38700008392334,\n",
       " 9.376999855041504,\n",
       " 10.11400032043457,\n",
       " 10.381999969482422,\n",
       " 9.645000457763672,\n",
       " 12.72599983215332,\n",
       " 11.98900032043457,\n",
       " 12.524999618530272,\n",
       " 12.324000358581545,\n",
       " 10.717000007629396,\n",
       " 11.31999969482422,\n",
       " 10.85099983215332,\n",
       " 13.32900047302246,\n",
       " 11.45400047302246,\n",
       " 11.052000045776367,\n",
       " 10.984999656677246,\n",
       " 12.79300022125244,\n",
       " 13.395999908447266,\n",
       " 11.253000259399414,\n",
       " 9.913000106811523,\n",
       " 10.180999755859377,\n",
       " 10.85099983215332,\n",
       " 10.04699993133545,\n",
       " 11.92199993133545,\n",
       " 11.45400047302246,\n",
       " 10.85099983215332,\n",
       " 11.185999870300291,\n",
       " 10.649999618530272,\n",
       " 9.979999542236328,\n",
       " 11.854999542236328,\n",
       " 10.381999969482422,\n",
       " 10.717000007629396,\n",
       " 10.85099983215332,\n",
       " 9.779000282287598,\n",
       " 9.376999855041504,\n",
       " 11.38700008392334,\n",
       " 11.854999542236328,\n",
       " 12.524999618530272,\n",
       " 12.72599983215332,\n",
       " 11.119000434875488,\n",
       " 11.788000106811523,\n",
       " 13.128000259399414,\n",
       " 10.583000183105469,\n",
       " 10.3149995803833,\n",
       " 9.444000244140623,\n",
       " 10.449000358581545,\n",
       " 9.845999717712402,\n",
       " 10.984999656677246,\n",
       " 10.717000007629396,\n",
       " 9.175999641418455,\n",
       " 9.645000457763672,\n",
       " 8.505999565124513,\n",
       " 10.515999794006348,\n",
       " 13.395999908447266,\n",
       " 12.592000007629396,\n",
       " 14.199999809265137,\n",
       " 12.592000007629396,\n",
       " 14.267000198364258,\n",
       " 12.592000007629396,\n",
       " 13.730999946594238,\n",
       " 15.13700008392334,\n",
       " 14.267000198364258,\n",
       " 12.524999618530272,\n",
       " 12.324000358581545,\n",
       " 13.26200008392334,\n",
       " 12.324000358581545,\n",
       " 9.645000457763672,\n",
       " 10.515999794006348,\n",
       " 9.376999855041504,\n",
       " 9.109000205993652,\n",
       " 9.243000030517578,\n",
       " 10.449000358581545,\n",
       " 11.052000045776367,\n",
       " 10.11400032043457,\n",
       " 11.119000434875488,\n",
       " 10.449000358581545,\n",
       " 10.515999794006348,\n",
       " 11.854999542236328,\n",
       " 11.854999542236328,\n",
       " 10.381999969482422,\n",
       " 11.185999870300291,\n",
       " 10.248000144958496,\n",
       " 10.91800022125244,\n",
       " 12.659000396728516,\n",
       " 13.597000122070312,\n",
       " 10.381999969482422,\n",
       " 9.979999542236328,\n",
       " 9.645000457763672,\n",
       " 11.720999717712402,\n",
       " 11.788000106811523,\n",
       " 10.449000358581545,\n",
       " 10.180999755859377,\n",
       " 12.927000045776367,\n",
       " 10.180999755859377,\n",
       " 9.444000244140623,\n",
       " 10.3149995803833,\n",
       " 10.717000007629396,\n",
       " 10.180999755859377,\n",
       " 11.854999542236328,\n",
       " 12.72599983215332,\n",
       " 14.065999984741213,\n",
       " 18.152000427246094,\n",
       " 14.60200023651123,\n",
       " 14.53499984741211,\n",
       " 14.401000022888184,\n",
       " 13.99899959564209,\n",
       " 14.065999984741213,\n",
       " 14.267000198364258,\n",
       " 14.60200023651123,\n",
       " 9.109000205993652,\n",
       " 11.45400047302246,\n",
       " 9.779000282287598,\n",
       " 10.85099983215332,\n",
       " 10.515999794006348,\n",
       " 9.779000282287598,\n",
       " 10.248000144958496,\n",
       " 9.645000457763672,\n",
       " 9.57800006866455,\n",
       " 11.98900032043457,\n",
       " 10.784000396728516,\n",
       " 10.11400032043457,\n",
       " 9.444000244140623,\n",
       " 11.31999969482422,\n",
       " 13.529999732971191,\n",
       " 12.458000183105469,\n",
       " 13.32900047302246,\n",
       " 15.270999908447266,\n",
       " 15.538999557495115,\n",
       " 15.13700008392334,\n",
       " 14.401000022888184,\n",
       " 14.133000373840332,\n",
       " 13.99899959564209,\n",
       " 14.937000274658203,\n",
       " 13.32900047302246,\n",
       " 10.85099983215332,\n",
       " 9.845999717712402,\n",
       " 10.248000144958496,\n",
       " 11.854999542236328,\n",
       " 8.572999954223633,\n",
       " 8.640000343322754,\n",
       " 8.305999755859375,\n",
       " 8.77400016784668,\n",
       " 8.038000106811522,\n",
       " 9.175999641418455,\n",
       " 9.444000244140623,\n",
       " 8.505999565124513,\n",
       " 10.04699993133545,\n",
       " 9.711999893188477,\n",
       " 9.979999542236328,\n",
       " 9.979999542236328,\n",
       " 13.597000122070312,\n",
       " 13.597000122070312,\n",
       " 12.123000144958494,\n",
       " 11.98900032043457,\n",
       " 11.98900032043457,\n",
       " 12.994000434875488,\n",
       " 13.79800033569336,\n",
       " 12.994000434875488,\n",
       " 9.979999542236328,\n",
       " 10.11400032043457,\n",
       " 9.845999717712402,\n",
       " 10.984999656677246,\n",
       " 8.371999740600586,\n",
       " 8.907999992370605,\n",
       " 9.041999816894531,\n",
       " 9.243000030517578,\n",
       " 8.23900032043457,\n",
       " 8.975000381469727,\n",
       " 8.505999565124513,\n",
       " 7.836999893188477,\n",
       " 9.175999641418455,\n",
       " 9.175999641418455,\n",
       " 8.371999740600586,\n",
       " 10.91800022125244,\n",
       " 11.520999908447266,\n",
       " 11.520999908447266,\n",
       " 12.123000144958494,\n",
       " 11.92199993133545,\n",
       " 11.720999717712402,\n",
       " 11.119000434875488,\n",
       " 11.119000434875488,\n",
       " 9.444000244140623,\n",
       " 8.706999778747559,\n",
       " 8.907999992370605,\n",
       " 10.11400032043457,\n",
       " 10.85099983215332,\n",
       " 9.376999855041504,\n",
       " 9.779000282287598,\n",
       " 9.51099967956543,\n",
       " 9.243000030517578,\n",
       " 8.77400016784668,\n",
       " 9.645000457763672,\n",
       " 9.109000205993652,\n",
       " 8.572999954223633,\n",
       " 10.85099983215332,\n",
       " 10.984999656677246,\n",
       " 12.79300022125244,\n",
       " 16.007999420166016,\n",
       " 19.1560001373291,\n",
       " 16.812000274658207,\n",
       " 17.615999221801758,\n",
       " 16.343000411987305,\n",
       " 18.01799964904785,\n",
       " 18.152000427246094,\n",
       " 16.208999633789062,\n",
       " 13.463000297546388,\n",
       " 10.3149995803833,\n",
       " 8.840999603271484,\n",
       " 10.248000144958496,\n",
       " 8.572999954223633,\n",
       " 8.77400016784668,\n",
       " 9.51099967956543,\n",
       " 8.77400016784668,\n",
       " 9.3100004196167,\n",
       " 8.305999755859375,\n",
       " 8.975000381469727,\n",
       " 8.840999603271484,\n",
       " 9.041999816894531,\n",
       " 11.253000259399414,\n",
       " 11.98900032043457,\n",
       " 12.524999618530272,\n",
       " 13.597000122070312,\n",
       " 14.60200023651123,\n",
       " 13.463000297546388,\n",
       " 12.256999969482422,\n",
       " 12.256999969482422,\n",
       " 11.588000297546388,\n",
       " 11.92199993133545,\n",
       " 11.520999908447266,\n",
       " 8.77400016784668,\n",
       " 7.97100019454956,\n",
       " 8.305999755859375,\n",
       " 9.376999855041504,\n",
       " 10.04699993133545,\n",
       " 8.23900032043457,\n",
       " 8.305999755859375,\n",
       " 7.903999805450439,\n",
       " 12.1899995803833,\n",
       " 7.836999893188477,\n",
       " 7.903999805450439,\n",
       " 6.429999828338622,\n",
       " 7.836999893188477,\n",
       " 8.975000381469727,\n",
       " 8.305999755859375,\n",
       " 8.104999542236326,\n",
       " 10.11400032043457,\n",
       " 13.19499969482422,\n",
       " 13.32900047302246,\n",
       " 13.864999771118164,\n",
       " 11.98900032043457,\n",
       " 11.854999542236328,\n",
       " 11.854999542236328,\n",
       " 11.119000434875488,\n",
       " 11.98900032043457,\n",
       " 8.975000381469727,\n",
       " 9.51099967956543,\n",
       " 10.11400032043457,\n",
       " 10.3149995803833,\n",
       " 8.640000343322754,\n",
       " 8.907999992370605,\n",
       " 9.3100004196167,\n",
       " 8.171999931335451,\n",
       " 7.836999893188477,\n",
       " 8.505999565124513,\n",
       " 7.234000205993652,\n",
       " 6.966000080108643,\n",
       " 7.166999816894531,\n",
       " 8.371999740600586,\n",
       " 9.109000205993652,\n",
       " 8.907999992370605,\n",
       " 8.505999565124513,\n",
       " 10.04699993133545,\n",
       " 10.85099983215332,\n",
       " 8.907999992370605,\n",
       " 9.51099967956543,\n",
       " 9.57800006866455,\n",
       " 9.645000457763672,\n",
       " 6.2290000915527335,\n",
       " 6.966000080108643,\n",
       " 7.301000118255615,\n",
       " 8.840999603271484,\n",
       " 9.243000030517578,\n",
       " 6.429999828338622,\n",
       " 6.697999954223633,\n",
       " 7.769999980926514,\n",
       " 8.104999542236326,\n",
       " 7.099999904632568,\n",
       " 7.836999893188477,\n",
       " 7.301000118255615,\n",
       " 6.697999954223633,\n",
       " 7.836999893188477,\n",
       " 7.434999942779541,\n",
       " 8.104999542236326,\n",
       " 7.836999893188477,\n",
       " 10.180999755859377,\n",
       " 10.04699993133545,\n",
       " 9.779000282287598,\n",
       " 8.439000129699707,\n",
       " 9.041999816894531,\n",
       " 9.3100004196167,\n",
       " 11.45400047302246,\n",
       " 7.703000068664551,\n",
       " 7.836999893188477,\n",
       " 7.769999980926514,\n",
       " 9.175999641418455,\n",
       " 9.645000457763672,\n",
       " 7.636000156402588,\n",
       " 8.038000106811522,\n",
       " 8.371999740600586,\n",
       " 8.371999740600586,\n",
       " 7.703000068664551,\n",
       " 8.505999565124513,\n",
       " 8.305999755859375,\n",
       " 8.104999542236326,\n",
       " 9.913000106811523,\n",
       " 10.248000144958496,\n",
       " 12.458000183105469,\n",
       " 14.267000198364258,\n",
       " 14.53499984741211,\n",
       " 15.87399959564209,\n",
       " 15.13700008392334,\n",
       " 14.468000411987305,\n",
       " 12.1899995803833,\n",
       " 12.79300022125244,\n",
       " 13.19499969482422,\n",
       " 13.597000122070312,\n",
       " 9.913000106811523,\n",
       " 8.104999542236326,\n",
       " 8.975000381469727,\n",
       " 9.3100004196167,\n",
       " 7.636000156402588,\n",
       " 8.23900032043457,\n",
       " 8.706999778747559,\n",
       " 7.903999805450439,\n",
       " 8.439000129699707,\n",
       " 8.505999565124513,\n",
       " 8.371999740600586,\n",
       " 8.171999931335451,\n",
       " 10.515999794006348,\n",
       " 11.45400047302246,\n",
       " 12.458000183105469,\n",
       " 12.055999755859377,\n",
       " 13.597000122070312,\n",
       " 13.79800033569336,\n",
       " 12.72599983215332,\n",
       " 11.38700008392334,\n",
       " 12.524999618530272,\n",
       " 12.055999755859377,\n",
       " 10.784000396728516,\n",
       " 8.572999954223633,\n",
       " 8.706999778747559,\n",
       " 9.645000457763672,\n",
       " 9.645000457763672,\n",
       " 9.51099967956543,\n",
       " 7.703000068664551,\n",
       " 7.903999805450439,\n",
       " 7.501999855041504,\n",
       " 9.57800006866455,\n",
       " 7.903999805450439,\n",
       " 8.371999740600586,\n",
       " 7.836999893188477,\n",
       " 7.636000156402588,\n",
       " 9.645000457763672,\n",
       " 9.57800006866455,\n",
       " 8.439000129699707,\n",
       " 10.649999618530272,\n",
       " 13.529999732971191,\n",
       " 13.32900047302246,\n",
       " 12.256999969482422,\n",
       " 11.185999870300291,\n",
       " 11.788000106811523,\n",
       " 12.256999969482422,\n",
       " 13.128000259399414,\n",
       " 11.119000434875488,\n",
       " 8.038000106811522,\n",
       " 8.706999778747559,\n",
       " 10.381999969482422,\n",
       " 10.180999755859377,\n",
       " 8.038000106811522,\n",
       " 8.706999778747559,\n",
       " 9.376999855041504,\n",
       " 9.376999855041504,\n",
       " 8.505999565124513,\n",
       " 8.975000381469727,\n",
       " 9.041999816894531,\n",
       " 8.505999565124513,\n",
       " 11.98900032043457,\n",
       " 11.98900032043457,\n",
       " 15.270999908447266,\n",
       " 14.937000274658203,\n",
       " 15.20400047302246,\n",
       " 16.945999145507812,\n",
       " 15.20400047302246,\n",
       " 13.932000160217283,\n",
       " 13.730999946594238,\n",
       " 13.529999732971191,\n",
       " 14.199999809265137,\n",
       " 13.79800033569336,\n",
       " 13.932000160217283,\n",
       " 12.927000045776367,\n",
       " 10.91800022125244,\n",
       " 11.520999908447266,\n",
       " 9.376999855041504,\n",
       " 10.04699993133545,\n",
       " 9.913000106811523,\n",
       " 8.23900032043457,\n",
       " 8.23900032043457,\n",
       " 9.376999855041504,\n",
       " 9.444000244140623,\n",
       " 8.907999992370605,\n",
       " 12.592000007629396,\n",
       " 14.53499984741211,\n",
       " 14.199999809265137,\n",
       " 15.06999969482422,\n",
       " 17.816999435424805,\n",
       " 18.152000427246094,\n",
       " 16.275999069213867,\n",
       " 15.270999908447266,\n",
       " 12.524999618530272,\n",
       " 13.32900047302246,\n",
       " 12.859999656677244,\n",
       " 12.324000358581545,\n",
       " 10.515999794006348,\n",
       " 11.92199993133545,\n",
       " 11.588000297546388,\n",
       " 11.588000297546388,\n",
       " 10.515999794006348,\n",
       " 11.588000297546388,\n",
       " 11.38700008392334,\n",
       " 11.119000434875488,\n",
       " 10.11400032043457,\n",
       " 10.515999794006348,\n",
       " 9.845999717712402,\n",
       " 9.845999717712402,\n",
       " 14.267000198364258,\n",
       " 14.668999671936035,\n",
       " 16.476999282836914,\n",
       " 14.803000450134276,\n",
       " 14.53499984741211,\n",
       " 13.663999557495115,\n",
       " 12.859999656677244,\n",
       " 13.32900047302246,\n",
       " 12.659000396728516,\n",
       " 11.720999717712402,\n",
       " 11.31999969482422,\n",
       " 11.92199993133545,\n",
       " 10.11400032043457,\n",
       " 11.119000434875488,\n",
       " 11.185999870300291,\n",
       " 11.788000106811523,\n",
       " 11.854999542236328,\n",
       " 12.72599983215332,\n",
       " 12.458000183105469,\n",
       " 12.123000144958494,\n",
       " 11.119000434875488,\n",
       " 11.31999969482422,\n",
       " 11.253000259399414,\n",
       " 11.253000259399414,\n",
       " 13.597000122070312,\n",
       " 16.075000762939453,\n",
       " 16.40999984741211,\n",
       " 16.208999633789062,\n",
       " 17.079999923706055,\n",
       " 18.2189998626709,\n",
       " 18.6200008392334,\n",
       " 17.75,\n",
       " 15.06999969482422,\n",
       " 16.142000198364258,\n",
       " 15.13700008392334,\n",
       " 15.538999557495115,\n",
       " 11.119000434875488,\n",
       " 11.720999717712402,\n",
       " 12.256999969482422,\n",
       " 12.927000045776367,\n",
       " 12.79300022125244,\n",
       " 14.199999809265137,\n",
       " 13.19499969482422,\n",
       " 12.524999618530272,\n",
       " 12.256999969482422,\n",
       " 12.1899995803833,\n",
       " 11.788000106811523,\n",
       " 13.19499969482422,\n",
       " 16.945999145507812,\n",
       " 17.214000701904293,\n",
       " 18.2189998626709,\n",
       " 17.951000213623047,\n",
       " 16.745000839233402,\n",
       " 16.275999069213867,\n",
       " 16.142000198364258,\n",
       " 15.13700008392334,\n",
       " 13.19499969482422,\n",
       " 12.659000396728516,\n",
       " 12.592000007629396,\n",
       " 5.0229997634887695,\n",
       " 3.2149999141693115,\n",
       " 3.549999952316284,\n",
       " 4.019000053405762,\n",
       " 5.960999965667725,\n",
       " 13.932000160217283,\n",
       " 14.736000061035154,\n",
       " 13.663999557495115,\n",
       " 13.864999771118164,\n",
       " 12.859999656677244,\n",
       " 12.458000183105469,\n",
       " 12.123000144958494,\n",
       " 13.26200008392334,\n",
       " 17.615999221801758,\n",
       " 17.75,\n",
       " 17.347999572753903,\n",
       " 16.075000762939453,\n",
       " 17.884000778198242,\n",
       " 18.41900062561035,\n",
       " 15.87399959564209,\n",
       " 16.007999420166016,\n",
       " 12.927000045776367,\n",
       " 12.927000045776367,\n",
       " 12.994000434875488,\n",
       " 13.79800033569336,\n",
       " 11.052000045776367,\n",
       " 11.654999732971191,\n",
       " 13.32900047302246,\n",
       " 14.333999633789062,\n",
       " 14.937000274658203,\n",
       " 15.739999771118164,\n",
       " 15.404999732971191,\n",
       " 13.597000122070312,\n",
       " 13.32900047302246,\n",
       " 13.128000259399414,\n",
       " 12.79300022125244,\n",
       " 13.932000160217283,\n",
       " 18.753999710083008,\n",
       " 16.812000274658207,\n",
       " 17.482000350952152,\n",
       " 17.415000915527347,\n",
       " 16.67799949645996,\n",
       " 14.401000022888184,\n",
       " 14.468000411987305,\n",
       " 14.267000198364258,\n",
       " 14.065999984741213,\n",
       " 12.659000396728516,\n",
       " 13.19499969482422,\n",
       " 11.654999732971191,\n",
       " 12.123000144958494,\n",
       " 12.659000396728516,\n",
       " 14.937000274658203,\n",
       " 15.472000122070312,\n",
       " 16.275999069213867,\n",
       " 16.611000061035153,\n",
       " 16.075000762939453,\n",
       " 15.13700008392334,\n",
       " 12.994000434875488,\n",
       " 12.859999656677244,\n",
       " 12.72599983215332,\n",
       " 14.133000373840332,\n",
       " 19.1560001373291,\n",
       " 18.285999298095703,\n",
       " 19.423999786376957,\n",
       " 19.290000915527344,\n",
       " 21.43400001525879,\n",
       " 19.558000564575195,\n",
       " 18.95499992370605,\n",
       " 16.812000274658207,\n",
       " 17.281000137329098,\n",
       " 17.079999923706055,\n",
       " 14.668999671936035,\n",
       " 14.937000274658203,\n",
       " 11.119000434875488,\n",
       " 12.390999794006348,\n",
       " 14.267000198364258,\n",
       " 14.267000198364258,\n",
       " 15.605999946594238,\n",
       " 16.208999633789062,\n",
       " 16.075000762939453,\n",
       " 15.404999732971191,\n",
       " 13.99899959564209,\n",
       " 13.529999732971191,\n",
       " 12.994000434875488,\n",
       " 13.864999771118164,\n",
       " 18.95499992370605,\n",
       " 18.41900062561035,\n",
       " 17.482000350952152,\n",
       " 17.415000915527347,\n",
       " 17.214000701904293,\n",
       " 15.003999710083008,\n",
       " 15.338000297546388,\n",
       " 13.597000122070312,\n",
       " 12.927000045776367,\n",
       " 13.79800033569336,\n",
       " 11.31999969482422,\n",
       " 12.79300022125244,\n",
       " 11.31999969482422,\n",
       " 13.128000259399414,\n",
       " 14.53499984741211,\n",
       " 13.529999732971191,\n",
       " 15.807000160217283,\n",
       " 16.878999710083008,\n",
       " 15.605999946594238,\n",
       " 15.20400047302246,\n",
       " 14.60200023651123,\n",
       " 13.99899959564209,\n",
       " 13.060999870300291,\n",
       " 13.99899959564209,\n",
       " 19.1560001373291,\n",
       " 19.089000701904297,\n",
       " 20.295000076293945,\n",
       " 19.35700035095215,\n",
       " 21.56800079345703,\n",
       " 21.03199958801269,\n",
       " 19.558000564575195,\n",
       " 19.02199935913086,\n",
       " 17.615999221801758,\n",
       " 17.01300048828125,\n",
       " 16.40999984741211,\n",
       " 16.476999282836914,\n",
       " 14.60200023651123,\n",
       " 13.26200008392334,\n",
       " 15.338000297546388,\n",
       " 16.343000411987305,\n",
       " 17.281000137329098,\n",
       " 17.75,\n",
       " 17.214000701904293,\n",
       " 16.476999282836914,\n",
       " 15.003999710083008,\n",
       " 14.401000022888184,\n",
       " 13.864999771118164,\n",
       " 11.119000434875488,\n",
       " 17.347999572753903,\n",
       " 17.548999786376953,\n",
       " 19.290000915527344,\n",
       " 20.96500015258789,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 21.367000579833984,\n",
       " 20.496000289916992,\n",
       " 19.691999435424805,\n",
       " 18.084999084472656,\n",
       " 18.2189998626709,\n",
       " 15.807000160217283,\n",
       " 16.075000762939453,\n",
       " 18.01799964904785,\n",
       " 15.940999984741213,\n",
       " 14.53499984741211,\n",
       " 11.98900032043457,\n",
       " 13.128000259399414,\n",
       " 13.395999908447266,\n",
       " 14.736000061035154,\n",
       " 15.605999946594238,\n",
       " 15.06999969482422,\n",
       " 13.730999946594238,\n",
       " 12.72599983215332,\n",
       " 12.659000396728516,\n",
       " 10.717000007629396,\n",
       " 11.98900032043457,\n",
       " 18.01799964904785,\n",
       " 19.290000915527344,\n",
       " 18.55299949645996,\n",
       " 19.959999084472656,\n",
       " 22.304000854492188,\n",
       " 20.83099937438965,\n",
       " 21.299999237060547,\n",
       " 19.290000915527344,\n",
       " 19.089000701904297,\n",
       " 18.41900062561035,\n",
       " 16.611000061035153,\n",
       " 16.075000762939453,\n",
       " 13.26200008392334,\n",
       " 12.659000396728516,\n",
       " 13.463000297546388,\n",
       " 14.267000198364258,\n",
       " 14.803000450134276,\n",
       " 14.468000411987305,\n",
       " 12.055999755859377,\n",
       " 11.185999870300291,\n",
       " 10.449000358581545,\n",
       " 10.984999656677246,\n",
       " 8.640000343322754,\n",
       " 9.51099967956543,\n",
       " 12.994000434875488,\n",
       " 11.588000297546388,\n",
       " 12.659000396728516,\n",
       " 15.003999710083008,\n",
       " 14.668999671936035,\n",
       " 13.79800033569336,\n",
       " 9.57800006866455,\n",
       " 9.376999855041504,\n",
       " 9.57800006866455,\n",
       " 8.371999740600586,\n",
       " 9.913000106811523,\n",
       " 9.779000282287598,\n",
       " 6.63100004196167,\n",
       " 6.966000080108643,\n",
       " 4.622000217437744,\n",
       " 3.013999938964844,\n",
       " 2.2769999504089355,\n",
       " 2.4110000133514404,\n",
       " 2.5450000762939453,\n",
       " 2.2769999504089355,\n",
       " 5.357999801635742,\n",
       " 8.640000343322754,\n",
       " 8.439000129699707,\n",
       " 8.171999931335451,\n",
       " 10.649999618530272,\n",
       " 9.243000030517578,\n",
       " 8.706999778747559,\n",
       " 8.572999954223633,\n",
       " 9.444000244140623,\n",
       " 9.041999816894531,\n",
       " 8.439000129699707,\n",
       " 8.23900032043457,\n",
       " 7.903999805450439,\n",
       " 8.305999755859375,\n",
       " 8.77400016784668,\n",
       " 8.640000343322754,\n",
       " 8.706999778747559,\n",
       " 9.109000205993652,\n",
       " 10.85099983215332,\n",
       " 8.907999992370605,\n",
       " 8.23900032043457,\n",
       " 8.104999542236326,\n",
       " 7.434999942779541,\n",
       " 8.104999542236326,\n",
       " 7.636000156402588,\n",
       " 8.305999755859375,\n",
       " 8.23900032043457,\n",
       " 8.104999542236326,\n",
       " 10.91800022125244,\n",
       " 9.979999542236328,\n",
       " 10.784000396728516,\n",
       " 12.524999618530272,\n",
       " 13.79800033569336,\n",
       " 11.654999732971191,\n",
       " 13.864999771118164,\n",
       " 11.45400047302246,\n",
       " 13.395999908447266,\n",
       " 12.123000144958494,\n",
       " 14.267000198364258,\n",
       " 13.463000297546388,\n",
       " 10.85099983215332,\n",
       " 9.979999542236328,\n",
       " 11.119000434875488,\n",
       " 10.984999656677246,\n",
       " 8.23900032043457,\n",
       " 9.041999816894531,\n",
       " 8.907999992370605,\n",
       " 9.041999816894531,\n",
       " 8.439000129699707,\n",
       " 9.243000030517578,\n",
       " 8.23900032043457,\n",
       " 8.038000106811522,\n",
       " 10.515999794006348,\n",
       " 9.376999855041504,\n",
       " 11.253000259399414,\n",
       " 12.524999618530272,\n",
       " 14.60200023651123,\n",
       " 13.463000297546388,\n",
       " 13.395999908447266,\n",
       " 13.060999870300291,\n",
       " 13.128000259399414,\n",
       " 13.932000160217283,\n",
       " 13.79800033569336,\n",
       " 12.524999618530272,\n",
       " 9.243000030517578,\n",
       " 9.711999893188477,\n",
       " 11.38700008392334,\n",
       " 11.588000297546388,\n",
       " 10.04699993133545,\n",
       " 10.11400032043457,\n",
       " 9.913000106811523,\n",
       " 9.645000457763672,\n",
       " 9.779000282287598,\n",
       " 10.04699993133545,\n",
       " 9.645000457763672,\n",
       " 9.913000106811523,\n",
       " 13.864999771118164,\n",
       " 12.324000358581545,\n",
       " 12.256999969482422,\n",
       " 12.055999755859377,\n",
       " 11.98900032043457,\n",
       " 11.38700008392334,\n",
       " 10.85099983215332,\n",
       " 9.243000030517578,\n",
       " 9.645000457763672,\n",
       " 9.175999641418455,\n",
       " 10.449000358581545,\n",
       " 10.984999656677246,\n",
       " 8.305999755859375,\n",
       " 9.913000106811523,\n",
       " 11.052000045776367,\n",
       " 11.45400047302246,\n",
       " 11.052000045776367,\n",
       " 11.98900032043457,\n",
       " 11.720999717712402,\n",
       " 11.92199993133545,\n",
       " 10.649999618530272,\n",
       " 10.91800022125244,\n",
       " 9.979999542236328,\n",
       " 10.784000396728516,\n",
       " 15.404999732971191,\n",
       " 14.267000198364258,\n",
       " 13.19499969482422,\n",
       " 14.869999885559082,\n",
       " 15.472000122070312,\n",
       " 14.401000022888184,\n",
       " 12.659000396728516,\n",
       " 12.592000007629396,\n",
       " 12.72599983215332,\n",
       " 13.395999908447266,\n",
       " 13.26200008392334,\n",
       " 11.654999732971191,\n",
       " 10.248000144958496,\n",
       " 9.645000457763672,\n",
       " 11.92199993133545,\n",
       " 12.123000144958494,\n",
       " 11.45400047302246,\n",
       " 12.1899995803833,\n",
       " 11.788000106811523,\n",
       " 12.055999755859377,\n",
       " 11.31999969482422,\n",
       " 11.185999870300291,\n",
       " 10.3149995803833,\n",
       " 11.45400047302246,\n",
       " 16.67799949645996,\n",
       " 17.01300048828125,\n",
       " 18.2189998626709,\n",
       " 17.816999435424805,\n",
       " 20.6299991607666,\n",
       " 19.558000564575195,\n",
       " 19.222999572753903,\n",
       " 17.951000213623047,\n",
       " 17.816999435424805,\n",
       " 18.01799964904785,\n",
       " 18.88800048828125,\n",
       " 18.2189998626709,\n",
       " 13.463000297546388,\n",
       " 11.38700008392334,\n",
       " 12.524999618530272,\n",
       " 11.92199993133545,\n",
       " 12.123000144958494,\n",
       " 12.927000045776367,\n",
       " 12.123000144958494,\n",
       " 11.45400047302246,\n",
       " 11.253000259399414,\n",
       " 10.91800022125244,\n",
       " 10.11400032043457,\n",
       " 10.3149995803833,\n",
       " 14.065999984741213,\n",
       " 14.133000373840332,\n",
       " 15.87399959564209,\n",
       " 15.338000297546388,\n",
       " 17.884000778198242,\n",
       " 16.544000625610348,\n",
       " 16.40999984741211,\n",
       " 14.803000450134276,\n",
       " 14.668999671936035,\n",
       " 14.937000274658203,\n",
       " 16.945999145507812,\n",
       " 15.538999557495115,\n",
       " 14.199999809265137,\n",
       " 11.654999732971191,\n",
       " 11.720999717712402,\n",
       " 12.659000396728516,\n",
       " 11.720999717712402,\n",
       " 13.395999908447266,\n",
       " 13.060999870300291,\n",
       " 12.256999969482422,\n",
       " 11.92199993133545,\n",
       " 11.588000297546388,\n",
       " 10.784000396728516,\n",
       " 11.854999542236328,\n",
       " 17.01300048828125,\n",
       " 15.807000160217283,\n",
       " 15.338000297546388,\n",
       " 15.20400047302246,\n",
       " 16.544000625610348,\n",
       " 14.668999671936035,\n",
       " 14.869999885559082,\n",
       " 14.937000274658203,\n",
       " 14.468000411987305,\n",
       " 13.060999870300291,\n",
       " 14.60200023651123,\n",
       " 10.04699993133545,\n",
       " 11.253000259399414,\n",
       " 11.38700008392334,\n",
       " 12.72599983215332,\n",
       " 13.864999771118164,\n",
       " 13.730999946594238,\n",
       " 14.736000061035154,\n",
       " 14.53499984741211,\n",
       " 13.26200008392334,\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['HUFL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8e0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "import numpy as np\n",
    "from gluonts.dataset.split import split\n",
    "\n",
    "df = pd.read_csv(\"/home/yogi/chronos-research/dataset/daily-all/ANTM.csv\")\n",
    "\n",
    "# Pastikan kolom 'timestamp' ada dan dikonversi ke datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Mengurutkan berdasarkan timestamp\n",
    "df = df.sort_values(by='timestamp')\n",
    "\n",
    "series_fields = [col for col in df.columns if col != 'timestamp']\n",
    "    \n",
    "# Menentukan frekuensi data (harus sudah teratur dengan interval yang konsisten)\n",
    "dataset_freq = \"D\"\n",
    "\n",
    "gts_dataset = []\n",
    "for _, row in df.iterrows():\n",
    "    for field in series_fields:\n",
    "        gts_dataset.append(\n",
    "            {\n",
    "                \"start\": pd.Period(row[\"timestamp\"], freq=dataset_freq),\n",
    "                \"target\": row[field],\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Split data menjadi train, validation, dan test\n",
    "train_df, remaining_df = train_test_split(gts_dataset, train_size=0.7, random_state=42)\n",
    "valid_df, test_df = train_test_split(remaining_df, test_size=0.2 / (0.1 + 0.2), random_state=42)\n",
    "\n",
    "# Split dataset untuk evaluasi\n",
    "_, test_template = split(test_df, offset=-60)\n",
    "test_data = test_template.generate_instances(60, windows=2, distance=20, max_history=75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ca72f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': Period('2005-12-29', 'D'), 'target': 46965580},\n",
       " {'start': Period('2001-12-05', 'D'), 'target': 432},\n",
       " {'start': Period('2015-01-26', 'D'), 'target': 894},\n",
       " {'start': Period('2006-04-14', 'D'), 'target': 0},\n",
       " {'start': Period('2016-07-19', 'D'), 'target': 820},\n",
       " {'start': Period('2019-09-05', 'D'), 'target': 1115},\n",
       " {'start': Period('2001-08-09', 'D'), 'target': 432},\n",
       " {'start': Period('2020-12-29', 'D'), 'target': 2050},\n",
       " {'start': Period('2006-07-21', 'D'), 'target': 17580841},\n",
       " {'start': Period('2014-11-05', 'D'), 'target': 785},\n",
       " {'start': Period('2015-06-30', 'D'), 'target': 4997994},\n",
       " {'start': Period('2016-05-23', 'D'), 'target': 650},\n",
       " {'start': Period('2014-06-19', 'D'), 'target': 957},\n",
       " {'start': Period('2009-08-24', 'D'), 'target': 2141},\n",
       " {'start': Period('2021-12-30', 'D'), 'target': 2250},\n",
       " {'start': Period('2007-02-27', 'D'), 'target': 1553},\n",
       " {'start': Period('2021-02-23', 'D'), 'target': 2920},\n",
       " {'start': Period('2002-05-21', 'D'), 'target': 436},\n",
       " {'start': Period('2020-07-15', 'D'), 'target': 665},\n",
       " {'start': Period('2008-04-24', 'D'), 'target': 68708441},\n",
       " {'start': Period('2011-09-15', 'D'), 'target': 15264111},\n",
       " {'start': Period('2018-10-04', 'D'), 'target': 820},\n",
       " {'start': Period('2006-04-12', 'D'), 'target': 839},\n",
       " {'start': Period('2001-06-21', 'D'), 'target': 436},\n",
       " {'start': Period('2012-09-26', 'D'), 'target': 1100},\n",
       " {'start': Period('2004-10-15', 'D'), 'target': 436},\n",
       " {'start': Period('2022-08-09', 'D'), 'target': 405818700},\n",
       " {'start': Period('2017-10-11', 'D'), 'target': 10587800},\n",
       " {'start': Period('2004-08-23', 'D'), 'target': 407},\n",
       " {'start': Period('2005-06-17', 'D'), 'target': 407},\n",
       " {'start': Period('2019-09-06', 'D'), 'target': 70609200},\n",
       " {'start': Period('2006-05-26', 'D'), 'target': 0},\n",
       " {'start': Period('2015-05-06', 'D'), 'target': 650},\n",
       " {'start': Period('2022-03-29', 'D'), 'target': 2530},\n",
       " {'start': Period('2022-01-25', 'D'), 'target': 1840},\n",
       " {'start': Period('2004-07-23', 'D'), 'target': 407},\n",
       " {'start': Period('2005-10-05', 'D'), 'target': 482},\n",
       " {'start': Period('2022-01-19', 'D'), 'target': 1705},\n",
       " {'start': Period('2011-06-01', 'D'), 'target': 1826},\n",
       " {'start': Period('2015-08-11', 'D'), 'target': 508},\n",
       " {'start': Period('2009-03-13', 'D'), 'target': 923},\n",
       " {'start': Period('2017-10-17', 'D'), 'target': 650},\n",
       " {'start': Period('2015-03-12', 'D'), 'target': 814},\n",
       " {'start': Period('2012-08-10', 'D'), 'target': 1016},\n",
       " {'start': Period('2013-01-04', 'D'), 'target': 3},\n",
       " {'start': Period('2017-12-21', 'D'), 'target': 625},\n",
       " {'start': Period('2008-09-26', 'D'), 'target': 1251},\n",
       " {'start': Period('2007-07-02', 'D'), 'target': 68076280},\n",
       " {'start': Period('2013-08-22', 'D'), 'target': 1142},\n",
       " {'start': Period('2012-03-09', 'D'), 'target': 1545},\n",
       " {'start': Period('2022-11-08', 'D'), 'target': 2000},\n",
       " {'start': Period('2014-08-14', 'D'), 'target': 1037},\n",
       " {'start': Period('2007-04-25', 'D'), 'target': 77868217},\n",
       " {'start': Period('2018-11-14', 'D'), 'target': 670},\n",
       " {'start': Period('2022-08-18', 'D'), 'target': 2070},\n",
       " {'start': Period('2009-08-26', 'D'), 'target': 2057},\n",
       " {'start': Period('2016-09-12', 'D'), 'target': 0},\n",
       " {'start': Period('2007-03-05', 'D'), 'target': 1486},\n",
       " {'start': Period('2009-09-17', 'D'), 'target': 2225},\n",
       " {'start': Period('2014-04-22', 'D'), 'target': 974},\n",
       " {'start': Period('2009-10-16', 'D'), 'target': 20874980},\n",
       " {'start': Period('2010-03-15', 'D'), 'target': 1805},\n",
       " {'start': Period('2020-08-24', 'D'), 'target': 780},\n",
       " {'start': Period('2010-12-08', 'D'), 'target': 2078},\n",
       " {'start': Period('2017-05-03', 'D'), 'target': 685},\n",
       " {'start': Period('2020-09-02', 'D'), 'target': 850},\n",
       " {'start': Period('2020-02-06', 'D'), 'target': 28180200},\n",
       " {'start': Period('2013-11-18', 'D'), 'target': 30145473},\n",
       " {'start': Period('2009-01-19', 'D'), 'target': 940},\n",
       " {'start': Period('2003-12-11', 'D'), 'target': 432},\n",
       " {'start': Period('2021-06-11', 'D'), 'target': 2500},\n",
       " {'start': Period('2015-09-18', 'D'), 'target': 398},\n",
       " {'start': Period('2016-07-12', 'D'), 'target': 770},\n",
       " {'start': Period('2008-07-10', 'D'), 'target': 2540},\n",
       " {'start': Period('2017-11-24', 'D'), 'target': 660},\n",
       " {'start': Period('2021-10-15', 'D'), 'target': 2470},\n",
       " {'start': Period('2004-03-24', 'D'), 'target': 436},\n",
       " {'start': Period('2018-07-03', 'D'), 'target': 835},\n",
       " {'start': Period('2015-01-07', 'D'), 'target': 14333014},\n",
       " {'start': Period('2001-07-09', 'D'), 'target': 432},\n",
       " {'start': Period('2005-05-05', 'D'), 'target': 436},\n",
       " {'start': Period('2013-06-05', 'D'), 'target': 1066},\n",
       " {'start': Period('2022-11-22', 'D'), 'target': 56464900},\n",
       " {'start': Period('2018-05-29', 'D'), 'target': 855},\n",
       " {'start': Period('2022-01-25', 'D'), 'target': 1755},\n",
       " {'start': Period('2006-06-27', 'D'), 'target': 705},\n",
       " {'start': Period('2002-03-14', 'D'), 'target': 0},\n",
       " {'start': Period('2014-05-29', 'D'), 'target': 0},\n",
       " {'start': Period('2002-08-07', 'D'), 'target': 436},\n",
       " {'start': Period('2005-10-12', 'D'), 'target': 474},\n",
       " {'start': Period('2018-09-05', 'D'), 'target': 800},\n",
       " {'start': Period('2017-04-20', 'D'), 'target': 715},\n",
       " {'start': Period('2002-09-30', 'D'), 'target': 432},\n",
       " {'start': Period('2014-10-22', 'D'), 'target': 806},\n",
       " {'start': Period('2018-10-15', 'D'), 'target': 800},\n",
       " {'start': Period('2011-02-03', 'D'), 'target': 1952},\n",
       " {'start': Period('2003-08-25', 'D'), 'target': 432},\n",
       " {'start': Period('2022-03-18', 'D'), 'target': 173667600},\n",
       " {'start': Period('2017-08-29', 'D'), 'target': 122694300},\n",
       " {'start': Period('2003-09-30', 'D'), 'target': 0},\n",
       " {'start': Period('2002-04-01', 'D'), 'target': 432},\n",
       " {'start': Period('2007-01-04', 'D'), 'target': 1301},\n",
       " {'start': Period('2019-07-16', 'D'), 'target': 875},\n",
       " {'start': Period('2002-03-19', 'D'), 'target': 432},\n",
       " {'start': Period('2001-08-15', 'D'), 'target': 0},\n",
       " {'start': Period('2008-03-19', 'D'), 'target': 2750},\n",
       " {'start': Period('2013-08-14', 'D'), 'target': 1091},\n",
       " {'start': Period('2005-07-28', 'D'), 'target': 432},\n",
       " {'start': Period('2006-07-27', 'D'), 'target': 797},\n",
       " {'start': Period('2014-10-09', 'D'), 'target': 856},\n",
       " {'start': Period('2018-11-05', 'D'), 'target': 685},\n",
       " {'start': Period('2001-05-03', 'D'), 'target': 432},\n",
       " {'start': Period('2016-11-01', 'D'), 'target': 895},\n",
       " {'start': Period('2021-06-25', 'D'), 'target': 2310},\n",
       " {'start': Period('2019-11-27', 'D'), 'target': 53831000},\n",
       " {'start': Period('2002-02-07', 'D'), 'target': 407},\n",
       " {'start': Period('2022-10-27', 'D'), 'target': 1820},\n",
       " {'start': Period('2012-05-18', 'D'), 'target': 1226},\n",
       " {'start': Period('2013-08-09', 'D'), 'target': 1024},\n",
       " {'start': Period('2011-02-18', 'D'), 'target': 1847},\n",
       " {'start': Period('2001-10-19', 'D'), 'target': 432},\n",
       " {'start': Period('2004-07-26', 'D'), 'target': 0},\n",
       " {'start': Period('2014-03-11', 'D'), 'target': 35698602},\n",
       " {'start': Period('2018-09-07', 'D'), 'target': 795},\n",
       " {'start': Period('2016-03-31', 'D'), 'target': 470},\n",
       " {'start': Period('2009-01-12', 'D'), 'target': 43573224},\n",
       " {'start': Period('2015-01-14', 'D'), 'target': 898},\n",
       " {'start': Period('2018-04-10', 'D'), 'target': 58705500},\n",
       " {'start': Period('2014-03-14', 'D'), 'target': 932},\n",
       " {'start': Period('2020-05-28', 'D'), 'target': 515},\n",
       " {'start': Period('2013-10-03', 'D'), 'target': 1251},\n",
       " {'start': Period('2019-12-03', 'D'), 'target': 775},\n",
       " {'start': Period('2018-02-08', 'D'), 'target': 850},\n",
       " {'start': Period('2018-10-19', 'D'), 'target': 760},\n",
       " {'start': Period('2014-04-11', 'D'), 'target': 907},\n",
       " {'start': Period('2006-06-30', 'D'), 'target': 776},\n",
       " {'start': Period('2020-04-24', 'D'), 'target': 86275300},\n",
       " {'start': Period('2011-12-16', 'D'), 'target': 6316840},\n",
       " {'start': Period('2002-01-14', 'D'), 'target': 436},\n",
       " {'start': Period('2015-04-03', 'D'), 'target': 760},\n",
       " {'start': Period('2011-03-07', 'D'), 'target': 11543175},\n",
       " {'start': Period('2016-11-22', 'D'), 'target': 76454500},\n",
       " {'start': Period('2020-08-20', 'D'), 'target': 810},\n",
       " {'start': Period('2006-06-14', 'D'), 'target': 617},\n",
       " {'start': Period('2004-11-22', 'D'), 'target': 407},\n",
       " {'start': Period('2007-07-13', 'D'), 'target': 32544349},\n",
       " {'start': Period('2009-01-21', 'D'), 'target': 915},\n",
       " {'start': Period('2006-08-28', 'D'), 'target': 923},\n",
       " {'start': Period('2020-06-24', 'D'), 'target': 620},\n",
       " {'start': Period('2018-05-24', 'D'), 'target': 845},\n",
       " {'start': Period('2012-04-27', 'D'), 'target': 3171515},\n",
       " {'start': Period('2017-02-23', 'D'), 'target': 19677800},\n",
       " {'start': Period('2009-11-17', 'D'), 'target': 1994},\n",
       " {'start': Period('2021-05-04', 'D'), 'target': 2500},\n",
       " {'start': Period('2006-12-11', 'D'), 'target': 1377},\n",
       " {'start': Period('2007-08-21', 'D'), 'target': 1889},\n",
       " {'start': Period('2004-03-15', 'D'), 'target': 407},\n",
       " {'start': Period('2005-08-03', 'D'), 'target': 0},\n",
       " {'start': Period('2019-05-15', 'D'), 'target': 720},\n",
       " {'start': Period('2016-05-31', 'D'), 'target': 650},\n",
       " {'start': Period('2008-11-12', 'D'), 'target': 932},\n",
       " {'start': Period('2008-06-16', 'D'), 'target': 2729},\n",
       " {'start': Period('2008-05-07', 'D'), 'target': 3044},\n",
       " {'start': Period('2001-12-06', 'D'), 'target': 407},\n",
       " {'start': Period('2021-09-16', 'D'), 'target': 2410},\n",
       " {'start': Period('2017-01-19', 'D'), 'target': 900},\n",
       " {'start': Period('2019-02-12', 'D'), 'target': 935},\n",
       " {'start': Period('2011-04-13', 'D'), 'target': 1973},\n",
       " {'start': Period('2006-03-17', 'D'), 'target': 722},\n",
       " {'start': Period('2016-09-27', 'D'), 'target': 780},\n",
       " {'start': Period('2008-04-23', 'D'), 'target': 2876},\n",
       " {'start': Period('2007-01-26', 'D'), 'target': 1360},\n",
       " {'start': Period('2004-08-19', 'D'), 'target': 432},\n",
       " {'start': Period('2022-09-07', 'D'), 'target': 1975},\n",
       " {'start': Period('2011-10-21', 'D'), 'target': 7995458},\n",
       " {'start': Period('2012-06-18', 'D'), 'target': 1075},\n",
       " {'start': Period('2003-12-09', 'D'), 'target': 432},\n",
       " {'start': Period('2021-12-03', 'D'), 'target': 2320},\n",
       " {'start': Period('2012-06-06', 'D'), 'target': 1016},\n",
       " {'start': Period('2020-10-01', 'D'), 'target': 45502700},\n",
       " {'start': Period('2016-02-01', 'D'), 'target': 104508600},\n",
       " {'start': Period('2016-04-06', 'D'), 'target': 505},\n",
       " {'start': Period('2003-01-21', 'D'), 'target': 432},\n",
       " {'start': Period('2020-02-27', 'D'), 'target': 650},\n",
       " {'start': Period('2013-08-07', 'D'), 'target': 1024},\n",
       " {'start': Period('2012-09-24', 'D'), 'target': 21532736},\n",
       " {'start': Period('2005-10-21', 'D'), 'target': 461},\n",
       " {'start': Period('2009-01-06', 'D'), 'target': 91663240},\n",
       " {'start': Period('2012-08-23', 'D'), 'target': 1033},\n",
       " {'start': Period('2022-10-12', 'D'), 'target': 1880},\n",
       " {'start': Period('2009-03-02', 'D'), 'target': 965},\n",
       " {'start': Period('2002-06-05', 'D'), 'target': 432},\n",
       " {'start': Period('2008-06-16', 'D'), 'target': 2729},\n",
       " {'start': Period('2008-11-25', 'D'), 'target': 122790288},\n",
       " {'start': Period('2018-04-02', 'D'), 'target': 785},\n",
       " {'start': Period('2009-02-19', 'D'), 'target': 923},\n",
       " {'start': Period('2019-01-30', 'D'), 'target': 960},\n",
       " {'start': Period('2016-03-02', 'D'), 'target': 365},\n",
       " {'start': Period('2007-07-25', 'D'), 'target': 2351},\n",
       " {'start': Period('2004-12-13', 'D'), 'target': 0},\n",
       " {'start': Period('2001-09-24', 'D'), 'target': 407},\n",
       " {'start': Period('2011-06-10', 'D'), 'target': 1763},\n",
       " {'start': Period('2014-08-04', 'D'), 'target': 31721112},\n",
       " {'start': Period('2021-06-07', 'D'), 'target': 2450},\n",
       " {'start': Period('2010-01-08', 'D'), 'target': 1973},\n",
       " {'start': Period('2013-05-06', 'D'), 'target': 3542359},\n",
       " {'start': Period('2014-03-12', 'D'), 'target': 26404299},\n",
       " {'start': Period('2020-03-12', 'D'), 'target': 490},\n",
       " {'start': Period('2010-12-10', 'D'), 'target': 11418171},\n",
       " {'start': Period('2017-03-06', 'D'), 'target': 755},\n",
       " {'start': Period('2002-12-16', 'D'), 'target': 436},\n",
       " {'start': Period('2002-09-11', 'D'), 'target': 432},\n",
       " {'start': Period('2019-07-03', 'D'), 'target': 845},\n",
       " {'start': Period('2019-05-29', 'D'), 'target': 38469900},\n",
       " {'start': Period('2014-02-05', 'D'), 'target': 839},\n",
       " {'start': Period('2007-04-25', 'D'), 'target': 2461},\n",
       " {'start': Period('2006-05-04', 'D'), 'target': 991},\n",
       " {'start': Period('2014-12-03', 'D'), 'target': 818},\n",
       " {'start': Period('2013-11-29', 'D'), 'target': 1075},\n",
       " {'start': Period('2017-01-25', 'D'), 'target': 820},\n",
       " {'start': Period('2015-01-29', 'D'), 'target': 886},\n",
       " {'start': Period('2020-02-04', 'D'), 'target': 735},\n",
       " {'start': Period('2012-05-24', 'D'), 'target': 1192},\n",
       " {'start': Period('2017-06-09', 'D'), 'target': 720},\n",
       " {'start': Period('2009-09-02', 'D'), 'target': 1847},\n",
       " {'start': Period('2017-06-30', 'D'), 'target': 695},\n",
       " {'start': Period('2006-01-16', 'D'), 'target': 785},\n",
       " {'start': Period('2001-11-29', 'D'), 'target': 436},\n",
       " {'start': Period('2010-05-28', 'D'), 'target': 0},\n",
       " {'start': Period('2003-05-05', 'D'), 'target': 436},\n",
       " {'start': Period('2006-06-29', 'D'), 'target': 760},\n",
       " {'start': Period('2006-06-06', 'D'), 'target': 697},\n",
       " {'start': Period('2003-02-13', 'D'), 'target': 436},\n",
       " {'start': Period('2008-08-29', 'D'), 'target': 1587},\n",
       " {'start': Period('2004-08-20', 'D'), 'target': 432},\n",
       " {'start': Period('2019-03-14', 'D'), 'target': 975},\n",
       " {'start': Period('2005-09-05', 'D'), 'target': 432},\n",
       " {'start': Period('2007-07-02', 'D'), 'target': 2158},\n",
       " {'start': Period('2004-01-12', 'D'), 'target': 407},\n",
       " {'start': Period('2022-08-01', 'D'), 'target': 1990},\n",
       " {'start': Period('2010-10-19', 'D'), 'target': 2057},\n",
       " {'start': Period('2004-09-30', 'D'), 'target': 407},\n",
       " {'start': Period('2021-04-28', 'D'), 'target': 138325400},\n",
       " {'start': Period('2003-06-06', 'D'), 'target': 407},\n",
       " {'start': Period('2020-04-07', 'D'), 'target': 555},\n",
       " {'start': Period('2020-07-01', 'D'), 'target': 610},\n",
       " {'start': Period('2001-05-04', 'D'), 'target': 436},\n",
       " {'start': Period('2014-07-31', 'D'), 'target': 0},\n",
       " {'start': Period('2012-10-01', 'D'), 'target': 1133},\n",
       " {'start': Period('2021-06-30', 'D'), 'target': 95174800},\n",
       " {'start': Period('2008-03-10', 'D'), 'target': 3296},\n",
       " {'start': Period('2013-03-14', 'D'), 'target': 26937051},\n",
       " {'start': Period('2002-04-22', 'D'), 'target': 432},\n",
       " {'start': Period('2016-12-13', 'D'), 'target': 895},\n",
       " {'start': Period('2004-09-13', 'D'), 'target': 432},\n",
       " {'start': Period('2015-02-16', 'D'), 'target': 11447577},\n",
       " {'start': Period('2015-09-08', 'D'), 'target': 398},\n",
       " {'start': Period('2009-12-24', 'D'), 'target': 1784},\n",
       " {'start': Period('2007-09-12', 'D'), 'target': 1931},\n",
       " {'start': Period('2009-06-25', 'D'), 'target': 1742},\n",
       " {'start': Period('2014-09-24', 'D'), 'target': 953},\n",
       " {'start': Period('2016-02-08', 'D'), 'target': 0},\n",
       " {'start': Period('2018-08-06', 'D'), 'target': 905},\n",
       " {'start': Period('2020-01-15', 'D'), 'target': 73346600},\n",
       " {'start': Period('2015-02-02', 'D'), 'target': 886},\n",
       " {'start': Period('2012-08-16', 'D'), 'target': 1033},\n",
       " {'start': Period('2021-05-26', 'D'), 'target': 0},\n",
       " {'start': Period('2013-03-21', 'D'), 'target': 1125},\n",
       " {'start': Period('2012-04-09', 'D'), 'target': 1503},\n",
       " {'start': Period('2020-03-09', 'D'), 'target': 550},\n",
       " {'start': Period('2010-01-25', 'D'), 'target': 1847},\n",
       " {'start': Period('2011-09-30', 'D'), 'target': 1217},\n",
       " {'start': Period('2002-09-06', 'D'), 'target': 407},\n",
       " {'start': Period('2018-01-19', 'D'), 'target': 765},\n",
       " {'start': Period('2013-07-11', 'D'), 'target': 865},\n",
       " {'start': Period('2008-01-25', 'D'), 'target': 2813},\n",
       " {'start': Period('2017-08-15', 'D'), 'target': 690},\n",
       " {'start': Period('2007-07-20', 'D'), 'target': 80405192},\n",
       " {'start': Period('2003-12-19', 'D'), 'target': 436},\n",
       " {'start': Period('2009-06-09', 'D'), 'target': 1805},\n",
       " {'start': Period('2003-05-19', 'D'), 'target': 432},\n",
       " {'start': Period('2015-11-10', 'D'), 'target': 271625100},\n",
       " {'start': Period('2017-11-03', 'D'), 'target': 670},\n",
       " {'start': Period('2019-01-30', 'D'), 'target': 935},\n",
       " {'start': Period('2005-03-09', 'D'), 'target': 407},\n",
       " {'start': Period('2013-09-17', 'D'), 'target': 1243},\n",
       " {'start': Period('2007-04-10', 'D'), 'target': 2444},\n",
       " {'start': Period('2018-05-17', 'D'), 'target': 815},\n",
       " {'start': Period('2003-04-15', 'D'), 'target': 0},\n",
       " {'start': Period('2006-02-22', 'D'), 'target': 655},\n",
       " {'start': Period('2019-08-09', 'D'), 'target': 1015},\n",
       " {'start': Period('2022-12-21', 'D'), 'target': 63043600},\n",
       " {'start': Period('2019-02-04', 'D'), 'target': 303518900},\n",
       " {'start': Period('2013-09-11', 'D'), 'target': 23703629},\n",
       " {'start': Period('2016-11-04', 'D'), 'target': 910},\n",
       " {'start': Period('2004-01-09', 'D'), 'target': 436},\n",
       " {'start': Period('2021-08-13', 'D'), 'target': 2410},\n",
       " {'start': Period('2009-02-03', 'D'), 'target': 907},\n",
       " {'start': Period('2006-06-16', 'D'), 'target': 701},\n",
       " {'start': Period('2009-04-27', 'D'), 'target': 1075},\n",
       " {'start': Period('2004-09-22', 'D'), 'target': 436},\n",
       " {'start': Period('2014-09-10', 'D'), 'target': 965},\n",
       " {'start': Period('2019-01-17', 'D'), 'target': 885},\n",
       " {'start': Period('2008-02-29', 'D'), 'target': 3401},\n",
       " {'start': Period('2001-10-31', 'D'), 'target': 407},\n",
       " {'start': Period('2001-11-02', 'D'), 'target': 0},\n",
       " {'start': Period('2010-11-24', 'D'), 'target': 2078},\n",
       " {'start': Period('2014-11-05', 'D'), 'target': 9918487},\n",
       " {'start': Period('2003-12-02', 'D'), 'target': 0},\n",
       " {'start': Period('2009-12-15', 'D'), 'target': 1889},\n",
       " {'start': Period('2004-09-15', 'D'), 'target': 436},\n",
       " {'start': Period('2010-06-07', 'D'), 'target': 1570},\n",
       " {'start': Period('2001-12-28', 'D'), 'target': 407},\n",
       " {'start': Period('2002-05-09', 'D'), 'target': 0},\n",
       " {'start': Period('2004-08-09', 'D'), 'target': 432},\n",
       " {'start': Period('2005-03-01', 'D'), 'target': 0},\n",
       " {'start': Period('2013-02-08', 'D'), 'target': 1150},\n",
       " {'start': Period('2019-08-06', 'D'), 'target': 945},\n",
       " {'start': Period('2007-02-07', 'D'), 'target': 1293},\n",
       " {'start': Period('2009-03-10', 'D'), 'target': 915},\n",
       " {'start': Period('2001-09-25', 'D'), 'target': 432},\n",
       " {'start': Period('2011-08-02', 'D'), 'target': 1700},\n",
       " {'start': Period('2008-06-19', 'D'), 'target': 2624},\n",
       " {'start': Period('2011-04-08', 'D'), 'target': 1952},\n",
       " {'start': Period('2020-11-25', 'D'), 'target': 303117600},\n",
       " {'start': Period('2013-05-17', 'D'), 'target': 1117},\n",
       " {'start': Period('2004-02-06', 'D'), 'target': 436},\n",
       " {'start': Period('2015-07-13', 'D'), 'target': 516},\n",
       " {'start': Period('2021-02-01', 'D'), 'target': 2640},\n",
       " {'start': Period('2014-09-03', 'D'), 'target': 982},\n",
       " {'start': Period('2017-01-06', 'D'), 'target': 885},\n",
       " {'start': Period('2004-07-09', 'D'), 'target': 436},\n",
       " {'start': Period('2015-01-28', 'D'), 'target': 881},\n",
       " {'start': Period('2021-06-30', 'D'), 'target': 2240},\n",
       " {'start': Period('2021-07-12', 'D'), 'target': 2520},\n",
       " {'start': Period('2022-04-14', 'D'), 'target': 2790},\n",
       " {'start': Period('2002-04-02', 'D'), 'target': 432},\n",
       " {'start': Period('2006-04-13', 'D'), 'target': 831},\n",
       " {'start': Period('2018-05-11', 'D'), 'target': 815},\n",
       " {'start': Period('2004-01-27', 'D'), 'target': 432},\n",
       " {'start': Period('2005-03-02', 'D'), 'target': 432},\n",
       " {'start': Period('2014-04-17', 'D'), 'target': 940},\n",
       " {'start': Period('2012-05-25', 'D'), 'target': 1167},\n",
       " {'start': Period('2007-10-11', 'D'), 'target': 2414},\n",
       " {'start': Period('2020-02-13', 'D'), 'target': 680},\n",
       " {'start': Period('2012-12-11', 'D'), 'target': 22100013},\n",
       " {'start': Period('2005-10-24', 'D'), 'target': 449},\n",
       " {'start': Period('2014-08-25', 'D'), 'target': 1033},\n",
       " {'start': Period('2018-05-24', 'D'), 'target': 63594700},\n",
       " {'start': Period('2017-05-26', 'D'), 'target': 700},\n",
       " {'start': Period('2008-11-24', 'D'), 'target': 806},\n",
       " {'start': Period('2016-08-04', 'D'), 'target': 815},\n",
       " {'start': Period('2003-09-19', 'D'), 'target': 407},\n",
       " {'start': Period('2017-03-29', 'D'), 'target': 21848400},\n",
       " {'start': Period('2013-11-15', 'D'), 'target': 1125},\n",
       " {'start': Period('2015-08-26', 'D'), 'target': 419},\n",
       " {'start': Period('2013-04-22', 'D'), 'target': 1133},\n",
       " {'start': Period('2021-10-13', 'D'), 'target': 70802000},\n",
       " {'start': Period('2005-10-07', 'D'), 'target': 457},\n",
       " {'start': Period('2001-12-05', 'D'), 'target': 436},\n",
       " {'start': Period('2020-04-17', 'D'), 'target': 530},\n",
       " {'start': Period('2004-04-07', 'D'), 'target': 436},\n",
       " {'start': Period('2016-05-17', 'D'), 'target': 685},\n",
       " {'start': Period('2017-09-13', 'D'), 'target': 680},\n",
       " {'start': Period('2019-05-29', 'D'), 'target': 705},\n",
       " {'start': Period('2010-04-13', 'D'), 'target': 59934985},\n",
       " {'start': Period('2022-01-20', 'D'), 'target': 1935},\n",
       " {'start': Period('2013-06-17', 'D'), 'target': 982},\n",
       " {'start': Period('2006-02-07', 'D'), 'target': 776},\n",
       " {'start': Period('2019-02-26', 'D'), 'target': 1045},\n",
       " {'start': Period('2002-08-01', 'D'), 'target': 0},\n",
       " {'start': Period('2014-07-24', 'D'), 'target': 1062},\n",
       " {'start': Period('2008-01-21', 'D'), 'target': 122129556},\n",
       " {'start': Period('2006-04-20', 'D'), 'target': 63067214},\n",
       " {'start': Period('2004-05-11', 'D'), 'target': 432},\n",
       " {'start': Period('2009-01-08', 'D'), 'target': 54473525},\n",
       " {'start': Period('2022-07-13', 'D'), 'target': 50792800},\n",
       " {'start': Period('2016-10-20', 'D'), 'target': 800},\n",
       " {'start': Period('2021-05-05', 'D'), 'target': 2630},\n",
       " {'start': Period('2003-01-01', 'D'), 'target': 436},\n",
       " {'start': Period('2020-03-04', 'D'), 'target': 610},\n",
       " {'start': Period('2007-07-13', 'D'), 'target': 2204},\n",
       " {'start': Period('2020-01-23', 'D'), 'target': 780},\n",
       " {'start': Period('2016-12-07', 'D'), 'target': 960},\n",
       " {'start': Period('2008-06-10', 'D'), 'target': 72621644},\n",
       " {'start': Period('2013-01-03', 'D'), 'target': 37171262},\n",
       " {'start': Period('2021-08-16', 'D'), 'target': 2390},\n",
       " {'start': Period('2010-11-11', 'D'), 'target': 2246},\n",
       " {'start': Period('2021-02-18', 'D'), 'target': 2670},\n",
       " {'start': Period('2007-09-28', 'D'), 'target': 2330},\n",
       " {'start': Period('2005-09-02', 'D'), 'target': 407},\n",
       " {'start': Period('2013-02-27', 'D'), 'target': 1066},\n",
       " {'start': Period('2014-06-19', 'D'), 'target': 974},\n",
       " {'start': Period('2018-05-17', 'D'), 'target': 810},\n",
       " {'start': Period('2017-11-30', 'D'), 'target': 665},\n",
       " {'start': Period('2008-08-04', 'D'), 'target': 2057},\n",
       " {'start': Period('2007-09-25', 'D'), 'target': 2351},\n",
       " {'start': Period('2007-11-20', 'D'), 'target': 3716},\n",
       " {'start': Period('2018-08-27', 'D'), 'target': 895},\n",
       " {'start': Period('2009-10-13', 'D'), 'target': 2225},\n",
       " {'start': Period('2006-04-06', 'D'), 'target': 802},\n",
       " {'start': Period('2009-03-04', 'D'), 'target': 974},\n",
       " {'start': Period('2017-02-10', 'D'), 'target': 28055200},\n",
       " {'start': Period('2008-05-30', 'D'), 'target': 2771},\n",
       " {'start': Period('2003-01-22', 'D'), 'target': 436},\n",
       " {'start': Period('2018-08-30', 'D'), 'target': 895},\n",
       " {'start': Period('2014-11-27', 'D'), 'target': 818},\n",
       " {'start': Period('2020-06-08', 'D'), 'target': 595},\n",
       " {'start': Period('2012-01-19', 'D'), 'target': 1453},\n",
       " {'start': Period('2018-07-18', 'D'), 'target': 910},\n",
       " {'start': Period('2013-04-15', 'D'), 'target': 12120572},\n",
       " {'start': Period('2015-10-21', 'D'), 'target': 429},\n",
       " {'start': Period('2010-10-22', 'D'), 'target': 2078},\n",
       " {'start': Period('2013-02-15', 'D'), 'target': 1142},\n",
       " {'start': Period('2015-01-30', 'D'), 'target': 898},\n",
       " {'start': Period('2015-09-29', 'D'), 'target': 22153824},\n",
       " {'start': Period('2002-10-31', 'D'), 'target': 432},\n",
       " {'start': Period('2008-09-22', 'D'), 'target': 152069071},\n",
       " {'start': Period('2004-12-30', 'D'), 'target': 436},\n",
       " {'start': Period('2021-05-21', 'D'), 'target': 2330},\n",
       " {'start': Period('2015-05-26', 'D'), 'target': 688},\n",
       " {'start': Period('2005-09-08', 'D'), 'target': 432},\n",
       " {'start': Period('2008-03-14', 'D'), 'target': 3128},\n",
       " {'start': Period('2004-06-03', 'D'), 'target': 0},\n",
       " {'start': Period('2016-11-29', 'D'), 'target': 990},\n",
       " {'start': Period('2021-07-26', 'D'), 'target': 2610},\n",
       " {'start': Period('2020-12-02', 'D'), 'target': 1260},\n",
       " {'start': Period('2011-06-14', 'D'), 'target': 10996731},\n",
       " {'start': Period('2003-12-30', 'D'), 'target': 407},\n",
       " {'start': Period('2022-11-04', 'D'), 'target': 1805},\n",
       " {'start': Period('2021-05-28', 'D'), 'target': 118544200},\n",
       " {'start': Period('2011-07-04', 'D'), 'target': 1763},\n",
       " {'start': Period('2016-04-28', 'D'), 'target': 740},\n",
       " {'start': Period('2022-11-09', 'D'), 'target': 1985},\n",
       " {'start': Period('2011-05-19', 'D'), 'target': 1868},\n",
       " {'start': Period('2019-05-16', 'D'), 'target': 715},\n",
       " {'start': Period('2016-12-26', 'D'), 'target': 860},\n",
       " {'start': Period('2014-02-28', 'D'), 'target': 873},\n",
       " {'start': Period('2007-04-27', 'D'), 'target': 2620},\n",
       " {'start': Period('2002-08-13', 'D'), 'target': 436},\n",
       " {'start': Period('2006-08-08', 'D'), 'target': 873},\n",
       " {'start': Period('2006-10-04', 'D'), 'target': 23780417},\n",
       " {'start': Period('2006-08-18', 'D'), 'target': 898},\n",
       " {'start': Period('2016-11-23', 'D'), 'target': 990},\n",
       " {'start': Period('2015-02-25', 'D'), 'target': 848},\n",
       " {'start': Period('2021-05-19', 'D'), 'target': 111892800},\n",
       " {'start': Period('2004-04-08', 'D'), 'target': 0},\n",
       " {'start': Period('2007-09-24', 'D'), 'target': 94981784},\n",
       " {'start': Period('2013-02-13', 'D'), 'target': 1133},\n",
       " {'start': Period('2011-01-10', 'D'), 'target': 1973},\n",
       " {'start': Period('2005-01-25', 'D'), 'target': 0},\n",
       " {'start': Period('2018-04-27', 'D'), 'target': 860},\n",
       " {'start': Period('2002-05-28', 'D'), 'target': 432},\n",
       " {'start': Period('2020-12-31', 'D'), 'target': 1935},\n",
       " {'start': Period('2018-04-30', 'D'), 'target': 845},\n",
       " {'start': Period('2017-07-19', 'D'), 'target': 725},\n",
       " {'start': Period('2007-05-11', 'D'), 'target': 2620},\n",
       " {'start': Period('2013-10-03', 'D'), 'target': 1201},\n",
       " {'start': Period('2018-01-25', 'D'), 'target': 810},\n",
       " {'start': Period('2019-10-11', 'D'), 'target': 985},\n",
       " {'start': Period('2007-11-20', 'D'), 'target': 3737},\n",
       " {'start': Period('2005-11-18', 'D'), 'target': 41161848},\n",
       " {'start': Period('2013-08-20', 'D'), 'target': 1016},\n",
       " {'start': Period('2006-10-26', 'D'), 'target': 1033},\n",
       " {'start': Period('2008-02-14', 'D'), 'target': 3548},\n",
       " {'start': Period('2005-09-22', 'D'), 'target': 436},\n",
       " {'start': Period('2020-07-17', 'D'), 'target': 655},\n",
       " {'start': Period('2003-01-20', 'D'), 'target': 407},\n",
       " {'start': Period('2006-11-15', 'D'), 'target': 1243},\n",
       " {'start': Period('2001-07-30', 'D'), 'target': 0},\n",
       " {'start': Period('2010-04-19', 'D'), 'target': 2015},\n",
       " {'start': Period('2004-04-26', 'D'), 'target': 432},\n",
       " {'start': Period('2009-12-29', 'D'), 'target': 1889},\n",
       " {'start': Period('2014-10-07', 'D'), 'target': 848},\n",
       " {'start': Period('2012-04-30', 'D'), 'target': 1444},\n",
       " {'start': Period('2007-11-21', 'D'), 'target': 3674},\n",
       " {'start': Period('2015-05-27', 'D'), 'target': 671},\n",
       " {'start': Period('2005-12-05', 'D'), 'target': 482},\n",
       " {'start': Period('2004-09-28', 'D'), 'target': 0},\n",
       " {'start': Period('2022-05-23', 'D'), 'target': 2530},\n",
       " {'start': Period('2006-10-18', 'D'), 'target': 1007},\n",
       " {'start': Period('2016-03-25', 'D'), 'target': 0},\n",
       " {'start': Period('2022-04-01', 'D'), 'target': 107947200},\n",
       " {'start': Period('2013-10-04', 'D'), 'target': 1209},\n",
       " {'start': Period('2001-08-03', 'D'), 'target': 0},\n",
       " {'start': Period('2014-09-12', 'D'), 'target': 961},\n",
       " {'start': Period('2014-10-06', 'D'), 'target': 877},\n",
       " {'start': Period('2003-03-17', 'D'), 'target': 432},\n",
       " {'start': Period('2007-06-19', 'D'), 'target': 28560310},\n",
       " {'start': Period('2013-10-22', 'D'), 'target': 9647884},\n",
       " {'start': Period('2009-08-12', 'D'), 'target': 2246},\n",
       " {'start': Period('2012-05-04', 'D'), 'target': 1444},\n",
       " {'start': Period('2005-05-27', 'D'), 'target': 407},\n",
       " {'start': Period('2017-05-30', 'D'), 'target': 735},\n",
       " {'start': Period('2022-01-03', 'D'), 'target': 74416700},\n",
       " {'start': Period('2022-06-03', 'D'), 'target': 2550},\n",
       " {'start': Period('2003-02-21', 'D'), 'target': 436},\n",
       " {'start': Period('2001-08-23', 'D'), 'target': 436},\n",
       " {'start': Period('2018-07-06', 'D'), 'target': 810},\n",
       " {'start': Period('2009-03-30', 'D'), 'target': 923},\n",
       " {'start': Period('2012-02-29', 'D'), 'target': 1646},\n",
       " {'start': Period('2008-05-02', 'D'), 'target': 2939},\n",
       " {'start': Period('2018-08-23', 'D'), 'target': 845},\n",
       " {'start': Period('2009-02-19', 'D'), 'target': 957},\n",
       " {'start': Period('2022-11-07', 'D'), 'target': 2020},\n",
       " {'start': Period('2009-12-29', 'D'), 'target': 32814594},\n",
       " {'start': Period('2007-04-03', 'D'), 'target': 2133},\n",
       " {'start': Period('2007-11-23', 'D'), 'target': 3905},\n",
       " {'start': Period('2020-08-05', 'D'), 'target': 182812800},\n",
       " {'start': Period('2011-06-28', 'D'), 'target': 1763},\n",
       " {'start': Period('2001-08-07', 'D'), 'target': 436},\n",
       " {'start': Period('2007-10-01', 'D'), 'target': 2309},\n",
       " {'start': Period('2008-03-06', 'D'), 'target': 51559159},\n",
       " {'start': Period('2015-09-09', 'D'), 'target': 404},\n",
       " {'start': Period('2016-06-10', 'D'), 'target': 730},\n",
       " {'start': Period('2006-05-31', 'D'), 'target': 760},\n",
       " {'start': Period('2014-10-31', 'D'), 'target': 827},\n",
       " {'start': Period('2020-03-06', 'D'), 'target': 49754200},\n",
       " {'start': Period('2014-03-31', 'D'), 'target': 953},\n",
       " {'start': Period('2008-01-24', 'D'), 'target': 2750},\n",
       " {'start': Period('2021-06-28', 'D'), 'target': 2230},\n",
       " {'start': Period('2008-02-20', 'D'), 'target': 3464},\n",
       " {'start': Period('2001-06-04', 'D'), 'target': 436},\n",
       " {'start': Period('2007-07-27', 'D'), 'target': 2204},\n",
       " {'start': Period('2021-04-01', 'D'), 'target': 2300},\n",
       " {'start': Period('2011-03-21', 'D'), 'target': 1826},\n",
       " {'start': Period('2015-08-21', 'D'), 'target': 419},\n",
       " {'start': Period('2009-07-29', 'D'), 'target': 1742},\n",
       " {'start': Period('2001-07-06', 'D'), 'target': 432},\n",
       " {'start': Period('2016-09-01', 'D'), 'target': 695},\n",
       " {'start': Period('2011-03-22', 'D'), 'target': 6101358},\n",
       " {'start': Period('2008-12-17', 'D'), 'target': 965},\n",
       " {'start': Period('2017-05-16', 'D'), 'target': 705},\n",
       " {'start': Period('2015-05-11', 'D'), 'target': 671},\n",
       " {'start': Period('2009-09-03', 'D'), 'target': 1910},\n",
       " {'start': Period('2005-04-21', 'D'), 'target': 0},\n",
       " {'start': Period('2020-11-27', 'D'), 'target': 1230},\n",
       " {'start': Period('2009-09-08', 'D'), 'target': 2120},\n",
       " {'start': Period('2007-11-12', 'D'), 'target': 3674},\n",
       " {'start': Period('2020-01-30', 'D'), 'target': 740},\n",
       " {'start': Period('2005-12-08', 'D'), 'target': 482},\n",
       " {'start': Period('2017-09-05', 'D'), 'target': 710},\n",
       " {'start': Period('2021-01-27', 'D'), 'target': 2490},\n",
       " {'start': Period('2001-04-26', 'D'), 'target': 436},\n",
       " {'start': Period('2016-12-05', 'D'), 'target': 965},\n",
       " {'start': Period('2004-01-09', 'D'), 'target': 432},\n",
       " {'start': Period('2008-10-06', 'D'), 'target': 890},\n",
       " {'start': Period('2022-08-17', 'D'), 'target': 2080},\n",
       " {'start': Period('2007-08-22', 'D'), 'target': 99621793},\n",
       " {'start': Period('2004-05-21', 'D'), 'target': 0},\n",
       " {'start': Period('2020-03-13', 'D'), 'target': 490},\n",
       " {'start': Period('2021-07-20', 'D'), 'target': 2610},\n",
       " {'start': Period('2007-11-14', 'D'), 'target': 3527},\n",
       " {'start': Period('2021-01-11', 'D'), 'target': 2530},\n",
       " {'start': Period('2012-01-03', 'D'), 'target': 1360},\n",
       " {'start': Period('2005-09-28', 'D'), 'target': 407},\n",
       " {'start': Period('2017-07-25', 'D'), 'target': 695},\n",
       " {'start': Period('2021-01-04', 'D'), 'target': 2190},\n",
       " {'start': Period('2010-09-17', 'D'), 'target': 1910},\n",
       " {'start': Period('2001-08-10', 'D'), 'target': 432},\n",
       " {'start': Period('2008-08-27', 'D'), 'target': 5678132},\n",
       " {'start': Period('2010-09-09', 'D'), 'target': 1805},\n",
       " {'start': Period('2007-05-22', 'D'), 'target': 2654},\n",
       " {'start': Period('2017-04-14', 'D'), 'target': 735},\n",
       " {'start': Period('2017-03-31', 'D'), 'target': 740},\n",
       " {'start': Period('2022-12-09', 'D'), 'target': 1980},\n",
       " {'start': Period('2014-12-16', 'D'), 'target': 21968462},\n",
       " {'start': Period('2017-12-12', 'D'), 'target': 600},\n",
       " {'start': Period('2017-04-28', 'D'), 'target': 695},\n",
       " {'start': Period('2015-02-20', 'D'), 'target': 873},\n",
       " {'start': Period('2015-04-15', 'D'), 'target': 4082255},\n",
       " {'start': Period('2003-04-24', 'D'), 'target': 432},\n",
       " {'start': Period('2016-10-05', 'D'), 'target': 220020500},\n",
       " {'start': Period('2009-01-16', 'D'), 'target': 940},\n",
       " {'start': Period('2016-01-25', 'D'), 'target': 311},\n",
       " {'start': Period('2008-01-02', 'D'), 'target': 41923179},\n",
       " {'start': Period('2001-05-09', 'D'), 'target': 436},\n",
       " {'start': Period('2021-03-09', 'D'), 'target': 2180},\n",
       " {'start': Period('2011-09-28', 'D'), 'target': 1217},\n",
       " {'start': Period('2001-08-27', 'D'), 'target': 0},\n",
       " {'start': Period('2008-03-25', 'D'), 'target': 82143335},\n",
       " {'start': Period('2010-09-29', 'D'), 'target': 19000523},\n",
       " {'start': Period('2011-06-01', 'D'), 'target': 1784},\n",
       " {'start': Period('2016-06-15', 'D'), 'target': 680},\n",
       " {'start': Period('2017-10-27', 'D'), 'target': 655},\n",
       " {'start': Period('2003-03-11', 'D'), 'target': 432},\n",
       " {'start': Period('2019-03-08', 'D'), 'target': 990},\n",
       " {'start': Period('2008-01-23', 'D'), 'target': 287213272},\n",
       " {'start': Period('2013-08-16', 'D'), 'target': 1133},\n",
       " {'start': Period('2021-10-25', 'D'), 'target': 50651600},\n",
       " {'start': Period('2017-03-16', 'D'), 'target': 54707700},\n",
       " {'start': Period('2017-03-31', 'D'), 'target': 730},\n",
       " {'start': Period('2006-03-16', 'D'), 'target': 730},\n",
       " {'start': Period('2007-09-07', 'D'), 'target': 208577772},\n",
       " {'start': Period('2012-11-29', 'D'), 'target': 1033},\n",
       " {'start': Period('2009-01-05', 'D'), 'target': 957},\n",
       " {'start': Period('2014-02-25', 'D'), 'target': 890},\n",
       " {'start': Period('2019-01-22', 'D'), 'target': 820},\n",
       " {'start': Period('2012-04-20', 'D'), 'target': 1503},\n",
       " {'start': Period('2001-12-25', 'D'), 'target': 407},\n",
       " {'start': Period('2022-05-05', 'D'), 'target': 2650},\n",
       " {'start': Period('2004-05-28', 'D'), 'target': 0},\n",
       " {'start': Period('2009-05-06', 'D'), 'target': 1268},\n",
       " {'start': Period('2019-10-10', 'D'), 'target': 106467700},\n",
       " {'start': Period('2009-12-08', 'D'), 'target': 1931},\n",
       " {'start': Period('2004-08-17', 'D'), 'target': 407},\n",
       " {'start': Period('2011-09-09', 'D'), 'target': 1595},\n",
       " {'start': Period('2019-09-17', 'D'), 'target': 1045},\n",
       " {'start': Period('2019-09-27', 'D'), 'target': 990},\n",
       " {'start': Period('2003-02-11', 'D'), 'target': 407},\n",
       " {'start': Period('2006-03-07', 'D'), 'target': 709},\n",
       " {'start': Period('2012-08-06', 'D'), 'target': 1058},\n",
       " {'start': Period('2009-02-16', 'D'), 'target': 940},\n",
       " {'start': Period('2016-02-08', 'D'), 'target': 340},\n",
       " {'start': Period('2001-05-16', 'D'), 'target': 432},\n",
       " {'start': Period('2005-09-08', 'D'), 'target': 432},\n",
       " {'start': Period('2017-05-17', 'D'), 'target': 730},\n",
       " {'start': Period('2006-05-29', 'D'), 'target': 684},\n",
       " {'start': Period('2013-10-29', 'D'), 'target': 1301},\n",
       " {'start': Period('2013-02-18', 'D'), 'target': 1125},\n",
       " {'start': Period('2005-12-16', 'D'), 'target': 562},\n",
       " {'start': Period('2016-03-08', 'D'), 'target': 213480900},\n",
       " {'start': Period('2005-10-28', 'D'), 'target': 428},\n",
       " {'start': Period('2018-12-25', 'D'), 'target': 0},\n",
       " {'start': Period('2011-11-08', 'D'), 'target': 13967646},\n",
       " {'start': Period('2015-08-05', 'D'), 'target': 503},\n",
       " {'start': Period('2005-05-10', 'D'), 'target': 432},\n",
       " {'start': Period('2008-03-21', 'D'), 'target': 0},\n",
       " {'start': Period('2010-04-22', 'D'), 'target': 2057},\n",
       " {'start': Period('2010-11-08', 'D'), 'target': 2288},\n",
       " {'start': Period('2005-08-04', 'D'), 'target': 436},\n",
       " {'start': Period('2017-07-05', 'D'), 'target': 695},\n",
       " {'start': Period('2012-04-18', 'D'), 'target': 1419},\n",
       " {'start': Period('2007-11-13', 'D'), 'target': 3779},\n",
       " {'start': Period('2013-02-26', 'D'), 'target': 1058},\n",
       " {'start': Period('2014-09-22', 'D'), 'target': 923},\n",
       " {'start': Period('2018-12-07', 'D'), 'target': 740},\n",
       " {'start': Period('2004-04-14', 'D'), 'target': 436},\n",
       " {'start': Period('2002-05-21', 'D'), 'target': 432},\n",
       " {'start': Period('2003-03-24', 'D'), 'target': 0},\n",
       " {'start': Period('2018-01-03', 'D'), 'target': 635},\n",
       " {'start': Period('2018-03-07', 'D'), 'target': 102570500},\n",
       " {'start': Period('2022-10-11', 'D'), 'target': 1895},\n",
       " {'start': Period('2006-03-24', 'D'), 'target': 726},\n",
       " {'start': Period('2009-09-28', 'D'), 'target': 2015},\n",
       " {'start': Period('2007-02-23', 'D'), 'target': 1495},\n",
       " {'start': Period('2019-03-12', 'D'), 'target': 955},\n",
       " {'start': Period('2003-01-27', 'D'), 'target': 407},\n",
       " {'start': Period('2022-09-15', 'D'), 'target': 2150},\n",
       " {'start': Period('2005-01-21', 'D'), 'target': 407},\n",
       " {'start': Period('2019-09-10', 'D'), 'target': 1130},\n",
       " {'start': Period('2020-10-16', 'D'), 'target': 940},\n",
       " {'start': Period('2004-04-23', 'D'), 'target': 432},\n",
       " {'start': Period('2008-04-16', 'D'), 'target': 2645},\n",
       " {'start': Period('2020-01-07', 'D'), 'target': 895},\n",
       " {'start': Period('2007-12-31', 'D'), 'target': 3758},\n",
       " {'start': Period('2008-10-31', 'D'), 'target': 873},\n",
       " {'start': Period('2001-08-24', 'D'), 'target': 407},\n",
       " {'start': Period('2012-06-08', 'D'), 'target': 991},\n",
       " {'start': Period('2021-09-03', 'D'), 'target': 29176500},\n",
       " {'start': Period('2021-07-16', 'D'), 'target': 2690},\n",
       " {'start': Period('2009-08-20', 'D'), 'target': 2057},\n",
       " {'start': Period('2009-07-08', 'D'), 'target': 0},\n",
       " {'start': Period('2013-01-23', 'D'), 'target': 9499666},\n",
       " {'start': Period('2003-10-31', 'D'), 'target': 432},\n",
       " {'start': Period('2008-07-22', 'D'), 'target': 2120},\n",
       " {'start': Period('2016-09-23', 'D'), 'target': 45387900},\n",
       " {'start': Period('2008-11-04', 'D'), 'target': 991},\n",
       " {'start': Period('2022-02-09', 'D'), 'target': 73968100},\n",
       " {'start': Period('2002-03-06', 'D'), 'target': 436},\n",
       " {'start': Period('2020-07-20', 'D'), 'target': 650},\n",
       " {'start': Period('2013-10-22', 'D'), 'target': 1335},\n",
       " {'start': Period('2006-12-07', 'D'), 'target': 23527434},\n",
       " {'start': Period('2014-06-23', 'D'), 'target': 7522350},\n",
       " {'start': Period('2004-03-12', 'D'), 'target': 432},\n",
       " {'start': Period('2002-03-21', 'D'), 'target': 0},\n",
       " {'start': Period('2004-10-04', 'D'), 'target': 436},\n",
       " {'start': Period('2001-12-12', 'D'), 'target': 436},\n",
       " {'start': Period('2015-05-13', 'D'), 'target': 692},\n",
       " {'start': Period('2017-06-16', 'D'), 'target': 725},\n",
       " {'start': Period('2008-10-03', 'D'), 'target': 1251},\n",
       " {'start': Period('2011-02-03', 'D'), 'target': 1931},\n",
       " {'start': Period('2011-03-22', 'D'), 'target': 1826},\n",
       " {'start': Period('2021-01-13', 'D'), 'target': 2850},\n",
       " {'start': Period('2005-05-23', 'D'), 'target': 436},\n",
       " {'start': Period('2005-07-19', 'D'), 'target': 436},\n",
       " {'start': Period('2004-09-01', 'D'), 'target': 407},\n",
       " {'start': Period('2009-09-07', 'D'), 'target': 1910},\n",
       " {'start': Period('2021-04-02', 'D'), 'target': 2240},\n",
       " {'start': Period('2017-11-09', 'D'), 'target': 103690000},\n",
       " {'start': Period('2009-05-28', 'D'), 'target': 40132058},\n",
       " {'start': Period('2015-07-03', 'D'), 'target': 571},\n",
       " {'start': Period('2007-07-13', 'D'), 'target': 2225},\n",
       " {'start': Period('2022-04-29', 'D'), 'target': 0},\n",
       " {'start': Period('2005-10-14', 'D'), 'target': 12018188},\n",
       " {'start': Period('2017-11-01', 'D'), 'target': 655},\n",
       " {'start': Period('2005-05-09', 'D'), 'target': 432},\n",
       " {'start': Period('2006-05-03', 'D'), 'target': 949},\n",
       " {'start': Period('2007-11-29', 'D'), 'target': 4031},\n",
       " {'start': Period('2001-07-04', 'D'), 'target': 407},\n",
       " {'start': Period('2005-05-24', 'D'), 'target': 407},\n",
       " {'start': Period('2010-07-20', 'D'), 'target': 1637},\n",
       " {'start': Period('2007-02-06', 'D'), 'target': 9354424},\n",
       " {'start': Period('2006-07-14', 'D'), 'target': 743},\n",
       " {'start': Period('2021-12-29', 'D'), 'target': 14304600},\n",
       " {'start': Period('2019-09-24', 'D'), 'target': 1055},\n",
       " {'start': Period('2014-09-30', 'D'), 'target': 8504758},\n",
       " {'start': Period('2011-10-17', 'D'), 'target': 1503},\n",
       " {'start': Period('2001-07-05', 'D'), 'target': 432},\n",
       " {'start': Period('2008-03-24', 'D'), 'target': 2771},\n",
       " {'start': Period('2004-01-15', 'D'), 'target': 432},\n",
       " {'start': Period('2020-09-28', 'D'), 'target': 740},\n",
       " {'start': Period('2017-03-08', 'D'), 'target': 730},\n",
       " {'start': Period('2013-02-08', 'D'), 'target': 1150},\n",
       " {'start': Period('2001-12-27', 'D'), 'target': 432},\n",
       " {'start': Period('2003-05-19', 'D'), 'target': 432},\n",
       " {'start': Period('2022-10-28', 'D'), 'target': 1835},\n",
       " {'start': Period('2012-02-13', 'D'), 'target': 1587},\n",
       " {'start': Period('2018-11-01', 'D'), 'target': 705},\n",
       " {'start': Period('2019-09-02', 'D'), 'target': 1170},\n",
       " {'start': Period('2013-01-07', 'D'), 'target': 1125},\n",
       " {'start': Period('2005-09-26', 'D'), 'target': 432},\n",
       " {'start': Period('2005-06-09', 'D'), 'target': 407},\n",
       " {'start': Period('2016-07-06', 'D'), 'target': 730},\n",
       " {'start': Period('2008-01-16', 'D'), 'target': 3275},\n",
       " {'start': Period('2016-06-27', 'D'), 'target': 70339400},\n",
       " {'start': Period('2008-06-17', 'D'), 'target': 2624},\n",
       " {'start': Period('2020-10-02', 'D'), 'target': 725},\n",
       " {'start': Period('2020-12-23', 'D'), 'target': 1790},\n",
       " {'start': Period('2010-06-02', 'D'), 'target': 1654},\n",
       " {'start': Period('2010-04-05', 'D'), 'target': 2015},\n",
       " {'start': Period('2006-08-23', 'D'), 'target': 991},\n",
       " {'start': Period('2008-01-21', 'D'), 'target': 2708},\n",
       " {'start': Period('2018-05-09', 'D'), 'target': 810},\n",
       " {'start': Period('2009-10-02', 'D'), 'target': 2099},\n",
       " {'start': Period('2008-09-29', 'D'), 'target': 0},\n",
       " {'start': Period('2009-03-09', 'D'), 'target': 957},\n",
       " {'start': Period('2011-02-11', 'D'), 'target': 1805},\n",
       " {'start': Period('2007-07-09', 'D'), 'target': 2385},\n",
       " {'start': Period('2012-06-19', 'D'), 'target': 1075},\n",
       " {'start': Period('2019-10-02', 'D'), 'target': 975},\n",
       " {'start': Period('2006-04-11', 'D'), 'target': 831},\n",
       " {'start': Period('2018-07-16', 'D'), 'target': 900},\n",
       " {'start': Period('2001-05-17', 'D'), 'target': 407},\n",
       " {'start': Period('2011-11-01', 'D'), 'target': 1419},\n",
       " {'start': Period('2007-06-27', 'D'), 'target': 2133},\n",
       " {'start': Period('2008-11-26', 'D'), 'target': 839},\n",
       " {'start': Period('2003-07-16', 'D'), 'target': 432},\n",
       " {'start': Period('2014-06-04', 'D'), 'target': 1016},\n",
       " {'start': Period('2019-05-27', 'D'), 'target': 735},\n",
       " {'start': Period('2008-06-06', 'D'), 'target': 2813},\n",
       " {'start': Period('2013-03-25', 'D'), 'target': 1133},\n",
       " {'start': Period('2019-10-07', 'D'), 'target': 965},\n",
       " {'start': Period('2008-02-18', 'D'), 'target': 3338},\n",
       " {'start': Period('2017-09-01', 'D'), 'target': 0},\n",
       " {'start': Period('2012-07-20', 'D'), 'target': 11945567},\n",
       " {'start': Period('2020-12-07', 'D'), 'target': 367250700},\n",
       " {'start': Period('2007-11-29', 'D'), 'target': 4451},\n",
       " {'start': Period('2017-06-20', 'D'), 'target': 705},\n",
       " {'start': Period('2002-11-14', 'D'), 'target': 407},\n",
       " {'start': Period('2010-03-18', 'D'), 'target': 1868},\n",
       " {'start': Period('2002-02-08', 'D'), 'target': 407},\n",
       " {'start': Period('2006-09-18', 'D'), 'target': 898},\n",
       " {'start': Period('2017-03-09', 'D'), 'target': 735},\n",
       " {'start': Period('2002-08-09', 'D'), 'target': 432},\n",
       " {'start': Period('2021-09-29', 'D'), 'target': 2320},\n",
       " {'start': Period('2018-05-01', 'D'), 'target': 845},\n",
       " {'start': Period('2022-03-17', 'D'), 'target': 2400},\n",
       " {'start': Period('2012-08-07', 'D'), 'target': 1075},\n",
       " {'start': Period('2002-03-27', 'D'), 'target': 436},\n",
       " {'start': Period('2014-02-27', 'D'), 'target': 869},\n",
       " {'start': Period('2011-06-08', 'D'), 'target': 1763},\n",
       " {'start': Period('2010-10-11', 'D'), 'target': 2057},\n",
       " {'start': Period('2020-01-13', 'D'), 'target': 47500600},\n",
       " {'start': Period('2014-01-20', 'D'), 'target': 848},\n",
       " {'start': Period('2012-03-27', 'D'), 'target': 1486},\n",
       " {'start': Period('2014-04-23', 'D'), 'target': 1041},\n",
       " {'start': Period('2004-04-05', 'D'), 'target': 432},\n",
       " {'start': Period('2019-08-14', 'D'), 'target': 1110},\n",
       " {'start': Period('2007-08-07', 'D'), 'target': 2015},\n",
       " {'start': Period('2017-03-23', 'D'), 'target': 740},\n",
       " {'start': Period('2010-01-18', 'D'), 'target': 1868},\n",
       " {'start': Period('2014-06-30', 'D'), 'target': 915},\n",
       " {'start': Period('2003-04-07', 'D'), 'target': 432},\n",
       " {'start': Period('2011-04-29', 'D'), 'target': 1910},\n",
       " {'start': Period('2017-03-07', 'D'), 'target': 760},\n",
       " {'start': Period('2002-02-22', 'D'), 'target': 432},\n",
       " {'start': Period('2004-09-30', 'D'), 'target': 432},\n",
       " {'start': Period('2008-08-12', 'D'), 'target': 1537},\n",
       " {'start': Period('2002-12-27', 'D'), 'target': 432},\n",
       " {'start': Period('2014-01-23', 'D'), 'target': 881},\n",
       " {'start': Period('2012-06-19', 'D'), 'target': 1117},\n",
       " {'start': Period('2022-05-13', 'D'), 'target': 2380},\n",
       " {'start': Period('2012-02-02', 'D'), 'target': 24059591},\n",
       " {'start': Period('2021-04-09', 'D'), 'target': 2490},\n",
       " {'start': Period('2019-07-08', 'D'), 'target': 825},\n",
       " {'start': Period('2002-06-03', 'D'), 'target': 0},\n",
       " {'start': Period('2020-06-22', 'D'), 'target': 610},\n",
       " {'start': Period('2018-11-02', 'D'), 'target': 705},\n",
       " {'start': Period('2019-10-28', 'D'), 'target': 950},\n",
       " {'start': Period('2005-11-30', 'D'), 'target': 453},\n",
       " {'start': Period('2003-11-14', 'D'), 'target': 436},\n",
       " {'start': Period('2001-05-10', 'D'), 'target': 432},\n",
       " {'start': Period('2010-12-02', 'D'), 'target': 2057},\n",
       " {'start': Period('2001-08-10', 'D'), 'target': 436},\n",
       " {'start': Period('2015-03-03', 'D'), 'target': 856},\n",
       " {'start': Period('2021-01-12', 'D'), 'target': 1147172800},\n",
       " {'start': Period('2010-04-27', 'D'), 'target': 2078},\n",
       " {'start': Period('2011-01-27', 'D'), 'target': 1910},\n",
       " {'start': Period('2019-12-02', 'D'), 'target': 805},\n",
       " {'start': Period('2022-10-07', 'D'), 'target': 1935},\n",
       " {'start': Period('2008-02-08', 'D'), 'target': 3086},\n",
       " {'start': Period('2020-09-25', 'D'), 'target': 715},\n",
       " {'start': Period('2020-06-25', 'D'), 'target': 595},\n",
       " {'start': Period('2008-09-30', 'D'), 'target': 1192},\n",
       " {'start': Period('2011-05-02', 'D'), 'target': 11455672},\n",
       " {'start': Period('2017-04-05', 'D'), 'target': 0},\n",
       " {'start': Period('2005-05-11', 'D'), 'target': 0},\n",
       " {'start': Period('2019-06-03', 'D'), 'target': 725},\n",
       " {'start': Period('2019-11-07', 'D'), 'target': 53514100},\n",
       " {'start': Period('2021-07-05', 'D'), 'target': 2260},\n",
       " {'start': Period('2022-05-06', 'D'), 'target': 2580},\n",
       " {'start': Period('2023-01-04', 'D'), 'target': 2050},\n",
       " {'start': Period('2018-07-17', 'D'), 'target': 905},\n",
       " {'start': Period('2008-05-26', 'D'), 'target': 2708},\n",
       " {'start': Period('2003-07-31', 'D'), 'target': 432},\n",
       " {'start': Period('2022-08-10', 'D'), 'target': 2110},\n",
       " {'start': Period('2004-06-24', 'D'), 'target': 407},\n",
       " {'start': Period('2010-12-03', 'D'), 'target': 2036},\n",
       " {'start': Period('2010-10-04', 'D'), 'target': 2036},\n",
       " {'start': Period('2022-12-13', 'D'), 'target': 1930},\n",
       " {'start': Period('2010-05-04', 'D'), 'target': 2036},\n",
       " {'start': Period('2016-10-07', 'D'), 'target': 800},\n",
       " {'start': Period('2016-04-29', 'D'), 'target': 775},\n",
       " {'start': Period('2016-08-23', 'D'), 'target': 50774000},\n",
       " {'start': Period('2011-11-23', 'D'), 'target': 1385},\n",
       " {'start': Period('2006-10-09', 'D'), 'target': 923},\n",
       " {'start': Period('2017-09-12', 'D'), 'target': 675},\n",
       " {'start': Period('2009-07-20', 'D'), 'target': 0},\n",
       " {'start': Period('2009-12-30', 'D'), 'target': 1847},\n",
       " {'start': Period('2008-11-14', 'D'), 'target': 881},\n",
       " {'start': Period('2015-03-11', 'D'), 'target': 823},\n",
       " {'start': Period('2008-08-18', 'D'), 'target': 1579},\n",
       " {'start': Period('2017-11-17', 'D'), 'target': 660},\n",
       " {'start': Period('2019-07-23', 'D'), 'target': 940},\n",
       " {'start': Period('2019-09-10', 'D'), 'target': 202036800},\n",
       " {'start': Period('2007-09-21', 'D'), 'target': 2225},\n",
       " {'start': Period('2005-12-29', 'D'), 'target': 600},\n",
       " {'start': Period('2017-10-18', 'D'), 'target': 650},\n",
       " {'start': Period('2010-10-08', 'D'), 'target': 2078},\n",
       " {'start': Period('2005-10-07', 'D'), 'target': 470},\n",
       " {'start': Period('2005-07-11', 'D'), 'target': 436},\n",
       " {'start': Period('2003-11-25', 'D'), 'target': 432},\n",
       " {'start': Period('2020-07-29', 'D'), 'target': 730},\n",
       " {'start': Period('2002-06-28', 'D'), 'target': 432},\n",
       " {'start': Period('2015-03-16', 'D'), 'target': 823},\n",
       " {'start': Period('2017-08-02', 'D'), 'target': 680},\n",
       " {'start': Period('2009-12-14', 'D'), 'target': 11758062},\n",
       " {'start': Period('2004-06-09', 'D'), 'target': 432},\n",
       " {'start': Period('2005-05-16', 'D'), 'target': 407},\n",
       " {'start': Period('2021-04-28', 'D'), 'target': 2350},\n",
       " {'start': Period('2019-11-04', 'D'), 'target': 148393600},\n",
       " {'start': Period('2003-03-07', 'D'), 'target': 432},\n",
       " {'start': Period('2006-10-11', 'D'), 'target': 957},\n",
       " {'start': Period('2014-02-12', 'D'), 'target': 869},\n",
       " {'start': Period('2011-07-20', 'D'), 'target': 1742},\n",
       " {'start': Period('2008-04-17', 'D'), 'target': 3023},\n",
       " {'start': Period('2003-12-16', 'D'), 'target': 407},\n",
       " {'start': Period('2002-04-30', 'D'), 'target': 436},\n",
       " {'start': Period('2007-04-16', 'D'), 'target': 2595},\n",
       " {'start': Period('2009-07-02', 'D'), 'target': 1742},\n",
       " {'start': Period('2009-10-30', 'D'), 'target': 2015},\n",
       " {'start': Period('2010-08-11', 'D'), 'target': 1763},\n",
       " {'start': Period('2004-12-02', 'D'), 'target': 432},\n",
       " {'start': Period('2009-03-10', 'D'), 'target': 32387797},\n",
       " {'start': Period('2003-11-10', 'D'), 'target': 0},\n",
       " {'start': Period('2002-04-19', 'D'), 'target': 407},\n",
       " {'start': Period('2007-03-14', 'D'), 'target': 92142420},\n",
       " {'start': Period('2009-05-07', 'D'), 'target': 204155031},\n",
       " {'start': Period('2010-03-24', 'D'), 'target': 1784},\n",
       " {'start': Period('2003-12-17', 'D'), 'target': 432},\n",
       " {'start': Period('2010-12-24', 'D'), 'target': 0},\n",
       " {'start': Period('2002-10-01', 'D'), 'target': 432},\n",
       " {'start': Period('2004-05-11', 'D'), 'target': 436},\n",
       " {'start': Period('2002-12-04', 'D'), 'target': 432},\n",
       " {'start': Period('2014-10-09', 'D'), 'target': 852},\n",
       " {'start': Period('2019-08-08', 'D'), 'target': 1010},\n",
       " {'start': Period('2008-06-09', 'D'), 'target': 2603},\n",
       " {'start': Period('2008-04-08', 'D'), 'target': 31794923},\n",
       " {'start': Period('2008-07-04', 'D'), 'target': 2603},\n",
       " {'start': Period('2015-06-19', 'D'), 'target': 604},\n",
       " {'start': Period('2002-07-26', 'D'), 'target': 407},\n",
       " {'start': Period('2007-05-09', 'D'), 'target': 2679},\n",
       " {'start': Period('2004-02-20', 'D'), 'target': 407},\n",
       " {'start': Period('2007-02-13', 'D'), 'target': 1276},\n",
       " {'start': Period('2017-04-20', 'D'), 'target': 710},\n",
       " {'start': Period('2013-04-01', 'D'), 'target': 1175},\n",
       " {'start': Period('2006-03-14', 'D'), 'target': 8940722},\n",
       " {'start': Period('2003-06-02', 'D'), 'target': 432},\n",
       " {'start': Period('2004-06-21', 'D'), 'target': 0},\n",
       " {'start': Period('2017-01-18', 'D'), 'target': 31798300},\n",
       " {'start': Period('2004-04-09', 'D'), 'target': 432},\n",
       " {'start': Period('2020-06-22', 'D'), 'target': 625},\n",
       " {'start': Period('2010-10-14', 'D'), 'target': 2099},\n",
       " {'start': Period('2018-12-07', 'D'), 'target': 740},\n",
       " {'start': Period('2007-07-04', 'D'), 'target': 40173726},\n",
       " {'start': Period('2015-07-07', 'D'), 'target': 3800461},\n",
       " {'start': Period('2020-05-12', 'D'), 'target': 515},\n",
       " {'start': Period('2017-07-26', 'D'), 'target': 59653900},\n",
       " {'start': Period('2006-03-09', 'D'), 'target': 27128723},\n",
       " {'start': Period('2002-08-29', 'D'), 'target': 432},\n",
       " {'start': Period('2013-10-30', 'D'), 'target': 1335},\n",
       " {'start': Period('2007-10-08', 'D'), 'target': 2330},\n",
       " {'start': Period('2008-12-11', 'D'), 'target': 179332323},\n",
       " {'start': Period('2004-07-01', 'D'), 'target': 436},\n",
       " {'start': Period('2004-10-08', 'D'), 'target': 432},\n",
       " {'start': Period('2011-11-14', 'D'), 'target': 1419},\n",
       " {'start': Period('2002-04-16', 'D'), 'target': 432},\n",
       " {'start': Period('2013-09-30', 'D'), 'target': 1192},\n",
       " {'start': Period('2001-12-20', 'D'), 'target': 407},\n",
       " {'start': Period('2002-09-11', 'D'), 'target': 432},\n",
       " {'start': Period('2004-07-01', 'D'), 'target': 432},\n",
       " {'start': Period('2013-03-20', 'D'), 'target': 13476561},\n",
       " {'start': Period('2001-12-04', 'D'), 'target': 436},\n",
       " {'start': Period('2001-08-01', 'D'), 'target': 436},\n",
       " {'start': Period('2017-10-17', 'D'), 'target': 650},\n",
       " {'start': Period('2015-05-04', 'D'), 'target': 6593634},\n",
       " {'start': Period('2011-03-21', 'D'), 'target': 1826},\n",
       " {'start': Period('2002-04-30', 'D'), 'target': 432},\n",
       " {'start': Period('2019-08-08', 'D'), 'target': 1075},\n",
       " {'start': Period('2011-10-27', 'D'), 'target': 1444},\n",
       " {'start': Period('2007-02-08', 'D'), 'target': 1318},\n",
       " {'start': Period('2003-02-28', 'D'), 'target': 432},\n",
       " {'start': Period('2008-03-18', 'D'), 'target': 2918},\n",
       " {'start': Period('2015-06-17', 'D'), 'target': 608},\n",
       " {'start': Period('2019-01-25', 'D'), 'target': 895},\n",
       " {'start': Period('2014-10-08', 'D'), 'target': 852},\n",
       " {'start': Period('2006-11-21', 'D'), 'target': 1268},\n",
       " {'start': Period('2016-12-26', 'D'), 'target': 855},\n",
       " {'start': Period('2021-08-02', 'D'), 'target': 2440},\n",
       " {'start': Period('2021-02-16', 'D'), 'target': 2910},\n",
       " {'start': Period('2022-07-20', 'D'), 'target': 1670},\n",
       " {'start': Period('2004-09-10', 'D'), 'target': 407},\n",
       " {'start': Period('2010-01-15', 'D'), 'target': 1868},\n",
       " {'start': Period('2005-05-25', 'D'), 'target': 0},\n",
       " {'start': Period('2011-10-25', 'D'), 'target': 25102477},\n",
       " {'start': Period('2018-04-04', 'D'), 'target': 775},\n",
       " {'start': Period('2014-01-22', 'D'), 'target': 62583629},\n",
       " {'start': Period('2004-10-06', 'D'), 'target': 0},\n",
       " {'start': Period('2001-05-24', 'D'), 'target': 432},\n",
       " {'start': Period('2016-02-26', 'D'), 'target': 374},\n",
       " {'start': Period('2020-02-19', 'D'), 'target': 700},\n",
       " {'start': Period('2009-11-16', 'D'), 'target': 1931},\n",
       " {'start': Period('2012-09-17', 'D'), 'target': 1201},\n",
       " {'start': Period('2016-10-19', 'D'), 'target': 830},\n",
       " {'start': Period('2019-09-09', 'D'), 'target': 1135},\n",
       " {'start': Period('2017-11-24', 'D'), 'target': 665},\n",
       " {'start': Period('2003-11-17', 'D'), 'target': 407},\n",
       " {'start': Period('2002-05-03', 'D'), 'target': 436},\n",
       " {'start': Period('2003-05-26', 'D'), 'target': 432},\n",
       " {'start': Period('2022-06-10', 'D'), 'target': 131007700},\n",
       " {'start': Period('2018-01-05', 'D'), 'target': 49323700},\n",
       " {'start': Period('2003-11-05', 'D'), 'target': 432},\n",
       " {'start': Period('2004-09-14', 'D'), 'target': 407},\n",
       " {'start': Period('2004-10-26', 'D'), 'target': 0},\n",
       " {'start': Period('2016-03-23', 'D'), 'target': 465},\n",
       " {'start': Period('2012-06-18', 'D'), 'target': 1075},\n",
       " {'start': Period('2017-07-17', 'D'), 'target': 705},\n",
       " {'start': Period('2020-02-05', 'D'), 'target': 730},\n",
       " {'start': Period('2020-03-31', 'D'), 'target': 89306500},\n",
       " {'start': Period('2006-10-05', 'D'), 'target': 923},\n",
       " {'start': Period('2011-04-19', 'D'), 'target': 7347821},\n",
       " {'start': Period('2020-11-16', 'D'), 'target': 1210},\n",
       " {'start': Period('2012-03-15', 'D'), 'target': 1545},\n",
       " {'start': Period('2010-06-23', 'D'), 'target': 1721},\n",
       " {'start': Period('2009-09-04', 'D'), 'target': 73129991},\n",
       " {'start': Period('2021-07-06', 'D'), 'target': 365880400},\n",
       " {'start': Period('2020-03-24', 'D'), 'target': 155141100},\n",
       " {'start': Period('2012-01-09', 'D'), 'target': 1385},\n",
       " {'start': Period('2007-05-30', 'D'), 'target': 2435},\n",
       " {'start': Period('2018-12-06', 'D'), 'target': 735},\n",
       " {'start': Period('2018-12-04', 'D'), 'target': 710},\n",
       " {'start': Period('2020-01-10', 'D'), 'target': 865},\n",
       " {'start': Period('2012-06-15', 'D'), 'target': 1133},\n",
       " {'start': Period('2010-12-29', 'D'), 'target': 2078},\n",
       " {'start': Period('2009-07-03', 'D'), 'target': 1679},\n",
       " {'start': Period('2015-06-09', 'D'), 'target': 6031951},\n",
       " {'start': Period('2022-08-02', 'D'), 'target': 2080},\n",
       " {'start': Period('2019-10-23', 'D'), 'target': 955},\n",
       " {'start': Period('2021-07-15', 'D'), 'target': 2580},\n",
       " {'start': Period('2018-11-21', 'D'), 'target': 72891500},\n",
       " {'start': Period('2003-07-08', 'D'), 'target': 407},\n",
       " {'start': Period('2005-12-15', 'D'), 'target': 566},\n",
       " {'start': Period('2021-12-20', 'D'), 'target': 53770200},\n",
       " {'start': Period('2005-05-02', 'D'), 'target': 436},\n",
       " {'start': Period('2015-04-27', 'D'), 'target': 10497670},\n",
       " {'start': Period('2006-08-24', 'D'), 'target': 932},\n",
       " {'start': Period('2005-03-31', 'D'), 'target': 432},\n",
       " {'start': Period('2006-04-07', 'D'), 'target': 818},\n",
       " {'start': Period('2022-07-12', 'D'), 'target': 1770},\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4a2dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "offset_alias_to_period_alias = {\n",
    "    \"WEEKDAY\": \"D\",\n",
    "    \"EOM\": \"M\",\n",
    "    \"BME\": \"M\",\n",
    "    \"SME\": \"M\",\n",
    "    \"BQS\": \"Q\",\n",
    "    \"QS\": \"Q\",\n",
    "    \"BQE\": \"Q\",\n",
    "    \"BQE-DEC\": \"Q\",\n",
    "    \"BQE-JAN\": \"Q\",\n",
    "    \"BQE-FEB\": \"Q\",\n",
    "    \"BQE-MAR\": \"Q\",\n",
    "    \"BQE-APR\": \"Q\",\n",
    "    \"BQE-MAY\": \"Q\",\n",
    "    \"BQE-JUN\": \"Q\",\n",
    "    \"BQE-JUL\": \"Q\",\n",
    "    \"BQE-AUG\": \"Q\",\n",
    "    \"BQE-SEP\": \"Q\",\n",
    "    \"BQE-OCT\": \"Q\",\n",
    "    \"BQE-NOV\": \"Q\",\n",
    "    \"MS\": \"M\",\n",
    "    \"D\": \"D\",\n",
    "    \"B\": \"B\",\n",
    "    \"min\": \"min\",\n",
    "    \"s\": \"s\",\n",
    "    \"ms\": \"ms\",\n",
    "    \"us\": \"us\",\n",
    "    \"ns\": \"ns\",\n",
    "    \"h\": \"h\",\n",
    "    \"QE\": \"Q\",\n",
    "    \"QE-DEC\": \"Q-DEC\",\n",
    "    \"QE-JAN\": \"Q-JAN\",\n",
    "    \"QE-FEB\": \"Q-FEB\",\n",
    "    \"QE-MAR\": \"Q-MAR\",\n",
    "    \"QE-APR\": \"Q-APR\",\n",
    "    \"QE-MAY\": \"Q-MAY\",\n",
    "    \"QE-JUN\": \"Q-JUN\",\n",
    "    \"QE-JUL\": \"Q-JUL\",\n",
    "    \"QE-AUG\": \"Q-AUG\",\n",
    "    \"QE-SEP\": \"Q-SEP\",\n",
    "    \"QE-OCT\": \"Q-OCT\",\n",
    "    \"QE-NOV\": \"Q-NOV\",\n",
    "    \"YE\": \"Y\",\n",
    "    \"YE-DEC\": \"Y-DEC\",\n",
    "    \"YE-JAN\": \"Y-JAN\",\n",
    "    \"YE-FEB\": \"Y-FEB\",\n",
    "    \"YE-MAR\": \"Y-MAR\",\n",
    "    \"YE-APR\": \"Y-APR\",\n",
    "    \"YE-MAY\": \"Y-MAY\",\n",
    "    \"YE-JUN\": \"Y-JUN\",\n",
    "    \"YE-JUL\": \"Y-JUL\",\n",
    "    \"YE-AUG\": \"Y-AUG\",\n",
    "    \"YE-SEP\": \"Y-SEP\",\n",
    "    \"YE-OCT\": \"Y-OCT\",\n",
    "    \"YE-NOV\": \"Y-NOV\",\n",
    "    \"W\": \"W\",\n",
    "    \"ME\": \"M\",\n",
    "    \"Y\": \"Y\",\n",
    "    \"BYE\": \"Y\",\n",
    "    \"BYE-DEC\": \"Y\",\n",
    "    \"BYE-JAN\": \"Y\",\n",
    "    \"BYE-FEB\": \"Y\",\n",
    "    \"BYE-MAR\": \"Y\",\n",
    "    \"BYE-APR\": \"Y\",\n",
    "    \"BYE-MAY\": \"Y\",\n",
    "    \"BYE-JUN\": \"Y\",\n",
    "    \"BYE-JUL\": \"Y\",\n",
    "    \"BYE-AUG\": \"Y\",\n",
    "    \"BYE-SEP\": \"Y\",\n",
    "    \"BYE-OCT\": \"Y\",\n",
    "    \"BYE-NOV\": \"Y\",\n",
    "    \"YS\": \"Y\",\n",
    "    \"BYS\": \"Y\",\n",
    "    \"QS-JAN\": \"Q\",\n",
    "    \"QS-FEB\": \"Q\",\n",
    "    \"QS-MAR\": \"Q\",\n",
    "    \"QS-APR\": \"Q\",\n",
    "    \"QS-MAY\": \"Q\",\n",
    "    \"QS-JUN\": \"Q\",\n",
    "    \"QS-JUL\": \"Q\",\n",
    "    \"QS-AUG\": \"Q\",\n",
    "    \"QS-SEP\": \"Q\",\n",
    "    \"QS-OCT\": \"Q\",\n",
    "    \"QS-NOV\": \"Q\",\n",
    "    \"QS-DEC\": \"Q\",\n",
    "    \"BQS-JAN\": \"Q\",\n",
    "    \"BQS-FEB\": \"Q\",\n",
    "    \"BQS-MAR\": \"Q\",\n",
    "    \"BQS-APR\": \"Q\",\n",
    "    \"BQS-MAY\": \"Q\",\n",
    "    \"BQS-JUN\": \"Q\",\n",
    "    \"BQS-JUL\": \"Q\",\n",
    "    \"BQS-AUG\": \"Q\",\n",
    "    \"BQS-SEP\": \"Q\",\n",
    "    \"BQS-OCT\": \"Q\",\n",
    "    \"BQS-NOV\": \"Q\",\n",
    "    \"BQS-DEC\": \"Q\",\n",
    "    \"YS-JAN\": \"Y\",\n",
    "    \"YS-FEB\": \"Y\",\n",
    "    \"YS-MAR\": \"Y\",\n",
    "    \"YS-APR\": \"Y\",\n",
    "    \"YS-MAY\": \"Y\",\n",
    "    \"YS-JUN\": \"Y\",\n",
    "    \"YS-JUL\": \"Y\",\n",
    "    \"YS-AUG\": \"Y\",\n",
    "    \"YS-SEP\": \"Y\",\n",
    "    \"YS-OCT\": \"Y\",\n",
    "    \"YS-NOV\": \"Y\",\n",
    "    \"YS-DEC\": \"Y\",\n",
    "    \"BYS-JAN\": \"Y\",\n",
    "    \"BYS-FEB\": \"Y\",\n",
    "    \"BYS-MAR\": \"Y\",\n",
    "    \"BYS-APR\": \"Y\",\n",
    "    \"BYS-MAY\": \"Y\",\n",
    "    \"BYS-JUN\": \"Y\",\n",
    "    \"BYS-JUL\": \"Y\",\n",
    "    \"BYS-AUG\": \"Y\",\n",
    "    \"BYS-SEP\": \"Y\",\n",
    "    \"BYS-OCT\": \"Y\",\n",
    "    \"BYS-NOV\": \"Y\",\n",
    "    \"BYS-DEC\": \"Y\",\n",
    "    \"Y-JAN\": \"Y-JAN\",\n",
    "    \"Y-FEB\": \"Y-FEB\",\n",
    "    \"Y-MAR\": \"Y-MAR\",\n",
    "    \"Y-APR\": \"Y-APR\",\n",
    "    \"Y-MAY\": \"Y-MAY\",\n",
    "    \"Y-JUN\": \"Y-JUN\",\n",
    "    \"Y-JUL\": \"Y-JUL\",\n",
    "    \"Y-AUG\": \"Y-AUG\",\n",
    "    \"Y-SEP\": \"Y-SEP\",\n",
    "    \"Y-OCT\": \"Y-OCT\",\n",
    "    \"Y-NOV\": \"Y-NOV\",\n",
    "    \"Y-DEC\": \"Y-DEC\",\n",
    "    \"Q-JAN\": \"Q-JAN\",\n",
    "    \"Q-FEB\": \"Q-FEB\",\n",
    "    \"Q-MAR\": \"Q-MAR\",\n",
    "    \"Q-APR\": \"Q-APR\",\n",
    "    \"Q-MAY\": \"Q-MAY\",\n",
    "    \"Q-JUN\": \"Q-JUN\",\n",
    "    \"Q-JUL\": \"Q-JUL\",\n",
    "    \"Q-AUG\": \"Q-AUG\",\n",
    "    \"Q-SEP\": \"Q-SEP\",\n",
    "    \"Q-OCT\": \"Q-OCT\",\n",
    "    \"Q-NOV\": \"Q-NOV\",\n",
    "    \"Q-DEC\": \"Q-DEC\",\n",
    "    \"W-MON\": \"W-MON\",\n",
    "    \"W-TUE\": \"W-TUE\",\n",
    "    \"W-WED\": \"W-WED\",\n",
    "    \"W-THU\": \"W-THU\",\n",
    "    \"W-FRI\": \"W-FRI\",\n",
    "    \"W-SAT\": \"W-SAT\",\n",
    "    \"W-SUN\": \"W-SUN\",\n",
    "}\n",
    "\n",
    "ds = datasets.load_dataset(\n",
    "    \"autogluon/chronos_datasets_extra\", \"ETTh\", split=\"train\", trust_remote_code=True\n",
    ")\n",
    "ds.set_format(\"numpy\")\n",
    "\n",
    "series_fields = [\n",
    "    col\n",
    "    for col in ds.features\n",
    "    if isinstance(ds.features[col], datasets.Sequence)\n",
    "]\n",
    "series_fields.remove(\"timestamp\")\n",
    "dataset_length = ds.info.splits[\"train\"].num_examples * len(series_fields)\n",
    "dataset_freq = pd.infer_freq(ds[0][\"timestamp\"])\n",
    "dataset_freq = offset_alias_to_period_alias.get(dataset_freq, dataset_freq)\n",
    "\n",
    "\n",
    "gts_dataset = []\n",
    "for hf_entry in ds:\n",
    "    for field in series_fields:\n",
    "        gts_dataset.append(\n",
    "            {\n",
    "                \"start\": pd.Period(\n",
    "                    hf_entry[\"timestamp\"][0],\n",
    "                    freq=dataset_freq,\n",
    "                ),\n",
    "                \"target\": hf_entry[field],\n",
    "            }\n",
    "        )\n",
    "\n",
    "train_df, remaining_df = train_test_split(gts_dataset, train_size=0.7, random_state=42)\n",
    "valid_df, test_df = train_test_split(remaining_df, test_size=0.2 / (0.1 + 0.2), random_state=42)\n",
    "\n",
    "# Split dataset for evaluation\n",
    "_, test_template = split(test_df, offset=-60)\n",
    "test_data = test_template.generate_instances(60, windows=2, distance=20, max_history=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfbd45df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': Period('2016-07-01 00:00', 'h'),\n",
       "  'target': array([12.481, 10.136, 11.309, ..., 10.974, 13.403, 10.052], dtype=float32)},\n",
       " {'start': Period('2016-07-01 00:00', 'h'),\n",
       "  'target': array([ 1.599,  1.492,  1.279, ..., -0.817,  5.472,  6.183], dtype=float32)},\n",
       " {'start': Period('2016-07-01 00:00', 'h'),\n",
       "  'target': array([2.009, 2.076, 1.741, ..., 3.818, 3.818, 3.55 ], dtype=float32)},\n",
       " {'start': Period('2016-07-01 00:00', 'h'),\n",
       "  'target': array([38.662 , 37.124 , 36.465 , ..., 48.1835, 46.8655, 45.9865],\n",
       "        dtype=float32)},\n",
       " {'start': Period('2016-07-01 00:00', 'h'),\n",
       "  'target': array([4.203, 4.142, 3.777, ..., 3.716, 3.655, 3.716], dtype=float32)},\n",
       " {'start': Period('2016-07-01 00:00', 'h'),\n",
       "  'target': array([41.13 , 37.528, 37.947, ..., 39.622, 43.643, 38.868], dtype=float32)},\n",
       " {'start': Period('2016-07-01 00:00', 'h'),\n",
       "  'target': array([ 9.355,  7.532,  9.007, ..., 11.661, 13.778, 10.669], dtype=float32)},\n",
       " {'start': Period('2016-07-01 00:00', 'h'),\n",
       "  'target': array([0.462, 0.426, 0.355, ..., 2.097, 2.097, 1.564], dtype=float32)},\n",
       " {'start': Period('2016-07-01 00:00', 'h'),\n",
       "  'target': array([30.531, 27.787, 27.787, ..., 10.271,  9.778,  9.567], dtype=float32)}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6342f7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingDataset(dataset=[{'start': Period('2001-04-16', 'D'), 'target': array([ 432,  432,  432, ..., 2050, 1965, 1985])}], splitter=OffsetSplitter(offset=-50))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/yogi/chronos-research/dataset/daily-all/ANTM.csv\")\n",
    "\n",
    "# Ensure the date column is in datetime format and sort by date\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(by='timestamp')\n",
    "\n",
    "# Prepare ListDataset for GluonTS\n",
    "prediction_length = 50\n",
    "freq = \"D\"  # Daily frequency\n",
    "dataset = [\n",
    "{\n",
    "    \"start\": pd.Period(df['timestamp'].iloc[0], freq=freq),\n",
    "    \"target\": df[\"close\"].values\n",
    "}\n",
    "]\n",
    "\n",
    "# Split dataset for evaluation\n",
    "train_data, test_data = split(dataset, offset=-prediction_length)\n",
    "test_data = test_data.generate_instances(prediction_length)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e658f045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248180/2209749135.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data_csv[\"ASII\"][0]=data_csv['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_csv[\"ASII\"][0]=data_csv['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_csv[\"ASII\"][0]=data_csv['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-04-04 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2003-08-11 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-07-23 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-07-16 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-12-19 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-07-18 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-11-06 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2003-05-01 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-07-16 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2003-11-11 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-06-11 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-07-16 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-11-22 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2003-07-15 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-05-02 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-07-19 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-11-02 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-03-21 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-12-03 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-11-21 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-07-09 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-06-18 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-01-21 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-01-18 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-03-22 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-08-13 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-10-15 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-18 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-05-18 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-07-05 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-07-01 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-07-18 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-12-31 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-07-19 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2003-10-13 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-09-19 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2003-04-23 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-12-24 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-10-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-10-23 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-07-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2003-07-10 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-11-29 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2002-04-19 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-06-25 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2001-04-17 00:00:00' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data['open'][0]=data['timestamp'][1]\n",
      "/tmp/ipykernel_248180/2209749135.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_csv[ds] = data['open'].iloc[:rows_to_take]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "\n",
    "dataset_name=[\"AALI\",\"ABBA\",\"ABDA\",\"ABMM\",\"ACES\",\"ACST\",\"ADCP\",\"ADES\",\"ADHI\",\"ADMF\",\"ADMG\",\"ADMR\",\"ADRO\",\"AGAR\",\"AGII\",\"AGRO\",\"AGRS\",\"AHAP\",\"AIMS\",\"AISA\",\"AKKU\",\"AKPI\",\"AKRA\",\"AKSI\",\"ALDO\",\"ALKA\",\"ALMI\",\"ALTO\",\"AMAG\",\"AMAN\",\"AMAR\",\"AMFG\",\"AMIN\",\"AMMS\",\"AMOR\",\"AMRT\",\"ANDI\",\"ANJT\",\"ANTM\",\"APEX\",\"APIC\",\"APII\",\"APLI\",\"APLN\",\"ARCI\",\"ARGO\",\"ARII\",\"ARKA\",\"ARKO\",\"ARMY\",\"ARNA\",\"ARTA\",\"ARTI\",\"ARTO\",\"ASBI\",\"ASDM\",\"ASGR\",\"ASHA\",\"ASJT\",\"ASLC\",\"ASMI\",\"ASPI\",\"ASRI\",\"ASRM\",\"ASSA\",\"ATAP\",\"ATIC\",\"AUTO\",\"AVIA\",\"AXIO\",\"AYLS\",\"BABP\",\"BACA\",\"BAJA\",\"BALI\",\"BANK\",\"BAPA\",\"BAPI\",\"BATA\",\"BAUT\",\"BAYU\",\"BBCA\",\"BBHI\",\"BBKP\",\"BBLD\",\"BBMD\",\"BBNI\",\"BBRI\",\"BBRM\",\"BBSI\",\"BBSS\",\"BBTN\",\"BBYB\",\"BCAP\",\"BCIC\",\"BCIP\",\"BDMN\",\"BEBS\",\"BEEF\",\"BEKS\",\"BELI\",\"BELL\",\"BESS\",\"BEST\",\"BFIN\",\"BGTG\",\"BHAT\",\"BHIT\",\"BIKA\",\"BIKE\",\"BIMA\",\"BINA\",\"BINO\",\"BIPI\",\"BIPP\",\"BIRD\",\"BISI\",\"BJBR\",\"BJTM\",\"BKDP\",\"BKSL\",\"BKSW\",\"BLTA\",\"BLTZ\",\"BLUE\",\"BMAS\",\"BMHS\",\"BMRI\",\"BMSR\",\"BMTR\",\"BNBA\",\"BNBR\",\"BNGA\",\"BNII\",\"BNLI\",\"BOBA\",\"BOGA\",\"BOLA\",\"BOLT\",\"BOSS\",\"BPFI\",\"BPII\",\"BPTR\",\"BRAM\",\"BRIS\",\"BRMS\",\"BRNA\",\"BRPT\",\"BSBK\",\"BSDE\",\"BSIM\",\"BSML\",\"BSSR\",\"BSWD\",\"BTEK\",\"BTEL\",\"BTON\",\"BTPN\",\"BTPS\",\"BUAH\",\"BUDI\",\"BUKA\",\"BUKK\",\"BULL\",\"BUMI\",\"BUVA\",\"BVIC\",\"BWPT\",\"BYAN\",\"CAKK\",\"CAMP\",\"CANI\",\"CARE\",\"CARS\",\"CASA\",\"CASH\",\"CASS\",\"CBMF\",\"CBUT\",\"CCSI\",\"CEKA\",\"CENT\",\"CFIN\",\"CHEM\",\"CINT\",\"CITA\",\"CITY\",\"CLAY\",\"CLEO\",\"CLPI\",\"CMNP\",\"CMNT\",\"CMPP\",\"CMRY\",\"CNKO\",\"CNTX\",\"COAL\",\"COCO\",\"COWL\",\"CPIN\",\"CPRI\",\"CPRO\",\"CRAB\",\"CSAP\",\"CSIS\",\"CSMI\",\"CSRA\",\"CTBN\",\"CTRA\",\"CTTH\",\"DADA\",\"DART\",\"DAYA\",\"DCII\",\"DEAL\",\"DEFI\",\"DEPO\",\"DEWA\",\"DEWI\",\"DFAM\",\"DGIK\",\"DGNS\",\"DIGI\",\"DILD\",\"DIVA\",\"DKFT\",\"DLTA\",\"DMAS\",\"DMMX\",\"DMND\",\"DNAR\",\"DNET\",\"DOID\",\"DPNS\",\"DPUM\",\"DRMA\",\"DSFI\",\"DSNG\",\"DSSA\",\"DUCK\",\"DUTI\",\"DVLA\",\"DWGL\",\"DYAN\",\"EAST\",\"ECII\",\"EDGE\",\"EKAD\",\"ELPI\",\"ELSA\",\"ELTY\",\"EMDE\",\"EMTK\",\"ENAK\",\"ENRG\",\"ENVY\",\"ENZO\",\"EPAC\",\"EPMT\",\"ERAA\",\"ERTX\",\"ESIP\",\"ESSA\",\"ESTA\",\"ESTI\",\"ETWA\",\"EURO\",\"EXCL\",\"FAPA\",\"FAST\",\"FASW\",\"FILM\",\"FIMP\",\"FIRE\",\"FISH\",\"FITT\",\"FLMC\",\"FMII\",\"FOOD\",\"FORU\",\"FORZ\",\"FPNI\",\"FREN\",\"FUJI\",\"GAMA\",\"GDST\",\"GDYR\",\"GEMA\",\"GEMS\",\"GGRM\",\"GGRP\",\"GHON\",\"GIAA\",\"GJTL\",\"GLOB\",\"GLVA\",\"GMFI\",\"GMTD\",\"GOLD\",\"GOLL\",\"GOOD\",\"GOTO\",\"GPRA\",\"GPSO\",\"GSMF\",\"GTBO\",\"GTSI\",\"GULA\",\"GWSA\",\"GZCO\",\"HADE\",\"HAIS\",\"HATM\",\"HDFA\",\"HDIT\",\"HEAL\",\"HELI\",\"HERO\",\"HEXA\",\"HITS\",\"HKMU\",\"HMSP\",\"HOKI\",\"HOME\",\"HOMI\",\"HOPE\",\"HOTL\",\"HRME\",\"HRTA\",\"HRUM\",\"IATA\",\"IBFN\",\"IBOS\",\"IBST\",\"ICBP\",\"ICON\",\"IDEA\",\"IDPR\",\"IFII\",\"IFSH\",\"IGAR\",\"IIKP\",\"IKAI\",\"IKAN\",\"IKBI\",\"IMAS\",\"IMJS\",\"IMPC\",\"INAF\",\"INAI\",\"INCF\",\"INCI\",\"INCO\",\"INDF\",\"INDO\",\"INDR\",\"INDS\",\"INDX\",\"INDY\",\"INKP\",\"INOV\",\"INPC\",\"INPP\",\"INPS\",\"INRU\",\"INTA\",\"INTD\",\"INTP\",\"IPAC\",\"IPCC\",\"IPCM\",\"IPOL\",\"IPPE\",\"IPTV\",\"IRRA\",\"ISAP\",\"ISAT\",\"ISSP\",\"ITIC\",\"ITMA\",\"ITMG\",\"JARR\",\"JAST\",\"JAWA\",\"JAYA\",\"JECC\",\"JGLE\",\"JIHD\",\"JKON\",\"JKSW\",\"JMAS\",\"JPFA\",\"JRPT\",\"JSKY\",\"JSMR\",\"JSPT\",\"JTPE\",\"KAEF\",\"KARW\",\"KAYU\",\"KBAG\",\"KBLI\",\"KBLM\",\"KBLV\",\"KBRI\",\"KDSI\",\"KDTN\",\"KEEN\",\"KEJU\",\"KETR\",\"KIAS\",\"KICI\",\"KIJA\",\"KINO\",\"KIOS\",\"KJEN\",\"KKES\",\"KKGI\",\"KLBF\",\"KLIN\",\"KMDS\",\"KMTR\",\"KOBX\",\"KOIN\",\"KONI\",\"KOPI\",\"KOTA\",\"KPAL\",\"KPAS\",\"KPIG\",\"KRAH\",\"KRAS\",\"KREN\",\"KRYA\",\"KUAS\",\"LABA\",\"LAND\",\"LAPD\",\"LCGP\",\"LCKM\",\"LEAD\",\"LFLO\",\"LIFE\",\"LINK\",\"LION\",\"LMAS\",\"LMPI\",\"LMSH\",\"LPCK\",\"LPGI\",\"LPIN\",\"LPKR\",\"LPLI\",\"LPPF\",\"LPPS\",\"LRNA\",\"LSIP\",\"LTLS\",\"LUCK\",\"LUCY\",\"MABA\",\"MAGP\",\"MAIN\",\"MAMI\",\"MAPA\",\"MAPB\",\"MAPI\",\"MARI\",\"MARK\",\"MASA\",\"MASB\",\"MAYA\",\"MBAP\",\"MBSS\",\"MBTO\",\"MCAS\",\"MCOL\",\"MCOR\",\"MDIA\",\"MDKA\",\"MDKI\",\"MDLN\",\"MDRN\",\"MEDC\",\"MEDS\",\"MEGA\",\"MERK\",\"META\",\"MFIN\",\"MFMI\",\"MGLV\",\"MGNA\",\"MGRO\",\"MICE\",\"MIDI\",\"MIKA\",\"MINA\",\"MIRA\",\"MITI\",\"MKNT\",\"MKPI\",\"MKTR\",\"MLBI\",\"MLIA\",\"MLPL\",\"MLPT\",\"MMIX\",\"MMLP\",\"MNCN\",\"MOLI\",\"MORA\",\"MPMX\",\"MPOW\",\"MPPA\",\"MPRO\",\"MRAT\",\"MREI\",\"MSIN\",\"MSKY\",\"MTDL\",\"MTEL\",\"MTFN\",\"MTLA\",\"MTMH\",\"MTPS\",\"MTRA\",\"MTSM\",\"MTWI\",\"MYOH\",\"MYOR\",\"MYRX\",\"MYTX\",\"NANO\",\"NASA\",\"NASI\",\"NATO\",\"NELY\",\"NETV\",\"NFCX\",\"NICK\",\"NICL\",\"NIKL\",\"NINE\",\"NIRO\",\"NISP\",\"NOBU\",\"NPGF\",\"NRCA\",\"NTBK\",\"NUSA\",\"NZIA\",\"OASA\",\"OBMD\",\"OCAP\",\"OILS\",\"OKAS\",\"OLIV\",\"OMED\",\"OMRE\",\"OPMS\",\"PADA\",\"PADI\",\"PALM\",\"PAMG\",\"PANI\",\"PANR\",\"PANS\",\"PBID\",\"PBRX\",\"PBSA\",\"PCAR\",\"PDES\",\"PDPP\",\"PEGE\",\"PEHA\",\"PGAS\",\"PGJO\",\"PGLI\",\"PGUN\",\"PICO\",\"PJAA\",\"PKPK\",\"PLAN\",\"PLAS\",\"PLIN\",\"PMJS\",\"PMMP\",\"PNBN\",\"PNBS\",\"PNGO\",\"PNIN\",\"PNLF\",\"PNSE\",\"POLA\",\"POLI\",\"POLL\",\"POLU\",\"POLY\",\"POOL\",\"PORT\",\"POSA\",\"POWR\",\"PPGL\",\"PPRE\",\"PPRO\",\"PRAS\",\"PRAY\",\"PRDA\",\"PRIM\",\"PSAB\",\"PSDN\",\"PSGO\",\"PSKT\",\"PSSI\",\"PTBA\",\"PTDU\",\"PTIS\",\"PTPP\",\"PTPW\",\"PTRO\",\"PTSN\",\"PTSP\",\"PUDP\",\"PURA\",\"PURE\",\"PURI\",\"PWON\",\"PYFA\",\"PZZA\",\"RAFI\",\"RAJA\",\"RALS\",\"RANC\",\"RBMS\",\"RCCC\",\"RDTX\",\"REAL\",\"RELI\",\"RICY\",\"RIGS\",\"RIMO\",\"RISE\",\"RMBA\",\"RMKE\",\"ROCK\",\"RODA\",\"RONY\",\"ROTI\",\"RSGK\",\"RUIS\",\"RUNS\",\"SAFE\",\"SAME\",\"SAMF\",\"SAPX\",\"SATU\",\"SBAT\",\"SBMA\",\"SCCO\",\"SCMA\",\"SCNP\",\"SCPI\",\"SDMU\",\"SDPC\",\"SDRA\",\"SEMA\",\"SFAN\",\"SGER\",\"SGRO\",\"SHID\",\"SHIP\",\"SICO\",\"SIDO\",\"SILO\",\"SIMA\",\"SIMP\",\"SINI\",\"SIPD\",\"SKBM\",\"SKLT\",\"SKRN\",\"SKYB\",\"SLIS\",\"SMAR\",\"SMBR\",\"SMCB\",\"SMDM\",\"SMDR\",\"SMGR\",\"SMKL\",\"SMKM\",\"SMMA\",\"SMMT\",\"SMRA\",\"SMRU\",\"SMSM\",\"SNLK\",\"SOCI\",\"SOFA\",\"SOHO\",\"SONA\",\"SOSS\",\"SOTS\",\"SPMA\",\"SPTO\",\"SQMI\",\"SRAJ\",\"SRIL\",\"SRSN\",\"SRTG\",\"SSIA\",\"SSMS\",\"SSTM\",\"STAA\",\"STAR\",\"STTP\",\"SULI\",\"SUPR\",\"SURE\",\"SWAT\",\"SWID\",\"TALF\",\"TAMA\",\"TAMU\",\"TAPG\",\"TARA\",\"TAXI\",\"TAYS\",\"TBIG\",\"TBLA\",\"TBMS\",\"TCID\",\"TCPI\",\"TDPM\",\"TEBE\",\"TECH\",\"TELE\",\"TFAS\",\"TFCO\",\"TGKA\",\"TGRA\",\"TIFA\",\"TINS\",\"TIRA\",\"TIRT\",\"TKIM\",\"TLDN\",\"TLKM\",\"TMAS\",\"TMPO\",\"TNCA\",\"TOBA\",\"TOOL\",\"TOPS\",\"TOTL\",\"TOTO\",\"TOWR\",\"TOYS\",\"TPIA\",\"TPMA\",\"TRAM\",\"TRGU\",\"TRIM\",\"TRIN\",\"TRIS\",\"TRJA\",\"TRST\",\"TRUE\",\"TRUK\",\"TRUS\",\"TSPC\",\"TUGU\",\"TURI\",\"UANG\",\"UCID\",\"UFOE\",\"ULTJ\",\"UNIC\",\"UNIQ\",\"UNIT\",\"UNSP\",\"UNTR\",\"UNVR\",\"URBN\",\"UVCR\",\"VICI\",\"VICO\",\"VINS\",\"VIVA\",\"VOKS\",\"VRNA\",\"VTNY\",\"WAPO\",\"WEGE\",\"WEHA\",\"WGSH\",\"WICO\",\"WIFI\",\"WIIM\",\"WIKA\",\"WINR\",\"WINS\",\"WIRG\",\"WMPP\",\"WMUU\",\"WOMF\",\"WOOD\",\"WOWS\",\"WSBP\",\"WSKT\",\"WTON\",\"YELO\",\"YPAS\",\"YULE\",\"ZATA\",\"ZBRA\",\"ZINC\",\"ZONE\",\"ZYRX\"]\n",
    "\n",
    "dataset =[]\n",
    "\n",
    "data_csv = pd.read_csv(f\"/home/yogi/chronos-research/dataset/daily-all/ASII.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# Ensure the date column is in datetime format and sort by date\n",
    "data_csv['timestamp'] = pd.to_datetime(data_csv['timestamp'])\n",
    "data_csv = data_csv.sort_values(by='timestamp')\n",
    "\n",
    "total_rows = len(data_csv['open'])\n",
    "rows_to_take = int(0.7 * total_rows)\n",
    "\n",
    "data_csv[\"ASII\"] = data_csv['open'].iloc[:rows_to_take]\n",
    "data_csv[\"ASII\"][0]=data_csv['timestamp'][1]\n",
    "\n",
    "data_csv = data_csv.drop(columns=['low', 'high', 'open', 'close', 'volume', 'timestamp'])\n",
    "\n",
    "count=0\n",
    "for ds in dataset_name:\n",
    "    data = pd.read_csv(f\"/home/yogi/chronos-research/dataset/daily-all/{ds}.csv\", parse_dates=['timestamp'])\n",
    "    total_rows = len(data['open'])\n",
    "    rows_to_take = int(0.7 * total_rows)\n",
    "    if rows_to_take < 3500:\n",
    "        continue\n",
    "    data['open'][0]=data['timestamp'][1]\n",
    "    data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
    "\n",
    "\n",
    "\n",
    "# Menyimpan data train dan test ke dalam file CSV baru\n",
    "data_csv.to_csv('/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/augment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "\n",
    "dataset_name=[\"AALI\",\"ABBA\",\"ABDA\",\"ABMM\",\"ACES\",\"ACST\",\"ADCP\",\"ADES\",\"ADHI\",\"ADMF\",\"ADMG\",\"ADMR\",\"ADRO\",\"AGAR\",\"AGII\",\"AGRO\",\"AGRS\",\"AHAP\",\"AIMS\",\"AISA\",\"AKKU\",\"AKPI\",\"AKRA\",\"AKSI\",\"ALDO\",\"ALKA\",\"ALMI\",\"ALTO\",\"AMAG\",\"AMAN\",\"AMAR\",\"AMFG\",\"AMIN\",\"AMMS\",\"AMOR\",\"AMRT\",\"ANDI\",\"ANJT\",\"ANTM\",\"APEX\",\"APIC\",\"APII\",\"APLI\",\"APLN\",\"ARCI\",\"ARGO\",\"ARII\",\"ARKA\",\"ARKO\",\"ARMY\",\"ARNA\",\"ARTA\",\"ARTI\",\"ARTO\",\"ASBI\",\"ASDM\",\"ASGR\",\"ASHA\",\"ASJT\",\"ASLC\",\"ASMI\",\"ASPI\",\"ASRI\",\"ASRM\",\"ASSA\",\"ATAP\",\"ATIC\",\"AUTO\",\"AVIA\",\"AXIO\",\"AYLS\",\"BABP\",\"BACA\",\"BAJA\",\"BALI\",\"BANK\",\"BAPA\",\"BAPI\",\"BATA\",\"BAUT\",\"BAYU\",\"BBCA\",\"BBHI\",\"BBKP\",\"BBLD\",\"BBMD\",\"BBNI\",\"BBRI\",\"BBRM\",\"BBSI\",\"BBSS\",\"BBTN\",\"BBYB\",\"BCAP\",\"BCIC\",\"BCIP\",\"BDMN\",\"BEBS\",\"BEEF\",\"BEKS\",\"BELI\",\"BELL\",\"BESS\",\"BEST\",\"BFIN\",\"BGTG\",\"BHAT\",\"BHIT\",\"BIKA\",\"BIKE\",\"BIMA\",\"BINA\",\"BINO\",\"BIPI\",\"BIPP\",\"BIRD\",\"BISI\",\"BJBR\",\"BJTM\",\"BKDP\",\"BKSL\",\"BKSW\",\"BLTA\",\"BLTZ\",\"BLUE\",\"BMAS\",\"BMHS\",\"BMRI\",\"BMSR\",\"BMTR\",\"BNBA\",\"BNBR\",\"BNGA\",\"BNII\",\"BNLI\",\"BOBA\",\"BOGA\",\"BOLA\",\"BOLT\",\"BOSS\",\"BPFI\",\"BPII\",\"BPTR\",\"BRAM\",\"BRIS\",\"BRMS\",\"BRNA\",\"BRPT\",\"BSBK\",\"BSDE\",\"BSIM\",\"BSML\",\"BSSR\",\"BSWD\",\"BTEK\",\"BTEL\",\"BTON\",\"BTPN\",\"BTPS\",\"BUAH\",\"BUDI\",\"BUKA\",\"BUKK\",\"BULL\",\"BUMI\",\"BUVA\",\"BVIC\",\"BWPT\",\"BYAN\",\"CAKK\",\"CAMP\",\"CANI\",\"CARE\",\"CARS\",\"CASA\",\"CASH\",\"CASS\",\"CBMF\",\"CBUT\",\"CCSI\",\"CEKA\",\"CENT\",\"CFIN\",\"CHEM\",\"CINT\",\"CITA\",\"CITY\",\"CLAY\",\"CLEO\",\"CLPI\",\"CMNP\",\"CMNT\",\"CMPP\",\"CMRY\",\"CNKO\",\"CNTX\",\"COAL\",\"COCO\",\"COWL\",\"CPIN\",\"CPRI\",\"CPRO\",\"CRAB\",\"CSAP\",\"CSIS\",\"CSMI\",\"CSRA\",\"CTBN\",\"CTRA\",\"CTTH\",\"DADA\",\"DART\",\"DAYA\",\"DCII\",\"DEAL\",\"DEFI\",\"DEPO\",\"DEWA\",\"DEWI\",\"DFAM\",\"DGIK\",\"DGNS\",\"DIGI\",\"DILD\",\"DIVA\",\"DKFT\",\"DLTA\",\"DMAS\",\"DMMX\",\"DMND\",\"DNAR\",\"DNET\",\"DOID\",\"DPNS\",\"DPUM\",\"DRMA\",\"DSFI\",\"DSNG\",\"DSSA\",\"DUCK\",\"DUTI\",\"DVLA\",\"DWGL\",\"DYAN\",\"EAST\",\"ECII\",\"EDGE\",\"EKAD\",\"ELPI\",\"ELSA\",\"ELTY\",\"EMDE\",\"EMTK\",\"ENAK\",\"ENRG\",\"ENVY\",\"ENZO\",\"EPAC\",\"EPMT\",\"ERAA\",\"ERTX\",\"ESIP\",\"ESSA\",\"ESTA\",\"ESTI\",\"ETWA\",\"EURO\",\"EXCL\",\"FAPA\",\"FAST\",\"FASW\",\"FILM\",\"FIMP\",\"FIRE\",\"FISH\",\"FITT\",\"FLMC\",\"FMII\",\"FOOD\",\"FORU\",\"FORZ\",\"FPNI\",\"FREN\",\"FUJI\",\"GAMA\",\"GDST\",\"GDYR\",\"GEMA\",\"GEMS\",\"GGRM\",\"GGRP\",\"GHON\",\"GIAA\",\"GJTL\",\"GLOB\",\"GLVA\",\"GMFI\",\"GMTD\",\"GOLD\",\"GOLL\",\"GOOD\",\"GOTO\",\"GPRA\",\"GPSO\",\"GSMF\",\"GTBO\",\"GTSI\",\"GULA\",\"GWSA\",\"GZCO\",\"HADE\",\"HAIS\",\"HATM\",\"HDFA\",\"HDIT\",\"HEAL\",\"HELI\",\"HERO\",\"HEXA\",\"HITS\",\"HKMU\",\"HMSP\",\"HOKI\",\"HOME\",\"HOMI\",\"HOPE\",\"HOTL\",\"HRME\",\"HRTA\",\"HRUM\",\"IATA\",\"IBFN\",\"IBOS\",\"IBST\",\"ICBP\",\"ICON\",\"IDEA\",\"IDPR\",\"IFII\",\"IFSH\",\"IGAR\",\"IIKP\",\"IKAI\",\"IKAN\",\"IKBI\",\"IMAS\",\"IMJS\",\"IMPC\",\"INAF\",\"INAI\",\"INCF\",\"INCI\",\"INCO\",\"INDF\",\"INDO\",\"INDR\",\"INDS\",\"INDX\",\"INDY\",\"INKP\",\"INOV\",\"INPC\",\"INPP\",\"INPS\",\"INRU\",\"INTA\",\"INTD\",\"INTP\",\"IPAC\",\"IPCC\",\"IPCM\",\"IPOL\",\"IPPE\",\"IPTV\",\"IRRA\",\"ISAP\",\"ISAT\",\"ISSP\",\"ITIC\",\"ITMA\",\"ITMG\",\"JARR\",\"JAST\",\"JAWA\",\"JAYA\",\"JECC\",\"JGLE\",\"JIHD\",\"JKON\",\"JKSW\",\"JMAS\",\"JPFA\",\"JRPT\",\"JSKY\",\"JSMR\",\"JSPT\",\"JTPE\",\"KAEF\",\"KARW\",\"KAYU\",\"KBAG\",\"KBLI\",\"KBLM\",\"KBLV\",\"KBRI\",\"KDSI\",\"KDTN\",\"KEEN\",\"KEJU\",\"KETR\",\"KIAS\",\"KICI\",\"KIJA\",\"KINO\",\"KIOS\",\"KJEN\",\"KKES\",\"KKGI\",\"KLBF\",\"KLIN\",\"KMDS\",\"KMTR\",\"KOBX\",\"KOIN\",\"KONI\",\"KOPI\",\"KOTA\",\"KPAL\",\"KPAS\",\"KPIG\",\"KRAH\",\"KRAS\",\"KREN\",\"KRYA\",\"KUAS\",\"LABA\",\"LAND\",\"LAPD\",\"LCGP\",\"LCKM\",\"LEAD\",\"LFLO\",\"LIFE\",\"LINK\",\"LION\",\"LMAS\",\"LMPI\",\"LMSH\",\"LPCK\",\"LPGI\",\"LPIN\",\"LPKR\",\"LPLI\",\"LPPF\",\"LPPS\",\"LRNA\",\"LSIP\",\"LTLS\",\"LUCK\",\"LUCY\",\"MABA\",\"MAGP\",\"MAIN\",\"MAMI\",\"MAPA\",\"MAPB\",\"MAPI\",\"MARI\",\"MARK\",\"MASA\",\"MASB\",\"MAYA\",\"MBAP\",\"MBSS\",\"MBTO\",\"MCAS\",\"MCOL\",\"MCOR\",\"MDIA\",\"MDKA\",\"MDKI\",\"MDLN\",\"MDRN\",\"MEDC\",\"MEDS\",\"MEGA\",\"MERK\",\"META\",\"MFIN\",\"MFMI\",\"MGLV\",\"MGNA\",\"MGRO\",\"MICE\",\"MIDI\",\"MIKA\",\"MINA\",\"MIRA\",\"MITI\",\"MKNT\",\"MKPI\",\"MKTR\",\"MLBI\",\"MLIA\",\"MLPL\",\"MLPT\",\"MMIX\",\"MMLP\",\"MNCN\",\"MOLI\",\"MORA\",\"MPMX\",\"MPOW\",\"MPPA\",\"MPRO\",\"MRAT\",\"MREI\",\"MSIN\",\"MSKY\",\"MTDL\",\"MTEL\",\"MTFN\",\"MTLA\",\"MTMH\",\"MTPS\",\"MTRA\",\"MTSM\",\"MTWI\",\"MYOH\",\"MYOR\",\"MYRX\",\"MYTX\",\"NANO\",\"NASA\",\"NASI\",\"NATO\",\"NELY\",\"NETV\",\"NFCX\",\"NICK\",\"NICL\",\"NIKL\",\"NINE\",\"NIRO\",\"NISP\",\"NOBU\",\"NPGF\",\"NRCA\",\"NTBK\",\"NUSA\",\"NZIA\",\"OASA\",\"OBMD\",\"OCAP\",\"OILS\",\"OKAS\",\"OLIV\",\"OMED\",\"OMRE\",\"OPMS\",\"PADA\",\"PADI\",\"PALM\",\"PAMG\",\"PANI\",\"PANR\",\"PANS\",\"PBID\",\"PBRX\",\"PBSA\",\"PCAR\",\"PDES\",\"PDPP\",\"PEGE\",\"PEHA\",\"PGAS\",\"PGJO\",\"PGLI\",\"PGUN\",\"PICO\",\"PJAA\",\"PKPK\",\"PLAN\",\"PLAS\",\"PLIN\",\"PMJS\",\"PMMP\",\"PNBN\",\"PNBS\",\"PNGO\",\"PNIN\",\"PNLF\",\"PNSE\",\"POLA\",\"POLI\",\"POLL\",\"POLU\",\"POLY\",\"POOL\",\"PORT\",\"POSA\",\"POWR\",\"PPGL\",\"PPRE\",\"PPRO\",\"PRAS\",\"PRAY\",\"PRDA\",\"PRIM\",\"PSAB\",\"PSDN\",\"PSGO\",\"PSKT\",\"PSSI\",\"PTBA\",\"PTDU\",\"PTIS\",\"PTPP\",\"PTPW\",\"PTRO\",\"PTSN\",\"PTSP\",\"PUDP\",\"PURA\",\"PURE\",\"PURI\",\"PWON\",\"PYFA\",\"PZZA\",\"RAFI\",\"RAJA\",\"RALS\",\"RANC\",\"RBMS\",\"RCCC\",\"RDTX\",\"REAL\",\"RELI\",\"RICY\",\"RIGS\",\"RIMO\",\"RISE\",\"RMBA\",\"RMKE\",\"ROCK\",\"RODA\",\"RONY\",\"ROTI\",\"RSGK\",\"RUIS\",\"RUNS\",\"SAFE\",\"SAME\",\"SAMF\",\"SAPX\",\"SATU\",\"SBAT\",\"SBMA\",\"SCCO\",\"SCMA\",\"SCNP\",\"SCPI\",\"SDMU\",\"SDPC\",\"SDRA\",\"SEMA\",\"SFAN\",\"SGER\",\"SGRO\",\"SHID\",\"SHIP\",\"SICO\",\"SIDO\",\"SILO\",\"SIMA\",\"SIMP\",\"SINI\",\"SIPD\",\"SKBM\",\"SKLT\",\"SKRN\",\"SKYB\",\"SLIS\",\"SMAR\",\"SMBR\",\"SMCB\",\"SMDM\",\"SMDR\",\"SMGR\",\"SMKL\",\"SMKM\",\"SMMA\",\"SMMT\",\"SMRA\",\"SMRU\",\"SMSM\",\"SNLK\",\"SOCI\",\"SOFA\",\"SOHO\",\"SONA\",\"SOSS\",\"SOTS\",\"SPMA\",\"SPTO\",\"SQMI\",\"SRAJ\",\"SRIL\",\"SRSN\",\"SRTG\",\"SSIA\",\"SSMS\",\"SSTM\",\"STAA\",\"STAR\",\"STTP\",\"SULI\",\"SUPR\",\"SURE\",\"SWAT\",\"SWID\",\"TALF\",\"TAMA\",\"TAMU\",\"TAPG\",\"TARA\",\"TAXI\",\"TAYS\",\"TBIG\",\"TBLA\",\"TBMS\",\"TCID\",\"TCPI\",\"TDPM\",\"TEBE\",\"TECH\",\"TELE\",\"TFAS\",\"TFCO\",\"TGKA\",\"TGRA\",\"TIFA\",\"TINS\",\"TIRA\",\"TIRT\",\"TKIM\",\"TLDN\",\"TLKM\",\"TMAS\",\"TMPO\",\"TNCA\",\"TOBA\",\"TOOL\",\"TOPS\",\"TOTL\",\"TOTO\",\"TOWR\",\"TOYS\",\"TPIA\",\"TPMA\",\"TRAM\",\"TRGU\",\"TRIM\",\"TRIN\",\"TRIS\",\"TRJA\",\"TRST\",\"TRUE\",\"TRUK\",\"TRUS\",\"TSPC\",\"TUGU\",\"TURI\",\"UANG\",\"UCID\",\"UFOE\",\"ULTJ\",\"UNIC\",\"UNIQ\",\"UNIT\",\"UNSP\",\"UNTR\",\"UNVR\",\"URBN\",\"UVCR\",\"VICI\",\"VICO\",\"VINS\",\"VIVA\",\"VOKS\",\"VRNA\",\"VTNY\",\"WAPO\",\"WEGE\",\"WEHA\",\"WGSH\",\"WICO\",\"WIFI\",\"WIIM\",\"WIKA\",\"WINR\",\"WINS\",\"WIRG\",\"WMPP\",\"WMUU\",\"WOMF\",\"WOOD\",\"WOWS\",\"WSBP\",\"WSKT\",\"WTON\",\"YELO\",\"YPAS\",\"YULE\",\"ZATA\",\"ZBRA\",\"ZINC\",\"ZONE\",\"ZYRX\"]\n",
    "\n",
    "dataset =[]\n",
    "\n",
    "data_csv = pd.read_csv(f\"/home/yogi/chronos-research/dataset/daily-all/ASII.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# Ensure the date column is in datetime format and sort by date\n",
    "data_csv['timestamp'] = pd.to_datetime(data_csv['timestamp'])\n",
    "data_csv = data_csv.sort_values(by='timestamp')\n",
    "\n",
    "total_rows = len(data_csv['open'])\n",
    "rows_to_take = int(0.7 * total_rows)\n",
    "\n",
    "data_csv[\"ASII\"] = data_csv['open'].iloc[:rows_to_take]\n",
    "data_csv[\"ASII\"][0]=data_csv['timestamp'][1]\n",
    "\n",
    "data_csv = data_csv.drop(columns=['low', 'high', 'open', 'close', 'volume', 'timestamp'])\n",
    "\n",
    "count=0\n",
    "for ds in dataset_name:\n",
    "    data = pd.read_csv(f\"/home/yogi/chronos-research/dataset/daily-all/{ds}.csv\", parse_dates=['timestamp'])\n",
    "    total_rows = len(data['open'])\n",
    "    rows_to_take = int(0.7 * total_rows)\n",
    "    if rows_to_take < 3000:\n",
    "        continue\n",
    "    data['open'][0]=data['timestamp'][1]\n",
    "    data_csv[ds] = data['open'].iloc[:rows_to_take]\n",
    "\n",
    "\n",
    "\n",
    "# Menyimpan data train dan test ke dalam file CSV baru\n",
    "data_csv.to_csv('/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/augment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d55480be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3406598/1965387958.py:1: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_augment=pd.read_csv(\"/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/augment.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASII</th>\n",
       "      <th>AALI</th>\n",
       "      <th>ABBA</th>\n",
       "      <th>ABDA</th>\n",
       "      <th>ADES</th>\n",
       "      <th>ADMG</th>\n",
       "      <th>AGRO</th>\n",
       "      <th>AHAP</th>\n",
       "      <th>AIMS</th>\n",
       "      <th>AISA</th>\n",
       "      <th>...</th>\n",
       "      <th>ULTJ</th>\n",
       "      <th>UNIC</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>UNSP</th>\n",
       "      <th>UNTR</th>\n",
       "      <th>UNVR</th>\n",
       "      <th>VOKS</th>\n",
       "      <th>WAPO</th>\n",
       "      <th>WICO</th>\n",
       "      <th>ZBRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>7575.0</td>\n",
       "      <td>24559</td>\n",
       "      <td>50</td>\n",
       "      <td>5900</td>\n",
       "      <td>1640</td>\n",
       "      <td>202</td>\n",
       "      <td>375</td>\n",
       "      <td>96</td>\n",
       "      <td>190</td>\n",
       "      <td>2510</td>\n",
       "      <td>...</td>\n",
       "      <td>995</td>\n",
       "      <td>1815</td>\n",
       "      <td>297</td>\n",
       "      <td>500</td>\n",
       "      <td>21800</td>\n",
       "      <td>6370</td>\n",
       "      <td>160</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>24107</td>\n",
       "      <td>50</td>\n",
       "      <td>5900</td>\n",
       "      <td>1615</td>\n",
       "      <td>199</td>\n",
       "      <td>359</td>\n",
       "      <td>96</td>\n",
       "      <td>190</td>\n",
       "      <td>2465</td>\n",
       "      <td>...</td>\n",
       "      <td>977</td>\n",
       "      <td>1815</td>\n",
       "      <td>268</td>\n",
       "      <td>500</td>\n",
       "      <td>21000</td>\n",
       "      <td>6260</td>\n",
       "      <td>160</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>7325.0</td>\n",
       "      <td>23273</td>\n",
       "      <td>50</td>\n",
       "      <td>5925</td>\n",
       "      <td>1600</td>\n",
       "      <td>193</td>\n",
       "      <td>360</td>\n",
       "      <td>96</td>\n",
       "      <td>190</td>\n",
       "      <td>2420</td>\n",
       "      <td>...</td>\n",
       "      <td>966</td>\n",
       "      <td>1815</td>\n",
       "      <td>282</td>\n",
       "      <td>500</td>\n",
       "      <td>20400</td>\n",
       "      <td>6230</td>\n",
       "      <td>160</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>7250.0</td>\n",
       "      <td>22439</td>\n",
       "      <td>50</td>\n",
       "      <td>5900</td>\n",
       "      <td>1590</td>\n",
       "      <td>198</td>\n",
       "      <td>370</td>\n",
       "      <td>111</td>\n",
       "      <td>185</td>\n",
       "      <td>2425</td>\n",
       "      <td>...</td>\n",
       "      <td>972</td>\n",
       "      <td>1815</td>\n",
       "      <td>282</td>\n",
       "      <td>500</td>\n",
       "      <td>20500</td>\n",
       "      <td>6235</td>\n",
       "      <td>160</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>7225.0</td>\n",
       "      <td>22249</td>\n",
       "      <td>50</td>\n",
       "      <td>5900</td>\n",
       "      <td>1600</td>\n",
       "      <td>192</td>\n",
       "      <td>375</td>\n",
       "      <td>111</td>\n",
       "      <td>185</td>\n",
       "      <td>2420</td>\n",
       "      <td>...</td>\n",
       "      <td>965</td>\n",
       "      <td>1815</td>\n",
       "      <td>265</td>\n",
       "      <td>500</td>\n",
       "      <td>20850</td>\n",
       "      <td>6260</td>\n",
       "      <td>160</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ASII   AALI ABBA  ABDA  ADES ADMG AGRO AHAP AIMS  AISA  ... ULTJ  \\\n",
       "3495  7575.0  24559   50  5900  1640  202  375   96  190  2510  ...  995   \n",
       "3496  7500.0  24107   50  5900  1615  199  359   96  190  2465  ...  977   \n",
       "3497  7325.0  23273   50  5925  1600  193  360   96  190  2420  ...  966   \n",
       "3498  7250.0  22439   50  5900  1590  198  370  111  185  2425  ...  972   \n",
       "3499  7225.0  22249   50  5900  1600  192  375  111  185  2420  ...  965   \n",
       "\n",
       "      UNIC UNIT UNSP   UNTR  UNVR VOKS WAPO WICO ZBRA  \n",
       "3495  1815  297  500  21800  6370  160   73   63  158  \n",
       "3496  1815  268  500  21000  6260  160   73   63  158  \n",
       "3497  1815  282  500  20400  6230  160   66   64  155  \n",
       "3498  1815  282  500  20500  6235  160   66   63  157  \n",
       "3499  1815  265  500  20850  6260  160   63   62  157  \n",
       "\n",
       "[5 rows x 270 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augment=pd.read_csv(\"/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/augment.csv\")\n",
    "data_augment.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e66a6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248180/745262439.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  \"target\": data_csv[column].iloc[1:].fillna(0).values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 98.,  96., 100., ...,   0.,   0.,   0.])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([547, 547, 524, ...,   0,   0,   0])},\n",
       " {'start': Period('2002-04-04', 'D'),\n",
       "  'target': array([275, 275, 275, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([194, 194, 194, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1125, 1125, 1125, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([165, 165, 165, ...,   0,   0,   0])},\n",
       " {'start': Period('2003-08-11', 'D'),\n",
       "  'target': array([95, 95, 95, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([90, 90, 90, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-07-23', 'D'),\n",
       "  'target': array([350, 487, 562, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([97, 97, 97, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([220, 220, 220, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([53, 53, 53, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-07-16', 'D'),\n",
       "  'target': array([105, 105, 105, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([41, 41, 41, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([337, 337, 337, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1350, 1350, 1350, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([432, 432, 432, ...,   0,   0,   0])},\n",
       " {'start': Period('2002-12-19', 'D'),\n",
       "  'target': array([1371, 1371, 1371, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([50, 50, 50, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([750, 750, 750, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-07-18', 'D'),\n",
       "  'target': array([35, 35, 35, ...,  0,  0,  0])},\n",
       " {'start': Period('2002-11-06', 'D'),\n",
       "  'target': array([132, 135, 125, ...,   0,   0,   0])},\n",
       " {'start': Period('2003-05-01', 'D'),\n",
       "  'target': array([423, 423, 423, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([87, 87, 87, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([210, 210, 210, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([280, 280, 280, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([236, 236, 236, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([249, 244, 249, ...,   0,   0,   0])},\n",
       " {'start': Period('2002-07-16', 'D'),\n",
       "  'target': array([94, 90, 90, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([135, 135, 135, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([145, 145, 145, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([175, 175, 175, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([10, 10, 10, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1232, 1232, 1232, ...,    0,    0,    0])},\n",
       " {'start': Period('2003-11-11', 'D'),\n",
       "  'target': array([ 97,  97, 105, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-06-11', 'D'),\n",
       "  'target': array([36, 37, 38, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1140, 1140, 1140, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-07-16', 'D'),\n",
       "  'target': array([77, 87, 85, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([6, 6, 6, ..., 0, 0, 0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([425, 410, 400, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([600, 600, 600, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([35, 35, 35, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([460, 460, 460, ...,   0,   0,   0])},\n",
       " {'start': Period('2002-11-22', 'D'),\n",
       "  'target': array([ 97,  97, 122, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([184, 184, 184, ...,   0,   0,   0])},\n",
       " {'start': Period('2003-07-15', 'D'),\n",
       "  'target': array([430, 417, 405, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([80, 80, 80, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([182, 182, 182, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([2506, 2088, 2506, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([219, 219, 219, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([156, 156, 156, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([621, 621, 621, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([675, 675, 675, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([79, 79, 79, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([6, 6, 6, ..., 0, 0, 0])},\n",
       " {'start': Period('2002-05-02', 'D'),\n",
       "  'target': array([174, 174, 166, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-07-19', 'D'),\n",
       "  'target': array([75, 77, 77, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([116, 116, 116, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([50, 50, 50, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([29, 29, 29, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([120, 120, 120, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-11-02', 'D'),\n",
       "  'target': array([39, 40, 41, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([103, 103, 103, ...,   0,   0,   0])},\n",
       " {'start': Period('2002-03-21', 'D'),\n",
       "  'target': array([153, 151, 156, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-12-03', 'D'),\n",
       "  'target': array([410, 390, 390, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([376, 376, 376, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([95, 95, 95, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-11-21', 'D'),\n",
       "  'target': array([145, 145, 145, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([300, 300, 300, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([31, 31, 31, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([800, 800, 800, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([49, 46, 44, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([200, 200, 200, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([55, 55, 55, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-07-09', 'D'),\n",
       "  'target': array([49, 49, 49, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([21, 21, 21, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([39, 39, 39, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([225, 225, 225, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([113, 113,  95, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-06-18', 'D'),\n",
       "  'target': array([76, 76, 71, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([525, 525, 525, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([600, 600, 600, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([235, 235, 235, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([205, 205, 205, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([124, 124, 124, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([201, 201, 201, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([582, 582, 582, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([59, 59, 59, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([220, 220, 215, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([375, 350, 350, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([86, 86, 86, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([390, 390, 390, ...,   0,   0,   0])},\n",
       " {'start': Period('2002-01-21', 'D'),\n",
       "  'target': array([165, 145, 140, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([200, 200, 200, ...,   0,   0,   0])},\n",
       " {'start': Period('2002-01-18', 'D'),\n",
       "  'target': array([295, 395, 525, ...,   0,   0,   0])},\n",
       " {'start': Period('2002-03-22', 'D'),\n",
       "  'target': array([500, 525, 525, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([550, 550, 550, ...,   0,   0,   0])},\n",
       " {'start': Period('2002-08-13', 'D'),\n",
       "  'target': array([34, 24, 28, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([12150, 12150, 12150, ...,     0,     0,     0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([240, 240, 240, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([405, 405, 405, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([30, 30, 30, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([106, 106, 106, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([125, 125, 125, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([2985, 2985, 2985, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([126, 126, 126, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([75, 70, 70, ...,  0,  0,  0])},\n",
       " {'start': Period('2002-10-15', 'D'),\n",
       "  'target': array([78, 81, 78, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([53, 53, 53, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([168, 168, 168, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([434, 434, 434, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-18', 'D'),\n",
       "  'target': array([225, 210, 180, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([170, 170, 170, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([413, 417, 400, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1520, 1520, 1520, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([800, 800, 775, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([775, 775, 775, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([38, 38, 38, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-05-18', 'D'),\n",
       "  'target': array([9500, 9500, 9500, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([230, 230, 225, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([49, 49, 49, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([840, 840, 840, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([50, 50, 46, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([50, 50, 50, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1100, 1100, 1100, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([3550, 3550, 3550, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([38, 38, 38, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([290, 290, 290, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([250, 250, 250, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([35, 35, 35, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([115, 115, 115, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([74, 74, 74, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1350, 1350, 1350, ...,    0,    0,    0])},\n",
       " {'start': Period('2002-04-17', 'D'),\n",
       "  'target': array([73, 74, 76, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-07-05', 'D'),\n",
       "  'target': array([210, 205, 210, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([455, 455, 455, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([70, 70, 70, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([225, 225, 225, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1954, 1954, 1954, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([360, 360, 355, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([175, 175, 175, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([242, 242, 242, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([117, 117, 117, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([10, 10, 10, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([39, 39, 39, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([100, 100, 100, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([35, 34, 40, ...,  0,  0,  0])},\n",
       " {'start': Period('2002-07-01', 'D'),\n",
       "  'target': array([6, 6, 6, ..., 0, 0, 0])},\n",
       " {'start': Period('2001-07-18', 'D'),\n",
       "  'target': array([145, 129, 113, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([77, 77, 77, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-12-31', 'D'),\n",
       "  'target': array([510, 510, 525, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([125, 125, 135, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([65, 65, 65, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([177, 177, 177, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([495, 495, 495, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([115, 115, 115, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([244, 244, 244, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([850, 850, 800, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([80000, 80000, 80000, ...,     0,     0,     0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([100, 100, 100, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([79, 79, 79, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([147, 145, 147, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([25, 25, 25, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([69, 69, 69, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([20, 20, 20, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([144, 144, 144, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([152, 152, 157, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([504, 504, 504, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([890, 890, 890, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-07-19', 'D'),\n",
       "  'target': array([115, 115, 115, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([25, 25, 25, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([890, 840, 742, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([255, 255, 255, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([290, 290, 285, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([358, 358, 358, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([440, 435, 430, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([525, 525, 525, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([119, 119, 119, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([18, 18, 17, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([105, 105, 105, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([225, 225, 225, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1404, 1404, 1404, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([15, 14, 14, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([14, 12, 13, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([310, 310, 310, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([89, 89, 89, ...,  0,  0,  0])},\n",
       " {'start': Period('2003-10-13', 'D'),\n",
       "  'target': array([235, 235, 235, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1000, 1000, 1000, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-09-19', 'D'),\n",
       "  'target': array([208, 225, 225, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([53, 52, 52, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([82, 82, 82, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([700, 700, 700, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([140, 140, 140, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([250, 250, 250, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([570, 570, 570, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([190, 190, 190, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([155, 155, 155, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([110, 110, 110, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([126, 126, 203, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([600, 600, 600, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([39, 39, 39, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([58, 58, 58, ...,  0,  0,  0])},\n",
       " {'start': Period('2003-04-23', 'D'),\n",
       "  'target': array([9, 9, 9, ..., 0, 0, 0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([125, 125, 125, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([91, 91, 91, ...,  0,  0,  0])},\n",
       " {'start': Period('2002-12-24', 'D'),\n",
       "  'target': array([120, 120, 120, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([295, 295, 295, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([400, 400, 400, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([173, 173, 173, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([17, 17, 17, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-10-17', 'D'),\n",
       "  'target': array([200, 230, 270, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([54, 54, 54, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1050, 1050, 1050, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([220, 215, 210, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1000, 1000, 1000, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([96, 93, 93, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-10-23', 'D'),\n",
       "  'target': array([229, 260, 250, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([65, 65, 65, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([875, 875, 875, ...,   0,   0,   0])},\n",
       " {'start': Period('2002-07-17', 'D'),\n",
       "  'target': array([45, 45, 45, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([13000, 13000, 13000, ...,     0,     0,     0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([180, 180, 180, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([120, 120, 120, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([446, 446, 437, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([2000, 2000, 2000, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1025, 1025, 1025, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([185, 190, 195, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([475, 475, 475, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([100, 100, 100, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([82, 82, 82, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1750, 1750, 1750, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([465, 465, 465, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([12, 12, 12, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([18, 18, 18, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([87, 87, 87, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([400, 385, 375, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([64, 60, 60, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([413, 413, 413, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([40, 40, 40, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([350, 350, 350, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([270, 270, 270, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([75, 75, 75, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([295, 295, 295, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([117, 105, 105, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([2425, 2400, 2375, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([300, 300, 300, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([300, 300, 300, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([99, 97, 99, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([170, 170, 170, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([200, 200, 200, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([137, 133, 129, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([835, 835, 835, ...,   0,   0,   0])},\n",
       " {'start': Period('2003-07-10', 'D'),\n",
       "  'target': array([86, 86, 86, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([297, 287, 277, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([27, 27, 27, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([173, 169, 169, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([65, 65, 60, ...,  0,  0,  0])},\n",
       " {'start': Period('2002-11-29', 'D'),\n",
       "  'target': array([ 97, 100, 107, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([600, 600, 600, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([170, 170, 170, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([62, 62, 62, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1100, 1125, 1125, ...,    0,    0,    0])},\n",
       " {'start': Period('2002-04-19', 'D'),\n",
       "  'target': array([950, 950, 950, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([4050, 4050, 4050, ...,    0,    0,    0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([308, 303, 298, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([615, 615, 615, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([39, 39, 39, ...,  0,  0,  0])},\n",
       " {'start': Period('2001-06-25', 'D'),\n",
       "  'target': array([500, 500, 600, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([240, 210, 210, ...,   0,   0,   0])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([60, 60, 60, ...,  0,  0,  0])}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augment=[]\n",
    "\n",
    "for column in data_csv.columns:\n",
    "    freq = \"D\"  # Daily frequency\n",
    "    augment_data = {\n",
    "        \"start\": pd.Period(pd.to_datetime(data_csv[column][0]), freq=freq),\n",
    "        \"target\": data_csv[column].iloc[1:].fillna(0).values\n",
    "    }\n",
    "    augment.append(augment_data)\n",
    "\n",
    "augment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c1582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248180/939571636.py:1: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_augment=pd.read_csv(\"/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/augment.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  98.,   96.,  100., ..., 7325., 7250., 7225.])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  547,   547,   524, ..., 23273, 22439, 22249])},\n",
       " {'start': Period('2002-04-04', 'D'),\n",
       "  'target': array([275, 275, 275, ...,  50,  50,  50])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 194,  194,  194, ..., 5925, 5900, 5900])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1125, 1125, 1125, ..., 1600, 1590, 1600])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([165, 165, 165, ..., 193, 198, 192])},\n",
       " {'start': Period('2003-08-11', 'D'),\n",
       "  'target': array([ 95,  95,  95, ..., 360, 370, 375])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 90,  90,  90, ...,  96, 111, 111])},\n",
       " {'start': Period('2001-07-23', 'D'),\n",
       "  'target': array([350, 487, 562, ..., 190, 185, 185])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  97,   97,   97, ..., 2420, 2425, 2420])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([220, 220, 220, ..., 800, 800, 800])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  53,   53,   53, ..., 1065, 1050, 1045])},\n",
       " {'start': Period('2001-07-16', 'D'),\n",
       "  'target': array([105, 105, 105, ..., 125, 125, 125])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 41,  41,  41, ..., 120, 120, 120])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([337, 337, 337, ..., 339, 333, 334])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1350, 1350, 1350, ..., 8275, 8200, 8150])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([432, 432, 432, ..., 965, 957, 957])},\n",
       " {'start': Period('2002-12-19', 'D'),\n",
       "  'target': array([1371, 1371, 1371, ...,  242,  241,  239])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([50, 50, 50, ..., 77, 77, 77])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 750,  750,  750, ..., 1150, 1150, 1150])},\n",
       " {'start': Period('2001-07-18', 'D'),\n",
       "  'target': array([ 35,  35,  35, ..., 915, 915, 920])},\n",
       " {'start': Period('2002-11-06', 'D'),\n",
       "  'target': array([132, 135, 125, ..., 278, 278, 278])},\n",
       " {'start': Period('2003-05-01', 'D'),\n",
       "  'target': array([423, 423, 423, ...,  89,  89,  85])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 87,  87,  87, ..., 775, 650, 650])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([210, 210, 210, ..., 910, 910, 910])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 280,  280,  280, ..., 2180, 2190, 2150])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([236, 236, 236, ..., 881, 846, 846])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 249,  244,  249, ..., 4000, 4050, 4050])},\n",
       " {'start': Period('2002-07-16', 'D'),\n",
       "  'target': array([94, 90, 90, ..., 64, 64, 60])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([135, 135, 135, ..., 960, 980, 940])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 145,  145,  145, ..., 1375, 1350, 1350])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 175,  175,  175, ..., 2470, 2440, 2410])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  10,   10,   10, ..., 1980, 1980, 1980])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1232, 1232, 1232, ..., 5650, 5800, 5650])},\n",
       " {'start': Period('2003-11-11', 'D'),\n",
       "  'target': array([  97,   97,  105, ..., 2605, 2600, 2635])},\n",
       " {'start': Period('2001-06-11', 'D'),\n",
       "  'target': array([ 36,  37,  38, ..., 167, 166, 167])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1140, 1140, 1140, ..., 3755, 3705, 3845])},\n",
       " {'start': Period('2001-07-16', 'D'),\n",
       "  'target': array([77, 87, 85, ..., 53, 53, 54])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  6,   6,   6, ..., 220, 220, 220])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([425, 410, 400, ..., 363, 357, 349])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([600, 600, 600, ..., 350, 350, 350])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([35, 35, 35, ..., 87, 89, 89])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([460, 460, 460, ..., 112, 113, 112])},\n",
       " {'start': Period('2002-11-22', 'D'),\n",
       "  'target': array([ 97,  97, 122, ..., 277, 277, 273])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([184, 184, 184, ..., 196, 196, 196])},\n",
       " {'start': Period('2003-07-15', 'D'),\n",
       "  'target': array([ 430,  417,  405, ..., 5325, 5387, 5400])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 80,  80,  80, ..., 150, 150, 150])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 182,  182,  182, ..., 1930, 1890, 1930])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([2506, 2088, 2506, ...,  500,  500,  500])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([219, 219, 219, ..., 980, 975, 975])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([156, 156, 156, ..., 290, 286, 284])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 621,  621,  621, ..., 1285, 1272, 1285])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 675,  675,  675, ..., 3020, 3020, 3020])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 79,  79,  79, ..., 711, 816, 781])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 6,  6,  6, ..., 28, 27, 27])},\n",
       " {'start': Period('2002-05-02', 'D'),\n",
       "  'target': array([ 174,  174,  166, ..., 4420, 4420, 4420])},\n",
       " {'start': Period('2001-07-19', 'D'),\n",
       "  'target': array([ 75,  77,  77, ..., 200, 200, 200])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([116, 116, 116, ..., 110, 112, 112])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 50,  50,  50, ..., 187, 185, 185])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 29,  29,  29, ..., 122, 123, 123])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([120, 120, 120, ..., 840, 850, 847])},\n",
       " {'start': Period('2001-11-02', 'D'),\n",
       "  'target': array([ 39,  40,  41, ..., 155, 155, 155])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([103, 103, 103, ..., 420, 428, 449])},\n",
       " {'start': Period('2002-03-21', 'D'),\n",
       "  'target': array([153, 151, 156, ..., 940, 940, 940])},\n",
       " {'start': Period('2001-12-03', 'D'),\n",
       "  'target': array([410, 390, 390, ..., 770, 760, 780])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 376,  376,  376, ..., 2160, 2078, 2110])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 95,  95,  95, ..., 182, 176, 182])},\n",
       " {'start': Period('2001-11-21', 'D'),\n",
       "  'target': array([145, 145, 145, ...,  93,  90,  89])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([300, 300, 300, ..., 775, 775, 775])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  31,   31,   31, ..., 3880, 3800, 3940])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 800,  800,  800, ..., 5550, 5550, 5550])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  49,   46,   44, ..., 1047, 1056, 1061])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([200, 200, 200, ...,  69,  69,  69])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 55,  55,  55, ..., 485, 485, 485])},\n",
       " {'start': Period('2001-07-09', 'D'),\n",
       "  'target': array([ 49,  49,  49, ..., 124, 124, 124])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 21,  21,  21, ..., 580, 585, 600])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 39,  39,  39, ..., 397, 397, 397])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 225,  225,  225, ..., 6900, 7700, 8330])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([113, 113,  95, ..., 715, 730, 735])},\n",
       " {'start': Period('2001-06-18', 'D'),\n",
       "  'target': array([ 76,  76,  71, ..., 221, 217, 217])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([525, 525, 525, ..., 386, 385, 385])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([600, 600, 600, ...,  53,  53,  53])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 235,  235,  235, ..., 4600, 4600, 4600])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 205,  205,  205, ..., 1800, 1820, 1780])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([124, 124, 124, ..., 449, 457, 457])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([201, 201, 201, ..., 500, 500, 500])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 582,  582,  582, ..., 3100, 3100, 3200])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([59, 59, 59, ..., 49, 49, 49])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([220, 220, 215, ..., 220, 220, 220])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([375, 350, 350, ..., 294, 294, 294])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  86,   86,   86, ..., 1075, 1050, 1050])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 390,  390,  390, ..., 1515, 1520, 1520])},\n",
       " {'start': Period('2002-01-21', 'D'),\n",
       "  'target': array([ 165,  145,  140, ..., 1710, 1710, 1710])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([200, 200, 200, ..., 451, 453, 453])},\n",
       " {'start': Period('2002-01-18', 'D'),\n",
       "  'target': array([295, 395, 525, ..., 655, 600, 600])},\n",
       " {'start': Period('2002-03-22', 'D'),\n",
       "  'target': array([500, 525, 525, ...,  95,  96,  94])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 550,  550,  550, ..., 1650, 1650, 1665])},\n",
       " {'start': Period('2002-08-13', 'D'),\n",
       "  'target': array([34, 24, 28, ..., 64, 65, 66])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([12150, 12150, 12150, ..., 54000, 55000, 55000])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 240,  240,  240, ..., 1715, 1710, 1720])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 405,  405,  405, ..., 8450, 8450, 8450])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([30, 30, 30, ..., 91, 97, 86])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 106,  106,  106, ..., 2410, 2410, 2420])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 125,  125,  125, ..., 3660, 3650, 3695])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([2985, 2985, 2985, ...,  335,  335,  335])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 126,  126,  126, ..., 2656, 2656, 2677])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 75,  70,  70, ..., 276, 276, 276])},\n",
       " {'start': Period('2002-10-15', 'D'),\n",
       "  'target': array([ 78,  81,  78, ..., 350, 330, 315])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([53, 53, 53, ..., 47, 48, 52])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([168, 168, 168, ..., 248, 248, 248])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 434,  434,  434, ..., 4450, 4405, 4400])},\n",
       " {'start': Period('2001-04-18', 'D'),\n",
       "  'target': array([225, 210, 180, ..., 170, 169, 170])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([170, 170, 170, ..., 156, 157, 152])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([413, 417, 400, ..., 200, 200, 200])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1520, 1520, 1520, ..., 4150, 4000, 4040])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 800,  800,  775, ..., 6950, 6950, 7050])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 775,  775,  775, ..., 1185, 1215, 1300])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  38,   38,   38, ..., 3360, 3360, 3360])},\n",
       " {'start': Period('2001-05-18', 'D'),\n",
       "  'target': array([9500, 9500, 9500, ...,  259,  252,  249])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 230,  230,  225, ..., 1275, 1255, 1245])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([49, 49, 49, ..., 86, 88, 87])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 840,  840,  840, ..., 1050, 1050, 1050])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 50,  50,  46, ..., 251, 251, 253])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([50, 50, 50, ..., 76, 76, 76])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 1100,  1100,  1100, ..., 23750, 23075, 23150])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([3550, 3550, 3550, ..., 3950, 3900, 3825])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 38,  38,  38, ..., 677, 677, 677])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 290,  290,  290, ..., 3000, 3000, 3000])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 250,  250,  250, ..., 1175, 1175, 1265])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([35, 35, 35, ..., 50, 50, 52])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 115,  115,  115, ..., 1250, 1255, 1365])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  74,   74,   74, ..., 1010, 1000, 1000])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1350, 1350, 1350, ...,  750,  750,  750])},\n",
       " {'start': Period('2002-04-17', 'D'),\n",
       "  'target': array([ 73,  74,  76, ..., 253, 253, 246])},\n",
       " {'start': Period('2001-07-05', 'D'),\n",
       "  'target': array([ 210,  205,  210, ..., 1390, 1390, 1390])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([455, 455, 455, ..., 209, 209, 210])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 70,  70,  70, ..., 135, 139, 135])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([225, 225, 225, ..., 149, 161, 150])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1954, 1954, 1954, ..., 3445, 3400, 3310])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([360, 360, 355, ..., 361, 365, 369])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([175, 175, 175, ..., 150, 150, 149])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([242, 242, 242, ..., 140, 137, 140])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([117, 117, 117, ..., 269, 270, 269])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 10,  10,  10, ..., 286, 282, 281])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  39,   39,   39, ..., 1660, 1660, 1665])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([100, 100, 100, ..., 137, 137, 137])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 35,  34,  40, ..., 128, 128, 132])},\n",
       " {'start': Period('2002-07-01', 'D'),\n",
       "  'target': array([  6,   6,   6, ..., 465, 466, 468])},\n",
       " {'start': Period('2001-07-18', 'D'),\n",
       "  'target': array([145, 129, 113, ...,  50,  50,  50])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  77,   77,   77, ..., 1095, 1095, 1095])},\n",
       " {'start': Period('2001-12-31', 'D'),\n",
       "  'target': array([510, 510, 525, ...,  50,  50,  50])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([125, 125, 135, ..., 180, 190, 185])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 65,  65,  65, ..., 695, 695, 692])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 177,  177,  177, ..., 7657, 7489, 7561])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 495,  495,  495, ..., 4925, 5000, 4995])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([115, 115, 115, ..., 320, 320, 320])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([244, 244, 244, ..., 793, 793, 793])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([850, 850, 800, ..., 530, 530, 535])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([80000, 80000, 80000, ..., 15975, 16375, 16900])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([100, 100, 100, ..., 218, 219, 219])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  79,   79,   79, ..., 1775, 1750, 1810])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([147, 145, 147, ..., 525, 530, 527])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([25, 25, 25, ..., 41, 41, 41])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  69,   69,   69, ..., 1078, 1052, 1034])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 20,  20,  20, ..., 510, 515, 510])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([144, 144, 144, ..., 680, 690, 725])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([152, 152, 157, ..., 666, 666, 668])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 504,  504,  504, ..., 2000, 1980, 2000])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 890,  890,  890, ..., 9958, 9958, 9958])},\n",
       " {'start': Period('2001-07-19', 'D'),\n",
       "  'target': array([115, 115, 115, ..., 199, 197, 194])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([25, 25, 25, ..., 50, 51, 50])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([890, 840, 742, ..., 480, 495, 490])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  255,   255,   255, ..., 11000, 13200, 14150])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([290, 290, 285, ..., 545, 530, 570])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([358, 358, 358, ..., 755, 745, 760])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 440,  435,  430, ..., 3195, 3195, 3195])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([525, 525, 525, ..., 389, 389, 378])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 119,  119,  119, ..., 4444, 4539, 4539])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 18,  18,  17, ...,  99, 105, 103])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([105, 105, 105, ..., 123, 124, 127])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([225, 225, 225, ..., 690, 690, 690])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1404, 1404, 1404, ...,  491,  490,  485])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  15,   14,   14, ..., 1208, 1192, 1183])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 14,  12,  13, ..., 124, 123, 122])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([310, 310, 310, ..., 112, 112, 109])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 89,  89,  89, ..., 705, 705, 705])},\n",
       " {'start': Period('2003-10-13', 'D'),\n",
       "  'target': array([235, 235, 235, ..., 430, 430, 430])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1000, 1000, 1000, ...,  340,  340,  340])},\n",
       " {'start': Period('2001-09-19', 'D'),\n",
       "  'target': array([208, 225, 225, ..., 477, 475, 479])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  53,   52,   52, ..., 5225, 5250, 5200])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 82,  82,  82, ..., 386, 398, 400])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([700, 700, 700, ..., 139, 139, 137])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([140, 140, 140, ..., 175, 175, 175])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 250,  250,  250, ..., 1480, 1520, 1535])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 570,  570,  570, ..., 2600, 2600, 2600])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([190, 190, 190, ..., 860, 860, 855])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([155, 155, 155, ..., 635, 635, 640])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([110, 110, 110, ..., 250, 252, 253])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([126, 126, 203, ..., 499, 499, 499])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([600, 600, 600, ...,  75,  72,  72])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 39,  39,  39, ..., 370, 370, 370])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 58,  58,  58, ..., 216, 223, 223])},\n",
       " {'start': Period('2003-04-23', 'D'),\n",
       "  'target': array([  9,   9,   9, ..., 314, 318, 316])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([125, 125, 125, ..., 145, 157, 144])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 91,  91,  91, ..., 124, 121, 112])},\n",
       " {'start': Period('2002-12-24', 'D'),\n",
       "  'target': array([ 120,  120,  120, ..., 1320, 1285, 1255])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 295,  295,  295, ..., 1220, 1225, 1220])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 400,  400,  400, ..., 5850, 5850, 5850])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([173, 173, 173, ..., 432, 432, 432])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 17,  17,  17, ..., 418, 420, 409])},\n",
       " {'start': Period('2001-10-17', 'D'),\n",
       "  'target': array([200, 230, 270, ..., 192, 192, 192])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([54, 54, 54, ..., 54, 54, 54])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1050, 1050, 1050, ..., 6000, 6000, 6000])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([220, 215, 210, ..., 183, 183, 185])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1000, 1000, 1000, ...,  255,  259,  256])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([96, 93, 93, ..., 69, 69, 69])},\n",
       " {'start': Period('2001-10-23', 'D'),\n",
       "  'target': array([229, 260, 250, ..., 463, 463, 463])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([65, 65, 65, ..., 98, 98, 98])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 875,  875,  875, ..., 3800, 3800, 3800])},\n",
       " {'start': Period('2002-07-17', 'D'),\n",
       "  'target': array([ 45,  45,  45, ..., 601, 601, 596])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([13000, 13000, 13000, ..., 29000, 29000, 29000])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([180, 180, 180, ...,  88,  89,  89])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([120, 120, 120, ..., 299, 301, 300])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([446, 446, 437, ..., 128, 128, 128])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([2000, 2000, 2000, ...,  540,  540,  550])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1025, 1025, 1025, ...,  705,  705,  705])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 185,  190,  195, ..., 6775, 6800, 6800])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 475,  475,  475, ..., 2760, 2735, 2735])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([100, 100, 100, ..., 157, 152, 153])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 82,  82,  82, ..., 338, 347, 371])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 1750,  1750,  1750, ..., 15825, 15700, 15775])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 465,  465,  465, ..., 3700, 3700, 3695])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  12,   12,   12, ..., 1795, 1805, 1790])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  18,   18,   18, ..., 1215, 1240, 1265])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  87,   87,   87, ..., 1062, 1050, 1045])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 400,  385,  375, ..., 4495, 4495, 4495])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 64,  60,  60, ..., 154, 159, 159])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([413, 413, 413, ...,  50,  50,  50])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 40,  40,  40, ..., 810, 805, 800])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([350, 350, 350, ...,  84,  89,  88])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 270,  270,  270, ..., 3080, 2925, 2925])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([75, 75, 75, ..., 71, 70, 71])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([295, 295, 295, ..., 675, 680, 690])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([117, 105, 105, ..., 626, 626, 626])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 2425,  2400,  2375, ..., 17500, 17525, 17900])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([300, 300, 300, ..., 935, 935, 935])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 300,  300,  300, ..., 2675, 2675, 2675])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  99,   97,   99, ..., 1305, 1250, 1335])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([170, 170, 170, ..., 150, 150, 150])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([200, 200, 200, ...,  76,  75,  74])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 137,  133,  129, ..., 1025, 1015, 1025])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 835,  835,  835, ..., 2810, 2795, 2790])},\n",
       " {'start': Period('2003-07-10', 'D'),\n",
       "  'target': array([ 86,  86,  86, ..., 291, 295, 289])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([297, 287, 277, ..., 130, 129, 127])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 27,  27,  27, ..., 349, 364, 369])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([173, 169, 169, ...,  69,  69,  69])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 65,  65,  60, ..., 348, 348, 345])},\n",
       " {'start': Period('2002-11-29', 'D'),\n",
       "  'target': array([ 97, 100, 107, ..., 195, 196, 196])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 600,  600,  600, ..., 2710, 2700, 2695])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([170, 170, 170, ..., 695, 700, 700])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 62,  62,  62, ..., 966, 972, 965])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([1100, 1125, 1125, ..., 1815, 1815, 1815])},\n",
       " {'start': Period('2002-04-19', 'D'),\n",
       "  'target': array([950, 950, 950, ..., 282, 282, 265])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([4050, 4050, 4050, ...,  500,  500,  500])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([  308,   303,   298, ..., 20400, 20500, 20850])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 615,  615,  615, ..., 6230, 6235, 6260])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 39,  39,  39, ..., 160, 160, 160])},\n",
       " {'start': Period('2001-06-25', 'D'),\n",
       "  'target': array([500, 500, 600, ...,  66,  66,  63])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([240, 210, 210, ...,  64,  63,  62])},\n",
       " {'start': Period('2001-04-17', 'D'),\n",
       "  'target': array([ 60,  60,  60, ..., 155, 157, 157])}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augment=pd.read_csv(\"/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/augment.csv\")\n",
    "augment=[]\n",
    "\n",
    "for column in data_augment.columns:\n",
    "    freq = \"D\"  # Daily frequency\n",
    "    augment_data = {\n",
    "        \"start\": pd.Period(pd.to_datetime(data_augment[column][0]), freq=freq),\n",
    "        \"target\": pd.to_numeric(data_augment[column].iloc[1:].fillna(0).values)\n",
    "    }\n",
    "    augment.append(augment_data)\n",
    "\n",
    "augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2efd7585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MASE    1.006511\n",
       "WQL     0.994295\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import gmean  # requires: pip install scipy\n",
    "\n",
    "\n",
    "def agg_relative_score(model_df: pd.DataFrame, baseline_df: pd.DataFrame):\n",
    "    relative_score = model_df.drop(\"model\", axis=\"columns\") / baseline_df.drop(\n",
    "        \"model\", axis=\"columns\"\n",
    "    )\n",
    "    return relative_score.agg(gmean)\n",
    "\n",
    "\n",
    "result_df = pd.read_csv(\"/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/result-augment-test75.csv\").set_index(\"dataset\")\n",
    "baseline_df = pd.read_csv(\"/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/result-no-augment-test.csv\").set_index(\"dataset\")\n",
    "\n",
    "agg_score_df = agg_relative_score(result_df, baseline_df)\n",
    "agg_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a50350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MASE    1.0\n",
       "WQL     1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import gmean  # requires: pip install scipy\n",
    "\n",
    "\n",
    "def agg_relative_score(model_df: pd.DataFrame, baseline_df: pd.DataFrame):\n",
    "    relative_score = model_df.drop(\"model\", axis=\"columns\") / baseline_df.drop(\n",
    "        \"model\", axis=\"columns\"\n",
    "    )\n",
    "    return relative_score.agg(gmean)\n",
    "\n",
    "\n",
    "result_df = pd.read_csv(\"/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/result-no-augment-test.csv\").set_index(\"dataset\")\n",
    "baseline_df = pd.read_csv(\"/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/result-no-augment-test.csv\").set_index(\"dataset\")\n",
    "\n",
    "agg_score_df = agg_relative_score(result_df, baseline_df)\n",
    "agg_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb2cb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MASE    0.862924\n",
       "WQL     0.940035\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import gmean  # requires: pip install scipy\n",
    "\n",
    "\n",
    "def agg_relative_score(model_df: pd.DataFrame, baseline_df: pd.DataFrame):\n",
    "    relative_score = model_df.drop(\"model\", axis=\"columns\") / baseline_df.drop(\n",
    "        \"model\", axis=\"columns\"\n",
    "    )\n",
    "    return relative_score.agg(gmean)\n",
    "\n",
    "\n",
    "result_df = pd.read_csv(\"/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/result-no-augment-valid.csv\").set_index(\"dataset\")\n",
    "baseline_df = pd.read_csv(\"/home/yogi/chronos-research/Retrieval-Augmented-Time-Series-Forecasting/result-no-augment-test.csv\").set_index(\"dataset\")\n",
    "\n",
    "agg_score_df = agg_relative_score(result_df, baseline_df)\n",
    "agg_score_df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "chronos-zero-shot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04b25d5da36c4b3d85c9f084f1a7e944": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0631addcb8314a5e9ffd0d8616cbe5bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "067b0017c8cb4d6881dcb74a1d909d1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "06d7f2870e4b44a9bfc243ea3c5f1e44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06dfa2c46e7f49fd8ee1377703af09fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "actual - actual.csv",
       "Sales - Sales.csv",
       "sales_forecast.csv"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Actual CSV:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_a7a8b83d7bd94db4b1374e5bb25e50a8",
      "style": "IPY_MODEL_40575e2075874b0b90c568d6d0c6ff56"
     }
    },
    "0835bfa97f0448aab6385ddd7bd14bd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "089f60a7f9634bca9c1d1da5cd45cd7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c3a97c25190457585b4dc023646f6b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "102a251d39594154a185530ac758af9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c2146e284fc4cc89706a055a4a67724",
      "placeholder": "",
      "style": "IPY_MODEL_1b958a3c132c445493156c549b42bf1b",
      "value": "config.json:100%"
     }
    },
    "108beac8131e4ea08d46d7b44fcc7650": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1874d8ee70074e41be76199fffd4f340": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FileUploadModel",
     "state": {
      "_counter": 1,
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FileUploadModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FileUploadView",
      "accept": ".csv",
      "button_style": "",
      "data": [
       null
      ],
      "description": "Upload CSV File",
      "description_tooltip": null,
      "disabled": false,
      "error": "",
      "icon": "upload",
      "layout": "IPY_MODEL_089f60a7f9634bca9c1d1da5cd45cd7f",
      "metadata": [
       {
        "lastModified": 1717850875965,
        "name": "Sales - Sales.csv",
        "size": 3138,
        "type": "text/csv"
       }
      ],
      "multiple": false,
      "style": "IPY_MODEL_0835bfa97f0448aab6385ddd7bd14bd5"
     }
    },
    "1b958a3c132c445493156c549b42bf1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c2146e284fc4cc89706a055a4a67724": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d12abb6a6b945d4adfe93f305fea145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Load Actual CSV",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_f661eb28781c491ab4ff0e3f3654dcb6",
      "style": "IPY_MODEL_a7f3fd07f9a04be580d5fd0953eb7548",
      "tooltip": ""
     }
    },
    "1d9325849f5c44dfacec7385f5b6e76e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_102a251d39594154a185530ac758af9f",
       "IPY_MODEL_590e88b2e7e04a5b88815adc7f698040",
       "IPY_MODEL_c2379e8bd42e4ed8a1df43db07600739"
      ],
      "layout": "IPY_MODEL_6c672aba408a471a9a0f2c6199197ef7"
     }
    },
    "200c293391c24638919f41d2324ac19d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2014f6a77f004ed0b477b899e8058438": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "290d548352f14232b8fc3f0e00bbcab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FileUploadModel",
     "state": {
      "_counter": 1,
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FileUploadModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FileUploadView",
      "accept": ".csv",
      "button_style": "",
      "data": [
       null
      ],
      "description": "Upload CSV File",
      "description_tooltip": null,
      "disabled": false,
      "error": "",
      "icon": "upload",
      "layout": "IPY_MODEL_8be2c56d750a45fca4247850d6bba538",
      "metadata": [
       {
        "lastModified": 1717850888150,
        "name": "actual - actual.csv",
        "size": 3424,
        "type": "text/csv"
       }
      ],
      "multiple": false,
      "style": "IPY_MODEL_2014f6a77f004ed0b477b899e8058438"
     }
    },
    "2e3ec3c003b1446fad1f71ff721d0033": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5215499cb26f4bcf88d53e423fe6a2e8",
       "IPY_MODEL_6931601939d744d2bdf69f8132b69ac8",
       "IPY_MODEL_4e7d2e3da952406f91cc77e60cefa607"
      ],
      "layout": "IPY_MODEL_ffd2308c13a548acbbdbc097725b3642"
     }
    },
    "3fc512b60a964ac7b58bb654cb3b08b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40575e2075874b0b90c568d6d0c6ff56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4478143f0f6a484abb05216c17265790": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_0631addcb8314a5e9ffd0d8616cbe5bc",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "File 'Sales - Sales.csv' Uploaded successfully, it may take a minute to show in the files section. Or you can hit the circular arrow to refresh your files folder.\n"
        ]
       }
      ]
     }
    },
    "4e7d2e3da952406f91cc77e60cefa607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcba3a7ee63d4e0d9b617092296f3449",
      "placeholder": "",
      "style": "IPY_MODEL_e5d5f382d01e41758df0cb7ad38de08e",
      "value": "142/142[00:00&lt;00:00,8.52kB/s]"
     }
    },
    "4f60c6407e6e422286143eb287a2de39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "date",
       "sales"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Sales Column:",
      "description_tooltip": null,
      "disabled": false,
      "index": 1,
      "layout": "IPY_MODEL_723d38a2a9c3419c87c26e66775f3ee3",
      "style": "IPY_MODEL_f9f6b232b6d04c39b28c1968ea733843"
     }
    },
    "5180a85361264cb28e8036c3603e795c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5215499cb26f4bcf88d53e423fe6a2e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fc512b60a964ac7b58bb654cb3b08b0",
      "placeholder": "",
      "style": "IPY_MODEL_0c3a97c25190457585b4dc023646f6b9",
      "value": "generation_config.json:100%"
     }
    },
    "534c91faa2254e05ab83a22ac4c119f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "541ab7863e044d4986f45f98f412dc4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54e10d909c4348889f6922c61d25cc0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    },
    "574237b7af15482b94c70e77760093a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5747d35ed914479ca4512d090d77e919": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57a56a4f30334d3ebd8752c16bf3e53c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "1",
       "2",
       "3",
       "4",
       "5",
       "6",
       "7",
       "8",
       "9",
       "10",
       "11",
       "12",
       "13",
       "14",
       "15",
       "16",
       "17",
       "18",
       "19",
       "20"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Forecast Length:",
      "description_tooltip": null,
      "disabled": false,
      "index": 11,
      "layout": "IPY_MODEL_e405b8661fd74ed7a857c478f60c960e",
      "style": "IPY_MODEL_067b0017c8cb4d6881dcb74a1d909d1b"
     }
    },
    "590e88b2e7e04a5b88815adc7f698040": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_541ab7863e044d4986f45f98f412dc4f",
      "max": 1113,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8384134624d470f8282806775f15ce4",
      "value": 1113
     }
    },
    "59821c23c0c34686a6d3bd5edf70e07c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Select Columns",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_ea5b5f1715c149d39752fa7ff11e7804",
      "style": "IPY_MODEL_c733ecb575654a81954d8e5e5722bb36",
      "tooltip": ""
     }
    },
    "598e1c32c74c4cfdaace8b0bf2498e6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "date",
       "sales"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Sales Column:",
      "description_tooltip": null,
      "disabled": false,
      "index": 1,
      "layout": "IPY_MODEL_7ac47337ccff4e68bd17bbbbeed45559",
      "style": "IPY_MODEL_906716ac7115467dadc90075136e68fa"
     }
    },
    "5db692cde53b48af8420bf42e76c3151": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e78922b5cfc14dd5b1442c3619723d0f",
      "placeholder": "",
      "style": "IPY_MODEL_7f0f9b40fdc14190baf4018fd77deb42",
      "value": "185M/185M[00:00&lt;00:00,280MB/s]"
     }
    },
    "5e1dfd1b3f3f4e4c8186192e973ad7d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "BoundedIntTextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "BoundedIntTextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntTextView",
      "continuous_update": false,
      "description": "Interval (days):",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_8ade5d3e926f458fab9eb03a4eab80e7",
      "max": 365,
      "min": 1,
      "step": 1,
      "style": "IPY_MODEL_54e10d909c4348889f6922c61d25cc0d",
      "value": 7
     }
    },
    "632eaddbb62f43b6827b82b991f5b406": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "date",
       "sales"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Date Column:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_04b25d5da36c4b3d85c9f084f1a7e944",
      "style": "IPY_MODEL_06d7f2870e4b44a9bfc243ea3c5f1e44"
     }
    },
    "67af81a8b78b4b8a8c805c459bf94c99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6931601939d744d2bdf69f8132b69ac8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9d908ca855840859c9f71c24f45fbdb",
      "max": 142,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67af81a8b78b4b8a8c805c459bf94c99",
      "value": 142
     }
    },
    "6a35904eafef4767ac32bd7de73d63f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Run Forecast",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_574237b7af15482b94c70e77760093a4",
      "style": "IPY_MODEL_d978aa2849df46a480ff1afbe1814261",
      "tooltip": "Click to run forecast"
     }
    },
    "6c672aba408a471a9a0f2c6199197ef7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c6fb77aed8146e69cb84aede8ea7d5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "723d38a2a9c3419c87c26e66775f3ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7973660a5f4243cf91cdc107c8c26dd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ac47337ccff4e68bd17bbbbeed45559": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e1073d3b09544a39d65eaa6c816349d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "Sales - Sales.csv"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "CSV Files:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_5180a85361264cb28e8036c3603e795c",
      "style": "IPY_MODEL_108beac8131e4ea08d46d7b44fcc7650"
     }
    },
    "7f0f9b40fdc14190baf4018fd77deb42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f65342b0ac1499382a1abe6675e9a34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5a616fd0dda4e0e89ad83d28ce233bd",
      "max": 184632480,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_534c91faa2254e05ab83a22ac4c119f5",
      "value": 184632480
     }
    },
    "869d500dfbd04e3ca7333cdc14b141ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "8ade5d3e926f458fab9eb03a4eab80e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8be2c56d750a45fca4247850d6bba538": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "906716ac7115467dadc90075136e68fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94a770aeb84e4a54bbd25b0efb4e7839": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0f4b4ea26b641d8aae2557c9e8a6158": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Load CSV File",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_94a770aeb84e4a54bbd25b0efb4e7839",
      "style": "IPY_MODEL_869d500dfbd04e3ca7333cdc14b141ed",
      "tooltip": ""
     }
    },
    "a4a71e01b34f4dedb1a35e4d8307be03": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_f535d45aa1b7463e930f9ec25c6e325f",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "File 'actual - actual.csv' Uploaded successfully, it may take a minute to show in the files section. Or you can hit the circular arrow to refresh your files folder.\n"
        ]
       }
      ]
     }
    },
    "a77113dcb21e4be9a53be4a773fac2ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7a8b83d7bd94db4b1374e5bb25e50a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7f3fd07f9a04be580d5fd0953eb7548": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "aaf7138099de4913a4162dfe9a331f33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Select Columns",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_7973660a5f4243cf91cdc107c8c26dd3",
      "style": "IPY_MODEL_f5e41a8ac0c74913b5d683f55ed6fd89",
      "tooltip": ""
     }
    },
    "b53f6242766f4b478f783e6b1fa5b20a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "date",
       "sales"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Date Column:",
      "description_tooltip": null,
      "disabled": false,
      "index": 0,
      "layout": "IPY_MODEL_da338a9ca6d849879ab4f2c5bd610202",
      "style": "IPY_MODEL_200c293391c24638919f41d2324ac19d"
     }
    },
    "c2379e8bd42e4ed8a1df43db07600739": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e92ca8cf37b74950a679b68a00b0405e",
      "placeholder": "",
      "style": "IPY_MODEL_5747d35ed914479ca4512d090d77e919",
      "value": "1.11k/1.11k[00:00&lt;00:00,78.1kB/s]"
     }
    },
    "c733ecb575654a81954d8e5e5722bb36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "c9d908ca855840859c9f71c24f45fbdb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d362cf94b1e4489a871deb9a887fe00f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb0f031412eb46168ec7a2764d59ae10",
       "IPY_MODEL_7f65342b0ac1499382a1abe6675e9a34",
       "IPY_MODEL_5db692cde53b48af8420bf42e76c3151"
      ],
      "layout": "IPY_MODEL_dbb913d79d714ac7815b634caf5bc52a"
     }
    },
    "d978aa2849df46a480ff1afbe1814261": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "da338a9ca6d849879ab4f2c5bd610202": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbb913d79d714ac7815b634caf5bc52a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e405b8661fd74ed7a857c478f60c960e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5a616fd0dda4e0e89ad83d28ce233bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5d5f382d01e41758df0cb7ad38de08e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e78922b5cfc14dd5b1442c3619723d0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e92ca8cf37b74950a679b68a00b0405e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea5b5f1715c149d39752fa7ff11e7804": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f535d45aa1b7463e930f9ec25c6e325f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5e41a8ac0c74913b5d683f55ed6fd89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "f661eb28781c491ab4ff0e3f3654dcb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8384134624d470f8282806775f15ce4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f9f6b232b6d04c39b28c1968ea733843": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb0f031412eb46168ec7a2764d59ae10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c6fb77aed8146e69cb84aede8ea7d5d",
      "placeholder": "",
      "style": "IPY_MODEL_a77113dcb21e4be9a53be4a773fac2ce",
      "value": "model.safetensors:100%"
     }
    },
    "fcba3a7ee63d4e0d9b617092296f3449": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffd2308c13a548acbbdbc097725b3642": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
