{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0025,
      "grad_norm": 0.32818135619163513,
      "learning_rate": 0.0009975000000000001,
      "loss": 2.138,
      "step": 500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.33922114968299866,
      "learning_rate": 0.000995,
      "loss": 2.1138,
      "step": 1000
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.35432663559913635,
      "learning_rate": 0.0009925000000000001,
      "loss": 2.1008,
      "step": 1500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.32476139068603516,
      "learning_rate": 0.00099,
      "loss": 2.0758,
      "step": 2000
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.339393675327301,
      "learning_rate": 0.0009875,
      "loss": 2.0784,
      "step": 2500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.35639312863349915,
      "learning_rate": 0.000985,
      "loss": 2.074,
      "step": 3000
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.3283926248550415,
      "learning_rate": 0.0009825,
      "loss": 2.0697,
      "step": 3500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.39411461353302,
      "learning_rate": 0.00098,
      "loss": 2.0448,
      "step": 4000
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.3229702115058899,
      "learning_rate": 0.0009775,
      "loss": 2.0419,
      "step": 4500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.35568609833717346,
      "learning_rate": 0.000975,
      "loss": 2.0366,
      "step": 5000
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.34729182720184326,
      "learning_rate": 0.0009725000000000001,
      "loss": 2.0291,
      "step": 5500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.370065838098526,
      "learning_rate": 0.0009699999999999999,
      "loss": 2.012,
      "step": 6000
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.45716384053230286,
      "learning_rate": 0.0009675,
      "loss": 1.996,
      "step": 6500
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.4013822674751282,
      "learning_rate": 0.000965,
      "loss": 1.9931,
      "step": 7000
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.4561116099357605,
      "learning_rate": 0.0009625,
      "loss": 1.9833,
      "step": 7500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4084717035293579,
      "learning_rate": 0.00096,
      "loss": 1.9719,
      "step": 8000
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.4480932950973511,
      "learning_rate": 0.0009575,
      "loss": 1.9644,
      "step": 8500
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.45078739523887634,
      "learning_rate": 0.000955,
      "loss": 1.9511,
      "step": 9000
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.4732641577720642,
      "learning_rate": 0.0009525,
      "loss": 1.9267,
      "step": 9500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.40165209770202637,
      "learning_rate": 0.00095,
      "loss": 1.9314,
      "step": 10000
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.5327157974243164,
      "learning_rate": 0.0009475,
      "loss": 1.9171,
      "step": 10500
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.5087348222732544,
      "learning_rate": 0.000945,
      "loss": 1.892,
      "step": 11000
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.5313195586204529,
      "learning_rate": 0.0009425,
      "loss": 1.9059,
      "step": 11500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6308708786964417,
      "learning_rate": 0.00094,
      "loss": 1.8878,
      "step": 12000
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.5848931670188904,
      "learning_rate": 0.0009375,
      "loss": 1.8872,
      "step": 12500
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.5244683623313904,
      "learning_rate": 0.0009350000000000001,
      "loss": 1.8624,
      "step": 13000
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.5556108951568604,
      "learning_rate": 0.0009325000000000001,
      "loss": 1.8619,
      "step": 13500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5300889611244202,
      "learning_rate": 0.00093,
      "loss": 1.8449,
      "step": 14000
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.6768564581871033,
      "learning_rate": 0.0009275,
      "loss": 1.8363,
      "step": 14500
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.6091274619102478,
      "learning_rate": 0.000925,
      "loss": 1.8193,
      "step": 15000
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.5915288329124451,
      "learning_rate": 0.0009225,
      "loss": 1.8256,
      "step": 15500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.6257628798484802,
      "learning_rate": 0.00092,
      "loss": 1.8016,
      "step": 16000
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.6791263222694397,
      "learning_rate": 0.0009175,
      "loss": 1.7962,
      "step": 16500
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.5990757942199707,
      "learning_rate": 0.000915,
      "loss": 1.7816,
      "step": 17000
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.7975059151649475,
      "learning_rate": 0.0009125,
      "loss": 1.7732,
      "step": 17500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6432626247406006,
      "learning_rate": 0.00091,
      "loss": 1.7729,
      "step": 18000
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.8038193583488464,
      "learning_rate": 0.0009075,
      "loss": 1.7644,
      "step": 18500
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.7596381306648254,
      "learning_rate": 0.0009050000000000001,
      "loss": 1.7453,
      "step": 19000
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.6444386839866638,
      "learning_rate": 0.0009025,
      "loss": 1.7452,
      "step": 19500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6110246181488037,
      "learning_rate": 0.0009000000000000001,
      "loss": 1.7416,
      "step": 20000
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.7949674725532532,
      "learning_rate": 0.0008975,
      "loss": 1.7337,
      "step": 20500
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.5875840187072754,
      "learning_rate": 0.0008950000000000001,
      "loss": 1.7097,
      "step": 21000
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.6700693368911743,
      "learning_rate": 0.0008925,
      "loss": 1.7057,
      "step": 21500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7054669857025146,
      "learning_rate": 0.0008900000000000001,
      "loss": 1.6939,
      "step": 22000
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.6127341389656067,
      "learning_rate": 0.0008874999999999999,
      "loss": 1.6907,
      "step": 22500
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.7233451008796692,
      "learning_rate": 0.000885,
      "loss": 1.6609,
      "step": 23000
    },
    {
      "epoch": 0.1175,
      "grad_norm": 0.7619771957397461,
      "learning_rate": 0.0008824999999999999,
      "loss": 1.6695,
      "step": 23500
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7583577036857605,
      "learning_rate": 0.00088,
      "loss": 1.6589,
      "step": 24000
    },
    {
      "epoch": 0.1225,
      "grad_norm": 0.7872738838195801,
      "learning_rate": 0.0008774999999999999,
      "loss": 1.6555,
      "step": 24500
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.7344703078269958,
      "learning_rate": 0.000875,
      "loss": 1.6577,
      "step": 25000
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.695345938205719,
      "learning_rate": 0.0008725000000000001,
      "loss": 1.6381,
      "step": 25500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7004199028015137,
      "learning_rate": 0.00087,
      "loss": 1.6412,
      "step": 26000
    },
    {
      "epoch": 0.1325,
      "grad_norm": 0.7260024547576904,
      "learning_rate": 0.0008675000000000001,
      "loss": 1.6292,
      "step": 26500
    },
    {
      "epoch": 0.135,
      "grad_norm": 0.7552803158760071,
      "learning_rate": 0.000865,
      "loss": 1.6158,
      "step": 27000
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.7550406455993652,
      "learning_rate": 0.0008625000000000001,
      "loss": 1.6123,
      "step": 27500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8036304712295532,
      "learning_rate": 0.00086,
      "loss": 1.5961,
      "step": 28000
    },
    {
      "epoch": 0.1425,
      "grad_norm": 0.748841404914856,
      "learning_rate": 0.0008575000000000001,
      "loss": 1.6047,
      "step": 28500
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.7956753373146057,
      "learning_rate": 0.000855,
      "loss": 1.601,
      "step": 29000
    },
    {
      "epoch": 0.1475,
      "grad_norm": 0.812049388885498,
      "learning_rate": 0.0008525000000000001,
      "loss": 1.5808,
      "step": 29500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7730938792228699,
      "learning_rate": 0.00085,
      "loss": 1.5746,
      "step": 30000
    },
    {
      "epoch": 0.1525,
      "grad_norm": 0.7364100217819214,
      "learning_rate": 0.0008475000000000001,
      "loss": 1.5735,
      "step": 30500
    },
    {
      "epoch": 0.155,
      "grad_norm": 0.7682073712348938,
      "learning_rate": 0.0008449999999999999,
      "loss": 1.5686,
      "step": 31000
    },
    {
      "epoch": 0.1575,
      "grad_norm": 0.7827340364456177,
      "learning_rate": 0.0008425,
      "loss": 1.5542,
      "step": 31500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.711016058921814,
      "learning_rate": 0.00084,
      "loss": 1.5513,
      "step": 32000
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.7724481821060181,
      "learning_rate": 0.0008375,
      "loss": 1.5449,
      "step": 32500
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.7735852003097534,
      "learning_rate": 0.000835,
      "loss": 1.5334,
      "step": 33000
    },
    {
      "epoch": 0.1675,
      "grad_norm": 0.8669442534446716,
      "learning_rate": 0.0008325,
      "loss": 1.5375,
      "step": 33500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8938687443733215,
      "learning_rate": 0.00083,
      "loss": 1.544,
      "step": 34000
    },
    {
      "epoch": 0.1725,
      "grad_norm": 0.7835668325424194,
      "learning_rate": 0.0008275,
      "loss": 1.5223,
      "step": 34500
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.8152807354927063,
      "learning_rate": 0.000825,
      "loss": 1.5238,
      "step": 35000
    },
    {
      "epoch": 0.1775,
      "grad_norm": 0.7825813889503479,
      "learning_rate": 0.0008225,
      "loss": 1.5068,
      "step": 35500
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8279501795768738,
      "learning_rate": 0.00082,
      "loss": 1.5017,
      "step": 36000
    },
    {
      "epoch": 0.1825,
      "grad_norm": 0.75173020362854,
      "learning_rate": 0.0008175,
      "loss": 1.5072,
      "step": 36500
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.8312385678291321,
      "learning_rate": 0.000815,
      "loss": 1.491,
      "step": 37000
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.8601638078689575,
      "learning_rate": 0.0008125000000000001,
      "loss": 1.4888,
      "step": 37500
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9030728936195374,
      "learning_rate": 0.0008100000000000001,
      "loss": 1.4831,
      "step": 38000
    },
    {
      "epoch": 0.1925,
      "grad_norm": 0.8524333238601685,
      "learning_rate": 0.0008075000000000001,
      "loss": 1.4806,
      "step": 38500
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.9938513040542603,
      "learning_rate": 0.000805,
      "loss": 1.478,
      "step": 39000
    },
    {
      "epoch": 0.1975,
      "grad_norm": 0.8239350318908691,
      "learning_rate": 0.0008025,
      "loss": 1.4649,
      "step": 39500
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8193582892417908,
      "learning_rate": 0.0008,
      "loss": 1.4626,
      "step": 40000
    },
    {
      "epoch": 0.2025,
      "grad_norm": 1.006777048110962,
      "learning_rate": 0.0007975,
      "loss": 1.4459,
      "step": 40500
    },
    {
      "epoch": 0.205,
      "grad_norm": 0.8280757665634155,
      "learning_rate": 0.000795,
      "loss": 1.4508,
      "step": 41000
    },
    {
      "epoch": 0.2075,
      "grad_norm": 0.8299202919006348,
      "learning_rate": 0.0007925,
      "loss": 1.4431,
      "step": 41500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7983468770980835,
      "learning_rate": 0.00079,
      "loss": 1.4352,
      "step": 42000
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.8761312961578369,
      "learning_rate": 0.0007875,
      "loss": 1.4342,
      "step": 42500
    },
    {
      "epoch": 0.215,
      "grad_norm": 0.7985135316848755,
      "learning_rate": 0.000785,
      "loss": 1.416,
      "step": 43000
    },
    {
      "epoch": 0.2175,
      "grad_norm": 0.9316146373748779,
      "learning_rate": 0.0007825,
      "loss": 1.4249,
      "step": 43500
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9389433264732361,
      "learning_rate": 0.0007800000000000001,
      "loss": 1.4283,
      "step": 44000
    },
    {
      "epoch": 0.2225,
      "grad_norm": 0.8169519305229187,
      "learning_rate": 0.0007775,
      "loss": 1.4101,
      "step": 44500
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.7943314909934998,
      "learning_rate": 0.0007750000000000001,
      "loss": 1.4094,
      "step": 45000
    },
    {
      "epoch": 0.2275,
      "grad_norm": 1.0342556238174438,
      "learning_rate": 0.0007725,
      "loss": 1.4083,
      "step": 45500
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8244766592979431,
      "learning_rate": 0.0007700000000000001,
      "loss": 1.3936,
      "step": 46000
    },
    {
      "epoch": 0.2325,
      "grad_norm": 0.8492168188095093,
      "learning_rate": 0.0007675,
      "loss": 1.3931,
      "step": 46500
    },
    {
      "epoch": 0.235,
      "grad_norm": 0.8379322290420532,
      "learning_rate": 0.0007650000000000001,
      "loss": 1.3918,
      "step": 47000
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.9070993065834045,
      "learning_rate": 0.0007624999999999999,
      "loss": 1.3809,
      "step": 47500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8076708316802979,
      "learning_rate": 0.00076,
      "loss": 1.3686,
      "step": 48000
    },
    {
      "epoch": 0.2425,
      "grad_norm": 0.8481590747833252,
      "learning_rate": 0.0007574999999999999,
      "loss": 1.3808,
      "step": 48500
    },
    {
      "epoch": 0.245,
      "grad_norm": 0.9494875073432922,
      "learning_rate": 0.000755,
      "loss": 1.3835,
      "step": 49000
    },
    {
      "epoch": 0.2475,
      "grad_norm": 0.9953011274337769,
      "learning_rate": 0.0007524999999999999,
      "loss": 1.367,
      "step": 49500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8652639985084534,
      "learning_rate": 0.00075,
      "loss": 1.3641,
      "step": 50000
    },
    {
      "epoch": 0.2525,
      "grad_norm": 0.8378599882125854,
      "learning_rate": 0.0007475000000000001,
      "loss": 1.3479,
      "step": 50500
    },
    {
      "epoch": 0.255,
      "grad_norm": 0.9277875423431396,
      "learning_rate": 0.000745,
      "loss": 1.3492,
      "step": 51000
    },
    {
      "epoch": 0.2575,
      "grad_norm": 0.8974598050117493,
      "learning_rate": 0.0007425000000000001,
      "loss": 1.3487,
      "step": 51500
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.062340497970581,
      "learning_rate": 0.00074,
      "loss": 1.3375,
      "step": 52000
    },
    {
      "epoch": 0.2625,
      "grad_norm": 0.9682818055152893,
      "learning_rate": 0.0007375000000000001,
      "loss": 1.3456,
      "step": 52500
    },
    {
      "epoch": 0.265,
      "grad_norm": 0.9593380689620972,
      "learning_rate": 0.000735,
      "loss": 1.3346,
      "step": 53000
    },
    {
      "epoch": 0.2675,
      "grad_norm": 0.99692302942276,
      "learning_rate": 0.0007325000000000001,
      "loss": 1.3281,
      "step": 53500
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9112920761108398,
      "learning_rate": 0.00073,
      "loss": 1.3234,
      "step": 54000
    },
    {
      "epoch": 0.2725,
      "grad_norm": 0.9115209579467773,
      "learning_rate": 0.0007275000000000001,
      "loss": 1.3156,
      "step": 54500
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.9324088096618652,
      "learning_rate": 0.000725,
      "loss": 1.3238,
      "step": 55000
    },
    {
      "epoch": 0.2775,
      "grad_norm": 0.8264107704162598,
      "learning_rate": 0.0007225,
      "loss": 1.3226,
      "step": 55500
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9345314502716064,
      "learning_rate": 0.0007199999999999999,
      "loss": 1.3034,
      "step": 56000
    },
    {
      "epoch": 0.2825,
      "grad_norm": 0.9294800162315369,
      "learning_rate": 0.0007175,
      "loss": 1.2968,
      "step": 56500
    },
    {
      "epoch": 0.285,
      "grad_norm": 0.8318557739257812,
      "learning_rate": 0.000715,
      "loss": 1.3044,
      "step": 57000
    },
    {
      "epoch": 0.2875,
      "grad_norm": 0.8692286610603333,
      "learning_rate": 0.0007125,
      "loss": 1.3212,
      "step": 57500
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.051326036453247,
      "learning_rate": 0.00071,
      "loss": 1.2951,
      "step": 58000
    },
    {
      "epoch": 0.2925,
      "grad_norm": 1.0039491653442383,
      "learning_rate": 0.0007075,
      "loss": 1.2841,
      "step": 58500
    },
    {
      "epoch": 0.295,
      "grad_norm": 0.9755054116249084,
      "learning_rate": 0.000705,
      "loss": 1.2776,
      "step": 59000
    },
    {
      "epoch": 0.2975,
      "grad_norm": 0.8989742398262024,
      "learning_rate": 0.0007025,
      "loss": 1.273,
      "step": 59500
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8772386908531189,
      "learning_rate": 0.0007,
      "loss": 1.2831,
      "step": 60000
    },
    {
      "epoch": 0.3025,
      "grad_norm": 0.899133026599884,
      "learning_rate": 0.0006975,
      "loss": 1.276,
      "step": 60500
    },
    {
      "epoch": 0.305,
      "grad_norm": 1.0367261171340942,
      "learning_rate": 0.000695,
      "loss": 1.2715,
      "step": 61000
    },
    {
      "epoch": 0.3075,
      "grad_norm": 0.9976819157600403,
      "learning_rate": 0.0006925,
      "loss": 1.2691,
      "step": 61500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9051356315612793,
      "learning_rate": 0.00069,
      "loss": 1.2673,
      "step": 62000
    },
    {
      "epoch": 0.3125,
      "grad_norm": 0.9746292233467102,
      "learning_rate": 0.0006875,
      "loss": 1.2663,
      "step": 62500
    },
    {
      "epoch": 0.315,
      "grad_norm": 0.9634332656860352,
      "learning_rate": 0.0006850000000000001,
      "loss": 1.2643,
      "step": 63000
    },
    {
      "epoch": 0.3175,
      "grad_norm": 0.9848639965057373,
      "learning_rate": 0.0006825000000000001,
      "loss": 1.2515,
      "step": 63500
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0029553174972534,
      "learning_rate": 0.00068,
      "loss": 1.2425,
      "step": 64000
    },
    {
      "epoch": 0.3225,
      "grad_norm": 0.9996365904808044,
      "learning_rate": 0.0006775,
      "loss": 1.2471,
      "step": 64500
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.8879905939102173,
      "learning_rate": 0.000675,
      "loss": 1.2506,
      "step": 65000
    },
    {
      "epoch": 0.3275,
      "grad_norm": 1.0813789367675781,
      "learning_rate": 0.0006725,
      "loss": 1.2455,
      "step": 65500
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9816136956214905,
      "learning_rate": 0.00067,
      "loss": 1.2344,
      "step": 66000
    },
    {
      "epoch": 0.3325,
      "grad_norm": 0.9478587508201599,
      "learning_rate": 0.0006675,
      "loss": 1.2279,
      "step": 66500
    },
    {
      "epoch": 0.335,
      "grad_norm": 1.0415900945663452,
      "learning_rate": 0.000665,
      "loss": 1.2278,
      "step": 67000
    },
    {
      "epoch": 0.3375,
      "grad_norm": 1.3076616525650024,
      "learning_rate": 0.0006625,
      "loss": 1.2278,
      "step": 67500
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8858146667480469,
      "learning_rate": 0.00066,
      "loss": 1.2213,
      "step": 68000
    },
    {
      "epoch": 0.3425,
      "grad_norm": 0.9345411658287048,
      "learning_rate": 0.0006575,
      "loss": 1.2146,
      "step": 68500
    },
    {
      "epoch": 0.345,
      "grad_norm": 1.078554391860962,
      "learning_rate": 0.0006550000000000001,
      "loss": 1.2226,
      "step": 69000
    },
    {
      "epoch": 0.3475,
      "grad_norm": 0.9434950351715088,
      "learning_rate": 0.0006525,
      "loss": 1.2055,
      "step": 69500
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.041344165802002,
      "learning_rate": 0.0006500000000000001,
      "loss": 1.2096,
      "step": 70000
    },
    {
      "epoch": 0.3525,
      "grad_norm": 0.9865460991859436,
      "learning_rate": 0.0006475,
      "loss": 1.207,
      "step": 70500
    },
    {
      "epoch": 0.355,
      "grad_norm": 1.0033142566680908,
      "learning_rate": 0.0006450000000000001,
      "loss": 1.2112,
      "step": 71000
    },
    {
      "epoch": 0.3575,
      "grad_norm": 1.180033564567566,
      "learning_rate": 0.0006425,
      "loss": 1.1992,
      "step": 71500
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0708523988723755,
      "learning_rate": 0.00064,
      "loss": 1.1935,
      "step": 72000
    },
    {
      "epoch": 0.3625,
      "grad_norm": 0.9090586304664612,
      "learning_rate": 0.0006374999999999999,
      "loss": 1.1829,
      "step": 72500
    },
    {
      "epoch": 0.365,
      "grad_norm": 0.8593592643737793,
      "learning_rate": 0.000635,
      "loss": 1.1973,
      "step": 73000
    },
    {
      "epoch": 0.3675,
      "grad_norm": 1.0286622047424316,
      "learning_rate": 0.0006324999999999999,
      "loss": 1.1881,
      "step": 73500
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0219566822052002,
      "learning_rate": 0.00063,
      "loss": 1.1779,
      "step": 74000
    },
    {
      "epoch": 0.3725,
      "grad_norm": 0.8773707151412964,
      "learning_rate": 0.0006274999999999999,
      "loss": 1.1719,
      "step": 74500
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.9018390774726868,
      "learning_rate": 0.000625,
      "loss": 1.1778,
      "step": 75000
    },
    {
      "epoch": 0.3775,
      "grad_norm": 0.9723303318023682,
      "learning_rate": 0.0006225000000000001,
      "loss": 1.177,
      "step": 75500
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9658707976341248,
      "learning_rate": 0.00062,
      "loss": 1.1712,
      "step": 76000
    },
    {
      "epoch": 0.3825,
      "grad_norm": 0.9194794297218323,
      "learning_rate": 0.0006175000000000001,
      "loss": 1.166,
      "step": 76500
    },
    {
      "epoch": 0.385,
      "grad_norm": 0.97408527135849,
      "learning_rate": 0.000615,
      "loss": 1.1696,
      "step": 77000
    },
    {
      "epoch": 0.3875,
      "grad_norm": 0.9506632089614868,
      "learning_rate": 0.0006125000000000001,
      "loss": 1.1501,
      "step": 77500
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.984164297580719,
      "learning_rate": 0.00061,
      "loss": 1.1581,
      "step": 78000
    },
    {
      "epoch": 0.3925,
      "grad_norm": 0.9477211236953735,
      "learning_rate": 0.0006075000000000001,
      "loss": 1.1526,
      "step": 78500
    },
    {
      "epoch": 0.395,
      "grad_norm": 1.0188319683074951,
      "learning_rate": 0.000605,
      "loss": 1.151,
      "step": 79000
    },
    {
      "epoch": 0.3975,
      "grad_norm": 1.1282663345336914,
      "learning_rate": 0.0006025000000000001,
      "loss": 1.1538,
      "step": 79500
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9443824291229248,
      "learning_rate": 0.0006,
      "loss": 1.1368,
      "step": 80000
    },
    {
      "epoch": 0.4025,
      "grad_norm": 1.0050138235092163,
      "learning_rate": 0.0005975,
      "loss": 1.1525,
      "step": 80500
    },
    {
      "epoch": 0.405,
      "grad_norm": 0.9848527908325195,
      "learning_rate": 0.0005949999999999999,
      "loss": 1.145,
      "step": 81000
    },
    {
      "epoch": 0.4075,
      "grad_norm": 1.1622711420059204,
      "learning_rate": 0.0005925,
      "loss": 1.1333,
      "step": 81500
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0308059453964233,
      "learning_rate": 0.00059,
      "loss": 1.1413,
      "step": 82000
    },
    {
      "epoch": 0.4125,
      "grad_norm": 1.0342671871185303,
      "learning_rate": 0.0005875,
      "loss": 1.1372,
      "step": 82500
    },
    {
      "epoch": 0.415,
      "grad_norm": 1.0597071647644043,
      "learning_rate": 0.000585,
      "loss": 1.1251,
      "step": 83000
    },
    {
      "epoch": 0.4175,
      "grad_norm": 0.9343894720077515,
      "learning_rate": 0.0005825,
      "loss": 1.122,
      "step": 83500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9965024590492249,
      "learning_rate": 0.00058,
      "loss": 1.1265,
      "step": 84000
    },
    {
      "epoch": 0.4225,
      "grad_norm": 1.0846943855285645,
      "learning_rate": 0.0005775,
      "loss": 1.1251,
      "step": 84500
    },
    {
      "epoch": 0.425,
      "grad_norm": 1.0317307710647583,
      "learning_rate": 0.000575,
      "loss": 1.106,
      "step": 85000
    },
    {
      "epoch": 0.4275,
      "grad_norm": 1.0483992099761963,
      "learning_rate": 0.0005725,
      "loss": 1.1221,
      "step": 85500
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0123639106750488,
      "learning_rate": 0.00057,
      "loss": 1.1166,
      "step": 86000
    },
    {
      "epoch": 0.4325,
      "grad_norm": 1.0176339149475098,
      "learning_rate": 0.0005675,
      "loss": 1.11,
      "step": 86500
    },
    {
      "epoch": 0.435,
      "grad_norm": 1.0069949626922607,
      "learning_rate": 0.000565,
      "loss": 1.1133,
      "step": 87000
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.8927513360977173,
      "learning_rate": 0.0005625000000000001,
      "loss": 1.0959,
      "step": 87500
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9091807007789612,
      "learning_rate": 0.0005600000000000001,
      "loss": 1.0972,
      "step": 88000
    },
    {
      "epoch": 0.4425,
      "grad_norm": 1.0401264429092407,
      "learning_rate": 0.0005575,
      "loss": 1.1035,
      "step": 88500
    },
    {
      "epoch": 0.445,
      "grad_norm": 1.0254827737808228,
      "learning_rate": 0.000555,
      "loss": 1.1013,
      "step": 89000
    },
    {
      "epoch": 0.4475,
      "grad_norm": 0.9753113389015198,
      "learning_rate": 0.0005525,
      "loss": 1.0952,
      "step": 89500
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.958233118057251,
      "learning_rate": 0.00055,
      "loss": 1.0874,
      "step": 90000
    },
    {
      "epoch": 0.4525,
      "grad_norm": 0.9952385425567627,
      "learning_rate": 0.0005475,
      "loss": 1.0843,
      "step": 90500
    },
    {
      "epoch": 0.455,
      "grad_norm": 0.9489436745643616,
      "learning_rate": 0.000545,
      "loss": 1.0899,
      "step": 91000
    },
    {
      "epoch": 0.4575,
      "grad_norm": 0.8481842279434204,
      "learning_rate": 0.0005425,
      "loss": 1.0917,
      "step": 91500
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.010193943977356,
      "learning_rate": 0.00054,
      "loss": 1.0819,
      "step": 92000
    },
    {
      "epoch": 0.4625,
      "grad_norm": 1.1289206743240356,
      "learning_rate": 0.0005375,
      "loss": 1.0753,
      "step": 92500
    },
    {
      "epoch": 0.465,
      "grad_norm": 0.9833800792694092,
      "learning_rate": 0.000535,
      "loss": 1.0807,
      "step": 93000
    },
    {
      "epoch": 0.4675,
      "grad_norm": 1.07359778881073,
      "learning_rate": 0.0005325,
      "loss": 1.0765,
      "step": 93500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9559533596038818,
      "learning_rate": 0.0005300000000000001,
      "loss": 1.0791,
      "step": 94000
    },
    {
      "epoch": 0.4725,
      "grad_norm": 1.0731371641159058,
      "learning_rate": 0.0005275,
      "loss": 1.0779,
      "step": 94500
    },
    {
      "epoch": 0.475,
      "grad_norm": 1.1952975988388062,
      "learning_rate": 0.0005250000000000001,
      "loss": 1.069,
      "step": 95000
    },
    {
      "epoch": 0.4775,
      "grad_norm": 0.9741662740707397,
      "learning_rate": 0.0005225,
      "loss": 1.0653,
      "step": 95500
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0313433408737183,
      "learning_rate": 0.0005200000000000001,
      "loss": 1.058,
      "step": 96000
    },
    {
      "epoch": 0.4825,
      "grad_norm": 1.064487338066101,
      "learning_rate": 0.0005175,
      "loss": 1.0565,
      "step": 96500
    },
    {
      "epoch": 0.485,
      "grad_norm": 0.9795621037483215,
      "learning_rate": 0.000515,
      "loss": 1.063,
      "step": 97000
    },
    {
      "epoch": 0.4875,
      "grad_norm": 1.1452744007110596,
      "learning_rate": 0.0005124999999999999,
      "loss": 1.0648,
      "step": 97500
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2524950504302979,
      "learning_rate": 0.00051,
      "loss": 1.0601,
      "step": 98000
    },
    {
      "epoch": 0.4925,
      "grad_norm": 1.2523456811904907,
      "learning_rate": 0.0005074999999999999,
      "loss": 1.0475,
      "step": 98500
    },
    {
      "epoch": 0.495,
      "grad_norm": 1.1445738077163696,
      "learning_rate": 0.000505,
      "loss": 1.0518,
      "step": 99000
    },
    {
      "epoch": 0.4975,
      "grad_norm": 1.0415863990783691,
      "learning_rate": 0.0005024999999999999,
      "loss": 1.0421,
      "step": 99500
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9451287984848022,
      "learning_rate": 0.0005,
      "loss": 1.0509,
      "step": 100000
    },
    {
      "epoch": 0.5025,
      "grad_norm": 0.949371874332428,
      "learning_rate": 0.0004975,
      "loss": 1.0355,
      "step": 100500
    },
    {
      "epoch": 0.505,
      "grad_norm": 0.9840850234031677,
      "learning_rate": 0.000495,
      "loss": 1.0347,
      "step": 101000
    },
    {
      "epoch": 0.5075,
      "grad_norm": 0.9239872097969055,
      "learning_rate": 0.0004925,
      "loss": 1.0456,
      "step": 101500
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.0129058361053467,
      "learning_rate": 0.00049,
      "loss": 1.0362,
      "step": 102000
    },
    {
      "epoch": 0.5125,
      "grad_norm": 0.9843114018440247,
      "learning_rate": 0.0004875,
      "loss": 1.0443,
      "step": 102500
    },
    {
      "epoch": 0.515,
      "grad_norm": 1.0922390222549438,
      "learning_rate": 0.00048499999999999997,
      "loss": 1.0362,
      "step": 103000
    },
    {
      "epoch": 0.5175,
      "grad_norm": 0.9595506191253662,
      "learning_rate": 0.0004825,
      "loss": 1.0231,
      "step": 103500
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.9875658750534058,
      "learning_rate": 0.00048,
      "loss": 1.0267,
      "step": 104000
    },
    {
      "epoch": 0.5225,
      "grad_norm": 0.96051424741745,
      "learning_rate": 0.0004775,
      "loss": 1.03,
      "step": 104500
    },
    {
      "epoch": 0.525,
      "grad_norm": 1.1159685850143433,
      "learning_rate": 0.000475,
      "loss": 1.0247,
      "step": 105000
    },
    {
      "epoch": 0.5275,
      "grad_norm": 1.0514447689056396,
      "learning_rate": 0.0004725,
      "loss": 1.0157,
      "step": 105500
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9616302251815796,
      "learning_rate": 0.00047,
      "loss": 1.0181,
      "step": 106000
    },
    {
      "epoch": 0.5325,
      "grad_norm": 1.142808198928833,
      "learning_rate": 0.00046750000000000003,
      "loss": 1.0182,
      "step": 106500
    },
    {
      "epoch": 0.535,
      "grad_norm": 0.9638955593109131,
      "learning_rate": 0.000465,
      "loss": 1.0112,
      "step": 107000
    },
    {
      "epoch": 0.5375,
      "grad_norm": 1.0090171098709106,
      "learning_rate": 0.0004625,
      "loss": 1.0041,
      "step": 107500
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0669554471969604,
      "learning_rate": 0.00046,
      "loss": 1.0129,
      "step": 108000
    },
    {
      "epoch": 0.5425,
      "grad_norm": 1.0513437986373901,
      "learning_rate": 0.0004575,
      "loss": 1.0137,
      "step": 108500
    },
    {
      "epoch": 0.545,
      "grad_norm": 0.9763213396072388,
      "learning_rate": 0.000455,
      "loss": 1.0098,
      "step": 109000
    },
    {
      "epoch": 0.5475,
      "grad_norm": 1.139932632446289,
      "learning_rate": 0.00045250000000000005,
      "loss": 1.0036,
      "step": 109500
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.0100107192993164,
      "learning_rate": 0.00045000000000000004,
      "loss": 1.0065,
      "step": 110000
    },
    {
      "epoch": 0.5525,
      "grad_norm": 1.1138192415237427,
      "learning_rate": 0.00044750000000000004,
      "loss": 0.9983,
      "step": 110500
    },
    {
      "epoch": 0.555,
      "grad_norm": 0.9722064733505249,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.984,
      "step": 111000
    },
    {
      "epoch": 0.5575,
      "grad_norm": 1.0417015552520752,
      "learning_rate": 0.0004425,
      "loss": 0.9972,
      "step": 111500
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.0143166780471802,
      "learning_rate": 0.00044,
      "loss": 0.9952,
      "step": 112000
    },
    {
      "epoch": 0.5625,
      "grad_norm": 1.0101902484893799,
      "learning_rate": 0.0004375,
      "loss": 0.9934,
      "step": 112500
    },
    {
      "epoch": 0.565,
      "grad_norm": 1.083875060081482,
      "learning_rate": 0.000435,
      "loss": 0.9949,
      "step": 113000
    },
    {
      "epoch": 0.5675,
      "grad_norm": 1.0749810934066772,
      "learning_rate": 0.0004325,
      "loss": 0.9798,
      "step": 113500
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.0029280185699463,
      "learning_rate": 0.00043,
      "loss": 0.9787,
      "step": 114000
    },
    {
      "epoch": 0.5725,
      "grad_norm": 1.1421724557876587,
      "learning_rate": 0.0004275,
      "loss": 0.9835,
      "step": 114500
    },
    {
      "epoch": 0.575,
      "grad_norm": 1.2307415008544922,
      "learning_rate": 0.000425,
      "loss": 0.9824,
      "step": 115000
    },
    {
      "epoch": 0.5775,
      "grad_norm": 0.970966637134552,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.9762,
      "step": 115500
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.9126542806625366,
      "learning_rate": 0.00042,
      "loss": 0.9823,
      "step": 116000
    },
    {
      "epoch": 0.5825,
      "grad_norm": 1.0853277444839478,
      "learning_rate": 0.0004175,
      "loss": 0.9695,
      "step": 116500
    },
    {
      "epoch": 0.585,
      "grad_norm": 1.1510920524597168,
      "learning_rate": 0.000415,
      "loss": 0.9743,
      "step": 117000
    },
    {
      "epoch": 0.5875,
      "grad_norm": 1.117012858390808,
      "learning_rate": 0.0004125,
      "loss": 0.9749,
      "step": 117500
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.17649245262146,
      "learning_rate": 0.00041,
      "loss": 0.9687,
      "step": 118000
    },
    {
      "epoch": 0.5925,
      "grad_norm": 1.0335581302642822,
      "learning_rate": 0.0004075,
      "loss": 0.9681,
      "step": 118500
    },
    {
      "epoch": 0.595,
      "grad_norm": 1.0052214860916138,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.9646,
      "step": 119000
    },
    {
      "epoch": 0.5975,
      "grad_norm": 0.9966657757759094,
      "learning_rate": 0.0004025,
      "loss": 0.9653,
      "step": 119500
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.1167680025100708,
      "learning_rate": 0.0004,
      "loss": 0.9505,
      "step": 120000
    },
    {
      "epoch": 0.6025,
      "grad_norm": 1.0268030166625977,
      "learning_rate": 0.0003975,
      "loss": 0.9602,
      "step": 120500
    },
    {
      "epoch": 0.605,
      "grad_norm": 1.0652222633361816,
      "learning_rate": 0.000395,
      "loss": 0.9475,
      "step": 121000
    },
    {
      "epoch": 0.6075,
      "grad_norm": 1.0980501174926758,
      "learning_rate": 0.0003925,
      "loss": 0.9552,
      "step": 121500
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8998873829841614,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.9475,
      "step": 122000
    },
    {
      "epoch": 0.6125,
      "grad_norm": 1.3113712072372437,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.9457,
      "step": 122500
    },
    {
      "epoch": 0.615,
      "grad_norm": 0.8950087428092957,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.954,
      "step": 123000
    },
    {
      "epoch": 0.6175,
      "grad_norm": 1.049476146697998,
      "learning_rate": 0.00038250000000000003,
      "loss": 0.9451,
      "step": 123500
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9713594913482666,
      "learning_rate": 0.00038,
      "loss": 0.948,
      "step": 124000
    },
    {
      "epoch": 0.6225,
      "grad_norm": 1.0691008567810059,
      "learning_rate": 0.0003775,
      "loss": 0.9395,
      "step": 124500
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.0166428089141846,
      "learning_rate": 0.000375,
      "loss": 0.9492,
      "step": 125000
    },
    {
      "epoch": 0.6275,
      "grad_norm": 1.0740458965301514,
      "learning_rate": 0.0003725,
      "loss": 0.9411,
      "step": 125500
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.1452453136444092,
      "learning_rate": 0.00037,
      "loss": 0.9452,
      "step": 126000
    },
    {
      "epoch": 0.6325,
      "grad_norm": 1.1113747358322144,
      "learning_rate": 0.0003675,
      "loss": 0.9359,
      "step": 126500
    },
    {
      "epoch": 0.635,
      "grad_norm": 1.1107048988342285,
      "learning_rate": 0.000365,
      "loss": 0.9333,
      "step": 127000
    },
    {
      "epoch": 0.6375,
      "grad_norm": 0.9884840250015259,
      "learning_rate": 0.0003625,
      "loss": 0.9255,
      "step": 127500
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0551331043243408,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.9239,
      "step": 128000
    },
    {
      "epoch": 0.6425,
      "grad_norm": 1.127010464668274,
      "learning_rate": 0.0003575,
      "loss": 0.9356,
      "step": 128500
    },
    {
      "epoch": 0.645,
      "grad_norm": 1.161539912223816,
      "learning_rate": 0.000355,
      "loss": 0.9255,
      "step": 129000
    },
    {
      "epoch": 0.6475,
      "grad_norm": 1.0940463542938232,
      "learning_rate": 0.0003525,
      "loss": 0.9303,
      "step": 129500
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.9920341372489929,
      "learning_rate": 0.00035,
      "loss": 0.9321,
      "step": 130000
    },
    {
      "epoch": 0.6525,
      "grad_norm": 1.1068230867385864,
      "learning_rate": 0.0003475,
      "loss": 0.9257,
      "step": 130500
    },
    {
      "epoch": 0.655,
      "grad_norm": 1.1144709587097168,
      "learning_rate": 0.000345,
      "loss": 0.921,
      "step": 131000
    },
    {
      "epoch": 0.6575,
      "grad_norm": 1.035180926322937,
      "learning_rate": 0.00034250000000000003,
      "loss": 0.9274,
      "step": 131500
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.2235051393508911,
      "learning_rate": 0.00034,
      "loss": 0.9179,
      "step": 132000
    },
    {
      "epoch": 0.6625,
      "grad_norm": 0.9709835052490234,
      "learning_rate": 0.0003375,
      "loss": 0.9209,
      "step": 132500
    },
    {
      "epoch": 0.665,
      "grad_norm": 1.2093480825424194,
      "learning_rate": 0.000335,
      "loss": 0.9166,
      "step": 133000
    },
    {
      "epoch": 0.6675,
      "grad_norm": 1.242810606956482,
      "learning_rate": 0.0003325,
      "loss": 0.9212,
      "step": 133500
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1947177648544312,
      "learning_rate": 0.00033,
      "loss": 0.9095,
      "step": 134000
    },
    {
      "epoch": 0.6725,
      "grad_norm": 1.1779237985610962,
      "learning_rate": 0.00032750000000000005,
      "loss": 0.911,
      "step": 134500
    },
    {
      "epoch": 0.675,
      "grad_norm": 1.088625192642212,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.9002,
      "step": 135000
    },
    {
      "epoch": 0.6775,
      "grad_norm": 1.1600061655044556,
      "learning_rate": 0.00032250000000000003,
      "loss": 0.9096,
      "step": 135500
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1399027109146118,
      "learning_rate": 0.00032,
      "loss": 0.8987,
      "step": 136000
    },
    {
      "epoch": 0.6825,
      "grad_norm": 1.1690380573272705,
      "learning_rate": 0.0003175,
      "loss": 0.915,
      "step": 136500
    },
    {
      "epoch": 0.685,
      "grad_norm": 1.0328893661499023,
      "learning_rate": 0.000315,
      "loss": 0.9078,
      "step": 137000
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.978959858417511,
      "learning_rate": 0.0003125,
      "loss": 0.9016,
      "step": 137500
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.0943025350570679,
      "learning_rate": 0.00031,
      "loss": 0.8993,
      "step": 138000
    },
    {
      "epoch": 0.6925,
      "grad_norm": 1.0280789136886597,
      "learning_rate": 0.0003075,
      "loss": 0.8938,
      "step": 138500
    },
    {
      "epoch": 0.695,
      "grad_norm": 1.1685359477996826,
      "learning_rate": 0.000305,
      "loss": 0.8942,
      "step": 139000
    },
    {
      "epoch": 0.6975,
      "grad_norm": 1.0666347742080688,
      "learning_rate": 0.0003025,
      "loss": 0.8935,
      "step": 139500
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1055760383605957,
      "learning_rate": 0.0003,
      "loss": 0.9016,
      "step": 140000
    },
    {
      "epoch": 0.7025,
      "grad_norm": 1.0998033285140991,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.8913,
      "step": 140500
    },
    {
      "epoch": 0.705,
      "grad_norm": 1.1000490188598633,
      "learning_rate": 0.000295,
      "loss": 0.8933,
      "step": 141000
    },
    {
      "epoch": 0.7075,
      "grad_norm": 1.0301998853683472,
      "learning_rate": 0.0002925,
      "loss": 0.8772,
      "step": 141500
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0300837755203247,
      "learning_rate": 0.00029,
      "loss": 0.8834,
      "step": 142000
    },
    {
      "epoch": 0.7125,
      "grad_norm": 1.069029688835144,
      "learning_rate": 0.0002875,
      "loss": 0.8842,
      "step": 142500
    },
    {
      "epoch": 0.715,
      "grad_norm": 1.0215758085250854,
      "learning_rate": 0.000285,
      "loss": 0.8809,
      "step": 143000
    },
    {
      "epoch": 0.7175,
      "grad_norm": 1.0780740976333618,
      "learning_rate": 0.0002825,
      "loss": 0.879,
      "step": 143500
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0955345630645752,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.881,
      "step": 144000
    },
    {
      "epoch": 0.7225,
      "grad_norm": 1.141230821609497,
      "learning_rate": 0.0002775,
      "loss": 0.8791,
      "step": 144500
    },
    {
      "epoch": 0.725,
      "grad_norm": 1.1365333795547485,
      "learning_rate": 0.000275,
      "loss": 0.8789,
      "step": 145000
    },
    {
      "epoch": 0.7275,
      "grad_norm": 1.1205986738204956,
      "learning_rate": 0.0002725,
      "loss": 0.8776,
      "step": 145500
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.2159098386764526,
      "learning_rate": 0.00027,
      "loss": 0.8744,
      "step": 146000
    },
    {
      "epoch": 0.7325,
      "grad_norm": 1.0927015542984009,
      "learning_rate": 0.0002675,
      "loss": 0.8692,
      "step": 146500
    },
    {
      "epoch": 0.735,
      "grad_norm": 1.0800552368164062,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.8703,
      "step": 147000
    },
    {
      "epoch": 0.7375,
      "grad_norm": 1.0477674007415771,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.8702,
      "step": 147500
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.1224433183670044,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.8642,
      "step": 148000
    },
    {
      "epoch": 0.7425,
      "grad_norm": 1.1176327466964722,
      "learning_rate": 0.0002575,
      "loss": 0.8757,
      "step": 148500
    },
    {
      "epoch": 0.745,
      "grad_norm": 1.2214609384536743,
      "learning_rate": 0.000255,
      "loss": 0.862,
      "step": 149000
    },
    {
      "epoch": 0.7475,
      "grad_norm": 1.0817699432373047,
      "learning_rate": 0.0002525,
      "loss": 0.8563,
      "step": 149500
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.257226586341858,
      "learning_rate": 0.00025,
      "loss": 0.8616,
      "step": 150000
    },
    {
      "epoch": 0.7525,
      "grad_norm": 0.9765138626098633,
      "learning_rate": 0.0002475,
      "loss": 0.8552,
      "step": 150500
    },
    {
      "epoch": 0.755,
      "grad_norm": 1.1250368356704712,
      "learning_rate": 0.000245,
      "loss": 0.8601,
      "step": 151000
    },
    {
      "epoch": 0.7575,
      "grad_norm": 1.1257456541061401,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.8545,
      "step": 151500
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0622601509094238,
      "learning_rate": 0.00024,
      "loss": 0.8545,
      "step": 152000
    },
    {
      "epoch": 0.7625,
      "grad_norm": 1.0432260036468506,
      "learning_rate": 0.0002375,
      "loss": 0.8491,
      "step": 152500
    },
    {
      "epoch": 0.765,
      "grad_norm": 1.1645985841751099,
      "learning_rate": 0.000235,
      "loss": 0.8558,
      "step": 153000
    },
    {
      "epoch": 0.7675,
      "grad_norm": 1.0939102172851562,
      "learning_rate": 0.0002325,
      "loss": 0.8532,
      "step": 153500
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.1931062936782837,
      "learning_rate": 0.00023,
      "loss": 0.8472,
      "step": 154000
    },
    {
      "epoch": 0.7725,
      "grad_norm": 1.249427080154419,
      "learning_rate": 0.0002275,
      "loss": 0.8497,
      "step": 154500
    },
    {
      "epoch": 0.775,
      "grad_norm": 1.0806199312210083,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.8497,
      "step": 155000
    },
    {
      "epoch": 0.7775,
      "grad_norm": 0.9918175339698792,
      "learning_rate": 0.00022250000000000001,
      "loss": 0.8424,
      "step": 155500
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.2173545360565186,
      "learning_rate": 0.00022,
      "loss": 0.8444,
      "step": 156000
    },
    {
      "epoch": 0.7825,
      "grad_norm": 0.9718335866928101,
      "learning_rate": 0.0002175,
      "loss": 0.8501,
      "step": 156500
    },
    {
      "epoch": 0.785,
      "grad_norm": 0.9815433025360107,
      "learning_rate": 0.000215,
      "loss": 0.8426,
      "step": 157000
    },
    {
      "epoch": 0.7875,
      "grad_norm": 1.06856107711792,
      "learning_rate": 0.0002125,
      "loss": 0.8358,
      "step": 157500
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2295098304748535,
      "learning_rate": 0.00021,
      "loss": 0.844,
      "step": 158000
    },
    {
      "epoch": 0.7925,
      "grad_norm": 1.023153305053711,
      "learning_rate": 0.0002075,
      "loss": 0.8366,
      "step": 158500
    },
    {
      "epoch": 0.795,
      "grad_norm": 1.2215145826339722,
      "learning_rate": 0.000205,
      "loss": 0.8365,
      "step": 159000
    },
    {
      "epoch": 0.7975,
      "grad_norm": 0.978364109992981,
      "learning_rate": 0.00020250000000000002,
      "loss": 0.8359,
      "step": 159500
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.188213586807251,
      "learning_rate": 0.0002,
      "loss": 0.8352,
      "step": 160000
    },
    {
      "epoch": 0.8025,
      "grad_norm": 1.019752025604248,
      "learning_rate": 0.0001975,
      "loss": 0.8337,
      "step": 160500
    },
    {
      "epoch": 0.805,
      "grad_norm": 1.0945103168487549,
      "learning_rate": 0.00019500000000000002,
      "loss": 0.8325,
      "step": 161000
    },
    {
      "epoch": 0.8075,
      "grad_norm": 1.1073329448699951,
      "learning_rate": 0.00019250000000000002,
      "loss": 0.8304,
      "step": 161500
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.0277682542800903,
      "learning_rate": 0.00019,
      "loss": 0.8326,
      "step": 162000
    },
    {
      "epoch": 0.8125,
      "grad_norm": 1.0723540782928467,
      "learning_rate": 0.0001875,
      "loss": 0.8327,
      "step": 162500
    },
    {
      "epoch": 0.815,
      "grad_norm": 2.062161922454834,
      "learning_rate": 0.000185,
      "loss": 0.823,
      "step": 163000
    },
    {
      "epoch": 0.8175,
      "grad_norm": 1.026750087738037,
      "learning_rate": 0.0001825,
      "loss": 0.8247,
      "step": 163500
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.180466651916504,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.8294,
      "step": 164000
    },
    {
      "epoch": 0.8225,
      "grad_norm": 1.0638693571090698,
      "learning_rate": 0.0001775,
      "loss": 0.8205,
      "step": 164500
    },
    {
      "epoch": 0.825,
      "grad_norm": 1.090575933456421,
      "learning_rate": 0.000175,
      "loss": 0.8215,
      "step": 165000
    },
    {
      "epoch": 0.8275,
      "grad_norm": 1.0341813564300537,
      "learning_rate": 0.0001725,
      "loss": 0.8242,
      "step": 165500
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.019928216934204,
      "learning_rate": 0.00017,
      "loss": 0.8207,
      "step": 166000
    },
    {
      "epoch": 0.8325,
      "grad_norm": 1.1539510488510132,
      "learning_rate": 0.0001675,
      "loss": 0.8245,
      "step": 166500
    },
    {
      "epoch": 0.835,
      "grad_norm": 1.1550542116165161,
      "learning_rate": 0.000165,
      "loss": 0.8258,
      "step": 167000
    },
    {
      "epoch": 0.8375,
      "grad_norm": 1.1228418350219727,
      "learning_rate": 0.00016250000000000002,
      "loss": 0.8102,
      "step": 167500
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.077062964439392,
      "learning_rate": 0.00016,
      "loss": 0.8168,
      "step": 168000
    },
    {
      "epoch": 0.8425,
      "grad_norm": 1.003520131111145,
      "learning_rate": 0.0001575,
      "loss": 0.8109,
      "step": 168500
    },
    {
      "epoch": 0.845,
      "grad_norm": 1.1189385652542114,
      "learning_rate": 0.000155,
      "loss": 0.8152,
      "step": 169000
    },
    {
      "epoch": 0.8475,
      "grad_norm": 1.1123557090759277,
      "learning_rate": 0.0001525,
      "loss": 0.8168,
      "step": 169500
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.1535475254058838,
      "learning_rate": 0.00015,
      "loss": 0.8097,
      "step": 170000
    },
    {
      "epoch": 0.8525,
      "grad_norm": 1.0665082931518555,
      "learning_rate": 0.0001475,
      "loss": 0.8101,
      "step": 170500
    },
    {
      "epoch": 0.855,
      "grad_norm": 1.079607605934143,
      "learning_rate": 0.000145,
      "loss": 0.815,
      "step": 171000
    },
    {
      "epoch": 0.8575,
      "grad_norm": 0.9452593326568604,
      "learning_rate": 0.0001425,
      "loss": 0.8155,
      "step": 171500
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.1650549173355103,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.8104,
      "step": 172000
    },
    {
      "epoch": 0.8625,
      "grad_norm": 1.1527403593063354,
      "learning_rate": 0.0001375,
      "loss": 0.8126,
      "step": 172500
    },
    {
      "epoch": 0.865,
      "grad_norm": 1.0533714294433594,
      "learning_rate": 0.000135,
      "loss": 0.8144,
      "step": 173000
    },
    {
      "epoch": 0.8675,
      "grad_norm": 1.1734055280685425,
      "learning_rate": 0.00013250000000000002,
      "loss": 0.8037,
      "step": 173500
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.1227372884750366,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.8125,
      "step": 174000
    },
    {
      "epoch": 0.8725,
      "grad_norm": 1.1375327110290527,
      "learning_rate": 0.0001275,
      "loss": 0.8095,
      "step": 174500
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.2081762552261353,
      "learning_rate": 0.000125,
      "loss": 0.8048,
      "step": 175000
    },
    {
      "epoch": 0.8775,
      "grad_norm": 1.0117928981781006,
      "learning_rate": 0.0001225,
      "loss": 0.8037,
      "step": 175500
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0332077741622925,
      "learning_rate": 0.00012,
      "loss": 0.801,
      "step": 176000
    },
    {
      "epoch": 0.8825,
      "grad_norm": 1.2721489667892456,
      "learning_rate": 0.0001175,
      "loss": 0.8034,
      "step": 176500
    },
    {
      "epoch": 0.885,
      "grad_norm": 1.09809148311615,
      "learning_rate": 0.000115,
      "loss": 0.8044,
      "step": 177000
    },
    {
      "epoch": 0.8875,
      "grad_norm": 1.0918397903442383,
      "learning_rate": 0.00011250000000000001,
      "loss": 0.7967,
      "step": 177500
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.177968978881836,
      "learning_rate": 0.00011,
      "loss": 0.7979,
      "step": 178000
    },
    {
      "epoch": 0.8925,
      "grad_norm": 1.1425845623016357,
      "learning_rate": 0.0001075,
      "loss": 0.7932,
      "step": 178500
    },
    {
      "epoch": 0.895,
      "grad_norm": 1.0645084381103516,
      "learning_rate": 0.000105,
      "loss": 0.7907,
      "step": 179000
    },
    {
      "epoch": 0.8975,
      "grad_norm": 1.0590410232543945,
      "learning_rate": 0.0001025,
      "loss": 0.7946,
      "step": 179500
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.0921027660369873,
      "learning_rate": 0.0001,
      "loss": 0.7978,
      "step": 180000
    },
    {
      "epoch": 0.9025,
      "grad_norm": 1.0518335103988647,
      "learning_rate": 9.750000000000001e-05,
      "loss": 0.79,
      "step": 180500
    },
    {
      "epoch": 0.905,
      "grad_norm": 1.2436790466308594,
      "learning_rate": 9.5e-05,
      "loss": 0.7957,
      "step": 181000
    },
    {
      "epoch": 0.9075,
      "grad_norm": 1.0119047164916992,
      "learning_rate": 9.25e-05,
      "loss": 0.7888,
      "step": 181500
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.0641480684280396,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.8022,
      "step": 182000
    },
    {
      "epoch": 0.9125,
      "grad_norm": 1.055338740348816,
      "learning_rate": 8.75e-05,
      "loss": 0.7901,
      "step": 182500
    },
    {
      "epoch": 0.915,
      "grad_norm": 1.0821335315704346,
      "learning_rate": 8.5e-05,
      "loss": 0.7841,
      "step": 183000
    },
    {
      "epoch": 0.9175,
      "grad_norm": 1.0404950380325317,
      "learning_rate": 8.25e-05,
      "loss": 0.79,
      "step": 183500
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.1952508687973022,
      "learning_rate": 8e-05,
      "loss": 0.7803,
      "step": 184000
    },
    {
      "epoch": 0.9225,
      "grad_norm": 0.944860577583313,
      "learning_rate": 7.75e-05,
      "loss": 0.7934,
      "step": 184500
    },
    {
      "epoch": 0.925,
      "grad_norm": 1.1464169025421143,
      "learning_rate": 7.5e-05,
      "loss": 0.798,
      "step": 185000
    },
    {
      "epoch": 0.9275,
      "grad_norm": 1.0066834688186646,
      "learning_rate": 7.25e-05,
      "loss": 0.7866,
      "step": 185500
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.326090931892395,
      "learning_rate": 7.000000000000001e-05,
      "loss": 0.7775,
      "step": 186000
    },
    {
      "epoch": 0.9325,
      "grad_norm": 1.202364206314087,
      "learning_rate": 6.75e-05,
      "loss": 0.7779,
      "step": 186500
    },
    {
      "epoch": 0.935,
      "grad_norm": 1.2272047996520996,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.7827,
      "step": 187000
    },
    {
      "epoch": 0.9375,
      "grad_norm": 1.1904196739196777,
      "learning_rate": 6.25e-05,
      "loss": 0.787,
      "step": 187500
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0538110733032227,
      "learning_rate": 6e-05,
      "loss": 0.7779,
      "step": 188000
    },
    {
      "epoch": 0.9425,
      "grad_norm": 1.0997984409332275,
      "learning_rate": 5.75e-05,
      "loss": 0.7715,
      "step": 188500
    },
    {
      "epoch": 0.945,
      "grad_norm": 1.0487412214279175,
      "learning_rate": 5.5e-05,
      "loss": 0.7772,
      "step": 189000
    },
    {
      "epoch": 0.9475,
      "grad_norm": 1.319932460784912,
      "learning_rate": 5.25e-05,
      "loss": 0.7748,
      "step": 189500
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.0813908576965332,
      "learning_rate": 5e-05,
      "loss": 0.7783,
      "step": 190000
    },
    {
      "epoch": 0.9525,
      "grad_norm": 0.9464123845100403,
      "learning_rate": 4.75e-05,
      "loss": 0.7882,
      "step": 190500
    },
    {
      "epoch": 0.955,
      "grad_norm": 1.0287472009658813,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.7808,
      "step": 191000
    },
    {
      "epoch": 0.9575,
      "grad_norm": 1.012153148651123,
      "learning_rate": 4.25e-05,
      "loss": 0.7809,
      "step": 191500
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.1072312593460083,
      "learning_rate": 4e-05,
      "loss": 0.7825,
      "step": 192000
    },
    {
      "epoch": 0.9625,
      "grad_norm": 1.1102235317230225,
      "learning_rate": 3.75e-05,
      "loss": 0.7837,
      "step": 192500
    },
    {
      "epoch": 0.965,
      "grad_norm": 1.0602003335952759,
      "learning_rate": 3.5000000000000004e-05,
      "loss": 0.779,
      "step": 193000
    },
    {
      "epoch": 0.9675,
      "grad_norm": 1.0712251663208008,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.773,
      "step": 193500
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1775165796279907,
      "learning_rate": 3e-05,
      "loss": 0.7789,
      "step": 194000
    },
    {
      "epoch": 0.9725,
      "grad_norm": 1.2112979888916016,
      "learning_rate": 2.75e-05,
      "loss": 0.771,
      "step": 194500
    },
    {
      "epoch": 0.975,
      "grad_norm": 1.1017986536026,
      "learning_rate": 2.5e-05,
      "loss": 0.7778,
      "step": 195000
    },
    {
      "epoch": 0.9775,
      "grad_norm": 1.0283279418945312,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.7814,
      "step": 195500
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.952886164188385,
      "learning_rate": 2e-05,
      "loss": 0.7787,
      "step": 196000
    },
    {
      "epoch": 0.9825,
      "grad_norm": 1.080257534980774,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.7757,
      "step": 196500
    },
    {
      "epoch": 0.985,
      "grad_norm": 1.0502594709396362,
      "learning_rate": 1.5e-05,
      "loss": 0.7741,
      "step": 197000
    },
    {
      "epoch": 0.9875,
      "grad_norm": 1.1614751815795898,
      "learning_rate": 1.25e-05,
      "loss": 0.7754,
      "step": 197500
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.1754238605499268,
      "learning_rate": 1e-05,
      "loss": 0.7744,
      "step": 198000
    },
    {
      "epoch": 0.9925,
      "grad_norm": 1.2205185890197754,
      "learning_rate": 7.5e-06,
      "loss": 0.767,
      "step": 198500
    },
    {
      "epoch": 0.995,
      "grad_norm": 1.031859040260315,
      "learning_rate": 5e-06,
      "loss": 0.768,
      "step": 199000
    },
    {
      "epoch": 0.9975,
      "grad_norm": 1.1030209064483643,
      "learning_rate": 2.5e-06,
      "loss": 0.773,
      "step": 199500
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.139090657234192,
      "learning_rate": 0.0,
      "loss": 0.7742,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.678793019392e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
