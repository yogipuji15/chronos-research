{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.25,
  "eval_steps": 500,
  "global_step": 100000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00125,
      "grad_norm": 0.3965936005115509,
      "learning_rate": 8.333333333333333e-07,
      "loss": 1.8391,
      "step": 500
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.3080460727214813,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 1.8441,
      "step": 1000
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.305588036775589,
      "learning_rate": 2.5e-06,
      "loss": 1.8271,
      "step": 1500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.285957932472229,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 1.8135,
      "step": 2000
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.29649654030799866,
      "learning_rate": 4.166666666666667e-06,
      "loss": 1.8292,
      "step": 2500
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.32879841327667236,
      "learning_rate": 5e-06,
      "loss": 1.8227,
      "step": 3000
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.2655847668647766,
      "learning_rate": 5.833333333333334e-06,
      "loss": 1.8157,
      "step": 3500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.277055948972702,
      "learning_rate": 6.666666666666667e-06,
      "loss": 1.8167,
      "step": 4000
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.24110299348831177,
      "learning_rate": 7.5e-06,
      "loss": 1.803,
      "step": 4500
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.3010740578174591,
      "learning_rate": 8.333333333333334e-06,
      "loss": 1.8181,
      "step": 5000
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.28713274002075195,
      "learning_rate": 9.166666666666666e-06,
      "loss": 1.8105,
      "step": 5500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.2596791982650757,
      "learning_rate": 1e-05,
      "loss": 1.8092,
      "step": 6000
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.3304290771484375,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 1.8024,
      "step": 6500
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.2913386821746826,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 1.8009,
      "step": 7000
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.2325076311826706,
      "learning_rate": 1.25e-05,
      "loss": 1.7951,
      "step": 7500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.29610252380371094,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 1.7964,
      "step": 8000
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.2960455119609833,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 1.7942,
      "step": 8500
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.2669047713279724,
      "learning_rate": 1.5e-05,
      "loss": 1.8008,
      "step": 9000
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.24875275790691376,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 1.7983,
      "step": 9500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.24964024126529694,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 1.7954,
      "step": 10000
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.32929572463035583,
      "learning_rate": 1.75e-05,
      "loss": 1.8029,
      "step": 10500
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.30232298374176025,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 1.8019,
      "step": 11000
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.25025495886802673,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 1.7925,
      "step": 11500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.22676324844360352,
      "learning_rate": 2e-05,
      "loss": 1.7963,
      "step": 12000
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.27403199672698975,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 1.7789,
      "step": 12500
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.2133154422044754,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 1.7895,
      "step": 13000
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.2564372420310974,
      "learning_rate": 2.25e-05,
      "loss": 1.7878,
      "step": 13500
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.26612094044685364,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 1.7774,
      "step": 14000
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.30583053827285767,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 1.7935,
      "step": 14500
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.2623724043369293,
      "learning_rate": 2.5e-05,
      "loss": 1.7872,
      "step": 15000
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.25921913981437683,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 1.7876,
      "step": 15500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.29753926396369934,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.7793,
      "step": 16000
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.2524040937423706,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 1.7879,
      "step": 16500
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.25968363881111145,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 1.7851,
      "step": 17000
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.27761855721473694,
      "learning_rate": 2.916666666666667e-05,
      "loss": 1.7702,
      "step": 17500
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.28709521889686584,
      "learning_rate": 3e-05,
      "loss": 1.7827,
      "step": 18000
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.27923768758773804,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 1.7746,
      "step": 18500
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.29258134961128235,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 1.7784,
      "step": 19000
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.27435219287872314,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 1.7724,
      "step": 19500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2840578556060791,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.7762,
      "step": 20000
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.28274959325790405,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 1.7713,
      "step": 20500
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.2887325882911682,
      "learning_rate": 3.5e-05,
      "loss": 1.7651,
      "step": 21000
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.23875805735588074,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 1.7703,
      "step": 21500
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.23569244146347046,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 1.7727,
      "step": 22000
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.3068108558654785,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.7712,
      "step": 22500
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.2756037712097168,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 1.7614,
      "step": 23000
    },
    {
      "epoch": 0.05875,
      "grad_norm": 0.3071737587451935,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 1.768,
      "step": 23500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.29972967505455017,
      "learning_rate": 4e-05,
      "loss": 1.7661,
      "step": 24000
    },
    {
      "epoch": 0.06125,
      "grad_norm": 0.27429911494255066,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 1.7729,
      "step": 24500
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.2951068878173828,
      "learning_rate": 4.166666666666667e-05,
      "loss": 1.7598,
      "step": 25000
    },
    {
      "epoch": 0.06375,
      "grad_norm": 0.2692449688911438,
      "learning_rate": 4.25e-05,
      "loss": 1.7627,
      "step": 25500
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.31761711835861206,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 1.7585,
      "step": 26000
    },
    {
      "epoch": 0.06625,
      "grad_norm": 0.2926730811595917,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 1.7645,
      "step": 26500
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.25728651881217957,
      "learning_rate": 4.5e-05,
      "loss": 1.7595,
      "step": 27000
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.2643634080886841,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 1.7532,
      "step": 27500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2808900773525238,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.7561,
      "step": 28000
    },
    {
      "epoch": 0.07125,
      "grad_norm": 0.3050808310508728,
      "learning_rate": 4.75e-05,
      "loss": 1.7526,
      "step": 28500
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.2786082327365875,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 1.7581,
      "step": 29000
    },
    {
      "epoch": 0.07375,
      "grad_norm": 0.27996209263801575,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 1.7504,
      "step": 29500
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.2714375853538513,
      "learning_rate": 5e-05,
      "loss": 1.7516,
      "step": 30000
    },
    {
      "epoch": 0.07625,
      "grad_norm": 0.28951916098594666,
      "learning_rate": 5.0833333333333333e-05,
      "loss": 1.7602,
      "step": 30500
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.3048747181892395,
      "learning_rate": 5.166666666666667e-05,
      "loss": 1.738,
      "step": 31000
    },
    {
      "epoch": 0.07875,
      "grad_norm": 0.3003440797328949,
      "learning_rate": 5.25e-05,
      "loss": 1.7477,
      "step": 31500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.32511106133461,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.7431,
      "step": 32000
    },
    {
      "epoch": 0.08125,
      "grad_norm": 0.30635157227516174,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 1.7298,
      "step": 32500
    },
    {
      "epoch": 0.0825,
      "grad_norm": 0.31054139137268066,
      "learning_rate": 5.500000000000001e-05,
      "loss": 1.7455,
      "step": 33000
    },
    {
      "epoch": 0.08375,
      "grad_norm": 0.3075023889541626,
      "learning_rate": 5.583333333333334e-05,
      "loss": 1.7413,
      "step": 33500
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.30683964490890503,
      "learning_rate": 5.666666666666667e-05,
      "loss": 1.7356,
      "step": 34000
    },
    {
      "epoch": 0.08625,
      "grad_norm": 0.33302393555641174,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 1.7421,
      "step": 34500
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.24339702725410461,
      "learning_rate": 5.833333333333334e-05,
      "loss": 1.7364,
      "step": 35000
    },
    {
      "epoch": 0.08875,
      "grad_norm": 0.31881600618362427,
      "learning_rate": 5.916666666666667e-05,
      "loss": 1.7398,
      "step": 35500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.2995544373989105,
      "learning_rate": 6e-05,
      "loss": 1.7425,
      "step": 36000
    },
    {
      "epoch": 0.09125,
      "grad_norm": 0.2647571563720703,
      "learning_rate": 6.083333333333333e-05,
      "loss": 1.7337,
      "step": 36500
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.3045324385166168,
      "learning_rate": 6.166666666666667e-05,
      "loss": 1.7372,
      "step": 37000
    },
    {
      "epoch": 0.09375,
      "grad_norm": 0.33696621656417847,
      "learning_rate": 6.25e-05,
      "loss": 1.7292,
      "step": 37500
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.29061657190322876,
      "learning_rate": 6.333333333333333e-05,
      "loss": 1.7327,
      "step": 38000
    },
    {
      "epoch": 0.09625,
      "grad_norm": 0.3155269920825958,
      "learning_rate": 6.416666666666668e-05,
      "loss": 1.7309,
      "step": 38500
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.3516119718551636,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.724,
      "step": 39000
    },
    {
      "epoch": 0.09875,
      "grad_norm": 0.3345243036746979,
      "learning_rate": 6.583333333333334e-05,
      "loss": 1.7221,
      "step": 39500
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.29643064737319946,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.7259,
      "step": 40000
    },
    {
      "epoch": 0.10125,
      "grad_norm": 0.2995443344116211,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.7267,
      "step": 40500
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.28133177757263184,
      "learning_rate": 6.833333333333333e-05,
      "loss": 1.7207,
      "step": 41000
    },
    {
      "epoch": 0.10375,
      "grad_norm": 0.33666127920150757,
      "learning_rate": 6.916666666666666e-05,
      "loss": 1.7215,
      "step": 41500
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.3393573462963104,
      "learning_rate": 7e-05,
      "loss": 1.7179,
      "step": 42000
    },
    {
      "epoch": 0.10625,
      "grad_norm": 0.35483357310295105,
      "learning_rate": 7.083333333333334e-05,
      "loss": 1.7224,
      "step": 42500
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.34516221284866333,
      "learning_rate": 7.166666666666667e-05,
      "loss": 1.7185,
      "step": 43000
    },
    {
      "epoch": 0.10875,
      "grad_norm": 0.3483272194862366,
      "learning_rate": 7.25e-05,
      "loss": 1.7101,
      "step": 43500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.3300081789493561,
      "learning_rate": 7.333333333333333e-05,
      "loss": 1.7089,
      "step": 44000
    },
    {
      "epoch": 0.11125,
      "grad_norm": 0.37269896268844604,
      "learning_rate": 7.416666666666668e-05,
      "loss": 1.7253,
      "step": 44500
    },
    {
      "epoch": 0.1125,
      "grad_norm": 0.352305144071579,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.7081,
      "step": 45000
    },
    {
      "epoch": 0.11375,
      "grad_norm": 0.3742040991783142,
      "learning_rate": 7.583333333333334e-05,
      "loss": 1.7139,
      "step": 45500
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.35160407423973083,
      "learning_rate": 7.666666666666667e-05,
      "loss": 1.7053,
      "step": 46000
    },
    {
      "epoch": 0.11625,
      "grad_norm": 0.33448660373687744,
      "learning_rate": 7.75e-05,
      "loss": 1.7113,
      "step": 46500
    },
    {
      "epoch": 0.1175,
      "grad_norm": 0.31512096524238586,
      "learning_rate": 7.833333333333333e-05,
      "loss": 1.7095,
      "step": 47000
    },
    {
      "epoch": 0.11875,
      "grad_norm": 0.336465984582901,
      "learning_rate": 7.916666666666666e-05,
      "loss": 1.7152,
      "step": 47500
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.318123996257782,
      "learning_rate": 8e-05,
      "loss": 1.6952,
      "step": 48000
    },
    {
      "epoch": 0.12125,
      "grad_norm": 0.3817586302757263,
      "learning_rate": 8.083333333333334e-05,
      "loss": 1.7093,
      "step": 48500
    },
    {
      "epoch": 0.1225,
      "grad_norm": 0.33122026920318604,
      "learning_rate": 8.166666666666667e-05,
      "loss": 1.7055,
      "step": 49000
    },
    {
      "epoch": 0.12375,
      "grad_norm": 0.3406773507595062,
      "learning_rate": 8.25e-05,
      "loss": 1.6917,
      "step": 49500
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.35693106055259705,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.6929,
      "step": 50000
    },
    {
      "epoch": 0.12625,
      "grad_norm": 0.3897812068462372,
      "learning_rate": 8.416666666666668e-05,
      "loss": 1.703,
      "step": 50500
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.37787866592407227,
      "learning_rate": 8.5e-05,
      "loss": 1.6984,
      "step": 51000
    },
    {
      "epoch": 0.12875,
      "grad_norm": 0.36986562609672546,
      "learning_rate": 8.583333333333334e-05,
      "loss": 1.6991,
      "step": 51500
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3455484211444855,
      "learning_rate": 8.666666666666667e-05,
      "loss": 1.6994,
      "step": 52000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 0.33623000979423523,
      "learning_rate": 8.75e-05,
      "loss": 1.6931,
      "step": 52500
    },
    {
      "epoch": 0.1325,
      "grad_norm": 0.4285266697406769,
      "learning_rate": 8.833333333333333e-05,
      "loss": 1.7029,
      "step": 53000
    },
    {
      "epoch": 0.13375,
      "grad_norm": 0.358153373003006,
      "learning_rate": 8.916666666666667e-05,
      "loss": 1.6991,
      "step": 53500
    },
    {
      "epoch": 0.135,
      "grad_norm": 0.35793787240982056,
      "learning_rate": 9e-05,
      "loss": 1.695,
      "step": 54000
    },
    {
      "epoch": 0.13625,
      "grad_norm": 0.33504530787467957,
      "learning_rate": 9.083333333333334e-05,
      "loss": 1.6791,
      "step": 54500
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.328583687543869,
      "learning_rate": 9.166666666666667e-05,
      "loss": 1.6779,
      "step": 55000
    },
    {
      "epoch": 0.13875,
      "grad_norm": 0.3535928428173065,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.6835,
      "step": 55500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3551371991634369,
      "learning_rate": 9.333333333333334e-05,
      "loss": 1.6913,
      "step": 56000
    },
    {
      "epoch": 0.14125,
      "grad_norm": 0.4095412790775299,
      "learning_rate": 9.416666666666667e-05,
      "loss": 1.6934,
      "step": 56500
    },
    {
      "epoch": 0.1425,
      "grad_norm": 0.3452630043029785,
      "learning_rate": 9.5e-05,
      "loss": 1.6819,
      "step": 57000
    },
    {
      "epoch": 0.14375,
      "grad_norm": 0.36045897006988525,
      "learning_rate": 9.583333333333334e-05,
      "loss": 1.6718,
      "step": 57500
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.37568575143814087,
      "learning_rate": 9.666666666666667e-05,
      "loss": 1.6746,
      "step": 58000
    },
    {
      "epoch": 0.14625,
      "grad_norm": 0.4119630753993988,
      "learning_rate": 9.75e-05,
      "loss": 1.6762,
      "step": 58500
    },
    {
      "epoch": 0.1475,
      "grad_norm": 0.34359216690063477,
      "learning_rate": 9.833333333333333e-05,
      "loss": 1.6745,
      "step": 59000
    },
    {
      "epoch": 0.14875,
      "grad_norm": 0.36260008811950684,
      "learning_rate": 9.916666666666667e-05,
      "loss": 1.6817,
      "step": 59500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.3880370855331421,
      "learning_rate": 0.0001,
      "loss": 1.6827,
      "step": 60000
    },
    {
      "epoch": 0.15125,
      "grad_norm": 0.4216972291469574,
      "learning_rate": 9.98529411764706e-05,
      "loss": 1.6678,
      "step": 60500
    },
    {
      "epoch": 0.1525,
      "grad_norm": 0.39023301005363464,
      "learning_rate": 9.970588235294118e-05,
      "loss": 1.6723,
      "step": 61000
    },
    {
      "epoch": 0.15375,
      "grad_norm": 0.41266247630119324,
      "learning_rate": 9.955882352941178e-05,
      "loss": 1.6827,
      "step": 61500
    },
    {
      "epoch": 0.155,
      "grad_norm": 0.38324448466300964,
      "learning_rate": 9.941176470588236e-05,
      "loss": 1.6781,
      "step": 62000
    },
    {
      "epoch": 0.15625,
      "grad_norm": 0.41438043117523193,
      "learning_rate": 9.926470588235295e-05,
      "loss": 1.6682,
      "step": 62500
    },
    {
      "epoch": 0.1575,
      "grad_norm": 0.3732743561267853,
      "learning_rate": 9.911764705882353e-05,
      "loss": 1.6767,
      "step": 63000
    },
    {
      "epoch": 0.15875,
      "grad_norm": 0.3683856129646301,
      "learning_rate": 9.897058823529413e-05,
      "loss": 1.6681,
      "step": 63500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4191763401031494,
      "learning_rate": 9.882352941176471e-05,
      "loss": 1.6639,
      "step": 64000
    },
    {
      "epoch": 0.16125,
      "grad_norm": 0.3452666103839874,
      "learning_rate": 9.86764705882353e-05,
      "loss": 1.6609,
      "step": 64500
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.39721575379371643,
      "learning_rate": 9.852941176470589e-05,
      "loss": 1.6612,
      "step": 65000
    },
    {
      "epoch": 0.16375,
      "grad_norm": 0.3614177405834198,
      "learning_rate": 9.838235294117647e-05,
      "loss": 1.6603,
      "step": 65500
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.3600771725177765,
      "learning_rate": 9.823529411764706e-05,
      "loss": 1.6535,
      "step": 66000
    },
    {
      "epoch": 0.16625,
      "grad_norm": 0.4283366799354553,
      "learning_rate": 9.808823529411765e-05,
      "loss": 1.6641,
      "step": 66500
    },
    {
      "epoch": 0.1675,
      "grad_norm": 0.3942333161830902,
      "learning_rate": 9.794117647058824e-05,
      "loss": 1.6626,
      "step": 67000
    },
    {
      "epoch": 0.16875,
      "grad_norm": 0.40322497487068176,
      "learning_rate": 9.779411764705882e-05,
      "loss": 1.6665,
      "step": 67500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.37164050340652466,
      "learning_rate": 9.764705882352942e-05,
      "loss": 1.6577,
      "step": 68000
    },
    {
      "epoch": 0.17125,
      "grad_norm": 0.47916415333747864,
      "learning_rate": 9.75e-05,
      "loss": 1.663,
      "step": 68500
    },
    {
      "epoch": 0.1725,
      "grad_norm": 0.41116273403167725,
      "learning_rate": 9.73529411764706e-05,
      "loss": 1.662,
      "step": 69000
    },
    {
      "epoch": 0.17375,
      "grad_norm": 0.4088917374610901,
      "learning_rate": 9.720588235294117e-05,
      "loss": 1.6477,
      "step": 69500
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.4533187747001648,
      "learning_rate": 9.705882352941177e-05,
      "loss": 1.66,
      "step": 70000
    },
    {
      "epoch": 0.17625,
      "grad_norm": 0.44719505310058594,
      "learning_rate": 9.691176470588235e-05,
      "loss": 1.6483,
      "step": 70500
    },
    {
      "epoch": 0.1775,
      "grad_norm": 0.41458579897880554,
      "learning_rate": 9.676470588235295e-05,
      "loss": 1.6512,
      "step": 71000
    },
    {
      "epoch": 0.17875,
      "grad_norm": 0.4261673390865326,
      "learning_rate": 9.661764705882354e-05,
      "loss": 1.6563,
      "step": 71500
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.41107118129730225,
      "learning_rate": 9.647058823529412e-05,
      "loss": 1.6432,
      "step": 72000
    },
    {
      "epoch": 0.18125,
      "grad_norm": 0.4575132727622986,
      "learning_rate": 9.632352941176472e-05,
      "loss": 1.637,
      "step": 72500
    },
    {
      "epoch": 0.1825,
      "grad_norm": 0.37223654985427856,
      "learning_rate": 9.61764705882353e-05,
      "loss": 1.6484,
      "step": 73000
    },
    {
      "epoch": 0.18375,
      "grad_norm": 0.4229198396205902,
      "learning_rate": 9.60294117647059e-05,
      "loss": 1.6448,
      "step": 73500
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.37884482741355896,
      "learning_rate": 9.588235294117648e-05,
      "loss": 1.6468,
      "step": 74000
    },
    {
      "epoch": 0.18625,
      "grad_norm": 0.5390732288360596,
      "learning_rate": 9.573529411764707e-05,
      "loss": 1.6469,
      "step": 74500
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.486435204744339,
      "learning_rate": 9.558823529411765e-05,
      "loss": 1.6429,
      "step": 75000
    },
    {
      "epoch": 0.18875,
      "grad_norm": 0.3907312750816345,
      "learning_rate": 9.544117647058825e-05,
      "loss": 1.6392,
      "step": 75500
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.40394824743270874,
      "learning_rate": 9.529411764705883e-05,
      "loss": 1.6457,
      "step": 76000
    },
    {
      "epoch": 0.19125,
      "grad_norm": 0.4110022485256195,
      "learning_rate": 9.514705882352941e-05,
      "loss": 1.6443,
      "step": 76500
    },
    {
      "epoch": 0.1925,
      "grad_norm": 0.44748222827911377,
      "learning_rate": 9.5e-05,
      "loss": 1.6424,
      "step": 77000
    },
    {
      "epoch": 0.19375,
      "grad_norm": 0.40395447611808777,
      "learning_rate": 9.485294117647059e-05,
      "loss": 1.6339,
      "step": 77500
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.5019798874855042,
      "learning_rate": 9.470588235294118e-05,
      "loss": 1.6427,
      "step": 78000
    },
    {
      "epoch": 0.19625,
      "grad_norm": 0.46941933035850525,
      "learning_rate": 9.455882352941176e-05,
      "loss": 1.6262,
      "step": 78500
    },
    {
      "epoch": 0.1975,
      "grad_norm": 0.3930617570877075,
      "learning_rate": 9.441176470588236e-05,
      "loss": 1.6297,
      "step": 79000
    },
    {
      "epoch": 0.19875,
      "grad_norm": 0.4903254210948944,
      "learning_rate": 9.426470588235294e-05,
      "loss": 1.6355,
      "step": 79500
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.47429540753364563,
      "learning_rate": 9.411764705882353e-05,
      "loss": 1.6353,
      "step": 80000
    },
    {
      "epoch": 0.20125,
      "grad_norm": 0.47476595640182495,
      "learning_rate": 9.397058823529412e-05,
      "loss": 1.6344,
      "step": 80500
    },
    {
      "epoch": 0.2025,
      "grad_norm": 0.4357253611087799,
      "learning_rate": 9.382352941176471e-05,
      "loss": 1.635,
      "step": 81000
    },
    {
      "epoch": 0.20375,
      "grad_norm": 0.46009543538093567,
      "learning_rate": 9.367647058823529e-05,
      "loss": 1.628,
      "step": 81500
    },
    {
      "epoch": 0.205,
      "grad_norm": 0.4663400948047638,
      "learning_rate": 9.352941176470589e-05,
      "loss": 1.6193,
      "step": 82000
    },
    {
      "epoch": 0.20625,
      "grad_norm": 0.3870235085487366,
      "learning_rate": 9.338235294117648e-05,
      "loss": 1.6272,
      "step": 82500
    },
    {
      "epoch": 0.2075,
      "grad_norm": 0.4751451015472412,
      "learning_rate": 9.323529411764706e-05,
      "loss": 1.6252,
      "step": 83000
    },
    {
      "epoch": 0.20875,
      "grad_norm": 0.4714394211769104,
      "learning_rate": 9.308823529411766e-05,
      "loss": 1.6291,
      "step": 83500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.4286724627017975,
      "learning_rate": 9.294117647058824e-05,
      "loss": 1.6204,
      "step": 84000
    },
    {
      "epoch": 0.21125,
      "grad_norm": 0.43996310234069824,
      "learning_rate": 9.279411764705884e-05,
      "loss": 1.6283,
      "step": 84500
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.437835693359375,
      "learning_rate": 9.264705882352942e-05,
      "loss": 1.6114,
      "step": 85000
    },
    {
      "epoch": 0.21375,
      "grad_norm": 0.43815916776657104,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.6171,
      "step": 85500
    },
    {
      "epoch": 0.215,
      "grad_norm": 0.4829290509223938,
      "learning_rate": 9.23529411764706e-05,
      "loss": 1.6297,
      "step": 86000
    },
    {
      "epoch": 0.21625,
      "grad_norm": 0.48703333735466003,
      "learning_rate": 9.220588235294119e-05,
      "loss": 1.6301,
      "step": 86500
    },
    {
      "epoch": 0.2175,
      "grad_norm": 0.4574023485183716,
      "learning_rate": 9.205882352941177e-05,
      "loss": 1.6122,
      "step": 87000
    },
    {
      "epoch": 0.21875,
      "grad_norm": 0.5148200988769531,
      "learning_rate": 9.191176470588235e-05,
      "loss": 1.6253,
      "step": 87500
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.4771931767463684,
      "learning_rate": 9.176470588235295e-05,
      "loss": 1.6252,
      "step": 88000
    },
    {
      "epoch": 0.22125,
      "grad_norm": 0.4449193775653839,
      "learning_rate": 9.161764705882353e-05,
      "loss": 1.6156,
      "step": 88500
    },
    {
      "epoch": 0.2225,
      "grad_norm": 0.44582101702690125,
      "learning_rate": 9.147058823529412e-05,
      "loss": 1.6142,
      "step": 89000
    },
    {
      "epoch": 0.22375,
      "grad_norm": 0.4331035912036896,
      "learning_rate": 9.13235294117647e-05,
      "loss": 1.6097,
      "step": 89500
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.43235719203948975,
      "learning_rate": 9.11764705882353e-05,
      "loss": 1.6074,
      "step": 90000
    },
    {
      "epoch": 0.22625,
      "grad_norm": 0.5079482197761536,
      "learning_rate": 9.102941176470588e-05,
      "loss": 1.61,
      "step": 90500
    },
    {
      "epoch": 0.2275,
      "grad_norm": 0.4910871386528015,
      "learning_rate": 9.088235294117648e-05,
      "loss": 1.6208,
      "step": 91000
    },
    {
      "epoch": 0.22875,
      "grad_norm": 0.4896155297756195,
      "learning_rate": 9.073529411764706e-05,
      "loss": 1.6092,
      "step": 91500
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4492570459842682,
      "learning_rate": 9.058823529411765e-05,
      "loss": 1.6039,
      "step": 92000
    },
    {
      "epoch": 0.23125,
      "grad_norm": 0.49751242995262146,
      "learning_rate": 9.044117647058823e-05,
      "loss": 1.604,
      "step": 92500
    },
    {
      "epoch": 0.2325,
      "grad_norm": 0.5014136433601379,
      "learning_rate": 9.029411764705883e-05,
      "loss": 1.6077,
      "step": 93000
    },
    {
      "epoch": 0.23375,
      "grad_norm": 0.47676050662994385,
      "learning_rate": 9.014705882352942e-05,
      "loss": 1.6031,
      "step": 93500
    },
    {
      "epoch": 0.235,
      "grad_norm": 0.5757561922073364,
      "learning_rate": 9e-05,
      "loss": 1.6076,
      "step": 94000
    },
    {
      "epoch": 0.23625,
      "grad_norm": 0.46745312213897705,
      "learning_rate": 8.98529411764706e-05,
      "loss": 1.6088,
      "step": 94500
    },
    {
      "epoch": 0.2375,
      "grad_norm": 0.400686651468277,
      "learning_rate": 8.970588235294118e-05,
      "loss": 1.5984,
      "step": 95000
    },
    {
      "epoch": 0.23875,
      "grad_norm": 0.5649771094322205,
      "learning_rate": 8.955882352941178e-05,
      "loss": 1.6035,
      "step": 95500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4160470962524414,
      "learning_rate": 8.941176470588236e-05,
      "loss": 1.6053,
      "step": 96000
    },
    {
      "epoch": 0.24125,
      "grad_norm": 0.47487449645996094,
      "learning_rate": 8.926470588235295e-05,
      "loss": 1.6041,
      "step": 96500
    },
    {
      "epoch": 0.2425,
      "grad_norm": 0.6136535406112671,
      "learning_rate": 8.911764705882354e-05,
      "loss": 1.6008,
      "step": 97000
    },
    {
      "epoch": 0.24375,
      "grad_norm": 0.4180643856525421,
      "learning_rate": 8.897058823529412e-05,
      "loss": 1.598,
      "step": 97500
    },
    {
      "epoch": 0.245,
      "grad_norm": 0.5150108337402344,
      "learning_rate": 8.882352941176471e-05,
      "loss": 1.6043,
      "step": 98000
    },
    {
      "epoch": 0.24625,
      "grad_norm": 0.5082566738128662,
      "learning_rate": 8.867647058823529e-05,
      "loss": 1.5953,
      "step": 98500
    },
    {
      "epoch": 0.2475,
      "grad_norm": 0.551842212677002,
      "learning_rate": 8.852941176470589e-05,
      "loss": 1.5916,
      "step": 99000
    },
    {
      "epoch": 0.24875,
      "grad_norm": 0.5332151651382446,
      "learning_rate": 8.838235294117647e-05,
      "loss": 1.602,
      "step": 99500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5041967630386353,
      "learning_rate": 8.823529411764706e-05,
      "loss": 1.5911,
      "step": 100000
    }
  ],
  "logging_steps": 500,
  "max_steps": 400000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.678793019392e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
