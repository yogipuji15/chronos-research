{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.75,
  "eval_steps": 500,
  "global_step": 300000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00125,
      "grad_norm": 0.864155650138855,
      "learning_rate": 8.333333333333333e-07,
      "loss": 2.0934,
      "step": 500
    },
    {
      "epoch": 0.0025,
      "grad_norm": 0.7021952271461487,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 2.0913,
      "step": 1000
    },
    {
      "epoch": 0.00375,
      "grad_norm": 0.7247902154922485,
      "learning_rate": 2.5e-06,
      "loss": 2.072,
      "step": 1500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.5956035256385803,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 2.0647,
      "step": 2000
    },
    {
      "epoch": 0.00625,
      "grad_norm": 0.6233073472976685,
      "learning_rate": 4.166666666666667e-06,
      "loss": 2.0743,
      "step": 2500
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.6304711103439331,
      "learning_rate": 5e-06,
      "loss": 2.0608,
      "step": 3000
    },
    {
      "epoch": 0.00875,
      "grad_norm": 0.6179541349411011,
      "learning_rate": 5.833333333333334e-06,
      "loss": 2.0557,
      "step": 3500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7056578993797302,
      "learning_rate": 6.666666666666667e-06,
      "loss": 2.0476,
      "step": 4000
    },
    {
      "epoch": 0.01125,
      "grad_norm": 0.7196956872940063,
      "learning_rate": 7.5e-06,
      "loss": 2.0499,
      "step": 4500
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.6280786395072937,
      "learning_rate": 8.333333333333334e-06,
      "loss": 2.0564,
      "step": 5000
    },
    {
      "epoch": 0.01375,
      "grad_norm": 0.6416502594947815,
      "learning_rate": 9.166666666666666e-06,
      "loss": 2.0461,
      "step": 5500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.568566083908081,
      "learning_rate": 1e-05,
      "loss": 2.0419,
      "step": 6000
    },
    {
      "epoch": 0.01625,
      "grad_norm": 0.5493419766426086,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 2.0404,
      "step": 6500
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.6433902978897095,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 2.0458,
      "step": 7000
    },
    {
      "epoch": 0.01875,
      "grad_norm": 0.5683876872062683,
      "learning_rate": 1.25e-05,
      "loss": 2.0438,
      "step": 7500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6052339673042297,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 2.0363,
      "step": 8000
    },
    {
      "epoch": 0.02125,
      "grad_norm": 0.5777627825737,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 2.0375,
      "step": 8500
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.6172158718109131,
      "learning_rate": 1.5e-05,
      "loss": 2.0297,
      "step": 9000
    },
    {
      "epoch": 0.02375,
      "grad_norm": 0.6084865927696228,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 2.0345,
      "step": 9500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.6073004007339478,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 2.0337,
      "step": 10000
    },
    {
      "epoch": 0.02625,
      "grad_norm": 0.6053885817527771,
      "learning_rate": 1.75e-05,
      "loss": 2.0259,
      "step": 10500
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.6602093577384949,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 2.0285,
      "step": 11000
    },
    {
      "epoch": 0.02875,
      "grad_norm": 0.6238638162612915,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 2.0267,
      "step": 11500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6253011226654053,
      "learning_rate": 2e-05,
      "loss": 2.0177,
      "step": 12000
    },
    {
      "epoch": 0.03125,
      "grad_norm": 0.5951969623565674,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 2.023,
      "step": 12500
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.6585981845855713,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 2.0196,
      "step": 13000
    },
    {
      "epoch": 0.03375,
      "grad_norm": 0.6671642065048218,
      "learning_rate": 2.25e-05,
      "loss": 2.0271,
      "step": 13500
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.708335280418396,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 2.0185,
      "step": 14000
    },
    {
      "epoch": 0.03625,
      "grad_norm": 0.668310284614563,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 2.0136,
      "step": 14500
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.6239287257194519,
      "learning_rate": 2.5e-05,
      "loss": 2.0176,
      "step": 15000
    },
    {
      "epoch": 0.03875,
      "grad_norm": 0.6692379117012024,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 2.0074,
      "step": 15500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6649496555328369,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 2.0113,
      "step": 16000
    },
    {
      "epoch": 0.04125,
      "grad_norm": 0.7117648720741272,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 2.0002,
      "step": 16500
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.6614023447036743,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 2.0064,
      "step": 17000
    },
    {
      "epoch": 0.04375,
      "grad_norm": 0.675977349281311,
      "learning_rate": 2.916666666666667e-05,
      "loss": 2.0036,
      "step": 17500
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.6832244396209717,
      "learning_rate": 3e-05,
      "loss": 2.0046,
      "step": 18000
    },
    {
      "epoch": 0.04625,
      "grad_norm": 0.6926181316375732,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 1.999,
      "step": 18500
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.7596989870071411,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 1.9992,
      "step": 19000
    },
    {
      "epoch": 0.04875,
      "grad_norm": 0.7731313109397888,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 2.0049,
      "step": 19500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7048933506011963,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.9748,
      "step": 20000
    },
    {
      "epoch": 0.05125,
      "grad_norm": 0.7708183526992798,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 1.9843,
      "step": 20500
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.8010103106498718,
      "learning_rate": 3.5e-05,
      "loss": 1.9855,
      "step": 21000
    },
    {
      "epoch": 0.05375,
      "grad_norm": 0.7820359468460083,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 1.9847,
      "step": 21500
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.7959474325180054,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 1.9877,
      "step": 22000
    },
    {
      "epoch": 0.05625,
      "grad_norm": 0.8328559398651123,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.9737,
      "step": 22500
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.8348504304885864,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 1.9715,
      "step": 23000
    },
    {
      "epoch": 0.05875,
      "grad_norm": 0.8890961408615112,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 1.969,
      "step": 23500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8386203646659851,
      "learning_rate": 4e-05,
      "loss": 1.9793,
      "step": 24000
    },
    {
      "epoch": 0.06125,
      "grad_norm": 0.8304561972618103,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 1.9767,
      "step": 24500
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.8839859962463379,
      "learning_rate": 4.166666666666667e-05,
      "loss": 1.9602,
      "step": 25000
    },
    {
      "epoch": 0.06375,
      "grad_norm": 0.8251996040344238,
      "learning_rate": 4.25e-05,
      "loss": 1.9653,
      "step": 25500
    },
    {
      "epoch": 0.065,
      "grad_norm": 1.0101752281188965,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 1.9575,
      "step": 26000
    },
    {
      "epoch": 0.06625,
      "grad_norm": 0.9769129753112793,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 1.9633,
      "step": 26500
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.9492970705032349,
      "learning_rate": 4.5e-05,
      "loss": 1.9598,
      "step": 27000
    },
    {
      "epoch": 0.06875,
      "grad_norm": 0.9648156762123108,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 1.9528,
      "step": 27500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.914553701877594,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.9512,
      "step": 28000
    },
    {
      "epoch": 0.07125,
      "grad_norm": 0.9479950070381165,
      "learning_rate": 4.75e-05,
      "loss": 1.9485,
      "step": 28500
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.9917711019515991,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 1.9436,
      "step": 29000
    },
    {
      "epoch": 0.07375,
      "grad_norm": 1.063467264175415,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 1.9449,
      "step": 29500
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.9776054620742798,
      "learning_rate": 5e-05,
      "loss": 1.936,
      "step": 30000
    },
    {
      "epoch": 0.07625,
      "grad_norm": 1.1549485921859741,
      "learning_rate": 5.0833333333333333e-05,
      "loss": 1.9379,
      "step": 30500
    },
    {
      "epoch": 0.0775,
      "grad_norm": 1.0316413640975952,
      "learning_rate": 5.166666666666667e-05,
      "loss": 1.9414,
      "step": 31000
    },
    {
      "epoch": 0.07875,
      "grad_norm": 1.0128039121627808,
      "learning_rate": 5.25e-05,
      "loss": 1.9222,
      "step": 31500
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2238264083862305,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.9253,
      "step": 32000
    },
    {
      "epoch": 0.08125,
      "grad_norm": 1.1280415058135986,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 1.9201,
      "step": 32500
    },
    {
      "epoch": 0.0825,
      "grad_norm": 1.1376125812530518,
      "learning_rate": 5.500000000000001e-05,
      "loss": 1.9192,
      "step": 33000
    },
    {
      "epoch": 0.08375,
      "grad_norm": 1.0999051332473755,
      "learning_rate": 5.583333333333334e-05,
      "loss": 1.9151,
      "step": 33500
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.9933043718338013,
      "learning_rate": 5.666666666666667e-05,
      "loss": 1.91,
      "step": 34000
    },
    {
      "epoch": 0.08625,
      "grad_norm": 1.2060508728027344,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 1.9097,
      "step": 34500
    },
    {
      "epoch": 0.0875,
      "grad_norm": 1.0517233610153198,
      "learning_rate": 5.833333333333334e-05,
      "loss": 1.9068,
      "step": 35000
    },
    {
      "epoch": 0.08875,
      "grad_norm": 1.151121735572815,
      "learning_rate": 5.916666666666667e-05,
      "loss": 1.8996,
      "step": 35500
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.071878433227539,
      "learning_rate": 6e-05,
      "loss": 1.898,
      "step": 36000
    },
    {
      "epoch": 0.09125,
      "grad_norm": 1.2146741151809692,
      "learning_rate": 6.083333333333333e-05,
      "loss": 1.8998,
      "step": 36500
    },
    {
      "epoch": 0.0925,
      "grad_norm": 1.2748982906341553,
      "learning_rate": 6.166666666666667e-05,
      "loss": 1.8844,
      "step": 37000
    },
    {
      "epoch": 0.09375,
      "grad_norm": 1.1616483926773071,
      "learning_rate": 6.25e-05,
      "loss": 1.8875,
      "step": 37500
    },
    {
      "epoch": 0.095,
      "grad_norm": 1.230504035949707,
      "learning_rate": 6.333333333333333e-05,
      "loss": 1.8871,
      "step": 38000
    },
    {
      "epoch": 0.09625,
      "grad_norm": 1.2021368741989136,
      "learning_rate": 6.416666666666668e-05,
      "loss": 1.8871,
      "step": 38500
    },
    {
      "epoch": 0.0975,
      "grad_norm": 1.2260793447494507,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.8799,
      "step": 39000
    },
    {
      "epoch": 0.09875,
      "grad_norm": 1.3143374919891357,
      "learning_rate": 6.583333333333334e-05,
      "loss": 1.8771,
      "step": 39500
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2593300342559814,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.8714,
      "step": 40000
    },
    {
      "epoch": 0.10125,
      "grad_norm": 1.40025794506073,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.865,
      "step": 40500
    },
    {
      "epoch": 0.1025,
      "grad_norm": 1.263132095336914,
      "learning_rate": 6.833333333333333e-05,
      "loss": 1.8626,
      "step": 41000
    },
    {
      "epoch": 0.10375,
      "grad_norm": 1.1864142417907715,
      "learning_rate": 6.916666666666666e-05,
      "loss": 1.8643,
      "step": 41500
    },
    {
      "epoch": 0.105,
      "grad_norm": 1.2174979448318481,
      "learning_rate": 7e-05,
      "loss": 1.8661,
      "step": 42000
    },
    {
      "epoch": 0.10625,
      "grad_norm": 1.5037810802459717,
      "learning_rate": 7.083333333333334e-05,
      "loss": 1.8588,
      "step": 42500
    },
    {
      "epoch": 0.1075,
      "grad_norm": 1.4078789949417114,
      "learning_rate": 7.166666666666667e-05,
      "loss": 1.8545,
      "step": 43000
    },
    {
      "epoch": 0.10875,
      "grad_norm": 1.2109127044677734,
      "learning_rate": 7.25e-05,
      "loss": 1.8453,
      "step": 43500
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.512188196182251,
      "learning_rate": 7.333333333333333e-05,
      "loss": 1.8476,
      "step": 44000
    },
    {
      "epoch": 0.11125,
      "grad_norm": 1.2102733850479126,
      "learning_rate": 7.416666666666668e-05,
      "loss": 1.8424,
      "step": 44500
    },
    {
      "epoch": 0.1125,
      "grad_norm": 1.3323529958724976,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.8446,
      "step": 45000
    },
    {
      "epoch": 0.11375,
      "grad_norm": 1.4106940031051636,
      "learning_rate": 7.583333333333334e-05,
      "loss": 1.8299,
      "step": 45500
    },
    {
      "epoch": 0.115,
      "grad_norm": 1.4618200063705444,
      "learning_rate": 7.666666666666667e-05,
      "loss": 1.8357,
      "step": 46000
    },
    {
      "epoch": 0.11625,
      "grad_norm": 1.424829125404358,
      "learning_rate": 7.75e-05,
      "loss": 1.8229,
      "step": 46500
    },
    {
      "epoch": 0.1175,
      "grad_norm": 1.5578261613845825,
      "learning_rate": 7.833333333333333e-05,
      "loss": 1.8266,
      "step": 47000
    },
    {
      "epoch": 0.11875,
      "grad_norm": 1.4147961139678955,
      "learning_rate": 7.916666666666666e-05,
      "loss": 1.8199,
      "step": 47500
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.450382113456726,
      "learning_rate": 8e-05,
      "loss": 1.8218,
      "step": 48000
    },
    {
      "epoch": 0.12125,
      "grad_norm": 1.5292165279388428,
      "learning_rate": 8.083333333333334e-05,
      "loss": 1.8175,
      "step": 48500
    },
    {
      "epoch": 0.1225,
      "grad_norm": 1.4269394874572754,
      "learning_rate": 8.166666666666667e-05,
      "loss": 1.8189,
      "step": 49000
    },
    {
      "epoch": 0.12375,
      "grad_norm": 1.3358274698257446,
      "learning_rate": 8.25e-05,
      "loss": 1.8126,
      "step": 49500
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.5615488290786743,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.8166,
      "step": 50000
    },
    {
      "epoch": 0.12625,
      "grad_norm": 1.5055317878723145,
      "learning_rate": 8.416666666666668e-05,
      "loss": 1.8015,
      "step": 50500
    },
    {
      "epoch": 0.1275,
      "grad_norm": 1.6018065214157104,
      "learning_rate": 8.5e-05,
      "loss": 1.7941,
      "step": 51000
    },
    {
      "epoch": 0.12875,
      "grad_norm": 1.4659924507141113,
      "learning_rate": 8.583333333333334e-05,
      "loss": 1.7903,
      "step": 51500
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.5612194538116455,
      "learning_rate": 8.666666666666667e-05,
      "loss": 1.7914,
      "step": 52000
    },
    {
      "epoch": 0.13125,
      "grad_norm": 1.6428014039993286,
      "learning_rate": 8.75e-05,
      "loss": 1.7794,
      "step": 52500
    },
    {
      "epoch": 0.1325,
      "grad_norm": 1.446271300315857,
      "learning_rate": 8.833333333333333e-05,
      "loss": 1.7814,
      "step": 53000
    },
    {
      "epoch": 0.13375,
      "grad_norm": 1.5774890184402466,
      "learning_rate": 8.916666666666667e-05,
      "loss": 1.7816,
      "step": 53500
    },
    {
      "epoch": 0.135,
      "grad_norm": 1.9530143737792969,
      "learning_rate": 9e-05,
      "loss": 1.7856,
      "step": 54000
    },
    {
      "epoch": 0.13625,
      "grad_norm": 1.4705753326416016,
      "learning_rate": 9.083333333333334e-05,
      "loss": 1.7677,
      "step": 54500
    },
    {
      "epoch": 0.1375,
      "grad_norm": 1.5492900609970093,
      "learning_rate": 9.166666666666667e-05,
      "loss": 1.7709,
      "step": 55000
    },
    {
      "epoch": 0.13875,
      "grad_norm": 1.8654483556747437,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.7642,
      "step": 55500
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6102670431137085,
      "learning_rate": 9.333333333333334e-05,
      "loss": 1.7582,
      "step": 56000
    },
    {
      "epoch": 0.14125,
      "grad_norm": 1.7278226613998413,
      "learning_rate": 9.416666666666667e-05,
      "loss": 1.7594,
      "step": 56500
    },
    {
      "epoch": 0.1425,
      "grad_norm": 1.683935523033142,
      "learning_rate": 9.5e-05,
      "loss": 1.7553,
      "step": 57000
    },
    {
      "epoch": 0.14375,
      "grad_norm": 1.6363633871078491,
      "learning_rate": 9.583333333333334e-05,
      "loss": 1.7579,
      "step": 57500
    },
    {
      "epoch": 0.145,
      "grad_norm": 1.6941801309585571,
      "learning_rate": 9.666666666666667e-05,
      "loss": 1.7435,
      "step": 58000
    },
    {
      "epoch": 0.14625,
      "grad_norm": 1.4741714000701904,
      "learning_rate": 9.75e-05,
      "loss": 1.748,
      "step": 58500
    },
    {
      "epoch": 0.1475,
      "grad_norm": 1.6150779724121094,
      "learning_rate": 9.833333333333333e-05,
      "loss": 1.7397,
      "step": 59000
    },
    {
      "epoch": 0.14875,
      "grad_norm": 1.7995890378952026,
      "learning_rate": 9.916666666666667e-05,
      "loss": 1.7325,
      "step": 59500
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.6700972318649292,
      "learning_rate": 0.0001,
      "loss": 1.7503,
      "step": 60000
    },
    {
      "epoch": 0.15125,
      "grad_norm": 1.6452245712280273,
      "learning_rate": 9.98529411764706e-05,
      "loss": 1.7333,
      "step": 60500
    },
    {
      "epoch": 0.1525,
      "grad_norm": 1.4547799825668335,
      "learning_rate": 9.970588235294118e-05,
      "loss": 1.7318,
      "step": 61000
    },
    {
      "epoch": 0.15375,
      "grad_norm": 1.8347376585006714,
      "learning_rate": 9.955882352941178e-05,
      "loss": 1.7218,
      "step": 61500
    },
    {
      "epoch": 0.155,
      "grad_norm": 1.5920315980911255,
      "learning_rate": 9.941176470588236e-05,
      "loss": 1.7077,
      "step": 62000
    },
    {
      "epoch": 0.15625,
      "grad_norm": 1.7212966680526733,
      "learning_rate": 9.926470588235295e-05,
      "loss": 1.7167,
      "step": 62500
    },
    {
      "epoch": 0.1575,
      "grad_norm": 1.5742084980010986,
      "learning_rate": 9.911764705882353e-05,
      "loss": 1.7074,
      "step": 63000
    },
    {
      "epoch": 0.15875,
      "grad_norm": 1.7368007898330688,
      "learning_rate": 9.897058823529413e-05,
      "loss": 1.7071,
      "step": 63500
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7699558734893799,
      "learning_rate": 9.882352941176471e-05,
      "loss": 1.7013,
      "step": 64000
    },
    {
      "epoch": 0.16125,
      "grad_norm": 1.667356014251709,
      "learning_rate": 9.86764705882353e-05,
      "loss": 1.6978,
      "step": 64500
    },
    {
      "epoch": 0.1625,
      "grad_norm": 1.732240915298462,
      "learning_rate": 9.852941176470589e-05,
      "loss": 1.6916,
      "step": 65000
    },
    {
      "epoch": 0.16375,
      "grad_norm": 1.7115635871887207,
      "learning_rate": 9.838235294117647e-05,
      "loss": 1.6869,
      "step": 65500
    },
    {
      "epoch": 0.165,
      "grad_norm": 1.6621785163879395,
      "learning_rate": 9.823529411764706e-05,
      "loss": 1.6902,
      "step": 66000
    },
    {
      "epoch": 0.16625,
      "grad_norm": 1.8152867555618286,
      "learning_rate": 9.808823529411765e-05,
      "loss": 1.6819,
      "step": 66500
    },
    {
      "epoch": 0.1675,
      "grad_norm": 1.6894257068634033,
      "learning_rate": 9.794117647058824e-05,
      "loss": 1.6829,
      "step": 67000
    },
    {
      "epoch": 0.16875,
      "grad_norm": 1.6845656633377075,
      "learning_rate": 9.779411764705882e-05,
      "loss": 1.6774,
      "step": 67500
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0552570819854736,
      "learning_rate": 9.764705882352942e-05,
      "loss": 1.672,
      "step": 68000
    },
    {
      "epoch": 0.17125,
      "grad_norm": 1.8374886512756348,
      "learning_rate": 9.75e-05,
      "loss": 1.6637,
      "step": 68500
    },
    {
      "epoch": 0.1725,
      "grad_norm": 1.6825402975082397,
      "learning_rate": 9.73529411764706e-05,
      "loss": 1.663,
      "step": 69000
    },
    {
      "epoch": 0.17375,
      "grad_norm": 1.767700433731079,
      "learning_rate": 9.720588235294117e-05,
      "loss": 1.6681,
      "step": 69500
    },
    {
      "epoch": 0.175,
      "grad_norm": 1.8300673961639404,
      "learning_rate": 9.705882352941177e-05,
      "loss": 1.6564,
      "step": 70000
    },
    {
      "epoch": 0.17625,
      "grad_norm": 1.9486585855484009,
      "learning_rate": 9.691176470588235e-05,
      "loss": 1.6574,
      "step": 70500
    },
    {
      "epoch": 0.1775,
      "grad_norm": 1.8369641304016113,
      "learning_rate": 9.676470588235295e-05,
      "loss": 1.6532,
      "step": 71000
    },
    {
      "epoch": 0.17875,
      "grad_norm": 1.9165257215499878,
      "learning_rate": 9.661764705882354e-05,
      "loss": 1.65,
      "step": 71500
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.930983543395996,
      "learning_rate": 9.647058823529412e-05,
      "loss": 1.6558,
      "step": 72000
    },
    {
      "epoch": 0.18125,
      "grad_norm": 1.8403406143188477,
      "learning_rate": 9.632352941176472e-05,
      "loss": 1.6452,
      "step": 72500
    },
    {
      "epoch": 0.1825,
      "grad_norm": 1.7135121822357178,
      "learning_rate": 9.61764705882353e-05,
      "loss": 1.6527,
      "step": 73000
    },
    {
      "epoch": 0.18375,
      "grad_norm": 1.9882559776306152,
      "learning_rate": 9.60294117647059e-05,
      "loss": 1.6385,
      "step": 73500
    },
    {
      "epoch": 0.185,
      "grad_norm": 1.8998135328292847,
      "learning_rate": 9.588235294117648e-05,
      "loss": 1.6272,
      "step": 74000
    },
    {
      "epoch": 0.18625,
      "grad_norm": 1.9979103803634644,
      "learning_rate": 9.573529411764707e-05,
      "loss": 1.6335,
      "step": 74500
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.8253353834152222,
      "learning_rate": 9.558823529411765e-05,
      "loss": 1.6316,
      "step": 75000
    },
    {
      "epoch": 0.18875,
      "grad_norm": 1.8128278255462646,
      "learning_rate": 9.544117647058825e-05,
      "loss": 1.6282,
      "step": 75500
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9996551275253296,
      "learning_rate": 9.529411764705883e-05,
      "loss": 1.628,
      "step": 76000
    },
    {
      "epoch": 0.19125,
      "grad_norm": 1.9150238037109375,
      "learning_rate": 9.514705882352941e-05,
      "loss": 1.6188,
      "step": 76500
    },
    {
      "epoch": 0.1925,
      "grad_norm": 1.760855793952942,
      "learning_rate": 9.5e-05,
      "loss": 1.6163,
      "step": 77000
    },
    {
      "epoch": 0.19375,
      "grad_norm": 1.7863938808441162,
      "learning_rate": 9.485294117647059e-05,
      "loss": 1.605,
      "step": 77500
    },
    {
      "epoch": 0.195,
      "grad_norm": 1.878404140472412,
      "learning_rate": 9.470588235294118e-05,
      "loss": 1.5966,
      "step": 78000
    },
    {
      "epoch": 0.19625,
      "grad_norm": 1.847072720527649,
      "learning_rate": 9.455882352941176e-05,
      "loss": 1.6143,
      "step": 78500
    },
    {
      "epoch": 0.1975,
      "grad_norm": 1.704306960105896,
      "learning_rate": 9.441176470588236e-05,
      "loss": 1.6023,
      "step": 79000
    },
    {
      "epoch": 0.19875,
      "grad_norm": 1.692057490348816,
      "learning_rate": 9.426470588235294e-05,
      "loss": 1.5902,
      "step": 79500
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9751724004745483,
      "learning_rate": 9.411764705882353e-05,
      "loss": 1.5882,
      "step": 80000
    },
    {
      "epoch": 0.20125,
      "grad_norm": 1.9542534351348877,
      "learning_rate": 9.397058823529412e-05,
      "loss": 1.5928,
      "step": 80500
    },
    {
      "epoch": 0.2025,
      "grad_norm": 2.0423014163970947,
      "learning_rate": 9.382352941176471e-05,
      "loss": 1.5969,
      "step": 81000
    },
    {
      "epoch": 0.20375,
      "grad_norm": 1.8790979385375977,
      "learning_rate": 9.367647058823529e-05,
      "loss": 1.5861,
      "step": 81500
    },
    {
      "epoch": 0.205,
      "grad_norm": 1.8653647899627686,
      "learning_rate": 9.352941176470589e-05,
      "loss": 1.5845,
      "step": 82000
    },
    {
      "epoch": 0.20625,
      "grad_norm": 1.9019354581832886,
      "learning_rate": 9.338235294117648e-05,
      "loss": 1.5756,
      "step": 82500
    },
    {
      "epoch": 0.2075,
      "grad_norm": 1.9376120567321777,
      "learning_rate": 9.323529411764706e-05,
      "loss": 1.5763,
      "step": 83000
    },
    {
      "epoch": 0.20875,
      "grad_norm": 1.823911428451538,
      "learning_rate": 9.308823529411766e-05,
      "loss": 1.5775,
      "step": 83500
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.3817126750946045,
      "learning_rate": 9.294117647058824e-05,
      "loss": 1.5728,
      "step": 84000
    },
    {
      "epoch": 0.21125,
      "grad_norm": 1.9881726503372192,
      "learning_rate": 9.279411764705884e-05,
      "loss": 1.5702,
      "step": 84500
    },
    {
      "epoch": 0.2125,
      "grad_norm": 2.000735282897949,
      "learning_rate": 9.264705882352942e-05,
      "loss": 1.5583,
      "step": 85000
    },
    {
      "epoch": 0.21375,
      "grad_norm": 1.6832503080368042,
      "learning_rate": 9.250000000000001e-05,
      "loss": 1.5575,
      "step": 85500
    },
    {
      "epoch": 0.215,
      "grad_norm": 2.570873260498047,
      "learning_rate": 9.23529411764706e-05,
      "loss": 1.5641,
      "step": 86000
    },
    {
      "epoch": 0.21625,
      "grad_norm": 2.144967794418335,
      "learning_rate": 9.220588235294119e-05,
      "loss": 1.5614,
      "step": 86500
    },
    {
      "epoch": 0.2175,
      "grad_norm": 1.9306477308273315,
      "learning_rate": 9.205882352941177e-05,
      "loss": 1.5623,
      "step": 87000
    },
    {
      "epoch": 0.21875,
      "grad_norm": 1.929075837135315,
      "learning_rate": 9.191176470588235e-05,
      "loss": 1.5503,
      "step": 87500
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1191513538360596,
      "learning_rate": 9.176470588235295e-05,
      "loss": 1.549,
      "step": 88000
    },
    {
      "epoch": 0.22125,
      "grad_norm": 1.9515572786331177,
      "learning_rate": 9.161764705882353e-05,
      "loss": 1.5487,
      "step": 88500
    },
    {
      "epoch": 0.2225,
      "grad_norm": 2.0747973918914795,
      "learning_rate": 9.147058823529412e-05,
      "loss": 1.5458,
      "step": 89000
    },
    {
      "epoch": 0.22375,
      "grad_norm": 2.114978551864624,
      "learning_rate": 9.13235294117647e-05,
      "loss": 1.5428,
      "step": 89500
    },
    {
      "epoch": 0.225,
      "grad_norm": 2.0483994483947754,
      "learning_rate": 9.11764705882353e-05,
      "loss": 1.5419,
      "step": 90000
    },
    {
      "epoch": 0.22625,
      "grad_norm": 1.9456595182418823,
      "learning_rate": 9.102941176470588e-05,
      "loss": 1.5346,
      "step": 90500
    },
    {
      "epoch": 0.2275,
      "grad_norm": 2.0005695819854736,
      "learning_rate": 9.088235294117648e-05,
      "loss": 1.5296,
      "step": 91000
    },
    {
      "epoch": 0.22875,
      "grad_norm": 1.8668255805969238,
      "learning_rate": 9.073529411764706e-05,
      "loss": 1.5282,
      "step": 91500
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0259811878204346,
      "learning_rate": 9.058823529411765e-05,
      "loss": 1.5277,
      "step": 92000
    },
    {
      "epoch": 0.23125,
      "grad_norm": 2.109956741333008,
      "learning_rate": 9.044117647058823e-05,
      "loss": 1.5291,
      "step": 92500
    },
    {
      "epoch": 0.2325,
      "grad_norm": 2.011131763458252,
      "learning_rate": 9.029411764705883e-05,
      "loss": 1.5196,
      "step": 93000
    },
    {
      "epoch": 0.23375,
      "grad_norm": 2.0656349658966064,
      "learning_rate": 9.014705882352942e-05,
      "loss": 1.5191,
      "step": 93500
    },
    {
      "epoch": 0.235,
      "grad_norm": 1.9676610231399536,
      "learning_rate": 9e-05,
      "loss": 1.5296,
      "step": 94000
    },
    {
      "epoch": 0.23625,
      "grad_norm": 2.046384811401367,
      "learning_rate": 8.98529411764706e-05,
      "loss": 1.5208,
      "step": 94500
    },
    {
      "epoch": 0.2375,
      "grad_norm": 1.921543836593628,
      "learning_rate": 8.970588235294118e-05,
      "loss": 1.5139,
      "step": 95000
    },
    {
      "epoch": 0.23875,
      "grad_norm": 2.0970609188079834,
      "learning_rate": 8.955882352941178e-05,
      "loss": 1.5034,
      "step": 95500
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2860233783721924,
      "learning_rate": 8.941176470588236e-05,
      "loss": 1.5094,
      "step": 96000
    },
    {
      "epoch": 0.24125,
      "grad_norm": 2.231862783432007,
      "learning_rate": 8.926470588235295e-05,
      "loss": 1.5071,
      "step": 96500
    },
    {
      "epoch": 0.2425,
      "grad_norm": 2.1513900756835938,
      "learning_rate": 8.911764705882354e-05,
      "loss": 1.5047,
      "step": 97000
    },
    {
      "epoch": 0.24375,
      "grad_norm": 2.338294267654419,
      "learning_rate": 8.897058823529412e-05,
      "loss": 1.5019,
      "step": 97500
    },
    {
      "epoch": 0.245,
      "grad_norm": 1.898435115814209,
      "learning_rate": 8.882352941176471e-05,
      "loss": 1.4984,
      "step": 98000
    },
    {
      "epoch": 0.24625,
      "grad_norm": 2.1696417331695557,
      "learning_rate": 8.867647058823529e-05,
      "loss": 1.5009,
      "step": 98500
    },
    {
      "epoch": 0.2475,
      "grad_norm": 2.022007465362549,
      "learning_rate": 8.852941176470589e-05,
      "loss": 1.4996,
      "step": 99000
    },
    {
      "epoch": 0.24875,
      "grad_norm": 2.053650140762329,
      "learning_rate": 8.838235294117647e-05,
      "loss": 1.4999,
      "step": 99500
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.189403772354126,
      "learning_rate": 8.823529411764706e-05,
      "loss": 1.4964,
      "step": 100000
    },
    {
      "epoch": 0.25125,
      "grad_norm": 2.046569585800171,
      "learning_rate": 8.808823529411765e-05,
      "loss": 1.4926,
      "step": 100500
    },
    {
      "epoch": 0.2525,
      "grad_norm": 2.0980119705200195,
      "learning_rate": 8.794117647058824e-05,
      "loss": 1.4845,
      "step": 101000
    },
    {
      "epoch": 0.25375,
      "grad_norm": 2.1288304328918457,
      "learning_rate": 8.779411764705882e-05,
      "loss": 1.4846,
      "step": 101500
    },
    {
      "epoch": 0.255,
      "grad_norm": 2.3454456329345703,
      "learning_rate": 8.764705882352942e-05,
      "loss": 1.4808,
      "step": 102000
    },
    {
      "epoch": 0.25625,
      "grad_norm": 2.2642769813537598,
      "learning_rate": 8.75e-05,
      "loss": 1.4794,
      "step": 102500
    },
    {
      "epoch": 0.2575,
      "grad_norm": 2.1582272052764893,
      "learning_rate": 8.73529411764706e-05,
      "loss": 1.4744,
      "step": 103000
    },
    {
      "epoch": 0.25875,
      "grad_norm": 2.106638193130493,
      "learning_rate": 8.720588235294118e-05,
      "loss": 1.4787,
      "step": 103500
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1480941772460938,
      "learning_rate": 8.705882352941177e-05,
      "loss": 1.4722,
      "step": 104000
    },
    {
      "epoch": 0.26125,
      "grad_norm": 1.9981615543365479,
      "learning_rate": 8.691176470588237e-05,
      "loss": 1.4674,
      "step": 104500
    },
    {
      "epoch": 0.2625,
      "grad_norm": 2.06508731842041,
      "learning_rate": 8.676470588235295e-05,
      "loss": 1.4629,
      "step": 105000
    },
    {
      "epoch": 0.26375,
      "grad_norm": 1.968605637550354,
      "learning_rate": 8.661764705882354e-05,
      "loss": 1.474,
      "step": 105500
    },
    {
      "epoch": 0.265,
      "grad_norm": 2.108788013458252,
      "learning_rate": 8.647058823529412e-05,
      "loss": 1.4693,
      "step": 106000
    },
    {
      "epoch": 0.26625,
      "grad_norm": 2.146681308746338,
      "learning_rate": 8.632352941176472e-05,
      "loss": 1.4592,
      "step": 106500
    },
    {
      "epoch": 0.2675,
      "grad_norm": 1.991684079170227,
      "learning_rate": 8.61764705882353e-05,
      "loss": 1.4609,
      "step": 107000
    },
    {
      "epoch": 0.26875,
      "grad_norm": 2.1728901863098145,
      "learning_rate": 8.60294117647059e-05,
      "loss": 1.4598,
      "step": 107500
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.1792445182800293,
      "learning_rate": 8.588235294117646e-05,
      "loss": 1.4611,
      "step": 108000
    },
    {
      "epoch": 0.27125,
      "grad_norm": 2.0192062854766846,
      "learning_rate": 8.573529411764706e-05,
      "loss": 1.4514,
      "step": 108500
    },
    {
      "epoch": 0.2725,
      "grad_norm": 1.9629765748977661,
      "learning_rate": 8.558823529411765e-05,
      "loss": 1.4421,
      "step": 109000
    },
    {
      "epoch": 0.27375,
      "grad_norm": 2.2860658168792725,
      "learning_rate": 8.544117647058823e-05,
      "loss": 1.4507,
      "step": 109500
    },
    {
      "epoch": 0.275,
      "grad_norm": 2.342651605606079,
      "learning_rate": 8.529411764705883e-05,
      "loss": 1.4458,
      "step": 110000
    },
    {
      "epoch": 0.27625,
      "grad_norm": 2.1216111183166504,
      "learning_rate": 8.514705882352941e-05,
      "loss": 1.4452,
      "step": 110500
    },
    {
      "epoch": 0.2775,
      "grad_norm": 2.0225422382354736,
      "learning_rate": 8.5e-05,
      "loss": 1.4439,
      "step": 111000
    },
    {
      "epoch": 0.27875,
      "grad_norm": 2.0051891803741455,
      "learning_rate": 8.485294117647059e-05,
      "loss": 1.4402,
      "step": 111500
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.0460360050201416,
      "learning_rate": 8.470588235294118e-05,
      "loss": 1.4359,
      "step": 112000
    },
    {
      "epoch": 0.28125,
      "grad_norm": 2.0898303985595703,
      "learning_rate": 8.455882352941176e-05,
      "loss": 1.4331,
      "step": 112500
    },
    {
      "epoch": 0.2825,
      "grad_norm": 2.153834581375122,
      "learning_rate": 8.441176470588236e-05,
      "loss": 1.4321,
      "step": 113000
    },
    {
      "epoch": 0.28375,
      "grad_norm": 2.120541572570801,
      "learning_rate": 8.426470588235294e-05,
      "loss": 1.4349,
      "step": 113500
    },
    {
      "epoch": 0.285,
      "grad_norm": 2.447187900543213,
      "learning_rate": 8.411764705882354e-05,
      "loss": 1.4258,
      "step": 114000
    },
    {
      "epoch": 0.28625,
      "grad_norm": 2.2278711795806885,
      "learning_rate": 8.397058823529412e-05,
      "loss": 1.4312,
      "step": 114500
    },
    {
      "epoch": 0.2875,
      "grad_norm": 2.336636543273926,
      "learning_rate": 8.382352941176471e-05,
      "loss": 1.4164,
      "step": 115000
    },
    {
      "epoch": 0.28875,
      "grad_norm": 2.2063844203948975,
      "learning_rate": 8.367647058823531e-05,
      "loss": 1.4257,
      "step": 115500
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.998403549194336,
      "learning_rate": 8.352941176470589e-05,
      "loss": 1.4149,
      "step": 116000
    },
    {
      "epoch": 0.29125,
      "grad_norm": 2.0230205059051514,
      "learning_rate": 8.338235294117648e-05,
      "loss": 1.4131,
      "step": 116500
    },
    {
      "epoch": 0.2925,
      "grad_norm": 2.2151365280151367,
      "learning_rate": 8.323529411764707e-05,
      "loss": 1.4133,
      "step": 117000
    },
    {
      "epoch": 0.29375,
      "grad_norm": 2.0627052783966064,
      "learning_rate": 8.308823529411766e-05,
      "loss": 1.4066,
      "step": 117500
    },
    {
      "epoch": 0.295,
      "grad_norm": 2.1680643558502197,
      "learning_rate": 8.294117647058824e-05,
      "loss": 1.4089,
      "step": 118000
    },
    {
      "epoch": 0.29625,
      "grad_norm": 2.3564538955688477,
      "learning_rate": 8.279411764705882e-05,
      "loss": 1.4112,
      "step": 118500
    },
    {
      "epoch": 0.2975,
      "grad_norm": 2.2060434818267822,
      "learning_rate": 8.26470588235294e-05,
      "loss": 1.4056,
      "step": 119000
    },
    {
      "epoch": 0.29875,
      "grad_norm": 2.391991376876831,
      "learning_rate": 8.25e-05,
      "loss": 1.4039,
      "step": 119500
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.203153133392334,
      "learning_rate": 8.23529411764706e-05,
      "loss": 1.4041,
      "step": 120000
    },
    {
      "epoch": 0.30125,
      "grad_norm": 2.3276350498199463,
      "learning_rate": 8.220588235294118e-05,
      "loss": 1.4059,
      "step": 120500
    },
    {
      "epoch": 0.3025,
      "grad_norm": 2.6853649616241455,
      "learning_rate": 8.205882352941177e-05,
      "loss": 1.4003,
      "step": 121000
    },
    {
      "epoch": 0.30375,
      "grad_norm": 2.2733757495880127,
      "learning_rate": 8.191176470588235e-05,
      "loss": 1.3985,
      "step": 121500
    },
    {
      "epoch": 0.305,
      "grad_norm": 2.094398021697998,
      "learning_rate": 8.176470588235295e-05,
      "loss": 1.3997,
      "step": 122000
    },
    {
      "epoch": 0.30625,
      "grad_norm": 2.2558937072753906,
      "learning_rate": 8.161764705882353e-05,
      "loss": 1.3934,
      "step": 122500
    },
    {
      "epoch": 0.3075,
      "grad_norm": 2.153789758682251,
      "learning_rate": 8.147058823529412e-05,
      "loss": 1.3919,
      "step": 123000
    },
    {
      "epoch": 0.30875,
      "grad_norm": 2.217172622680664,
      "learning_rate": 8.13235294117647e-05,
      "loss": 1.3883,
      "step": 123500
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.2822790145874023,
      "learning_rate": 8.11764705882353e-05,
      "loss": 1.3791,
      "step": 124000
    },
    {
      "epoch": 0.31125,
      "grad_norm": 2.401904582977295,
      "learning_rate": 8.102941176470588e-05,
      "loss": 1.3887,
      "step": 124500
    },
    {
      "epoch": 0.3125,
      "grad_norm": 2.230330467224121,
      "learning_rate": 8.088235294117648e-05,
      "loss": 1.3854,
      "step": 125000
    },
    {
      "epoch": 0.31375,
      "grad_norm": 2.0501105785369873,
      "learning_rate": 8.073529411764706e-05,
      "loss": 1.3808,
      "step": 125500
    },
    {
      "epoch": 0.315,
      "grad_norm": 2.2248446941375732,
      "learning_rate": 8.058823529411765e-05,
      "loss": 1.3844,
      "step": 126000
    },
    {
      "epoch": 0.31625,
      "grad_norm": 2.086890459060669,
      "learning_rate": 8.044117647058825e-05,
      "loss": 1.3789,
      "step": 126500
    },
    {
      "epoch": 0.3175,
      "grad_norm": 2.275092840194702,
      "learning_rate": 8.029411764705883e-05,
      "loss": 1.3759,
      "step": 127000
    },
    {
      "epoch": 0.31875,
      "grad_norm": 2.6254987716674805,
      "learning_rate": 8.014705882352943e-05,
      "loss": 1.3834,
      "step": 127500
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.4472849369049072,
      "learning_rate": 8e-05,
      "loss": 1.3748,
      "step": 128000
    },
    {
      "epoch": 0.32125,
      "grad_norm": 2.295266628265381,
      "learning_rate": 7.98529411764706e-05,
      "loss": 1.378,
      "step": 128500
    },
    {
      "epoch": 0.3225,
      "grad_norm": 2.4539663791656494,
      "learning_rate": 7.970588235294118e-05,
      "loss": 1.3687,
      "step": 129000
    },
    {
      "epoch": 0.32375,
      "grad_norm": 2.192370653152466,
      "learning_rate": 7.955882352941176e-05,
      "loss": 1.3621,
      "step": 129500
    },
    {
      "epoch": 0.325,
      "grad_norm": 2.5690841674804688,
      "learning_rate": 7.941176470588235e-05,
      "loss": 1.3627,
      "step": 130000
    },
    {
      "epoch": 0.32625,
      "grad_norm": 2.2920329570770264,
      "learning_rate": 7.926470588235294e-05,
      "loss": 1.3638,
      "step": 130500
    },
    {
      "epoch": 0.3275,
      "grad_norm": 2.2123403549194336,
      "learning_rate": 7.911764705882354e-05,
      "loss": 1.3578,
      "step": 131000
    },
    {
      "epoch": 0.32875,
      "grad_norm": 2.342984437942505,
      "learning_rate": 7.897058823529412e-05,
      "loss": 1.3581,
      "step": 131500
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.410817861557007,
      "learning_rate": 7.882352941176471e-05,
      "loss": 1.3577,
      "step": 132000
    },
    {
      "epoch": 0.33125,
      "grad_norm": 2.1265199184417725,
      "learning_rate": 7.86764705882353e-05,
      "loss": 1.3617,
      "step": 132500
    },
    {
      "epoch": 0.3325,
      "grad_norm": 2.1869089603424072,
      "learning_rate": 7.852941176470589e-05,
      "loss": 1.353,
      "step": 133000
    },
    {
      "epoch": 0.33375,
      "grad_norm": 2.4214186668395996,
      "learning_rate": 7.838235294117647e-05,
      "loss": 1.3556,
      "step": 133500
    },
    {
      "epoch": 0.335,
      "grad_norm": 2.2959020137786865,
      "learning_rate": 7.823529411764707e-05,
      "loss": 1.3549,
      "step": 134000
    },
    {
      "epoch": 0.33625,
      "grad_norm": 2.3249847888946533,
      "learning_rate": 7.808823529411765e-05,
      "loss": 1.3561,
      "step": 134500
    },
    {
      "epoch": 0.3375,
      "grad_norm": 2.358555793762207,
      "learning_rate": 7.794117647058824e-05,
      "loss": 1.3485,
      "step": 135000
    },
    {
      "epoch": 0.33875,
      "grad_norm": 2.459110736846924,
      "learning_rate": 7.779411764705882e-05,
      "loss": 1.3485,
      "step": 135500
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1878654956817627,
      "learning_rate": 7.764705882352942e-05,
      "loss": 1.3488,
      "step": 136000
    },
    {
      "epoch": 0.34125,
      "grad_norm": 2.293134927749634,
      "learning_rate": 7.75e-05,
      "loss": 1.3346,
      "step": 136500
    },
    {
      "epoch": 0.3425,
      "grad_norm": 2.469749689102173,
      "learning_rate": 7.73529411764706e-05,
      "loss": 1.3399,
      "step": 137000
    },
    {
      "epoch": 0.34375,
      "grad_norm": 2.307737350463867,
      "learning_rate": 7.720588235294119e-05,
      "loss": 1.3457,
      "step": 137500
    },
    {
      "epoch": 0.345,
      "grad_norm": 2.088409900665283,
      "learning_rate": 7.705882352941177e-05,
      "loss": 1.3311,
      "step": 138000
    },
    {
      "epoch": 0.34625,
      "grad_norm": 2.4007630348205566,
      "learning_rate": 7.691176470588237e-05,
      "loss": 1.3374,
      "step": 138500
    },
    {
      "epoch": 0.3475,
      "grad_norm": 2.236370086669922,
      "learning_rate": 7.676470588235295e-05,
      "loss": 1.3289,
      "step": 139000
    },
    {
      "epoch": 0.34875,
      "grad_norm": 2.495439291000366,
      "learning_rate": 7.661764705882354e-05,
      "loss": 1.3338,
      "step": 139500
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3328397274017334,
      "learning_rate": 7.647058823529411e-05,
      "loss": 1.3314,
      "step": 140000
    },
    {
      "epoch": 0.35125,
      "grad_norm": 2.324357032775879,
      "learning_rate": 7.63235294117647e-05,
      "loss": 1.3259,
      "step": 140500
    },
    {
      "epoch": 0.3525,
      "grad_norm": 2.2554330825805664,
      "learning_rate": 7.617647058823529e-05,
      "loss": 1.326,
      "step": 141000
    },
    {
      "epoch": 0.35375,
      "grad_norm": 2.354511022567749,
      "learning_rate": 7.602941176470588e-05,
      "loss": 1.336,
      "step": 141500
    },
    {
      "epoch": 0.355,
      "grad_norm": 2.498732805252075,
      "learning_rate": 7.588235294117648e-05,
      "loss": 1.3239,
      "step": 142000
    },
    {
      "epoch": 0.35625,
      "grad_norm": 2.381298303604126,
      "learning_rate": 7.573529411764706e-05,
      "loss": 1.3225,
      "step": 142500
    },
    {
      "epoch": 0.3575,
      "grad_norm": 2.4002790451049805,
      "learning_rate": 7.558823529411765e-05,
      "loss": 1.3222,
      "step": 143000
    },
    {
      "epoch": 0.35875,
      "grad_norm": 2.365462303161621,
      "learning_rate": 7.544117647058824e-05,
      "loss": 1.3244,
      "step": 143500
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.1691019535064697,
      "learning_rate": 7.529411764705883e-05,
      "loss": 1.3149,
      "step": 144000
    },
    {
      "epoch": 0.36125,
      "grad_norm": 2.607802152633667,
      "learning_rate": 7.514705882352941e-05,
      "loss": 1.3123,
      "step": 144500
    },
    {
      "epoch": 0.3625,
      "grad_norm": 2.284097194671631,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.3238,
      "step": 145000
    },
    {
      "epoch": 0.36375,
      "grad_norm": 2.4125654697418213,
      "learning_rate": 7.485294117647059e-05,
      "loss": 1.3205,
      "step": 145500
    },
    {
      "epoch": 0.365,
      "grad_norm": 2.3298709392547607,
      "learning_rate": 7.470588235294118e-05,
      "loss": 1.3136,
      "step": 146000
    },
    {
      "epoch": 0.36625,
      "grad_norm": 2.202871561050415,
      "learning_rate": 7.455882352941176e-05,
      "loss": 1.3078,
      "step": 146500
    },
    {
      "epoch": 0.3675,
      "grad_norm": 2.3526196479797363,
      "learning_rate": 7.441176470588236e-05,
      "loss": 1.3162,
      "step": 147000
    },
    {
      "epoch": 0.36875,
      "grad_norm": 2.53977370262146,
      "learning_rate": 7.426470588235294e-05,
      "loss": 1.3092,
      "step": 147500
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.356201171875,
      "learning_rate": 7.411764705882354e-05,
      "loss": 1.3067,
      "step": 148000
    },
    {
      "epoch": 0.37125,
      "grad_norm": 2.452322006225586,
      "learning_rate": 7.397058823529413e-05,
      "loss": 1.3062,
      "step": 148500
    },
    {
      "epoch": 0.3725,
      "grad_norm": 2.272728204727173,
      "learning_rate": 7.382352941176471e-05,
      "loss": 1.3072,
      "step": 149000
    },
    {
      "epoch": 0.37375,
      "grad_norm": 2.2003324031829834,
      "learning_rate": 7.367647058823531e-05,
      "loss": 1.3067,
      "step": 149500
    },
    {
      "epoch": 0.375,
      "grad_norm": 2.4289183616638184,
      "learning_rate": 7.352941176470589e-05,
      "loss": 1.2948,
      "step": 150000
    },
    {
      "epoch": 0.37625,
      "grad_norm": 2.2461652755737305,
      "learning_rate": 7.338235294117647e-05,
      "loss": 1.3046,
      "step": 150500
    },
    {
      "epoch": 0.3775,
      "grad_norm": 2.449512481689453,
      "learning_rate": 7.323529411764705e-05,
      "loss": 1.2989,
      "step": 151000
    },
    {
      "epoch": 0.37875,
      "grad_norm": 2.210604190826416,
      "learning_rate": 7.308823529411765e-05,
      "loss": 1.3011,
      "step": 151500
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.2556333541870117,
      "learning_rate": 7.294117647058823e-05,
      "loss": 1.2989,
      "step": 152000
    },
    {
      "epoch": 0.38125,
      "grad_norm": 2.2830073833465576,
      "learning_rate": 7.279411764705882e-05,
      "loss": 1.2997,
      "step": 152500
    },
    {
      "epoch": 0.3825,
      "grad_norm": 2.191676616668701,
      "learning_rate": 7.264705882352942e-05,
      "loss": 1.2841,
      "step": 153000
    },
    {
      "epoch": 0.38375,
      "grad_norm": 2.382915496826172,
      "learning_rate": 7.25e-05,
      "loss": 1.288,
      "step": 153500
    },
    {
      "epoch": 0.385,
      "grad_norm": 2.263369083404541,
      "learning_rate": 7.23529411764706e-05,
      "loss": 1.2879,
      "step": 154000
    },
    {
      "epoch": 0.38625,
      "grad_norm": 2.5618536472320557,
      "learning_rate": 7.220588235294118e-05,
      "loss": 1.2881,
      "step": 154500
    },
    {
      "epoch": 0.3875,
      "grad_norm": 2.3712716102600098,
      "learning_rate": 7.205882352941177e-05,
      "loss": 1.2895,
      "step": 155000
    },
    {
      "epoch": 0.38875,
      "grad_norm": 2.5053884983062744,
      "learning_rate": 7.191176470588235e-05,
      "loss": 1.2827,
      "step": 155500
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.418099880218506,
      "learning_rate": 7.176470588235295e-05,
      "loss": 1.286,
      "step": 156000
    },
    {
      "epoch": 0.39125,
      "grad_norm": 2.584590196609497,
      "learning_rate": 7.161764705882353e-05,
      "loss": 1.2806,
      "step": 156500
    },
    {
      "epoch": 0.3925,
      "grad_norm": 2.252080202102661,
      "learning_rate": 7.147058823529412e-05,
      "loss": 1.2815,
      "step": 157000
    },
    {
      "epoch": 0.39375,
      "grad_norm": 2.1735785007476807,
      "learning_rate": 7.13235294117647e-05,
      "loss": 1.281,
      "step": 157500
    },
    {
      "epoch": 0.395,
      "grad_norm": 2.37723708152771,
      "learning_rate": 7.11764705882353e-05,
      "loss": 1.2834,
      "step": 158000
    },
    {
      "epoch": 0.39625,
      "grad_norm": 2.432288408279419,
      "learning_rate": 7.102941176470588e-05,
      "loss": 1.2755,
      "step": 158500
    },
    {
      "epoch": 0.3975,
      "grad_norm": 2.4025306701660156,
      "learning_rate": 7.088235294117648e-05,
      "loss": 1.2695,
      "step": 159000
    },
    {
      "epoch": 0.39875,
      "grad_norm": 2.2100512981414795,
      "learning_rate": 7.073529411764707e-05,
      "loss": 1.2674,
      "step": 159500
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2154786586761475,
      "learning_rate": 7.058823529411765e-05,
      "loss": 1.2645,
      "step": 160000
    },
    {
      "epoch": 0.40125,
      "grad_norm": 2.203855037689209,
      "learning_rate": 7.044117647058825e-05,
      "loss": 1.2809,
      "step": 160500
    },
    {
      "epoch": 0.4025,
      "grad_norm": 2.264664888381958,
      "learning_rate": 7.029411764705882e-05,
      "loss": 1.276,
      "step": 161000
    },
    {
      "epoch": 0.40375,
      "grad_norm": 2.4014358520507812,
      "learning_rate": 7.014705882352941e-05,
      "loss": 1.2721,
      "step": 161500
    },
    {
      "epoch": 0.405,
      "grad_norm": 2.537879467010498,
      "learning_rate": 7e-05,
      "loss": 1.2731,
      "step": 162000
    },
    {
      "epoch": 0.40625,
      "grad_norm": 2.4002249240875244,
      "learning_rate": 6.985294117647059e-05,
      "loss": 1.2616,
      "step": 162500
    },
    {
      "epoch": 0.4075,
      "grad_norm": 2.6392035484313965,
      "learning_rate": 6.970588235294117e-05,
      "loss": 1.2547,
      "step": 163000
    },
    {
      "epoch": 0.40875,
      "grad_norm": 2.476381301879883,
      "learning_rate": 6.955882352941177e-05,
      "loss": 1.2506,
      "step": 163500
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.6254448890686035,
      "learning_rate": 6.941176470588236e-05,
      "loss": 1.2634,
      "step": 164000
    },
    {
      "epoch": 0.41125,
      "grad_norm": 2.3435239791870117,
      "learning_rate": 6.926470588235294e-05,
      "loss": 1.2561,
      "step": 164500
    },
    {
      "epoch": 0.4125,
      "grad_norm": 2.547390937805176,
      "learning_rate": 6.911764705882354e-05,
      "loss": 1.2597,
      "step": 165000
    },
    {
      "epoch": 0.41375,
      "grad_norm": 2.3623147010803223,
      "learning_rate": 6.897058823529412e-05,
      "loss": 1.2568,
      "step": 165500
    },
    {
      "epoch": 0.415,
      "grad_norm": 2.526686191558838,
      "learning_rate": 6.882352941176471e-05,
      "loss": 1.2552,
      "step": 166000
    },
    {
      "epoch": 0.41625,
      "grad_norm": 2.710631847381592,
      "learning_rate": 6.86764705882353e-05,
      "loss": 1.2586,
      "step": 166500
    },
    {
      "epoch": 0.4175,
      "grad_norm": 2.2156848907470703,
      "learning_rate": 6.852941176470589e-05,
      "loss": 1.2617,
      "step": 167000
    },
    {
      "epoch": 0.41875,
      "grad_norm": 2.2995924949645996,
      "learning_rate": 6.838235294117647e-05,
      "loss": 1.2454,
      "step": 167500
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.371124744415283,
      "learning_rate": 6.823529411764707e-05,
      "loss": 1.2449,
      "step": 168000
    },
    {
      "epoch": 0.42125,
      "grad_norm": 2.3514716625213623,
      "learning_rate": 6.808823529411765e-05,
      "loss": 1.242,
      "step": 168500
    },
    {
      "epoch": 0.4225,
      "grad_norm": 2.3689701557159424,
      "learning_rate": 6.794117647058824e-05,
      "loss": 1.2481,
      "step": 169000
    },
    {
      "epoch": 0.42375,
      "grad_norm": 2.5759057998657227,
      "learning_rate": 6.779411764705882e-05,
      "loss": 1.2508,
      "step": 169500
    },
    {
      "epoch": 0.425,
      "grad_norm": 2.487494468688965,
      "learning_rate": 6.764705882352942e-05,
      "loss": 1.247,
      "step": 170000
    },
    {
      "epoch": 0.42625,
      "grad_norm": 2.4003617763519287,
      "learning_rate": 6.750000000000001e-05,
      "loss": 1.2455,
      "step": 170500
    },
    {
      "epoch": 0.4275,
      "grad_norm": 2.3018627166748047,
      "learning_rate": 6.73529411764706e-05,
      "loss": 1.2366,
      "step": 171000
    },
    {
      "epoch": 0.42875,
      "grad_norm": 2.4495832920074463,
      "learning_rate": 6.720588235294119e-05,
      "loss": 1.2419,
      "step": 171500
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.4437222480773926,
      "learning_rate": 6.705882352941176e-05,
      "loss": 1.2401,
      "step": 172000
    },
    {
      "epoch": 0.43125,
      "grad_norm": 2.705007553100586,
      "learning_rate": 6.691176470588235e-05,
      "loss": 1.247,
      "step": 172500
    },
    {
      "epoch": 0.4325,
      "grad_norm": 2.4442286491394043,
      "learning_rate": 6.676470588235294e-05,
      "loss": 1.239,
      "step": 173000
    },
    {
      "epoch": 0.43375,
      "grad_norm": 2.3683998584747314,
      "learning_rate": 6.661764705882353e-05,
      "loss": 1.2341,
      "step": 173500
    },
    {
      "epoch": 0.435,
      "grad_norm": 2.6261143684387207,
      "learning_rate": 6.647058823529411e-05,
      "loss": 1.2333,
      "step": 174000
    },
    {
      "epoch": 0.43625,
      "grad_norm": 2.5061094760894775,
      "learning_rate": 6.632352941176471e-05,
      "loss": 1.2345,
      "step": 174500
    },
    {
      "epoch": 0.4375,
      "grad_norm": 2.5903124809265137,
      "learning_rate": 6.61764705882353e-05,
      "loss": 1.2329,
      "step": 175000
    },
    {
      "epoch": 0.43875,
      "grad_norm": 2.3735239505767822,
      "learning_rate": 6.602941176470588e-05,
      "loss": 1.231,
      "step": 175500
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3800880908966064,
      "learning_rate": 6.588235294117648e-05,
      "loss": 1.2356,
      "step": 176000
    },
    {
      "epoch": 0.44125,
      "grad_norm": 2.502641439437866,
      "learning_rate": 6.573529411764706e-05,
      "loss": 1.2329,
      "step": 176500
    },
    {
      "epoch": 0.4425,
      "grad_norm": 2.3010106086730957,
      "learning_rate": 6.558823529411765e-05,
      "loss": 1.2279,
      "step": 177000
    },
    {
      "epoch": 0.44375,
      "grad_norm": 2.3097739219665527,
      "learning_rate": 6.544117647058824e-05,
      "loss": 1.2268,
      "step": 177500
    },
    {
      "epoch": 0.445,
      "grad_norm": 2.3293702602386475,
      "learning_rate": 6.529411764705883e-05,
      "loss": 1.2241,
      "step": 178000
    },
    {
      "epoch": 0.44625,
      "grad_norm": 2.526203155517578,
      "learning_rate": 6.514705882352941e-05,
      "loss": 1.2225,
      "step": 178500
    },
    {
      "epoch": 0.4475,
      "grad_norm": 2.3001139163970947,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.2275,
      "step": 179000
    },
    {
      "epoch": 0.44875,
      "grad_norm": 2.5065267086029053,
      "learning_rate": 6.485294117647059e-05,
      "loss": 1.2242,
      "step": 179500
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.6434381008148193,
      "learning_rate": 6.470588235294118e-05,
      "loss": 1.2326,
      "step": 180000
    },
    {
      "epoch": 0.45125,
      "grad_norm": 2.3355553150177,
      "learning_rate": 6.455882352941177e-05,
      "loss": 1.224,
      "step": 180500
    },
    {
      "epoch": 0.4525,
      "grad_norm": 2.298152446746826,
      "learning_rate": 6.441176470588236e-05,
      "loss": 1.2242,
      "step": 181000
    },
    {
      "epoch": 0.45375,
      "grad_norm": 2.383094549179077,
      "learning_rate": 6.426470588235294e-05,
      "loss": 1.2211,
      "step": 181500
    },
    {
      "epoch": 0.455,
      "grad_norm": 2.4184646606445312,
      "learning_rate": 6.411764705882354e-05,
      "loss": 1.2254,
      "step": 182000
    },
    {
      "epoch": 0.45625,
      "grad_norm": 2.32745099067688,
      "learning_rate": 6.397058823529412e-05,
      "loss": 1.2166,
      "step": 182500
    },
    {
      "epoch": 0.4575,
      "grad_norm": 2.562584400177002,
      "learning_rate": 6.38235294117647e-05,
      "loss": 1.2077,
      "step": 183000
    },
    {
      "epoch": 0.45875,
      "grad_norm": 2.391141176223755,
      "learning_rate": 6.36764705882353e-05,
      "loss": 1.2131,
      "step": 183500
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.4422452449798584,
      "learning_rate": 6.352941176470588e-05,
      "loss": 1.2092,
      "step": 184000
    },
    {
      "epoch": 0.46125,
      "grad_norm": 2.477567672729492,
      "learning_rate": 6.338235294117647e-05,
      "loss": 1.2079,
      "step": 184500
    },
    {
      "epoch": 0.4625,
      "grad_norm": 2.454660177230835,
      "learning_rate": 6.323529411764705e-05,
      "loss": 1.2026,
      "step": 185000
    },
    {
      "epoch": 0.46375,
      "grad_norm": 2.3424630165100098,
      "learning_rate": 6.308823529411765e-05,
      "loss": 1.2145,
      "step": 185500
    },
    {
      "epoch": 0.465,
      "grad_norm": 2.447232961654663,
      "learning_rate": 6.294117647058824e-05,
      "loss": 1.2055,
      "step": 186000
    },
    {
      "epoch": 0.46625,
      "grad_norm": 2.638826847076416,
      "learning_rate": 6.279411764705882e-05,
      "loss": 1.21,
      "step": 186500
    },
    {
      "epoch": 0.4675,
      "grad_norm": 2.757253408432007,
      "learning_rate": 6.264705882352942e-05,
      "loss": 1.2077,
      "step": 187000
    },
    {
      "epoch": 0.46875,
      "grad_norm": 2.596118450164795,
      "learning_rate": 6.25e-05,
      "loss": 1.2032,
      "step": 187500
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.527400016784668,
      "learning_rate": 6.23529411764706e-05,
      "loss": 1.2056,
      "step": 188000
    },
    {
      "epoch": 0.47125,
      "grad_norm": 2.297567844390869,
      "learning_rate": 6.220588235294118e-05,
      "loss": 1.2029,
      "step": 188500
    },
    {
      "epoch": 0.4725,
      "grad_norm": 2.1715664863586426,
      "learning_rate": 6.205882352941177e-05,
      "loss": 1.2033,
      "step": 189000
    },
    {
      "epoch": 0.47375,
      "grad_norm": 2.577035427093506,
      "learning_rate": 6.191176470588235e-05,
      "loss": 1.2063,
      "step": 189500
    },
    {
      "epoch": 0.475,
      "grad_norm": 2.838693618774414,
      "learning_rate": 6.176470588235295e-05,
      "loss": 1.1997,
      "step": 190000
    },
    {
      "epoch": 0.47625,
      "grad_norm": 2.408811569213867,
      "learning_rate": 6.161764705882353e-05,
      "loss": 1.1912,
      "step": 190500
    },
    {
      "epoch": 0.4775,
      "grad_norm": 2.5274436473846436,
      "learning_rate": 6.147058823529413e-05,
      "loss": 1.1955,
      "step": 191000
    },
    {
      "epoch": 0.47875,
      "grad_norm": 2.4410622119903564,
      "learning_rate": 6.132352941176471e-05,
      "loss": 1.1902,
      "step": 191500
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.4901912212371826,
      "learning_rate": 6.11764705882353e-05,
      "loss": 1.1948,
      "step": 192000
    },
    {
      "epoch": 0.48125,
      "grad_norm": 2.276115655899048,
      "learning_rate": 6.102941176470589e-05,
      "loss": 1.1888,
      "step": 192500
    },
    {
      "epoch": 0.4825,
      "grad_norm": 2.478522539138794,
      "learning_rate": 6.0882352941176465e-05,
      "loss": 1.197,
      "step": 193000
    },
    {
      "epoch": 0.48375,
      "grad_norm": 2.580656051635742,
      "learning_rate": 6.073529411764706e-05,
      "loss": 1.1902,
      "step": 193500
    },
    {
      "epoch": 0.485,
      "grad_norm": 2.2363038063049316,
      "learning_rate": 6.058823529411765e-05,
      "loss": 1.1907,
      "step": 194000
    },
    {
      "epoch": 0.48625,
      "grad_norm": 2.4618072509765625,
      "learning_rate": 6.044117647058824e-05,
      "loss": 1.1838,
      "step": 194500
    },
    {
      "epoch": 0.4875,
      "grad_norm": 2.9996697902679443,
      "learning_rate": 6.0294117647058825e-05,
      "loss": 1.1771,
      "step": 195000
    },
    {
      "epoch": 0.48875,
      "grad_norm": 2.662705898284912,
      "learning_rate": 6.014705882352941e-05,
      "loss": 1.1876,
      "step": 195500
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.650442361831665,
      "learning_rate": 6e-05,
      "loss": 1.1901,
      "step": 196000
    },
    {
      "epoch": 0.49125,
      "grad_norm": 2.613839864730835,
      "learning_rate": 5.985294117647059e-05,
      "loss": 1.1856,
      "step": 196500
    },
    {
      "epoch": 0.4925,
      "grad_norm": 2.494935989379883,
      "learning_rate": 5.970588235294118e-05,
      "loss": 1.1897,
      "step": 197000
    },
    {
      "epoch": 0.49375,
      "grad_norm": 2.7307724952697754,
      "learning_rate": 5.9558823529411766e-05,
      "loss": 1.1788,
      "step": 197500
    },
    {
      "epoch": 0.495,
      "grad_norm": 2.392272710800171,
      "learning_rate": 5.9411764705882355e-05,
      "loss": 1.1831,
      "step": 198000
    },
    {
      "epoch": 0.49625,
      "grad_norm": 2.3738341331481934,
      "learning_rate": 5.926470588235294e-05,
      "loss": 1.1926,
      "step": 198500
    },
    {
      "epoch": 0.4975,
      "grad_norm": 2.560666799545288,
      "learning_rate": 5.911764705882353e-05,
      "loss": 1.1808,
      "step": 199000
    },
    {
      "epoch": 0.49875,
      "grad_norm": 2.2938504219055176,
      "learning_rate": 5.897058823529412e-05,
      "loss": 1.1756,
      "step": 199500
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.3969051837921143,
      "learning_rate": 5.882352941176471e-05,
      "loss": 1.1787,
      "step": 200000
    },
    {
      "epoch": 0.50125,
      "grad_norm": 2.494455575942993,
      "learning_rate": 5.86764705882353e-05,
      "loss": 1.1738,
      "step": 200500
    },
    {
      "epoch": 0.5025,
      "grad_norm": 2.4024252891540527,
      "learning_rate": 5.852941176470589e-05,
      "loss": 1.1823,
      "step": 201000
    },
    {
      "epoch": 0.50375,
      "grad_norm": 2.5413730144500732,
      "learning_rate": 5.838235294117648e-05,
      "loss": 1.1783,
      "step": 201500
    },
    {
      "epoch": 0.505,
      "grad_norm": 2.304356336593628,
      "learning_rate": 5.823529411764707e-05,
      "loss": 1.1771,
      "step": 202000
    },
    {
      "epoch": 0.50625,
      "grad_norm": 2.6115269660949707,
      "learning_rate": 5.8088235294117656e-05,
      "loss": 1.1794,
      "step": 202500
    },
    {
      "epoch": 0.5075,
      "grad_norm": 2.475510835647583,
      "learning_rate": 5.7941176470588244e-05,
      "loss": 1.1722,
      "step": 203000
    },
    {
      "epoch": 0.50875,
      "grad_norm": 2.687138795852661,
      "learning_rate": 5.779411764705882e-05,
      "loss": 1.1744,
      "step": 203500
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.6553337574005127,
      "learning_rate": 5.764705882352941e-05,
      "loss": 1.1667,
      "step": 204000
    },
    {
      "epoch": 0.51125,
      "grad_norm": 2.412468910217285,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 1.1724,
      "step": 204500
    },
    {
      "epoch": 0.5125,
      "grad_norm": 2.48706316947937,
      "learning_rate": 5.735294117647059e-05,
      "loss": 1.1643,
      "step": 205000
    },
    {
      "epoch": 0.51375,
      "grad_norm": 2.4404425621032715,
      "learning_rate": 5.720588235294118e-05,
      "loss": 1.1714,
      "step": 205500
    },
    {
      "epoch": 0.515,
      "grad_norm": 2.516812562942505,
      "learning_rate": 5.7058823529411766e-05,
      "loss": 1.1679,
      "step": 206000
    },
    {
      "epoch": 0.51625,
      "grad_norm": 2.587414264678955,
      "learning_rate": 5.6911764705882355e-05,
      "loss": 1.1672,
      "step": 206500
    },
    {
      "epoch": 0.5175,
      "grad_norm": 2.4593842029571533,
      "learning_rate": 5.676470588235294e-05,
      "loss": 1.1613,
      "step": 207000
    },
    {
      "epoch": 0.51875,
      "grad_norm": 2.5913445949554443,
      "learning_rate": 5.661764705882353e-05,
      "loss": 1.1589,
      "step": 207500
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.288665771484375,
      "learning_rate": 5.647058823529412e-05,
      "loss": 1.1634,
      "step": 208000
    },
    {
      "epoch": 0.52125,
      "grad_norm": 2.6833064556121826,
      "learning_rate": 5.632352941176471e-05,
      "loss": 1.1592,
      "step": 208500
    },
    {
      "epoch": 0.5225,
      "grad_norm": 2.5224902629852295,
      "learning_rate": 5.6176470588235296e-05,
      "loss": 1.1626,
      "step": 209000
    },
    {
      "epoch": 0.52375,
      "grad_norm": 2.455576181411743,
      "learning_rate": 5.6029411764705884e-05,
      "loss": 1.1655,
      "step": 209500
    },
    {
      "epoch": 0.525,
      "grad_norm": 2.4824559688568115,
      "learning_rate": 5.588235294117647e-05,
      "loss": 1.1498,
      "step": 210000
    },
    {
      "epoch": 0.52625,
      "grad_norm": 2.4436275959014893,
      "learning_rate": 5.573529411764706e-05,
      "loss": 1.1562,
      "step": 210500
    },
    {
      "epoch": 0.5275,
      "grad_norm": 2.528538227081299,
      "learning_rate": 5.558823529411765e-05,
      "loss": 1.1581,
      "step": 211000
    },
    {
      "epoch": 0.52875,
      "grad_norm": 2.3996434211730957,
      "learning_rate": 5.5441176470588244e-05,
      "loss": 1.1576,
      "step": 211500
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.6720902919769287,
      "learning_rate": 5.529411764705883e-05,
      "loss": 1.1519,
      "step": 212000
    },
    {
      "epoch": 0.53125,
      "grad_norm": 2.3601903915405273,
      "learning_rate": 5.514705882352942e-05,
      "loss": 1.1536,
      "step": 212500
    },
    {
      "epoch": 0.5325,
      "grad_norm": 2.6915717124938965,
      "learning_rate": 5.500000000000001e-05,
      "loss": 1.1597,
      "step": 213000
    },
    {
      "epoch": 0.53375,
      "grad_norm": 2.4880948066711426,
      "learning_rate": 5.48529411764706e-05,
      "loss": 1.1477,
      "step": 213500
    },
    {
      "epoch": 0.535,
      "grad_norm": 2.551832437515259,
      "learning_rate": 5.4705882352941185e-05,
      "loss": 1.1536,
      "step": 214000
    },
    {
      "epoch": 0.53625,
      "grad_norm": 2.5373525619506836,
      "learning_rate": 5.455882352941176e-05,
      "loss": 1.152,
      "step": 214500
    },
    {
      "epoch": 0.5375,
      "grad_norm": 2.497643232345581,
      "learning_rate": 5.441176470588235e-05,
      "loss": 1.1482,
      "step": 215000
    },
    {
      "epoch": 0.53875,
      "grad_norm": 2.327524185180664,
      "learning_rate": 5.4264705882352936e-05,
      "loss": 1.1559,
      "step": 215500
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.743957757949829,
      "learning_rate": 5.411764705882353e-05,
      "loss": 1.1507,
      "step": 216000
    },
    {
      "epoch": 0.54125,
      "grad_norm": 2.3673720359802246,
      "learning_rate": 5.397058823529412e-05,
      "loss": 1.1451,
      "step": 216500
    },
    {
      "epoch": 0.5425,
      "grad_norm": 2.943145513534546,
      "learning_rate": 5.382352941176471e-05,
      "loss": 1.1424,
      "step": 217000
    },
    {
      "epoch": 0.54375,
      "grad_norm": 2.494499921798706,
      "learning_rate": 5.3676470588235296e-05,
      "loss": 1.1461,
      "step": 217500
    },
    {
      "epoch": 0.545,
      "grad_norm": 2.498103618621826,
      "learning_rate": 5.3529411764705884e-05,
      "loss": 1.1478,
      "step": 218000
    },
    {
      "epoch": 0.54625,
      "grad_norm": 2.563406229019165,
      "learning_rate": 5.338235294117647e-05,
      "loss": 1.1504,
      "step": 218500
    },
    {
      "epoch": 0.5475,
      "grad_norm": 2.7017951011657715,
      "learning_rate": 5.323529411764706e-05,
      "loss": 1.1458,
      "step": 219000
    },
    {
      "epoch": 0.54875,
      "grad_norm": 2.7403852939605713,
      "learning_rate": 5.308823529411765e-05,
      "loss": 1.1474,
      "step": 219500
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.8220419883728027,
      "learning_rate": 5.294117647058824e-05,
      "loss": 1.142,
      "step": 220000
    },
    {
      "epoch": 0.55125,
      "grad_norm": 2.4828763008117676,
      "learning_rate": 5.2794117647058826e-05,
      "loss": 1.1459,
      "step": 220500
    },
    {
      "epoch": 0.5525,
      "grad_norm": 2.415154218673706,
      "learning_rate": 5.2647058823529414e-05,
      "loss": 1.1362,
      "step": 221000
    },
    {
      "epoch": 0.55375,
      "grad_norm": 2.4206387996673584,
      "learning_rate": 5.25e-05,
      "loss": 1.1391,
      "step": 221500
    },
    {
      "epoch": 0.555,
      "grad_norm": 2.481785297393799,
      "learning_rate": 5.235294117647059e-05,
      "loss": 1.1377,
      "step": 222000
    },
    {
      "epoch": 0.55625,
      "grad_norm": 2.360701322555542,
      "learning_rate": 5.2205882352941185e-05,
      "loss": 1.1419,
      "step": 222500
    },
    {
      "epoch": 0.5575,
      "grad_norm": 2.568507432937622,
      "learning_rate": 5.2058823529411774e-05,
      "loss": 1.1367,
      "step": 223000
    },
    {
      "epoch": 0.55875,
      "grad_norm": 2.5451760292053223,
      "learning_rate": 5.191176470588236e-05,
      "loss": 1.1344,
      "step": 223500
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.4477531909942627,
      "learning_rate": 5.176470588235295e-05,
      "loss": 1.1316,
      "step": 224000
    },
    {
      "epoch": 0.56125,
      "grad_norm": 2.4316399097442627,
      "learning_rate": 5.161764705882354e-05,
      "loss": 1.1339,
      "step": 224500
    },
    {
      "epoch": 0.5625,
      "grad_norm": 2.7117879390716553,
      "learning_rate": 5.147058823529411e-05,
      "loss": 1.1342,
      "step": 225000
    },
    {
      "epoch": 0.56375,
      "grad_norm": 2.587298631668091,
      "learning_rate": 5.13235294117647e-05,
      "loss": 1.1302,
      "step": 225500
    },
    {
      "epoch": 0.565,
      "grad_norm": 2.7208480834960938,
      "learning_rate": 5.117647058823529e-05,
      "loss": 1.1339,
      "step": 226000
    },
    {
      "epoch": 0.56625,
      "grad_norm": 2.2944743633270264,
      "learning_rate": 5.102941176470588e-05,
      "loss": 1.1271,
      "step": 226500
    },
    {
      "epoch": 0.5675,
      "grad_norm": 2.6220908164978027,
      "learning_rate": 5.088235294117647e-05,
      "loss": 1.1246,
      "step": 227000
    },
    {
      "epoch": 0.56875,
      "grad_norm": 2.61667537689209,
      "learning_rate": 5.073529411764706e-05,
      "loss": 1.1287,
      "step": 227500
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.3278980255126953,
      "learning_rate": 5.058823529411765e-05,
      "loss": 1.1273,
      "step": 228000
    },
    {
      "epoch": 0.57125,
      "grad_norm": 2.603015184402466,
      "learning_rate": 5.044117647058824e-05,
      "loss": 1.1264,
      "step": 228500
    },
    {
      "epoch": 0.5725,
      "grad_norm": 2.5613722801208496,
      "learning_rate": 5.0294117647058826e-05,
      "loss": 1.1252,
      "step": 229000
    },
    {
      "epoch": 0.57375,
      "grad_norm": 2.6727373600006104,
      "learning_rate": 5.0147058823529414e-05,
      "loss": 1.132,
      "step": 229500
    },
    {
      "epoch": 0.575,
      "grad_norm": 2.596782922744751,
      "learning_rate": 5e-05,
      "loss": 1.1304,
      "step": 230000
    },
    {
      "epoch": 0.57625,
      "grad_norm": 2.3166377544403076,
      "learning_rate": 4.985294117647059e-05,
      "loss": 1.1248,
      "step": 230500
    },
    {
      "epoch": 0.5775,
      "grad_norm": 2.8563783168792725,
      "learning_rate": 4.970588235294118e-05,
      "loss": 1.1151,
      "step": 231000
    },
    {
      "epoch": 0.57875,
      "grad_norm": 2.79630184173584,
      "learning_rate": 4.955882352941177e-05,
      "loss": 1.1186,
      "step": 231500
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.392573356628418,
      "learning_rate": 4.9411764705882355e-05,
      "loss": 1.1203,
      "step": 232000
    },
    {
      "epoch": 0.58125,
      "grad_norm": 2.5912342071533203,
      "learning_rate": 4.9264705882352944e-05,
      "loss": 1.1202,
      "step": 232500
    },
    {
      "epoch": 0.5825,
      "grad_norm": 2.4824278354644775,
      "learning_rate": 4.911764705882353e-05,
      "loss": 1.1151,
      "step": 233000
    },
    {
      "epoch": 0.58375,
      "grad_norm": 2.457792282104492,
      "learning_rate": 4.897058823529412e-05,
      "loss": 1.1229,
      "step": 233500
    },
    {
      "epoch": 0.585,
      "grad_norm": 2.5589985847473145,
      "learning_rate": 4.882352941176471e-05,
      "loss": 1.1218,
      "step": 234000
    },
    {
      "epoch": 0.58625,
      "grad_norm": 2.5349178314208984,
      "learning_rate": 4.86764705882353e-05,
      "loss": 1.112,
      "step": 234500
    },
    {
      "epoch": 0.5875,
      "grad_norm": 2.5233044624328613,
      "learning_rate": 4.8529411764705885e-05,
      "loss": 1.1212,
      "step": 235000
    },
    {
      "epoch": 0.58875,
      "grad_norm": 2.62233829498291,
      "learning_rate": 4.838235294117647e-05,
      "loss": 1.1167,
      "step": 235500
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.738234519958496,
      "learning_rate": 4.823529411764706e-05,
      "loss": 1.1139,
      "step": 236000
    },
    {
      "epoch": 0.59125,
      "grad_norm": 2.6387786865234375,
      "learning_rate": 4.808823529411765e-05,
      "loss": 1.1147,
      "step": 236500
    },
    {
      "epoch": 0.5925,
      "grad_norm": 2.6359457969665527,
      "learning_rate": 4.794117647058824e-05,
      "loss": 1.1178,
      "step": 237000
    },
    {
      "epoch": 0.59375,
      "grad_norm": 2.577141761779785,
      "learning_rate": 4.7794117647058826e-05,
      "loss": 1.1189,
      "step": 237500
    },
    {
      "epoch": 0.595,
      "grad_norm": 2.5956122875213623,
      "learning_rate": 4.7647058823529414e-05,
      "loss": 1.1099,
      "step": 238000
    },
    {
      "epoch": 0.59625,
      "grad_norm": 2.395097494125366,
      "learning_rate": 4.75e-05,
      "loss": 1.1162,
      "step": 238500
    },
    {
      "epoch": 0.5975,
      "grad_norm": 2.6729071140289307,
      "learning_rate": 4.735294117647059e-05,
      "loss": 1.1006,
      "step": 239000
    },
    {
      "epoch": 0.59875,
      "grad_norm": 2.572138547897339,
      "learning_rate": 4.720588235294118e-05,
      "loss": 1.1057,
      "step": 239500
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.612157106399536,
      "learning_rate": 4.705882352941177e-05,
      "loss": 1.1107,
      "step": 240000
    },
    {
      "epoch": 0.60125,
      "grad_norm": 2.5691709518432617,
      "learning_rate": 4.6911764705882356e-05,
      "loss": 1.1076,
      "step": 240500
    },
    {
      "epoch": 0.6025,
      "grad_norm": 2.534736394882202,
      "learning_rate": 4.6764705882352944e-05,
      "loss": 1.1061,
      "step": 241000
    },
    {
      "epoch": 0.60375,
      "grad_norm": 2.5131285190582275,
      "learning_rate": 4.661764705882353e-05,
      "loss": 1.1035,
      "step": 241500
    },
    {
      "epoch": 0.605,
      "grad_norm": 2.8205342292785645,
      "learning_rate": 4.647058823529412e-05,
      "loss": 1.1043,
      "step": 242000
    },
    {
      "epoch": 0.60625,
      "grad_norm": 2.452885866165161,
      "learning_rate": 4.632352941176471e-05,
      "loss": 1.1069,
      "step": 242500
    },
    {
      "epoch": 0.6075,
      "grad_norm": 2.476759672164917,
      "learning_rate": 4.61764705882353e-05,
      "loss": 1.1027,
      "step": 243000
    },
    {
      "epoch": 0.60875,
      "grad_norm": 2.955815076828003,
      "learning_rate": 4.6029411764705885e-05,
      "loss": 1.1025,
      "step": 243500
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.9270498752593994,
      "learning_rate": 4.588235294117647e-05,
      "loss": 1.1055,
      "step": 244000
    },
    {
      "epoch": 0.61125,
      "grad_norm": 2.794257164001465,
      "learning_rate": 4.573529411764706e-05,
      "loss": 1.1006,
      "step": 244500
    },
    {
      "epoch": 0.6125,
      "grad_norm": 2.5204029083251953,
      "learning_rate": 4.558823529411765e-05,
      "loss": 1.0988,
      "step": 245000
    },
    {
      "epoch": 0.61375,
      "grad_norm": 2.4985482692718506,
      "learning_rate": 4.544117647058824e-05,
      "loss": 1.1027,
      "step": 245500
    },
    {
      "epoch": 0.615,
      "grad_norm": 2.5125551223754883,
      "learning_rate": 4.5294117647058826e-05,
      "loss": 1.1001,
      "step": 246000
    },
    {
      "epoch": 0.61625,
      "grad_norm": 2.5887086391448975,
      "learning_rate": 4.5147058823529415e-05,
      "loss": 1.1031,
      "step": 246500
    },
    {
      "epoch": 0.6175,
      "grad_norm": 2.605804204940796,
      "learning_rate": 4.5e-05,
      "loss": 1.0954,
      "step": 247000
    },
    {
      "epoch": 0.61875,
      "grad_norm": 2.5250449180603027,
      "learning_rate": 4.485294117647059e-05,
      "loss": 1.0979,
      "step": 247500
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.3237292766571045,
      "learning_rate": 4.470588235294118e-05,
      "loss": 1.0942,
      "step": 248000
    },
    {
      "epoch": 0.62125,
      "grad_norm": 2.521552085876465,
      "learning_rate": 4.455882352941177e-05,
      "loss": 1.0952,
      "step": 248500
    },
    {
      "epoch": 0.6225,
      "grad_norm": 2.65012526512146,
      "learning_rate": 4.4411764705882356e-05,
      "loss": 1.0872,
      "step": 249000
    },
    {
      "epoch": 0.62375,
      "grad_norm": 2.6492221355438232,
      "learning_rate": 4.4264705882352944e-05,
      "loss": 1.0948,
      "step": 249500
    },
    {
      "epoch": 0.625,
      "grad_norm": 2.481151580810547,
      "learning_rate": 4.411764705882353e-05,
      "loss": 1.0968,
      "step": 250000
    },
    {
      "epoch": 0.62625,
      "grad_norm": 2.3635401725769043,
      "learning_rate": 4.397058823529412e-05,
      "loss": 1.0917,
      "step": 250500
    },
    {
      "epoch": 0.6275,
      "grad_norm": 2.5509214401245117,
      "learning_rate": 4.382352941176471e-05,
      "loss": 1.0899,
      "step": 251000
    },
    {
      "epoch": 0.62875,
      "grad_norm": 2.5183722972869873,
      "learning_rate": 4.36764705882353e-05,
      "loss": 1.0958,
      "step": 251500
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.871598482131958,
      "learning_rate": 4.3529411764705885e-05,
      "loss": 1.0946,
      "step": 252000
    },
    {
      "epoch": 0.63125,
      "grad_norm": 2.49452543258667,
      "learning_rate": 4.3382352941176474e-05,
      "loss": 1.094,
      "step": 252500
    },
    {
      "epoch": 0.6325,
      "grad_norm": 2.4102635383605957,
      "learning_rate": 4.323529411764706e-05,
      "loss": 1.0857,
      "step": 253000
    },
    {
      "epoch": 0.63375,
      "grad_norm": 2.4867613315582275,
      "learning_rate": 4.308823529411765e-05,
      "loss": 1.0931,
      "step": 253500
    },
    {
      "epoch": 0.635,
      "grad_norm": 2.632295846939087,
      "learning_rate": 4.294117647058823e-05,
      "loss": 1.0894,
      "step": 254000
    },
    {
      "epoch": 0.63625,
      "grad_norm": 2.374581813812256,
      "learning_rate": 4.2794117647058827e-05,
      "loss": 1.0907,
      "step": 254500
    },
    {
      "epoch": 0.6375,
      "grad_norm": 2.6477749347686768,
      "learning_rate": 4.2647058823529415e-05,
      "loss": 1.0866,
      "step": 255000
    },
    {
      "epoch": 0.63875,
      "grad_norm": 2.565864324569702,
      "learning_rate": 4.25e-05,
      "loss": 1.084,
      "step": 255500
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.5048460960388184,
      "learning_rate": 4.235294117647059e-05,
      "loss": 1.0836,
      "step": 256000
    },
    {
      "epoch": 0.64125,
      "grad_norm": 2.4995381832122803,
      "learning_rate": 4.220588235294118e-05,
      "loss": 1.0818,
      "step": 256500
    },
    {
      "epoch": 0.6425,
      "grad_norm": 2.65207839012146,
      "learning_rate": 4.205882352941177e-05,
      "loss": 1.09,
      "step": 257000
    },
    {
      "epoch": 0.64375,
      "grad_norm": 2.6430552005767822,
      "learning_rate": 4.1911764705882356e-05,
      "loss": 1.0842,
      "step": 257500
    },
    {
      "epoch": 0.645,
      "grad_norm": 2.640596389770508,
      "learning_rate": 4.1764705882352944e-05,
      "loss": 1.0814,
      "step": 258000
    },
    {
      "epoch": 0.64625,
      "grad_norm": 2.440311908721924,
      "learning_rate": 4.161764705882353e-05,
      "loss": 1.0783,
      "step": 258500
    },
    {
      "epoch": 0.6475,
      "grad_norm": 2.4819464683532715,
      "learning_rate": 4.147058823529412e-05,
      "loss": 1.0815,
      "step": 259000
    },
    {
      "epoch": 0.64875,
      "grad_norm": 2.6636641025543213,
      "learning_rate": 4.13235294117647e-05,
      "loss": 1.0776,
      "step": 259500
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.5795629024505615,
      "learning_rate": 4.11764705882353e-05,
      "loss": 1.0849,
      "step": 260000
    },
    {
      "epoch": 0.65125,
      "grad_norm": 2.516101360321045,
      "learning_rate": 4.1029411764705886e-05,
      "loss": 1.0838,
      "step": 260500
    },
    {
      "epoch": 0.6525,
      "grad_norm": 2.538804531097412,
      "learning_rate": 4.0882352941176474e-05,
      "loss": 1.0847,
      "step": 261000
    },
    {
      "epoch": 0.65375,
      "grad_norm": 2.3689796924591064,
      "learning_rate": 4.073529411764706e-05,
      "loss": 1.0813,
      "step": 261500
    },
    {
      "epoch": 0.655,
      "grad_norm": 2.7157042026519775,
      "learning_rate": 4.058823529411765e-05,
      "loss": 1.0774,
      "step": 262000
    },
    {
      "epoch": 0.65625,
      "grad_norm": 2.519381523132324,
      "learning_rate": 4.044117647058824e-05,
      "loss": 1.0749,
      "step": 262500
    },
    {
      "epoch": 0.6575,
      "grad_norm": 2.8122472763061523,
      "learning_rate": 4.029411764705883e-05,
      "loss": 1.0798,
      "step": 263000
    },
    {
      "epoch": 0.65875,
      "grad_norm": 2.6348166465759277,
      "learning_rate": 4.0147058823529415e-05,
      "loss": 1.0774,
      "step": 263500
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.853752374649048,
      "learning_rate": 4e-05,
      "loss": 1.0735,
      "step": 264000
    },
    {
      "epoch": 0.66125,
      "grad_norm": 2.630239725112915,
      "learning_rate": 3.985294117647059e-05,
      "loss": 1.0827,
      "step": 264500
    },
    {
      "epoch": 0.6625,
      "grad_norm": 2.4465134143829346,
      "learning_rate": 3.970588235294117e-05,
      "loss": 1.0782,
      "step": 265000
    },
    {
      "epoch": 0.66375,
      "grad_norm": 2.6083240509033203,
      "learning_rate": 3.955882352941177e-05,
      "loss": 1.0731,
      "step": 265500
    },
    {
      "epoch": 0.665,
      "grad_norm": 2.3370916843414307,
      "learning_rate": 3.9411764705882356e-05,
      "loss": 1.0693,
      "step": 266000
    },
    {
      "epoch": 0.66625,
      "grad_norm": 2.484907627105713,
      "learning_rate": 3.9264705882352945e-05,
      "loss": 1.0791,
      "step": 266500
    },
    {
      "epoch": 0.6675,
      "grad_norm": 2.6024162769317627,
      "learning_rate": 3.911764705882353e-05,
      "loss": 1.0807,
      "step": 267000
    },
    {
      "epoch": 0.66875,
      "grad_norm": 2.5944442749023438,
      "learning_rate": 3.897058823529412e-05,
      "loss": 1.0673,
      "step": 267500
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.6577041149139404,
      "learning_rate": 3.882352941176471e-05,
      "loss": 1.0744,
      "step": 268000
    },
    {
      "epoch": 0.67125,
      "grad_norm": 2.7445476055145264,
      "learning_rate": 3.86764705882353e-05,
      "loss": 1.0694,
      "step": 268500
    },
    {
      "epoch": 0.6725,
      "grad_norm": 2.6325106620788574,
      "learning_rate": 3.8529411764705886e-05,
      "loss": 1.0687,
      "step": 269000
    },
    {
      "epoch": 0.67375,
      "grad_norm": 2.9431755542755127,
      "learning_rate": 3.8382352941176474e-05,
      "loss": 1.0731,
      "step": 269500
    },
    {
      "epoch": 0.675,
      "grad_norm": 2.5025148391723633,
      "learning_rate": 3.8235294117647055e-05,
      "loss": 1.0735,
      "step": 270000
    },
    {
      "epoch": 0.67625,
      "grad_norm": 2.6670727729797363,
      "learning_rate": 3.8088235294117644e-05,
      "loss": 1.0654,
      "step": 270500
    },
    {
      "epoch": 0.6775,
      "grad_norm": 2.6931042671203613,
      "learning_rate": 3.794117647058824e-05,
      "loss": 1.0737,
      "step": 271000
    },
    {
      "epoch": 0.67875,
      "grad_norm": 2.7536087036132812,
      "learning_rate": 3.779411764705883e-05,
      "loss": 1.0743,
      "step": 271500
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.418431282043457,
      "learning_rate": 3.7647058823529415e-05,
      "loss": 1.0634,
      "step": 272000
    },
    {
      "epoch": 0.68125,
      "grad_norm": 2.5493288040161133,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 1.0655,
      "step": 272500
    },
    {
      "epoch": 0.6825,
      "grad_norm": 2.758572816848755,
      "learning_rate": 3.735294117647059e-05,
      "loss": 1.0652,
      "step": 273000
    },
    {
      "epoch": 0.68375,
      "grad_norm": 2.729078769683838,
      "learning_rate": 3.720588235294118e-05,
      "loss": 1.0679,
      "step": 273500
    },
    {
      "epoch": 0.685,
      "grad_norm": 2.5662195682525635,
      "learning_rate": 3.705882352941177e-05,
      "loss": 1.0659,
      "step": 274000
    },
    {
      "epoch": 0.68625,
      "grad_norm": 2.5718321800231934,
      "learning_rate": 3.6911764705882356e-05,
      "loss": 1.0638,
      "step": 274500
    },
    {
      "epoch": 0.6875,
      "grad_norm": 2.7004499435424805,
      "learning_rate": 3.6764705882352945e-05,
      "loss": 1.0654,
      "step": 275000
    },
    {
      "epoch": 0.68875,
      "grad_norm": 3.051971673965454,
      "learning_rate": 3.6617647058823526e-05,
      "loss": 1.0593,
      "step": 275500
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.676548480987549,
      "learning_rate": 3.6470588235294114e-05,
      "loss": 1.0592,
      "step": 276000
    },
    {
      "epoch": 0.69125,
      "grad_norm": 2.7732057571411133,
      "learning_rate": 3.632352941176471e-05,
      "loss": 1.0648,
      "step": 276500
    },
    {
      "epoch": 0.6925,
      "grad_norm": 2.8439791202545166,
      "learning_rate": 3.61764705882353e-05,
      "loss": 1.0563,
      "step": 277000
    },
    {
      "epoch": 0.69375,
      "grad_norm": 2.5426418781280518,
      "learning_rate": 3.6029411764705886e-05,
      "loss": 1.0566,
      "step": 277500
    },
    {
      "epoch": 0.695,
      "grad_norm": 2.595641851425171,
      "learning_rate": 3.5882352941176474e-05,
      "loss": 1.0612,
      "step": 278000
    },
    {
      "epoch": 0.69625,
      "grad_norm": 2.5637600421905518,
      "learning_rate": 3.573529411764706e-05,
      "loss": 1.0638,
      "step": 278500
    },
    {
      "epoch": 0.6975,
      "grad_norm": 2.8251953125,
      "learning_rate": 3.558823529411765e-05,
      "loss": 1.0643,
      "step": 279000
    },
    {
      "epoch": 0.69875,
      "grad_norm": 2.531024932861328,
      "learning_rate": 3.544117647058824e-05,
      "loss": 1.0583,
      "step": 279500
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.7871036529541016,
      "learning_rate": 3.529411764705883e-05,
      "loss": 1.0561,
      "step": 280000
    },
    {
      "epoch": 0.70125,
      "grad_norm": 2.6005635261535645,
      "learning_rate": 3.514705882352941e-05,
      "loss": 1.0553,
      "step": 280500
    },
    {
      "epoch": 0.7025,
      "grad_norm": 2.8144302368164062,
      "learning_rate": 3.5e-05,
      "loss": 1.059,
      "step": 281000
    },
    {
      "epoch": 0.70375,
      "grad_norm": 2.7708051204681396,
      "learning_rate": 3.4852941176470585e-05,
      "loss": 1.0584,
      "step": 281500
    },
    {
      "epoch": 0.705,
      "grad_norm": 2.61830735206604,
      "learning_rate": 3.470588235294118e-05,
      "loss": 1.0547,
      "step": 282000
    },
    {
      "epoch": 0.70625,
      "grad_norm": 2.4873297214508057,
      "learning_rate": 3.455882352941177e-05,
      "loss": 1.0543,
      "step": 282500
    },
    {
      "epoch": 0.7075,
      "grad_norm": 2.6350300312042236,
      "learning_rate": 3.441176470588236e-05,
      "loss": 1.0582,
      "step": 283000
    },
    {
      "epoch": 0.70875,
      "grad_norm": 2.4632725715637207,
      "learning_rate": 3.4264705882352945e-05,
      "loss": 1.0602,
      "step": 283500
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.6500465869903564,
      "learning_rate": 3.411764705882353e-05,
      "loss": 1.0543,
      "step": 284000
    },
    {
      "epoch": 0.71125,
      "grad_norm": 2.4969217777252197,
      "learning_rate": 3.397058823529412e-05,
      "loss": 1.0563,
      "step": 284500
    },
    {
      "epoch": 0.7125,
      "grad_norm": 2.614496946334839,
      "learning_rate": 3.382352941176471e-05,
      "loss": 1.044,
      "step": 285000
    },
    {
      "epoch": 0.71375,
      "grad_norm": 2.6655654907226562,
      "learning_rate": 3.36764705882353e-05,
      "loss": 1.05,
      "step": 285500
    },
    {
      "epoch": 0.715,
      "grad_norm": 2.620931386947632,
      "learning_rate": 3.352941176470588e-05,
      "loss": 1.0489,
      "step": 286000
    },
    {
      "epoch": 0.71625,
      "grad_norm": 2.8155977725982666,
      "learning_rate": 3.338235294117647e-05,
      "loss": 1.0547,
      "step": 286500
    },
    {
      "epoch": 0.7175,
      "grad_norm": 2.572967290878296,
      "learning_rate": 3.3235294117647056e-05,
      "loss": 1.0519,
      "step": 287000
    },
    {
      "epoch": 0.71875,
      "grad_norm": 2.764085531234741,
      "learning_rate": 3.308823529411765e-05,
      "loss": 1.0511,
      "step": 287500
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.8652760982513428,
      "learning_rate": 3.294117647058824e-05,
      "loss": 1.0491,
      "step": 288000
    },
    {
      "epoch": 0.72125,
      "grad_norm": 2.7121033668518066,
      "learning_rate": 3.279411764705883e-05,
      "loss": 1.0495,
      "step": 288500
    },
    {
      "epoch": 0.7225,
      "grad_norm": 2.3121631145477295,
      "learning_rate": 3.2647058823529416e-05,
      "loss": 1.0479,
      "step": 289000
    },
    {
      "epoch": 0.72375,
      "grad_norm": 3.045198917388916,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 1.0533,
      "step": 289500
    },
    {
      "epoch": 0.725,
      "grad_norm": 2.6233670711517334,
      "learning_rate": 3.235294117647059e-05,
      "loss": 1.0438,
      "step": 290000
    },
    {
      "epoch": 0.72625,
      "grad_norm": 2.587834358215332,
      "learning_rate": 3.220588235294118e-05,
      "loss": 1.046,
      "step": 290500
    },
    {
      "epoch": 0.7275,
      "grad_norm": 2.74204158782959,
      "learning_rate": 3.205882352941177e-05,
      "loss": 1.048,
      "step": 291000
    },
    {
      "epoch": 0.72875,
      "grad_norm": 2.6445424556732178,
      "learning_rate": 3.191176470588235e-05,
      "loss": 1.0443,
      "step": 291500
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.655660390853882,
      "learning_rate": 3.176470588235294e-05,
      "loss": 1.0498,
      "step": 292000
    },
    {
      "epoch": 0.73125,
      "grad_norm": 2.6894021034240723,
      "learning_rate": 3.161764705882353e-05,
      "loss": 1.044,
      "step": 292500
    },
    {
      "epoch": 0.7325,
      "grad_norm": 2.6882712841033936,
      "learning_rate": 3.147058823529412e-05,
      "loss": 1.0425,
      "step": 293000
    },
    {
      "epoch": 0.73375,
      "grad_norm": 2.385178565979004,
      "learning_rate": 3.132352941176471e-05,
      "loss": 1.0474,
      "step": 293500
    },
    {
      "epoch": 0.735,
      "grad_norm": 2.7581658363342285,
      "learning_rate": 3.11764705882353e-05,
      "loss": 1.0424,
      "step": 294000
    },
    {
      "epoch": 0.73625,
      "grad_norm": 2.595710039138794,
      "learning_rate": 3.1029411764705886e-05,
      "loss": 1.0438,
      "step": 294500
    },
    {
      "epoch": 0.7375,
      "grad_norm": 2.762242555618286,
      "learning_rate": 3.0882352941176475e-05,
      "loss": 1.0438,
      "step": 295000
    },
    {
      "epoch": 0.73875,
      "grad_norm": 2.787874698638916,
      "learning_rate": 3.073529411764706e-05,
      "loss": 1.0447,
      "step": 295500
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.6584982872009277,
      "learning_rate": 3.058823529411765e-05,
      "loss": 1.0427,
      "step": 296000
    },
    {
      "epoch": 0.74125,
      "grad_norm": 2.8827602863311768,
      "learning_rate": 3.0441176470588233e-05,
      "loss": 1.0441,
      "step": 296500
    },
    {
      "epoch": 0.7425,
      "grad_norm": 2.4264986515045166,
      "learning_rate": 3.0294117647058824e-05,
      "loss": 1.0454,
      "step": 297000
    },
    {
      "epoch": 0.74375,
      "grad_norm": 2.357619524002075,
      "learning_rate": 3.0147058823529413e-05,
      "loss": 1.0411,
      "step": 297500
    },
    {
      "epoch": 0.745,
      "grad_norm": 2.5390353202819824,
      "learning_rate": 3e-05,
      "loss": 1.0388,
      "step": 298000
    },
    {
      "epoch": 0.74625,
      "grad_norm": 2.5595881938934326,
      "learning_rate": 2.985294117647059e-05,
      "loss": 1.0449,
      "step": 298500
    },
    {
      "epoch": 0.7475,
      "grad_norm": 2.9906880855560303,
      "learning_rate": 2.9705882352941177e-05,
      "loss": 1.0433,
      "step": 299000
    },
    {
      "epoch": 0.74875,
      "grad_norm": 2.58695387840271,
      "learning_rate": 2.9558823529411766e-05,
      "loss": 1.0356,
      "step": 299500
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.51128888130188,
      "learning_rate": 2.9411764705882354e-05,
      "loss": 1.0419,
      "step": 300000
    }
  ],
  "logging_steps": 500,
  "max_steps": 400000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6036379058176e+18,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
