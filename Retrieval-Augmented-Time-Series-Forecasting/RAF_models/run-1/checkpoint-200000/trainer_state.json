{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005,
      "grad_norm": 1.3626619577407837,
      "learning_rate": 0.0009995000000000002,
      "loss": 3.5026,
      "step": 100
    },
    {
      "epoch": 0.001,
      "grad_norm": 2.206193208694458,
      "learning_rate": 0.000999,
      "loss": 2.8462,
      "step": 200
    },
    {
      "epoch": 0.0015,
      "grad_norm": 2.171489953994751,
      "learning_rate": 0.0009985,
      "loss": 2.4549,
      "step": 300
    },
    {
      "epoch": 0.002,
      "grad_norm": 2.194277048110962,
      "learning_rate": 0.000998,
      "loss": 2.2012,
      "step": 400
    },
    {
      "epoch": 0.0025,
      "grad_norm": 2.062251567840576,
      "learning_rate": 0.0009975000000000001,
      "loss": 2.0109,
      "step": 500
    },
    {
      "epoch": 0.003,
      "grad_norm": 2.422410011291504,
      "learning_rate": 0.000997,
      "loss": 1.7954,
      "step": 600
    },
    {
      "epoch": 0.0035,
      "grad_norm": 2.4502406120300293,
      "learning_rate": 0.0009965,
      "loss": 1.6644,
      "step": 700
    },
    {
      "epoch": 0.004,
      "grad_norm": 2.1582679748535156,
      "learning_rate": 0.000996,
      "loss": 1.5446,
      "step": 800
    },
    {
      "epoch": 0.0045,
      "grad_norm": 2.0989644527435303,
      "learning_rate": 0.0009955,
      "loss": 1.4673,
      "step": 900
    },
    {
      "epoch": 0.005,
      "grad_norm": 2.02192759513855,
      "learning_rate": 0.000995,
      "loss": 1.3969,
      "step": 1000
    },
    {
      "epoch": 0.0055,
      "grad_norm": 2.123414993286133,
      "learning_rate": 0.0009945000000000002,
      "loss": 1.3473,
      "step": 1100
    },
    {
      "epoch": 0.006,
      "grad_norm": 1.9165456295013428,
      "learning_rate": 0.000994,
      "loss": 1.2889,
      "step": 1200
    },
    {
      "epoch": 0.0065,
      "grad_norm": 1.7586935758590698,
      "learning_rate": 0.0009935,
      "loss": 1.2218,
      "step": 1300
    },
    {
      "epoch": 0.007,
      "grad_norm": 1.761252522468567,
      "learning_rate": 0.000993,
      "loss": 1.1876,
      "step": 1400
    },
    {
      "epoch": 0.0075,
      "grad_norm": 1.9131025075912476,
      "learning_rate": 0.0009925000000000001,
      "loss": 1.1384,
      "step": 1500
    },
    {
      "epoch": 0.008,
      "grad_norm": 1.9409284591674805,
      "learning_rate": 0.000992,
      "loss": 1.1206,
      "step": 1600
    },
    {
      "epoch": 0.0085,
      "grad_norm": 1.8026634454727173,
      "learning_rate": 0.0009915,
      "loss": 1.0733,
      "step": 1700
    },
    {
      "epoch": 0.009,
      "grad_norm": 2.267911672592163,
      "learning_rate": 0.000991,
      "loss": 1.0467,
      "step": 1800
    },
    {
      "epoch": 0.0095,
      "grad_norm": 2.074922561645508,
      "learning_rate": 0.0009905,
      "loss": 1.0136,
      "step": 1900
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0485684871673584,
      "learning_rate": 0.00099,
      "loss": 1.0026,
      "step": 2000
    },
    {
      "epoch": 0.0105,
      "grad_norm": 2.2760543823242188,
      "learning_rate": 0.0009895000000000001,
      "loss": 0.9721,
      "step": 2100
    },
    {
      "epoch": 0.011,
      "grad_norm": 1.6513290405273438,
      "learning_rate": 0.000989,
      "loss": 0.9441,
      "step": 2200
    },
    {
      "epoch": 0.0115,
      "grad_norm": 1.990080714225769,
      "learning_rate": 0.0009885,
      "loss": 0.9222,
      "step": 2300
    },
    {
      "epoch": 0.012,
      "grad_norm": 1.5553154945373535,
      "learning_rate": 0.000988,
      "loss": 0.8881,
      "step": 2400
    },
    {
      "epoch": 0.0125,
      "grad_norm": 1.7103835344314575,
      "learning_rate": 0.0009875,
      "loss": 0.8971,
      "step": 2500
    },
    {
      "epoch": 0.013,
      "grad_norm": 1.7731612920761108,
      "learning_rate": 0.000987,
      "loss": 0.855,
      "step": 2600
    },
    {
      "epoch": 0.0135,
      "grad_norm": 2.5454516410827637,
      "learning_rate": 0.0009865,
      "loss": 0.8291,
      "step": 2700
    },
    {
      "epoch": 0.014,
      "grad_norm": 1.5750901699066162,
      "learning_rate": 0.0009860000000000001,
      "loss": 0.8339,
      "step": 2800
    },
    {
      "epoch": 0.0145,
      "grad_norm": 2.6945877075195312,
      "learning_rate": 0.0009855,
      "loss": 0.8128,
      "step": 2900
    },
    {
      "epoch": 0.015,
      "grad_norm": 1.7542814016342163,
      "learning_rate": 0.000985,
      "loss": 0.8188,
      "step": 3000
    },
    {
      "epoch": 0.0155,
      "grad_norm": 1.7264618873596191,
      "learning_rate": 0.0009845000000000001,
      "loss": 0.7755,
      "step": 3100
    },
    {
      "epoch": 0.016,
      "grad_norm": 1.838820219039917,
      "learning_rate": 0.000984,
      "loss": 0.7746,
      "step": 3200
    },
    {
      "epoch": 0.0165,
      "grad_norm": 1.7749289274215698,
      "learning_rate": 0.0009835,
      "loss": 0.7533,
      "step": 3300
    },
    {
      "epoch": 0.017,
      "grad_norm": 1.803883671760559,
      "learning_rate": 0.000983,
      "loss": 0.7357,
      "step": 3400
    },
    {
      "epoch": 0.0175,
      "grad_norm": 1.8927305936813354,
      "learning_rate": 0.0009825,
      "loss": 0.7574,
      "step": 3500
    },
    {
      "epoch": 0.018,
      "grad_norm": 2.4070775508880615,
      "learning_rate": 0.000982,
      "loss": 0.724,
      "step": 3600
    },
    {
      "epoch": 0.0185,
      "grad_norm": 1.414262294769287,
      "learning_rate": 0.0009815000000000002,
      "loss": 0.7268,
      "step": 3700
    },
    {
      "epoch": 0.019,
      "grad_norm": 1.8538713455200195,
      "learning_rate": 0.000981,
      "loss": 0.6936,
      "step": 3800
    },
    {
      "epoch": 0.0195,
      "grad_norm": 2.1911487579345703,
      "learning_rate": 0.0009805,
      "loss": 0.7088,
      "step": 3900
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.6126028299331665,
      "learning_rate": 0.00098,
      "loss": 0.698,
      "step": 4000
    },
    {
      "epoch": 0.0205,
      "grad_norm": 2.185476303100586,
      "learning_rate": 0.0009795000000000001,
      "loss": 0.6857,
      "step": 4100
    },
    {
      "epoch": 0.021,
      "grad_norm": 1.8924272060394287,
      "learning_rate": 0.000979,
      "loss": 0.6561,
      "step": 4200
    },
    {
      "epoch": 0.0215,
      "grad_norm": 1.6329762935638428,
      "learning_rate": 0.0009785,
      "loss": 0.6403,
      "step": 4300
    },
    {
      "epoch": 0.022,
      "grad_norm": 1.526397705078125,
      "learning_rate": 0.000978,
      "loss": 0.6514,
      "step": 4400
    },
    {
      "epoch": 0.0225,
      "grad_norm": 1.9491087198257446,
      "learning_rate": 0.0009775,
      "loss": 0.635,
      "step": 4500
    },
    {
      "epoch": 0.023,
      "grad_norm": 1.9008631706237793,
      "learning_rate": 0.000977,
      "loss": 0.6094,
      "step": 4600
    },
    {
      "epoch": 0.0235,
      "grad_norm": 2.016075849533081,
      "learning_rate": 0.0009765,
      "loss": 0.6322,
      "step": 4700
    },
    {
      "epoch": 0.024,
      "grad_norm": 2.560422658920288,
      "learning_rate": 0.000976,
      "loss": 0.6036,
      "step": 4800
    },
    {
      "epoch": 0.0245,
      "grad_norm": 1.9207898378372192,
      "learning_rate": 0.0009755,
      "loss": 0.6332,
      "step": 4900
    },
    {
      "epoch": 0.025,
      "grad_norm": 2.2170045375823975,
      "learning_rate": 0.000975,
      "loss": 0.5969,
      "step": 5000
    },
    {
      "epoch": 0.0255,
      "grad_norm": 2.2286148071289062,
      "learning_rate": 0.0009745000000000001,
      "loss": 0.6066,
      "step": 5100
    },
    {
      "epoch": 0.026,
      "grad_norm": 1.8456134796142578,
      "learning_rate": 0.000974,
      "loss": 0.6082,
      "step": 5200
    },
    {
      "epoch": 0.0265,
      "grad_norm": 1.5108368396759033,
      "learning_rate": 0.0009735000000000001,
      "loss": 0.5777,
      "step": 5300
    },
    {
      "epoch": 0.027,
      "grad_norm": 2.3727681636810303,
      "learning_rate": 0.000973,
      "loss": 0.5671,
      "step": 5400
    },
    {
      "epoch": 0.0275,
      "grad_norm": 1.5568031072616577,
      "learning_rate": 0.0009725000000000001,
      "loss": 0.5617,
      "step": 5500
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.5401747226715088,
      "learning_rate": 0.000972,
      "loss": 0.5638,
      "step": 5600
    },
    {
      "epoch": 0.0285,
      "grad_norm": 1.5553429126739502,
      "learning_rate": 0.0009715,
      "loss": 0.5574,
      "step": 5700
    },
    {
      "epoch": 0.029,
      "grad_norm": 1.8895928859710693,
      "learning_rate": 0.000971,
      "loss": 0.5556,
      "step": 5800
    },
    {
      "epoch": 0.0295,
      "grad_norm": 1.3597182035446167,
      "learning_rate": 0.0009705,
      "loss": 0.551,
      "step": 5900
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.520305871963501,
      "learning_rate": 0.0009699999999999999,
      "loss": 0.5459,
      "step": 6000
    },
    {
      "epoch": 0.0305,
      "grad_norm": 1.9005918502807617,
      "learning_rate": 0.0009695000000000001,
      "loss": 0.5517,
      "step": 6100
    },
    {
      "epoch": 0.031,
      "grad_norm": 1.6730371713638306,
      "learning_rate": 0.000969,
      "loss": 0.5359,
      "step": 6200
    },
    {
      "epoch": 0.0315,
      "grad_norm": 1.845162034034729,
      "learning_rate": 0.0009685000000000001,
      "loss": 0.5277,
      "step": 6300
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.729354739189148,
      "learning_rate": 0.000968,
      "loss": 0.5181,
      "step": 6400
    },
    {
      "epoch": 0.0325,
      "grad_norm": 1.4188706874847412,
      "learning_rate": 0.0009675,
      "loss": 0.5213,
      "step": 6500
    },
    {
      "epoch": 0.033,
      "grad_norm": 1.8383156061172485,
      "learning_rate": 0.000967,
      "loss": 0.5258,
      "step": 6600
    },
    {
      "epoch": 0.0335,
      "grad_norm": 1.4560388326644897,
      "learning_rate": 0.0009665,
      "loss": 0.5097,
      "step": 6700
    },
    {
      "epoch": 0.034,
      "grad_norm": 1.7786757946014404,
      "learning_rate": 0.000966,
      "loss": 0.5171,
      "step": 6800
    },
    {
      "epoch": 0.0345,
      "grad_norm": 1.6881370544433594,
      "learning_rate": 0.0009655,
      "loss": 0.511,
      "step": 6900
    },
    {
      "epoch": 0.035,
      "grad_norm": 1.5206915140151978,
      "learning_rate": 0.000965,
      "loss": 0.4991,
      "step": 7000
    },
    {
      "epoch": 0.0355,
      "grad_norm": 1.7958691120147705,
      "learning_rate": 0.0009645000000000001,
      "loss": 0.513,
      "step": 7100
    },
    {
      "epoch": 0.036,
      "grad_norm": 1.420515775680542,
      "learning_rate": 0.000964,
      "loss": 0.4987,
      "step": 7200
    },
    {
      "epoch": 0.0365,
      "grad_norm": 1.3726085424423218,
      "learning_rate": 0.0009635000000000001,
      "loss": 0.4869,
      "step": 7300
    },
    {
      "epoch": 0.037,
      "grad_norm": 1.2928271293640137,
      "learning_rate": 0.000963,
      "loss": 0.4801,
      "step": 7400
    },
    {
      "epoch": 0.0375,
      "grad_norm": 2.0542521476745605,
      "learning_rate": 0.0009625,
      "loss": 0.4812,
      "step": 7500
    },
    {
      "epoch": 0.038,
      "grad_norm": 1.276404857635498,
      "learning_rate": 0.000962,
      "loss": 0.4689,
      "step": 7600
    },
    {
      "epoch": 0.0385,
      "grad_norm": 1.5163438320159912,
      "learning_rate": 0.0009615,
      "loss": 0.4734,
      "step": 7700
    },
    {
      "epoch": 0.039,
      "grad_norm": 1.265627384185791,
      "learning_rate": 0.0009609999999999999,
      "loss": 0.4796,
      "step": 7800
    },
    {
      "epoch": 0.0395,
      "grad_norm": 2.1292293071746826,
      "learning_rate": 0.0009605000000000001,
      "loss": 0.4721,
      "step": 7900
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.3607243299484253,
      "learning_rate": 0.00096,
      "loss": 0.4472,
      "step": 8000
    },
    {
      "epoch": 0.0405,
      "grad_norm": 1.3733081817626953,
      "learning_rate": 0.0009595000000000001,
      "loss": 0.471,
      "step": 8100
    },
    {
      "epoch": 0.041,
      "grad_norm": 1.4373153448104858,
      "learning_rate": 0.000959,
      "loss": 0.4604,
      "step": 8200
    },
    {
      "epoch": 0.0415,
      "grad_norm": 1.404497742652893,
      "learning_rate": 0.0009585,
      "loss": 0.4515,
      "step": 8300
    },
    {
      "epoch": 0.042,
      "grad_norm": 1.4931670427322388,
      "learning_rate": 0.000958,
      "loss": 0.4525,
      "step": 8400
    },
    {
      "epoch": 0.0425,
      "grad_norm": 1.509932279586792,
      "learning_rate": 0.0009575,
      "loss": 0.4491,
      "step": 8500
    },
    {
      "epoch": 0.043,
      "grad_norm": 1.3134630918502808,
      "learning_rate": 0.000957,
      "loss": 0.4577,
      "step": 8600
    },
    {
      "epoch": 0.0435,
      "grad_norm": 2.869931697845459,
      "learning_rate": 0.0009565,
      "loss": 0.453,
      "step": 8700
    },
    {
      "epoch": 0.044,
      "grad_norm": 1.6119091510772705,
      "learning_rate": 0.0009559999999999999,
      "loss": 0.4374,
      "step": 8800
    },
    {
      "epoch": 0.0445,
      "grad_norm": 1.0774575471878052,
      "learning_rate": 0.0009555000000000001,
      "loss": 0.4201,
      "step": 8900
    },
    {
      "epoch": 0.045,
      "grad_norm": 1.58920156955719,
      "learning_rate": 0.000955,
      "loss": 0.4289,
      "step": 9000
    },
    {
      "epoch": 0.0455,
      "grad_norm": 1.2510288953781128,
      "learning_rate": 0.0009545,
      "loss": 0.4287,
      "step": 9100
    },
    {
      "epoch": 0.046,
      "grad_norm": 1.2649812698364258,
      "learning_rate": 0.000954,
      "loss": 0.4236,
      "step": 9200
    },
    {
      "epoch": 0.0465,
      "grad_norm": 1.4384291172027588,
      "learning_rate": 0.0009535,
      "loss": 0.4248,
      "step": 9300
    },
    {
      "epoch": 0.047,
      "grad_norm": 1.689027190208435,
      "learning_rate": 0.000953,
      "loss": 0.4153,
      "step": 9400
    },
    {
      "epoch": 0.0475,
      "grad_norm": 1.262943148612976,
      "learning_rate": 0.0009525,
      "loss": 0.4096,
      "step": 9500
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.569871425628662,
      "learning_rate": 0.0009519999999999999,
      "loss": 0.4115,
      "step": 9600
    },
    {
      "epoch": 0.0485,
      "grad_norm": 1.7166751623153687,
      "learning_rate": 0.0009515,
      "loss": 0.4157,
      "step": 9700
    },
    {
      "epoch": 0.049,
      "grad_norm": 2.5343124866485596,
      "learning_rate": 0.000951,
      "loss": 0.4131,
      "step": 9800
    },
    {
      "epoch": 0.0495,
      "grad_norm": 1.4842497110366821,
      "learning_rate": 0.0009505000000000001,
      "loss": 0.4215,
      "step": 9900
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.014364004135132,
      "learning_rate": 0.00095,
      "loss": 0.4074,
      "step": 10000
    },
    {
      "epoch": 0.0505,
      "grad_norm": 1.218414545059204,
      "learning_rate": 0.0009495,
      "loss": 0.4087,
      "step": 10100
    },
    {
      "epoch": 0.051,
      "grad_norm": 1.3709949254989624,
      "learning_rate": 0.000949,
      "loss": 0.4059,
      "step": 10200
    },
    {
      "epoch": 0.0515,
      "grad_norm": 1.780603289604187,
      "learning_rate": 0.0009485,
      "loss": 0.4111,
      "step": 10300
    },
    {
      "epoch": 0.052,
      "grad_norm": 1.0993335247039795,
      "learning_rate": 0.000948,
      "loss": 0.3926,
      "step": 10400
    },
    {
      "epoch": 0.0525,
      "grad_norm": 1.49943208694458,
      "learning_rate": 0.0009475,
      "loss": 0.3901,
      "step": 10500
    },
    {
      "epoch": 0.053,
      "grad_norm": 1.0976864099502563,
      "learning_rate": 0.0009469999999999999,
      "loss": 0.3837,
      "step": 10600
    },
    {
      "epoch": 0.0535,
      "grad_norm": 1.615087866783142,
      "learning_rate": 0.0009465000000000001,
      "loss": 0.3783,
      "step": 10700
    },
    {
      "epoch": 0.054,
      "grad_norm": 1.5178855657577515,
      "learning_rate": 0.000946,
      "loss": 0.3858,
      "step": 10800
    },
    {
      "epoch": 0.0545,
      "grad_norm": 1.2673115730285645,
      "learning_rate": 0.0009455,
      "loss": 0.3817,
      "step": 10900
    },
    {
      "epoch": 0.055,
      "grad_norm": 1.600358009338379,
      "learning_rate": 0.000945,
      "loss": 0.3821,
      "step": 11000
    },
    {
      "epoch": 0.0555,
      "grad_norm": 1.1589401960372925,
      "learning_rate": 0.0009445,
      "loss": 0.3756,
      "step": 11100
    },
    {
      "epoch": 0.056,
      "grad_norm": 1.4533239603042603,
      "learning_rate": 0.000944,
      "loss": 0.3695,
      "step": 11200
    },
    {
      "epoch": 0.0565,
      "grad_norm": 2.251915454864502,
      "learning_rate": 0.0009435,
      "loss": 0.367,
      "step": 11300
    },
    {
      "epoch": 0.057,
      "grad_norm": 1.8077936172485352,
      "learning_rate": 0.0009429999999999999,
      "loss": 0.3772,
      "step": 11400
    },
    {
      "epoch": 0.0575,
      "grad_norm": 1.5903682708740234,
      "learning_rate": 0.0009425,
      "loss": 0.376,
      "step": 11500
    },
    {
      "epoch": 0.058,
      "grad_norm": 1.7477425336837769,
      "learning_rate": 0.000942,
      "loss": 0.3709,
      "step": 11600
    },
    {
      "epoch": 0.0585,
      "grad_norm": 1.1704810857772827,
      "learning_rate": 0.0009415000000000001,
      "loss": 0.3729,
      "step": 11700
    },
    {
      "epoch": 0.059,
      "grad_norm": 1.665906310081482,
      "learning_rate": 0.000941,
      "loss": 0.3766,
      "step": 11800
    },
    {
      "epoch": 0.0595,
      "grad_norm": 1.4422377347946167,
      "learning_rate": 0.0009405,
      "loss": 0.3724,
      "step": 11900
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9659502506256104,
      "learning_rate": 0.00094,
      "loss": 0.3671,
      "step": 12000
    },
    {
      "epoch": 0.0605,
      "grad_norm": 2.0363786220550537,
      "learning_rate": 0.0009395,
      "loss": 0.3601,
      "step": 12100
    },
    {
      "epoch": 0.061,
      "grad_norm": 1.493308186531067,
      "learning_rate": 0.000939,
      "loss": 0.3618,
      "step": 12200
    },
    {
      "epoch": 0.0615,
      "grad_norm": 1.5741482973098755,
      "learning_rate": 0.0009385,
      "loss": 0.3618,
      "step": 12300
    },
    {
      "epoch": 0.062,
      "grad_norm": 1.5839391946792603,
      "learning_rate": 0.0009379999999999999,
      "loss": 0.3614,
      "step": 12400
    },
    {
      "epoch": 0.0625,
      "grad_norm": 1.9855793714523315,
      "learning_rate": 0.0009375,
      "loss": 0.3509,
      "step": 12500
    },
    {
      "epoch": 0.063,
      "grad_norm": 1.3981670141220093,
      "learning_rate": 0.0009370000000000001,
      "loss": 0.3614,
      "step": 12600
    },
    {
      "epoch": 0.0635,
      "grad_norm": 1.4821994304656982,
      "learning_rate": 0.0009365,
      "loss": 0.3593,
      "step": 12700
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.2558940649032593,
      "learning_rate": 0.0009360000000000001,
      "loss": 0.3486,
      "step": 12800
    },
    {
      "epoch": 0.0645,
      "grad_norm": 1.185732126235962,
      "learning_rate": 0.0009355,
      "loss": 0.3415,
      "step": 12900
    },
    {
      "epoch": 0.065,
      "grad_norm": 1.4554134607315063,
      "learning_rate": 0.0009350000000000001,
      "loss": 0.3643,
      "step": 13000
    },
    {
      "epoch": 0.0655,
      "grad_norm": 1.592567801475525,
      "learning_rate": 0.0009345,
      "loss": 0.3543,
      "step": 13100
    },
    {
      "epoch": 0.066,
      "grad_norm": 1.337355613708496,
      "learning_rate": 0.000934,
      "loss": 0.3356,
      "step": 13200
    },
    {
      "epoch": 0.0665,
      "grad_norm": 1.1408249139785767,
      "learning_rate": 0.0009335,
      "loss": 0.3453,
      "step": 13300
    },
    {
      "epoch": 0.067,
      "grad_norm": 2.258240222930908,
      "learning_rate": 0.000933,
      "loss": 0.3386,
      "step": 13400
    },
    {
      "epoch": 0.0675,
      "grad_norm": 1.5705679655075073,
      "learning_rate": 0.0009325000000000001,
      "loss": 0.3535,
      "step": 13500
    },
    {
      "epoch": 0.068,
      "grad_norm": 1.0535602569580078,
      "learning_rate": 0.0009320000000000001,
      "loss": 0.3349,
      "step": 13600
    },
    {
      "epoch": 0.0685,
      "grad_norm": 1.3584295511245728,
      "learning_rate": 0.0009315,
      "loss": 0.3491,
      "step": 13700
    },
    {
      "epoch": 0.069,
      "grad_norm": 1.2726765871047974,
      "learning_rate": 0.0009310000000000001,
      "loss": 0.3398,
      "step": 13800
    },
    {
      "epoch": 0.0695,
      "grad_norm": 1.1827642917633057,
      "learning_rate": 0.0009305,
      "loss": 0.33,
      "step": 13900
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3970048427581787,
      "learning_rate": 0.00093,
      "loss": 0.3339,
      "step": 14000
    },
    {
      "epoch": 0.0705,
      "grad_norm": 1.1885062456130981,
      "learning_rate": 0.0009295,
      "loss": 0.327,
      "step": 14100
    },
    {
      "epoch": 0.071,
      "grad_norm": 1.1453804969787598,
      "learning_rate": 0.000929,
      "loss": 0.3379,
      "step": 14200
    },
    {
      "epoch": 0.0715,
      "grad_norm": 1.0594562292099,
      "learning_rate": 0.0009285,
      "loss": 0.3278,
      "step": 14300
    },
    {
      "epoch": 0.072,
      "grad_norm": 1.5966843366622925,
      "learning_rate": 0.0009280000000000001,
      "loss": 0.3259,
      "step": 14400
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.8779556751251221,
      "learning_rate": 0.0009275,
      "loss": 0.3238,
      "step": 14500
    },
    {
      "epoch": 0.073,
      "grad_norm": 1.1234468221664429,
      "learning_rate": 0.0009270000000000001,
      "loss": 0.3224,
      "step": 14600
    },
    {
      "epoch": 0.0735,
      "grad_norm": 1.116816520690918,
      "learning_rate": 0.0009265,
      "loss": 0.3321,
      "step": 14700
    },
    {
      "epoch": 0.074,
      "grad_norm": 1.1459312438964844,
      "learning_rate": 0.0009260000000000001,
      "loss": 0.3071,
      "step": 14800
    },
    {
      "epoch": 0.0745,
      "grad_norm": 1.1178582906723022,
      "learning_rate": 0.0009255,
      "loss": 0.3208,
      "step": 14900
    },
    {
      "epoch": 0.075,
      "grad_norm": 1.56632399559021,
      "learning_rate": 0.000925,
      "loss": 0.3246,
      "step": 15000
    },
    {
      "epoch": 0.0755,
      "grad_norm": 1.4012008905410767,
      "learning_rate": 0.0009245,
      "loss": 0.3317,
      "step": 15100
    },
    {
      "epoch": 0.076,
      "grad_norm": 1.042084813117981,
      "learning_rate": 0.000924,
      "loss": 0.3255,
      "step": 15200
    },
    {
      "epoch": 0.0765,
      "grad_norm": 1.0665909051895142,
      "learning_rate": 0.0009235000000000001,
      "loss": 0.3195,
      "step": 15300
    },
    {
      "epoch": 0.077,
      "grad_norm": 1.4157215356826782,
      "learning_rate": 0.0009230000000000001,
      "loss": 0.3242,
      "step": 15400
    },
    {
      "epoch": 0.0775,
      "grad_norm": 1.064416766166687,
      "learning_rate": 0.0009225,
      "loss": 0.3204,
      "step": 15500
    },
    {
      "epoch": 0.078,
      "grad_norm": 1.3699592351913452,
      "learning_rate": 0.0009220000000000001,
      "loss": 0.3151,
      "step": 15600
    },
    {
      "epoch": 0.0785,
      "grad_norm": 1.0483126640319824,
      "learning_rate": 0.0009215,
      "loss": 0.3191,
      "step": 15700
    },
    {
      "epoch": 0.079,
      "grad_norm": 1.4428246021270752,
      "learning_rate": 0.000921,
      "loss": 0.314,
      "step": 15800
    },
    {
      "epoch": 0.0795,
      "grad_norm": 1.1351206302642822,
      "learning_rate": 0.0009205,
      "loss": 0.3159,
      "step": 15900
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.064708948135376,
      "learning_rate": 0.00092,
      "loss": 0.3253,
      "step": 16000
    },
    {
      "epoch": 0.0805,
      "grad_norm": 1.3647997379302979,
      "learning_rate": 0.0009195,
      "loss": 0.3066,
      "step": 16100
    },
    {
      "epoch": 0.081,
      "grad_norm": 1.6604310274124146,
      "learning_rate": 0.0009190000000000001,
      "loss": 0.3073,
      "step": 16200
    },
    {
      "epoch": 0.0815,
      "grad_norm": 1.2354897260665894,
      "learning_rate": 0.0009185,
      "loss": 0.2966,
      "step": 16300
    },
    {
      "epoch": 0.082,
      "grad_norm": 1.124354362487793,
      "learning_rate": 0.0009180000000000001,
      "loss": 0.3035,
      "step": 16400
    },
    {
      "epoch": 0.0825,
      "grad_norm": 1.525809407234192,
      "learning_rate": 0.0009175,
      "loss": 0.2973,
      "step": 16500
    },
    {
      "epoch": 0.083,
      "grad_norm": 1.159363865852356,
      "learning_rate": 0.0009170000000000001,
      "loss": 0.3058,
      "step": 16600
    },
    {
      "epoch": 0.0835,
      "grad_norm": 2.0053188800811768,
      "learning_rate": 0.0009165,
      "loss": 0.3007,
      "step": 16700
    },
    {
      "epoch": 0.084,
      "grad_norm": 1.1285561323165894,
      "learning_rate": 0.000916,
      "loss": 0.2966,
      "step": 16800
    },
    {
      "epoch": 0.0845,
      "grad_norm": 1.900081992149353,
      "learning_rate": 0.0009155,
      "loss": 0.2953,
      "step": 16900
    },
    {
      "epoch": 0.085,
      "grad_norm": 1.1907408237457275,
      "learning_rate": 0.000915,
      "loss": 0.3042,
      "step": 17000
    },
    {
      "epoch": 0.0855,
      "grad_norm": 1.678031086921692,
      "learning_rate": 0.0009145,
      "loss": 0.2862,
      "step": 17100
    },
    {
      "epoch": 0.086,
      "grad_norm": 1.228696584701538,
      "learning_rate": 0.0009140000000000001,
      "loss": 0.2917,
      "step": 17200
    },
    {
      "epoch": 0.0865,
      "grad_norm": 1.2456926107406616,
      "learning_rate": 0.0009135,
      "loss": 0.2876,
      "step": 17300
    },
    {
      "epoch": 0.087,
      "grad_norm": 1.1257070302963257,
      "learning_rate": 0.0009130000000000001,
      "loss": 0.2981,
      "step": 17400
    },
    {
      "epoch": 0.0875,
      "grad_norm": 1.5054497718811035,
      "learning_rate": 0.0009125,
      "loss": 0.2928,
      "step": 17500
    },
    {
      "epoch": 0.088,
      "grad_norm": 7.307071685791016,
      "learning_rate": 0.000912,
      "loss": 0.2929,
      "step": 17600
    },
    {
      "epoch": 0.0885,
      "grad_norm": 1.3850972652435303,
      "learning_rate": 0.0009115,
      "loss": 0.2944,
      "step": 17700
    },
    {
      "epoch": 0.089,
      "grad_norm": 1.114221215248108,
      "learning_rate": 0.000911,
      "loss": 0.2912,
      "step": 17800
    },
    {
      "epoch": 0.0895,
      "grad_norm": 1.5638025999069214,
      "learning_rate": 0.0009105,
      "loss": 0.2897,
      "step": 17900
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.1080979108810425,
      "learning_rate": 0.00091,
      "loss": 0.2919,
      "step": 18000
    },
    {
      "epoch": 0.0905,
      "grad_norm": 1.525860071182251,
      "learning_rate": 0.0009095,
      "loss": 0.2856,
      "step": 18100
    },
    {
      "epoch": 0.091,
      "grad_norm": 1.3805941343307495,
      "learning_rate": 0.0009090000000000001,
      "loss": 0.2846,
      "step": 18200
    },
    {
      "epoch": 0.0915,
      "grad_norm": 1.5403894186019897,
      "learning_rate": 0.0009085,
      "loss": 0.2921,
      "step": 18300
    },
    {
      "epoch": 0.092,
      "grad_norm": 1.183824062347412,
      "learning_rate": 0.0009080000000000001,
      "loss": 0.2849,
      "step": 18400
    },
    {
      "epoch": 0.0925,
      "grad_norm": 1.2869700193405151,
      "learning_rate": 0.0009075,
      "loss": 0.2862,
      "step": 18500
    },
    {
      "epoch": 0.093,
      "grad_norm": 2.1458873748779297,
      "learning_rate": 0.000907,
      "loss": 0.281,
      "step": 18600
    },
    {
      "epoch": 0.0935,
      "grad_norm": 1.1493144035339355,
      "learning_rate": 0.0009065,
      "loss": 0.2827,
      "step": 18700
    },
    {
      "epoch": 0.094,
      "grad_norm": 1.2592980861663818,
      "learning_rate": 0.000906,
      "loss": 0.2819,
      "step": 18800
    },
    {
      "epoch": 0.0945,
      "grad_norm": 1.6370441913604736,
      "learning_rate": 0.0009055,
      "loss": 0.2868,
      "step": 18900
    },
    {
      "epoch": 0.095,
      "grad_norm": 8.64887523651123,
      "learning_rate": 0.0009050000000000001,
      "loss": 0.2858,
      "step": 19000
    },
    {
      "epoch": 0.0955,
      "grad_norm": 1.5624624490737915,
      "learning_rate": 0.0009045,
      "loss": 0.2839,
      "step": 19100
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.7944364547729492,
      "learning_rate": 0.0009040000000000001,
      "loss": 0.2841,
      "step": 19200
    },
    {
      "epoch": 0.0965,
      "grad_norm": 1.1049925088882446,
      "learning_rate": 0.0009035,
      "loss": 0.2829,
      "step": 19300
    },
    {
      "epoch": 0.097,
      "grad_norm": 0.9795631170272827,
      "learning_rate": 0.000903,
      "loss": 0.274,
      "step": 19400
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.9741241931915283,
      "learning_rate": 0.0009025,
      "loss": 0.2765,
      "step": 19500
    },
    {
      "epoch": 0.098,
      "grad_norm": 1.5115597248077393,
      "learning_rate": 0.000902,
      "loss": 0.2705,
      "step": 19600
    },
    {
      "epoch": 0.0985,
      "grad_norm": 1.5197654962539673,
      "learning_rate": 0.0009015,
      "loss": 0.2624,
      "step": 19700
    },
    {
      "epoch": 0.099,
      "grad_norm": 1.1512205600738525,
      "learning_rate": 0.000901,
      "loss": 0.2769,
      "step": 19800
    },
    {
      "epoch": 0.0995,
      "grad_norm": 1.507742166519165,
      "learning_rate": 0.0009004999999999999,
      "loss": 0.2654,
      "step": 19900
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.527294874191284,
      "learning_rate": 0.0009000000000000001,
      "loss": 0.2757,
      "step": 20000
    },
    {
      "epoch": 0.1005,
      "grad_norm": 1.579679250717163,
      "learning_rate": 0.0008995,
      "loss": 0.2708,
      "step": 20100
    },
    {
      "epoch": 0.101,
      "grad_norm": 1.124881386756897,
      "learning_rate": 0.0008990000000000001,
      "loss": 0.2761,
      "step": 20200
    },
    {
      "epoch": 0.1015,
      "grad_norm": 1.2676948308944702,
      "learning_rate": 0.0008985,
      "loss": 0.2711,
      "step": 20300
    },
    {
      "epoch": 0.102,
      "grad_norm": 1.2551568746566772,
      "learning_rate": 0.000898,
      "loss": 0.2828,
      "step": 20400
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.9978771209716797,
      "learning_rate": 0.0008975,
      "loss": 0.2704,
      "step": 20500
    },
    {
      "epoch": 0.103,
      "grad_norm": 0.7280104756355286,
      "learning_rate": 0.000897,
      "loss": 0.2685,
      "step": 20600
    },
    {
      "epoch": 0.1035,
      "grad_norm": 0.8714795112609863,
      "learning_rate": 0.0008964999999999999,
      "loss": 0.2557,
      "step": 20700
    },
    {
      "epoch": 0.104,
      "grad_norm": 1.0128730535507202,
      "learning_rate": 0.000896,
      "loss": 0.2668,
      "step": 20800
    },
    {
      "epoch": 0.1045,
      "grad_norm": 1.6130393743515015,
      "learning_rate": 0.0008955,
      "loss": 0.264,
      "step": 20900
    },
    {
      "epoch": 0.105,
      "grad_norm": 1.1587135791778564,
      "learning_rate": 0.0008950000000000001,
      "loss": 0.2715,
      "step": 21000
    },
    {
      "epoch": 0.1055,
      "grad_norm": 1.3078339099884033,
      "learning_rate": 0.0008945,
      "loss": 0.2674,
      "step": 21100
    },
    {
      "epoch": 0.106,
      "grad_norm": 1.2761437892913818,
      "learning_rate": 0.000894,
      "loss": 0.2612,
      "step": 21200
    },
    {
      "epoch": 0.1065,
      "grad_norm": 1.5104763507843018,
      "learning_rate": 0.0008935,
      "loss": 0.2716,
      "step": 21300
    },
    {
      "epoch": 0.107,
      "grad_norm": 3.1975250244140625,
      "learning_rate": 0.000893,
      "loss": 0.2694,
      "step": 21400
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.9594959616661072,
      "learning_rate": 0.0008925,
      "loss": 0.2601,
      "step": 21500
    },
    {
      "epoch": 0.108,
      "grad_norm": 3.4007253646850586,
      "learning_rate": 0.000892,
      "loss": 0.2716,
      "step": 21600
    },
    {
      "epoch": 0.1085,
      "grad_norm": 0.8877611756324768,
      "learning_rate": 0.0008914999999999999,
      "loss": 0.2668,
      "step": 21700
    },
    {
      "epoch": 0.109,
      "grad_norm": 1.2563772201538086,
      "learning_rate": 0.0008910000000000001,
      "loss": 0.2709,
      "step": 21800
    },
    {
      "epoch": 0.1095,
      "grad_norm": 0.9536858797073364,
      "learning_rate": 0.0008905,
      "loss": 0.2575,
      "step": 21900
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.485809087753296,
      "learning_rate": 0.0008900000000000001,
      "loss": 0.257,
      "step": 22000
    },
    {
      "epoch": 0.1105,
      "grad_norm": 2.1028432846069336,
      "learning_rate": 0.0008895,
      "loss": 0.2609,
      "step": 22100
    },
    {
      "epoch": 0.111,
      "grad_norm": 1.2342133522033691,
      "learning_rate": 0.000889,
      "loss": 0.2473,
      "step": 22200
    },
    {
      "epoch": 0.1115,
      "grad_norm": 0.9893059134483337,
      "learning_rate": 0.0008885,
      "loss": 0.2641,
      "step": 22300
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.5361992120742798,
      "learning_rate": 0.000888,
      "loss": 0.2514,
      "step": 22400
    },
    {
      "epoch": 0.1125,
      "grad_norm": 1.0390677452087402,
      "learning_rate": 0.0008874999999999999,
      "loss": 0.2519,
      "step": 22500
    },
    {
      "epoch": 0.113,
      "grad_norm": 1.4859060049057007,
      "learning_rate": 0.000887,
      "loss": 0.2641,
      "step": 22600
    },
    {
      "epoch": 0.1135,
      "grad_norm": 0.8651059865951538,
      "learning_rate": 0.0008865,
      "loss": 0.2524,
      "step": 22700
    },
    {
      "epoch": 0.114,
      "grad_norm": 1.1760598421096802,
      "learning_rate": 0.0008860000000000001,
      "loss": 0.2521,
      "step": 22800
    },
    {
      "epoch": 0.1145,
      "grad_norm": 1.2301913499832153,
      "learning_rate": 0.0008855,
      "loss": 0.2465,
      "step": 22900
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.8666963577270508,
      "learning_rate": 0.000885,
      "loss": 0.2458,
      "step": 23000
    },
    {
      "epoch": 0.1155,
      "grad_norm": 0.9478781819343567,
      "learning_rate": 0.0008845,
      "loss": 0.2527,
      "step": 23100
    },
    {
      "epoch": 0.116,
      "grad_norm": 1.1816303730010986,
      "learning_rate": 0.000884,
      "loss": 0.2407,
      "step": 23200
    },
    {
      "epoch": 0.1165,
      "grad_norm": 1.2366359233856201,
      "learning_rate": 0.0008835,
      "loss": 0.2537,
      "step": 23300
    },
    {
      "epoch": 0.117,
      "grad_norm": 1.1047219038009644,
      "learning_rate": 0.000883,
      "loss": 0.2482,
      "step": 23400
    },
    {
      "epoch": 0.1175,
      "grad_norm": 1.6886755228042603,
      "learning_rate": 0.0008824999999999999,
      "loss": 0.2482,
      "step": 23500
    },
    {
      "epoch": 0.118,
      "grad_norm": 1.3411227464675903,
      "learning_rate": 0.000882,
      "loss": 0.2499,
      "step": 23600
    },
    {
      "epoch": 0.1185,
      "grad_norm": 1.1679317951202393,
      "learning_rate": 0.0008815,
      "loss": 0.2464,
      "step": 23700
    },
    {
      "epoch": 0.119,
      "grad_norm": 0.9729589223861694,
      "learning_rate": 0.0008810000000000001,
      "loss": 0.2401,
      "step": 23800
    },
    {
      "epoch": 0.1195,
      "grad_norm": 1.1108342409133911,
      "learning_rate": 0.0008805,
      "loss": 0.254,
      "step": 23900
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1101652383804321,
      "learning_rate": 0.00088,
      "loss": 0.2351,
      "step": 24000
    },
    {
      "epoch": 0.1205,
      "grad_norm": 0.7644184231758118,
      "learning_rate": 0.0008795,
      "loss": 0.2397,
      "step": 24100
    },
    {
      "epoch": 0.121,
      "grad_norm": 1.431426763534546,
      "learning_rate": 0.000879,
      "loss": 0.2463,
      "step": 24200
    },
    {
      "epoch": 0.1215,
      "grad_norm": 3.429363965988159,
      "learning_rate": 0.0008784999999999999,
      "loss": 0.2386,
      "step": 24300
    },
    {
      "epoch": 0.122,
      "grad_norm": 1.3043302297592163,
      "learning_rate": 0.000878,
      "loss": 0.2401,
      "step": 24400
    },
    {
      "epoch": 0.1225,
      "grad_norm": 1.7369928359985352,
      "learning_rate": 0.0008774999999999999,
      "loss": 0.2458,
      "step": 24500
    },
    {
      "epoch": 0.123,
      "grad_norm": 1.1039798259735107,
      "learning_rate": 0.0008770000000000001,
      "loss": 0.2482,
      "step": 24600
    },
    {
      "epoch": 0.1235,
      "grad_norm": 1.4437940120697021,
      "learning_rate": 0.0008765,
      "loss": 0.2439,
      "step": 24700
    },
    {
      "epoch": 0.124,
      "grad_norm": 1.2215367555618286,
      "learning_rate": 0.000876,
      "loss": 0.2427,
      "step": 24800
    },
    {
      "epoch": 0.1245,
      "grad_norm": 0.9872219562530518,
      "learning_rate": 0.0008755,
      "loss": 0.2445,
      "step": 24900
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.86788010597229,
      "learning_rate": 0.000875,
      "loss": 0.2544,
      "step": 25000
    },
    {
      "epoch": 0.1255,
      "grad_norm": 3.9402008056640625,
      "learning_rate": 0.0008745000000000001,
      "loss": 0.239,
      "step": 25100
    },
    {
      "epoch": 0.126,
      "grad_norm": 1.054709553718567,
      "learning_rate": 0.000874,
      "loss": 0.2384,
      "step": 25200
    },
    {
      "epoch": 0.1265,
      "grad_norm": 0.9578445553779602,
      "learning_rate": 0.0008735,
      "loss": 0.2447,
      "step": 25300
    },
    {
      "epoch": 0.127,
      "grad_norm": 1.4882580041885376,
      "learning_rate": 0.000873,
      "loss": 0.2446,
      "step": 25400
    },
    {
      "epoch": 0.1275,
      "grad_norm": 1.2198188304901123,
      "learning_rate": 0.0008725000000000001,
      "loss": 0.2363,
      "step": 25500
    },
    {
      "epoch": 0.128,
      "grad_norm": 2.2715957164764404,
      "learning_rate": 0.000872,
      "loss": 0.2509,
      "step": 25600
    },
    {
      "epoch": 0.1285,
      "grad_norm": 1.1166445016860962,
      "learning_rate": 0.0008715000000000001,
      "loss": 0.2424,
      "step": 25700
    },
    {
      "epoch": 0.129,
      "grad_norm": 1.1235605478286743,
      "learning_rate": 0.000871,
      "loss": 0.2325,
      "step": 25800
    },
    {
      "epoch": 0.1295,
      "grad_norm": 1.024023413658142,
      "learning_rate": 0.0008705000000000001,
      "loss": 0.2255,
      "step": 25900
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7851558923721313,
      "learning_rate": 0.00087,
      "loss": 0.2444,
      "step": 26000
    },
    {
      "epoch": 0.1305,
      "grad_norm": 1.3178762197494507,
      "learning_rate": 0.0008695,
      "loss": 0.2217,
      "step": 26100
    },
    {
      "epoch": 0.131,
      "grad_norm": 1.7875105142593384,
      "learning_rate": 0.000869,
      "loss": 0.2354,
      "step": 26200
    },
    {
      "epoch": 0.1315,
      "grad_norm": 1.562821388244629,
      "learning_rate": 0.0008685,
      "loss": 0.2351,
      "step": 26300
    },
    {
      "epoch": 0.132,
      "grad_norm": 1.4854997396469116,
      "learning_rate": 0.0008680000000000001,
      "loss": 0.2272,
      "step": 26400
    },
    {
      "epoch": 0.1325,
      "grad_norm": 1.3886260986328125,
      "learning_rate": 0.0008675000000000001,
      "loss": 0.2278,
      "step": 26500
    },
    {
      "epoch": 0.133,
      "grad_norm": 1.2066770792007446,
      "learning_rate": 0.000867,
      "loss": 0.2355,
      "step": 26600
    },
    {
      "epoch": 0.1335,
      "grad_norm": 0.8717833757400513,
      "learning_rate": 0.0008665000000000001,
      "loss": 0.2352,
      "step": 26700
    },
    {
      "epoch": 0.134,
      "grad_norm": 1.2269855737686157,
      "learning_rate": 0.000866,
      "loss": 0.2415,
      "step": 26800
    },
    {
      "epoch": 0.1345,
      "grad_norm": 0.7054443955421448,
      "learning_rate": 0.0008655000000000001,
      "loss": 0.2213,
      "step": 26900
    },
    {
      "epoch": 0.135,
      "grad_norm": 1.3643933534622192,
      "learning_rate": 0.000865,
      "loss": 0.2222,
      "step": 27000
    },
    {
      "epoch": 0.1355,
      "grad_norm": 1.355952501296997,
      "learning_rate": 0.0008645,
      "loss": 0.2259,
      "step": 27100
    },
    {
      "epoch": 0.136,
      "grad_norm": 1.0648972988128662,
      "learning_rate": 0.000864,
      "loss": 0.218,
      "step": 27200
    },
    {
      "epoch": 0.1365,
      "grad_norm": 0.9009698033332825,
      "learning_rate": 0.0008635,
      "loss": 0.2271,
      "step": 27300
    },
    {
      "epoch": 0.137,
      "grad_norm": 1.0133544206619263,
      "learning_rate": 0.000863,
      "loss": 0.2241,
      "step": 27400
    },
    {
      "epoch": 0.1375,
      "grad_norm": 1.057817816734314,
      "learning_rate": 0.0008625000000000001,
      "loss": 0.2244,
      "step": 27500
    },
    {
      "epoch": 0.138,
      "grad_norm": 1.2036343812942505,
      "learning_rate": 0.000862,
      "loss": 0.2289,
      "step": 27600
    },
    {
      "epoch": 0.1385,
      "grad_norm": 1.4093092679977417,
      "learning_rate": 0.0008615000000000001,
      "loss": 0.2361,
      "step": 27700
    },
    {
      "epoch": 0.139,
      "grad_norm": 2.9162375926971436,
      "learning_rate": 0.000861,
      "loss": 0.2347,
      "step": 27800
    },
    {
      "epoch": 0.1395,
      "grad_norm": 1.0906909704208374,
      "learning_rate": 0.0008605,
      "loss": 0.2202,
      "step": 27900
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.564171314239502,
      "learning_rate": 0.00086,
      "loss": 0.2253,
      "step": 28000
    },
    {
      "epoch": 0.1405,
      "grad_norm": 1.1820166110992432,
      "learning_rate": 0.0008595,
      "loss": 0.2236,
      "step": 28100
    },
    {
      "epoch": 0.141,
      "grad_norm": 3.7714314460754395,
      "learning_rate": 0.000859,
      "loss": 0.2361,
      "step": 28200
    },
    {
      "epoch": 0.1415,
      "grad_norm": 0.9296143054962158,
      "learning_rate": 0.0008585000000000001,
      "loss": 0.2274,
      "step": 28300
    },
    {
      "epoch": 0.142,
      "grad_norm": 1.1266804933547974,
      "learning_rate": 0.000858,
      "loss": 0.2238,
      "step": 28400
    },
    {
      "epoch": 0.1425,
      "grad_norm": 1.0850348472595215,
      "learning_rate": 0.0008575000000000001,
      "loss": 0.218,
      "step": 28500
    },
    {
      "epoch": 0.143,
      "grad_norm": 0.6001381874084473,
      "learning_rate": 0.000857,
      "loss": 0.2212,
      "step": 28600
    },
    {
      "epoch": 0.1435,
      "grad_norm": 1.2053052186965942,
      "learning_rate": 0.0008565000000000001,
      "loss": 0.2238,
      "step": 28700
    },
    {
      "epoch": 0.144,
      "grad_norm": 1.3295255899429321,
      "learning_rate": 0.000856,
      "loss": 0.2308,
      "step": 28800
    },
    {
      "epoch": 0.1445,
      "grad_norm": 3.114919424057007,
      "learning_rate": 0.0008555,
      "loss": 0.2202,
      "step": 28900
    },
    {
      "epoch": 0.145,
      "grad_norm": 1.9705382585525513,
      "learning_rate": 0.000855,
      "loss": 0.2158,
      "step": 29000
    },
    {
      "epoch": 0.1455,
      "grad_norm": 1.4375900030136108,
      "learning_rate": 0.0008545,
      "loss": 0.2257,
      "step": 29100
    },
    {
      "epoch": 0.146,
      "grad_norm": 0.987909197807312,
      "learning_rate": 0.000854,
      "loss": 0.2165,
      "step": 29200
    },
    {
      "epoch": 0.1465,
      "grad_norm": 1.1233655214309692,
      "learning_rate": 0.0008535000000000001,
      "loss": 0.2139,
      "step": 29300
    },
    {
      "epoch": 0.147,
      "grad_norm": 1.0516636371612549,
      "learning_rate": 0.000853,
      "loss": 0.2314,
      "step": 29400
    },
    {
      "epoch": 0.1475,
      "grad_norm": 2.058110475540161,
      "learning_rate": 0.0008525000000000001,
      "loss": 0.2144,
      "step": 29500
    },
    {
      "epoch": 0.148,
      "grad_norm": 1.8681602478027344,
      "learning_rate": 0.000852,
      "loss": 0.2236,
      "step": 29600
    },
    {
      "epoch": 0.1485,
      "grad_norm": 1.165597677230835,
      "learning_rate": 0.0008515,
      "loss": 0.2202,
      "step": 29700
    },
    {
      "epoch": 0.149,
      "grad_norm": 1.2449655532836914,
      "learning_rate": 0.000851,
      "loss": 0.2209,
      "step": 29800
    },
    {
      "epoch": 0.1495,
      "grad_norm": 2.937723398208618,
      "learning_rate": 0.0008505,
      "loss": 0.2202,
      "step": 29900
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.654266357421875,
      "learning_rate": 0.00085,
      "loss": 0.2126,
      "step": 30000
    },
    {
      "epoch": 0.1505,
      "grad_norm": 1.7254972457885742,
      "learning_rate": 0.0008495000000000001,
      "loss": 0.2259,
      "step": 30100
    },
    {
      "epoch": 0.151,
      "grad_norm": 1.70552659034729,
      "learning_rate": 0.000849,
      "loss": 0.2089,
      "step": 30200
    },
    {
      "epoch": 0.1515,
      "grad_norm": 1.0526539087295532,
      "learning_rate": 0.0008485000000000001,
      "loss": 0.2186,
      "step": 30300
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.9282636046409607,
      "learning_rate": 0.000848,
      "loss": 0.2047,
      "step": 30400
    },
    {
      "epoch": 0.1525,
      "grad_norm": 0.7975742220878601,
      "learning_rate": 0.0008475000000000001,
      "loss": 0.2181,
      "step": 30500
    },
    {
      "epoch": 0.153,
      "grad_norm": 2.4836156368255615,
      "learning_rate": 0.000847,
      "loss": 0.2123,
      "step": 30600
    },
    {
      "epoch": 0.1535,
      "grad_norm": 1.3952665328979492,
      "learning_rate": 0.0008465,
      "loss": 0.2157,
      "step": 30700
    },
    {
      "epoch": 0.154,
      "grad_norm": 1.1944987773895264,
      "learning_rate": 0.000846,
      "loss": 0.2067,
      "step": 30800
    },
    {
      "epoch": 0.1545,
      "grad_norm": 5.667100429534912,
      "learning_rate": 0.0008455,
      "loss": 0.2197,
      "step": 30900
    },
    {
      "epoch": 0.155,
      "grad_norm": 2.7349653244018555,
      "learning_rate": 0.0008449999999999999,
      "loss": 0.2124,
      "step": 31000
    },
    {
      "epoch": 0.1555,
      "grad_norm": 0.8530601263046265,
      "learning_rate": 0.0008445000000000001,
      "loss": 0.2253,
      "step": 31100
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.7215296030044556,
      "learning_rate": 0.000844,
      "loss": 0.2084,
      "step": 31200
    },
    {
      "epoch": 0.1565,
      "grad_norm": 1.4410732984542847,
      "learning_rate": 0.0008435000000000001,
      "loss": 0.2069,
      "step": 31300
    },
    {
      "epoch": 0.157,
      "grad_norm": 2.0024287700653076,
      "learning_rate": 0.000843,
      "loss": 0.2043,
      "step": 31400
    },
    {
      "epoch": 0.1575,
      "grad_norm": 8.462298393249512,
      "learning_rate": 0.0008425,
      "loss": 0.2194,
      "step": 31500
    },
    {
      "epoch": 0.158,
      "grad_norm": 1.2126274108886719,
      "learning_rate": 0.000842,
      "loss": 0.2123,
      "step": 31600
    },
    {
      "epoch": 0.1585,
      "grad_norm": 0.9344167709350586,
      "learning_rate": 0.0008415,
      "loss": 0.2143,
      "step": 31700
    },
    {
      "epoch": 0.159,
      "grad_norm": 2.0420796871185303,
      "learning_rate": 0.000841,
      "loss": 0.2069,
      "step": 31800
    },
    {
      "epoch": 0.1595,
      "grad_norm": 1.0209420919418335,
      "learning_rate": 0.0008405,
      "loss": 0.2011,
      "step": 31900
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0286139249801636,
      "learning_rate": 0.00084,
      "loss": 0.2183,
      "step": 32000
    },
    {
      "epoch": 0.1605,
      "grad_norm": 0.7460246682167053,
      "learning_rate": 0.0008395000000000001,
      "loss": 0.2061,
      "step": 32100
    },
    {
      "epoch": 0.161,
      "grad_norm": 0.9301573634147644,
      "learning_rate": 0.000839,
      "loss": 0.2062,
      "step": 32200
    },
    {
      "epoch": 0.1615,
      "grad_norm": 1.5539835691452026,
      "learning_rate": 0.0008385,
      "loss": 0.2055,
      "step": 32300
    },
    {
      "epoch": 0.162,
      "grad_norm": 0.5836048722267151,
      "learning_rate": 0.000838,
      "loss": 0.1989,
      "step": 32400
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.8872018456459045,
      "learning_rate": 0.0008375,
      "loss": 0.2012,
      "step": 32500
    },
    {
      "epoch": 0.163,
      "grad_norm": 1.6214334964752197,
      "learning_rate": 0.000837,
      "loss": 0.2045,
      "step": 32600
    },
    {
      "epoch": 0.1635,
      "grad_norm": 0.8429814577102661,
      "learning_rate": 0.0008365,
      "loss": 0.2038,
      "step": 32700
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.6917031407356262,
      "learning_rate": 0.0008359999999999999,
      "loss": 0.2091,
      "step": 32800
    },
    {
      "epoch": 0.1645,
      "grad_norm": 1.259731650352478,
      "learning_rate": 0.0008355000000000001,
      "loss": 0.2131,
      "step": 32900
    },
    {
      "epoch": 0.165,
      "grad_norm": 1.560652256011963,
      "learning_rate": 0.000835,
      "loss": 0.209,
      "step": 33000
    },
    {
      "epoch": 0.1655,
      "grad_norm": 0.7861653566360474,
      "learning_rate": 0.0008345000000000001,
      "loss": 0.2001,
      "step": 33100
    },
    {
      "epoch": 0.166,
      "grad_norm": 1.7938896417617798,
      "learning_rate": 0.000834,
      "loss": 0.204,
      "step": 33200
    },
    {
      "epoch": 0.1665,
      "grad_norm": 0.9031243324279785,
      "learning_rate": 0.0008335,
      "loss": 0.2068,
      "step": 33300
    },
    {
      "epoch": 0.167,
      "grad_norm": 1.8858081102371216,
      "learning_rate": 0.000833,
      "loss": 0.2065,
      "step": 33400
    },
    {
      "epoch": 0.1675,
      "grad_norm": 0.8635398149490356,
      "learning_rate": 0.0008325,
      "loss": 0.198,
      "step": 33500
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.8646530508995056,
      "learning_rate": 0.000832,
      "loss": 0.1913,
      "step": 33600
    },
    {
      "epoch": 0.1685,
      "grad_norm": 1.0315335988998413,
      "learning_rate": 0.0008315,
      "loss": 0.2116,
      "step": 33700
    },
    {
      "epoch": 0.169,
      "grad_norm": 1.1770519018173218,
      "learning_rate": 0.0008309999999999999,
      "loss": 0.204,
      "step": 33800
    },
    {
      "epoch": 0.1695,
      "grad_norm": 2.4179022312164307,
      "learning_rate": 0.0008305000000000001,
      "loss": 0.2004,
      "step": 33900
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6927066445350647,
      "learning_rate": 0.00083,
      "loss": 0.1934,
      "step": 34000
    },
    {
      "epoch": 0.1705,
      "grad_norm": 0.8531962633132935,
      "learning_rate": 0.0008295,
      "loss": 0.2046,
      "step": 34100
    },
    {
      "epoch": 0.171,
      "grad_norm": 2.1872498989105225,
      "learning_rate": 0.000829,
      "loss": 0.2012,
      "step": 34200
    },
    {
      "epoch": 0.1715,
      "grad_norm": 1.2818896770477295,
      "learning_rate": 0.0008285,
      "loss": 0.1969,
      "step": 34300
    },
    {
      "epoch": 0.172,
      "grad_norm": 1.0195579528808594,
      "learning_rate": 0.000828,
      "loss": 0.186,
      "step": 34400
    },
    {
      "epoch": 0.1725,
      "grad_norm": 0.9634889960289001,
      "learning_rate": 0.0008275,
      "loss": 0.2034,
      "step": 34500
    },
    {
      "epoch": 0.173,
      "grad_norm": 1.0135911703109741,
      "learning_rate": 0.0008269999999999999,
      "loss": 0.1908,
      "step": 34600
    },
    {
      "epoch": 0.1735,
      "grad_norm": 1.7293275594711304,
      "learning_rate": 0.0008265,
      "loss": 0.2094,
      "step": 34700
    },
    {
      "epoch": 0.174,
      "grad_norm": 1.2154041528701782,
      "learning_rate": 0.000826,
      "loss": 0.1959,
      "step": 34800
    },
    {
      "epoch": 0.1745,
      "grad_norm": 0.8924216628074646,
      "learning_rate": 0.0008255000000000001,
      "loss": 0.1965,
      "step": 34900
    },
    {
      "epoch": 0.175,
      "grad_norm": 1.446703553199768,
      "learning_rate": 0.000825,
      "loss": 0.1968,
      "step": 35000
    },
    {
      "epoch": 0.1755,
      "grad_norm": 1.062172293663025,
      "learning_rate": 0.0008245,
      "loss": 0.2021,
      "step": 35100
    },
    {
      "epoch": 0.176,
      "grad_norm": 1.0708903074264526,
      "learning_rate": 0.000824,
      "loss": 0.1924,
      "step": 35200
    },
    {
      "epoch": 0.1765,
      "grad_norm": 0.9133870601654053,
      "learning_rate": 0.0008235,
      "loss": 0.1938,
      "step": 35300
    },
    {
      "epoch": 0.177,
      "grad_norm": 1.7284014225006104,
      "learning_rate": 0.000823,
      "loss": 0.1997,
      "step": 35400
    },
    {
      "epoch": 0.1775,
      "grad_norm": 2.220036506652832,
      "learning_rate": 0.0008225,
      "loss": 0.2026,
      "step": 35500
    },
    {
      "epoch": 0.178,
      "grad_norm": 1.1461352109909058,
      "learning_rate": 0.0008219999999999999,
      "loss": 0.1911,
      "step": 35600
    },
    {
      "epoch": 0.1785,
      "grad_norm": 1.0035839080810547,
      "learning_rate": 0.0008215000000000001,
      "loss": 0.1952,
      "step": 35700
    },
    {
      "epoch": 0.179,
      "grad_norm": 1.6651129722595215,
      "learning_rate": 0.000821,
      "loss": 0.2006,
      "step": 35800
    },
    {
      "epoch": 0.1795,
      "grad_norm": 1.0035711526870728,
      "learning_rate": 0.0008205,
      "loss": 0.1952,
      "step": 35900
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.184370994567871,
      "learning_rate": 0.00082,
      "loss": 0.1969,
      "step": 36000
    },
    {
      "epoch": 0.1805,
      "grad_norm": 2.0692694187164307,
      "learning_rate": 0.0008195,
      "loss": 0.1955,
      "step": 36100
    },
    {
      "epoch": 0.181,
      "grad_norm": 0.8342360258102417,
      "learning_rate": 0.000819,
      "loss": 0.1909,
      "step": 36200
    },
    {
      "epoch": 0.1815,
      "grad_norm": 1.5093661546707153,
      "learning_rate": 0.0008185,
      "loss": 0.2005,
      "step": 36300
    },
    {
      "epoch": 0.182,
      "grad_norm": 1.3546031713485718,
      "learning_rate": 0.0008179999999999999,
      "loss": 0.1864,
      "step": 36400
    },
    {
      "epoch": 0.1825,
      "grad_norm": 1.8593316078186035,
      "learning_rate": 0.0008175,
      "loss": 0.2004,
      "step": 36500
    },
    {
      "epoch": 0.183,
      "grad_norm": 4.806891441345215,
      "learning_rate": 0.000817,
      "loss": 0.1908,
      "step": 36600
    },
    {
      "epoch": 0.1835,
      "grad_norm": 0.8226456046104431,
      "learning_rate": 0.0008165000000000001,
      "loss": 0.1916,
      "step": 36700
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.8455052375793457,
      "learning_rate": 0.000816,
      "loss": 0.1855,
      "step": 36800
    },
    {
      "epoch": 0.1845,
      "grad_norm": 1.2355563640594482,
      "learning_rate": 0.0008155,
      "loss": 0.1904,
      "step": 36900
    },
    {
      "epoch": 0.185,
      "grad_norm": 1.0640389919281006,
      "learning_rate": 0.000815,
      "loss": 0.197,
      "step": 37000
    },
    {
      "epoch": 0.1855,
      "grad_norm": 1.474684476852417,
      "learning_rate": 0.0008145,
      "loss": 0.202,
      "step": 37100
    },
    {
      "epoch": 0.186,
      "grad_norm": 1.0318242311477661,
      "learning_rate": 0.0008139999999999999,
      "loss": 0.194,
      "step": 37200
    },
    {
      "epoch": 0.1865,
      "grad_norm": 1.274810791015625,
      "learning_rate": 0.0008135,
      "loss": 0.2022,
      "step": 37300
    },
    {
      "epoch": 0.187,
      "grad_norm": 1.3166437149047852,
      "learning_rate": 0.0008129999999999999,
      "loss": 0.1869,
      "step": 37400
    },
    {
      "epoch": 0.1875,
      "grad_norm": 0.5899837613105774,
      "learning_rate": 0.0008125000000000001,
      "loss": 0.1878,
      "step": 37500
    },
    {
      "epoch": 0.188,
      "grad_norm": 1.0535411834716797,
      "learning_rate": 0.0008120000000000001,
      "loss": 0.1876,
      "step": 37600
    },
    {
      "epoch": 0.1885,
      "grad_norm": 1.0375338792800903,
      "learning_rate": 0.0008115,
      "loss": 0.19,
      "step": 37700
    },
    {
      "epoch": 0.189,
      "grad_norm": 0.8927537798881531,
      "learning_rate": 0.0008110000000000001,
      "loss": 0.1844,
      "step": 37800
    },
    {
      "epoch": 0.1895,
      "grad_norm": 0.9112972021102905,
      "learning_rate": 0.0008105,
      "loss": 0.1828,
      "step": 37900
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9444352984428406,
      "learning_rate": 0.0008100000000000001,
      "loss": 0.1857,
      "step": 38000
    },
    {
      "epoch": 0.1905,
      "grad_norm": 1.0199611186981201,
      "learning_rate": 0.0008095,
      "loss": 0.1822,
      "step": 38100
    },
    {
      "epoch": 0.191,
      "grad_norm": 1.1086788177490234,
      "learning_rate": 0.000809,
      "loss": 0.1801,
      "step": 38200
    },
    {
      "epoch": 0.1915,
      "grad_norm": 0.8440733551979065,
      "learning_rate": 0.0008085,
      "loss": 0.1809,
      "step": 38300
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.7209734320640564,
      "learning_rate": 0.000808,
      "loss": 0.1781,
      "step": 38400
    },
    {
      "epoch": 0.1925,
      "grad_norm": 1.1017894744873047,
      "learning_rate": 0.0008075000000000001,
      "loss": 0.1876,
      "step": 38500
    },
    {
      "epoch": 0.193,
      "grad_norm": 0.6813100576400757,
      "learning_rate": 0.0008070000000000001,
      "loss": 0.1964,
      "step": 38600
    },
    {
      "epoch": 0.1935,
      "grad_norm": 2.3109190464019775,
      "learning_rate": 0.0008065,
      "loss": 0.1945,
      "step": 38700
    },
    {
      "epoch": 0.194,
      "grad_norm": 1.1920535564422607,
      "learning_rate": 0.0008060000000000001,
      "loss": 0.1874,
      "step": 38800
    },
    {
      "epoch": 0.1945,
      "grad_norm": 1.0139449834823608,
      "learning_rate": 0.0008055,
      "loss": 0.1906,
      "step": 38900
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.7453034520149231,
      "learning_rate": 0.000805,
      "loss": 0.1807,
      "step": 39000
    },
    {
      "epoch": 0.1955,
      "grad_norm": 0.6670463681221008,
      "learning_rate": 0.0008045,
      "loss": 0.1767,
      "step": 39100
    },
    {
      "epoch": 0.196,
      "grad_norm": 1.423661708831787,
      "learning_rate": 0.000804,
      "loss": 0.1765,
      "step": 39200
    },
    {
      "epoch": 0.1965,
      "grad_norm": 0.643251895904541,
      "learning_rate": 0.0008035,
      "loss": 0.1785,
      "step": 39300
    },
    {
      "epoch": 0.197,
      "grad_norm": 1.2332186698913574,
      "learning_rate": 0.0008030000000000001,
      "loss": 0.1788,
      "step": 39400
    },
    {
      "epoch": 0.1975,
      "grad_norm": 1.226971983909607,
      "learning_rate": 0.0008025,
      "loss": 0.1893,
      "step": 39500
    },
    {
      "epoch": 0.198,
      "grad_norm": 1.7226746082305908,
      "learning_rate": 0.0008020000000000001,
      "loss": 0.1856,
      "step": 39600
    },
    {
      "epoch": 0.1985,
      "grad_norm": 1.0542858839035034,
      "learning_rate": 0.0008015,
      "loss": 0.1727,
      "step": 39700
    },
    {
      "epoch": 0.199,
      "grad_norm": 1.4002505540847778,
      "learning_rate": 0.0008010000000000001,
      "loss": 0.1828,
      "step": 39800
    },
    {
      "epoch": 0.1995,
      "grad_norm": 1.4812240600585938,
      "learning_rate": 0.0008005,
      "loss": 0.1806,
      "step": 39900
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8395201563835144,
      "learning_rate": 0.0008,
      "loss": 0.1755,
      "step": 40000
    },
    {
      "epoch": 0.2005,
      "grad_norm": 2.4945056438446045,
      "learning_rate": 0.0007995,
      "loss": 0.1782,
      "step": 40100
    },
    {
      "epoch": 0.201,
      "grad_norm": 0.685526430606842,
      "learning_rate": 0.000799,
      "loss": 0.1746,
      "step": 40200
    },
    {
      "epoch": 0.2015,
      "grad_norm": 1.7105779647827148,
      "learning_rate": 0.0007985000000000001,
      "loss": 0.1876,
      "step": 40300
    },
    {
      "epoch": 0.202,
      "grad_norm": 0.9024176001548767,
      "learning_rate": 0.0007980000000000001,
      "loss": 0.1772,
      "step": 40400
    },
    {
      "epoch": 0.2025,
      "grad_norm": 1.0358220338821411,
      "learning_rate": 0.0007975,
      "loss": 0.1875,
      "step": 40500
    },
    {
      "epoch": 0.203,
      "grad_norm": 0.9358763098716736,
      "learning_rate": 0.0007970000000000001,
      "loss": 0.178,
      "step": 40600
    },
    {
      "epoch": 0.2035,
      "grad_norm": 0.8522273898124695,
      "learning_rate": 0.0007965,
      "loss": 0.1735,
      "step": 40700
    },
    {
      "epoch": 0.204,
      "grad_norm": 1.0063583850860596,
      "learning_rate": 0.000796,
      "loss": 0.1805,
      "step": 40800
    },
    {
      "epoch": 0.2045,
      "grad_norm": 0.947521448135376,
      "learning_rate": 0.0007955,
      "loss": 0.1797,
      "step": 40900
    },
    {
      "epoch": 0.205,
      "grad_norm": 1.1289085149765015,
      "learning_rate": 0.000795,
      "loss": 0.1827,
      "step": 41000
    },
    {
      "epoch": 0.2055,
      "grad_norm": 0.9888177514076233,
      "learning_rate": 0.0007945,
      "loss": 0.1775,
      "step": 41100
    },
    {
      "epoch": 0.206,
      "grad_norm": 1.1289904117584229,
      "learning_rate": 0.0007940000000000001,
      "loss": 0.1864,
      "step": 41200
    },
    {
      "epoch": 0.2065,
      "grad_norm": 1.0054011344909668,
      "learning_rate": 0.0007935,
      "loss": 0.172,
      "step": 41300
    },
    {
      "epoch": 0.207,
      "grad_norm": 0.8711631894111633,
      "learning_rate": 0.0007930000000000001,
      "loss": 0.181,
      "step": 41400
    },
    {
      "epoch": 0.2075,
      "grad_norm": 1.0733085870742798,
      "learning_rate": 0.0007925,
      "loss": 0.1754,
      "step": 41500
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.8049861192703247,
      "learning_rate": 0.0007920000000000001,
      "loss": 0.1799,
      "step": 41600
    },
    {
      "epoch": 0.2085,
      "grad_norm": 1.3156856298446655,
      "learning_rate": 0.0007915,
      "loss": 0.1726,
      "step": 41700
    },
    {
      "epoch": 0.209,
      "grad_norm": 1.14285147190094,
      "learning_rate": 0.000791,
      "loss": 0.1802,
      "step": 41800
    },
    {
      "epoch": 0.2095,
      "grad_norm": 0.9447842240333557,
      "learning_rate": 0.0007905,
      "loss": 0.1756,
      "step": 41900
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0279295444488525,
      "learning_rate": 0.00079,
      "loss": 0.1805,
      "step": 42000
    },
    {
      "epoch": 0.2105,
      "grad_norm": 1.0157562494277954,
      "learning_rate": 0.0007894999999999999,
      "loss": 0.1779,
      "step": 42100
    },
    {
      "epoch": 0.211,
      "grad_norm": 1.3968994617462158,
      "learning_rate": 0.0007890000000000001,
      "loss": 0.1819,
      "step": 42200
    },
    {
      "epoch": 0.2115,
      "grad_norm": 1.8941478729248047,
      "learning_rate": 0.0007885,
      "loss": 0.1741,
      "step": 42300
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.740360677242279,
      "learning_rate": 0.0007880000000000001,
      "loss": 0.179,
      "step": 42400
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.9300795793533325,
      "learning_rate": 0.0007875,
      "loss": 0.1721,
      "step": 42500
    },
    {
      "epoch": 0.213,
      "grad_norm": 1.1957988739013672,
      "learning_rate": 0.000787,
      "loss": 0.1763,
      "step": 42600
    },
    {
      "epoch": 0.2135,
      "grad_norm": 0.9539681673049927,
      "learning_rate": 0.0007865,
      "loss": 0.1773,
      "step": 42700
    },
    {
      "epoch": 0.214,
      "grad_norm": 1.1966164112091064,
      "learning_rate": 0.000786,
      "loss": 0.1689,
      "step": 42800
    },
    {
      "epoch": 0.2145,
      "grad_norm": 0.852078914642334,
      "learning_rate": 0.0007855,
      "loss": 0.1739,
      "step": 42900
    },
    {
      "epoch": 0.215,
      "grad_norm": 1.3892775774002075,
      "learning_rate": 0.000785,
      "loss": 0.1749,
      "step": 43000
    },
    {
      "epoch": 0.2155,
      "grad_norm": 0.977335512638092,
      "learning_rate": 0.0007845,
      "loss": 0.1774,
      "step": 43100
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.7078301310539246,
      "learning_rate": 0.0007840000000000001,
      "loss": 0.1787,
      "step": 43200
    },
    {
      "epoch": 0.2165,
      "grad_norm": 0.965630054473877,
      "learning_rate": 0.0007835,
      "loss": 0.179,
      "step": 43300
    },
    {
      "epoch": 0.217,
      "grad_norm": 0.9170293211936951,
      "learning_rate": 0.0007830000000000001,
      "loss": 0.1619,
      "step": 43400
    },
    {
      "epoch": 0.2175,
      "grad_norm": 1.5352846384048462,
      "learning_rate": 0.0007825,
      "loss": 0.1655,
      "step": 43500
    },
    {
      "epoch": 0.218,
      "grad_norm": 1.4641368389129639,
      "learning_rate": 0.000782,
      "loss": 0.1727,
      "step": 43600
    },
    {
      "epoch": 0.2185,
      "grad_norm": 1.1905194520950317,
      "learning_rate": 0.0007815,
      "loss": 0.1683,
      "step": 43700
    },
    {
      "epoch": 0.219,
      "grad_norm": 0.9352644681930542,
      "learning_rate": 0.000781,
      "loss": 0.1652,
      "step": 43800
    },
    {
      "epoch": 0.2195,
      "grad_norm": 1.0229827165603638,
      "learning_rate": 0.0007804999999999999,
      "loss": 0.1755,
      "step": 43900
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0085821151733398,
      "learning_rate": 0.0007800000000000001,
      "loss": 0.1715,
      "step": 44000
    },
    {
      "epoch": 0.2205,
      "grad_norm": 3.0200724601745605,
      "learning_rate": 0.0007795,
      "loss": 0.1607,
      "step": 44100
    },
    {
      "epoch": 0.221,
      "grad_norm": 0.7657324075698853,
      "learning_rate": 0.0007790000000000001,
      "loss": 0.1728,
      "step": 44200
    },
    {
      "epoch": 0.2215,
      "grad_norm": 1.2001996040344238,
      "learning_rate": 0.0007785,
      "loss": 0.1713,
      "step": 44300
    },
    {
      "epoch": 0.222,
      "grad_norm": 1.543410301208496,
      "learning_rate": 0.000778,
      "loss": 0.1758,
      "step": 44400
    },
    {
      "epoch": 0.2225,
      "grad_norm": 0.9655971527099609,
      "learning_rate": 0.0007775,
      "loss": 0.1585,
      "step": 44500
    },
    {
      "epoch": 0.223,
      "grad_norm": 3.814441442489624,
      "learning_rate": 0.000777,
      "loss": 0.1681,
      "step": 44600
    },
    {
      "epoch": 0.2235,
      "grad_norm": 2.0931649208068848,
      "learning_rate": 0.0007765,
      "loss": 0.1721,
      "step": 44700
    },
    {
      "epoch": 0.224,
      "grad_norm": 1.5027815103530884,
      "learning_rate": 0.000776,
      "loss": 0.168,
      "step": 44800
    },
    {
      "epoch": 0.2245,
      "grad_norm": 2.169065237045288,
      "learning_rate": 0.0007754999999999999,
      "loss": 0.1656,
      "step": 44900
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.367113471031189,
      "learning_rate": 0.0007750000000000001,
      "loss": 0.164,
      "step": 45000
    },
    {
      "epoch": 0.2255,
      "grad_norm": 1.0590142011642456,
      "learning_rate": 0.0007745,
      "loss": 0.1866,
      "step": 45100
    },
    {
      "epoch": 0.226,
      "grad_norm": 0.9832817912101746,
      "learning_rate": 0.0007740000000000001,
      "loss": 0.1646,
      "step": 45200
    },
    {
      "epoch": 0.2265,
      "grad_norm": 0.9458784461021423,
      "learning_rate": 0.0007735,
      "loss": 0.1706,
      "step": 45300
    },
    {
      "epoch": 0.227,
      "grad_norm": 1.0375490188598633,
      "learning_rate": 0.000773,
      "loss": 0.1612,
      "step": 45400
    },
    {
      "epoch": 0.2275,
      "grad_norm": 1.3864988088607788,
      "learning_rate": 0.0007725,
      "loss": 0.176,
      "step": 45500
    },
    {
      "epoch": 0.228,
      "grad_norm": 1.4155303239822388,
      "learning_rate": 0.000772,
      "loss": 0.1717,
      "step": 45600
    },
    {
      "epoch": 0.2285,
      "grad_norm": 1.377301573753357,
      "learning_rate": 0.0007714999999999999,
      "loss": 0.1644,
      "step": 45700
    },
    {
      "epoch": 0.229,
      "grad_norm": 1.0888571739196777,
      "learning_rate": 0.000771,
      "loss": 0.1607,
      "step": 45800
    },
    {
      "epoch": 0.2295,
      "grad_norm": 0.9165117144584656,
      "learning_rate": 0.0007705,
      "loss": 0.1722,
      "step": 45900
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.0378113985061646,
      "learning_rate": 0.0007700000000000001,
      "loss": 0.1566,
      "step": 46000
    },
    {
      "epoch": 0.2305,
      "grad_norm": 2.649554967880249,
      "learning_rate": 0.0007695,
      "loss": 0.1622,
      "step": 46100
    },
    {
      "epoch": 0.231,
      "grad_norm": 0.9136324524879456,
      "learning_rate": 0.000769,
      "loss": 0.1694,
      "step": 46200
    },
    {
      "epoch": 0.2315,
      "grad_norm": 4.584300994873047,
      "learning_rate": 0.0007685,
      "loss": 0.1589,
      "step": 46300
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.8834588527679443,
      "learning_rate": 0.000768,
      "loss": 0.1583,
      "step": 46400
    },
    {
      "epoch": 0.2325,
      "grad_norm": 0.9176506996154785,
      "learning_rate": 0.0007675,
      "loss": 0.1636,
      "step": 46500
    },
    {
      "epoch": 0.233,
      "grad_norm": 0.9634557962417603,
      "learning_rate": 0.000767,
      "loss": 0.1683,
      "step": 46600
    },
    {
      "epoch": 0.2335,
      "grad_norm": 1.1172267198562622,
      "learning_rate": 0.0007664999999999999,
      "loss": 0.17,
      "step": 46700
    },
    {
      "epoch": 0.234,
      "grad_norm": 1.6818562746047974,
      "learning_rate": 0.0007660000000000001,
      "loss": 0.1639,
      "step": 46800
    },
    {
      "epoch": 0.2345,
      "grad_norm": 0.7254186868667603,
      "learning_rate": 0.0007655,
      "loss": 0.1686,
      "step": 46900
    },
    {
      "epoch": 0.235,
      "grad_norm": 1.0454447269439697,
      "learning_rate": 0.0007650000000000001,
      "loss": 0.1585,
      "step": 47000
    },
    {
      "epoch": 0.2355,
      "grad_norm": 0.9580823183059692,
      "learning_rate": 0.0007645,
      "loss": 0.1571,
      "step": 47100
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.6099129319190979,
      "learning_rate": 0.000764,
      "loss": 0.1634,
      "step": 47200
    },
    {
      "epoch": 0.2365,
      "grad_norm": 0.7451627850532532,
      "learning_rate": 0.0007635,
      "loss": 0.1605,
      "step": 47300
    },
    {
      "epoch": 0.237,
      "grad_norm": 0.6651568412780762,
      "learning_rate": 0.000763,
      "loss": 0.1703,
      "step": 47400
    },
    {
      "epoch": 0.2375,
      "grad_norm": 1.2261412143707275,
      "learning_rate": 0.0007624999999999999,
      "loss": 0.1619,
      "step": 47500
    },
    {
      "epoch": 0.238,
      "grad_norm": 1.3452223539352417,
      "learning_rate": 0.000762,
      "loss": 0.1597,
      "step": 47600
    },
    {
      "epoch": 0.2385,
      "grad_norm": 0.8144148588180542,
      "learning_rate": 0.0007615,
      "loss": 0.1588,
      "step": 47700
    },
    {
      "epoch": 0.239,
      "grad_norm": 1.8318592309951782,
      "learning_rate": 0.0007610000000000001,
      "loss": 0.1633,
      "step": 47800
    },
    {
      "epoch": 0.2395,
      "grad_norm": 1.6004054546356201,
      "learning_rate": 0.0007605,
      "loss": 0.1595,
      "step": 47900
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7175245881080627,
      "learning_rate": 0.00076,
      "loss": 0.1513,
      "step": 48000
    },
    {
      "epoch": 0.2405,
      "grad_norm": 5.914588928222656,
      "learning_rate": 0.0007595,
      "loss": 0.1586,
      "step": 48100
    },
    {
      "epoch": 0.241,
      "grad_norm": 0.42815664410591125,
      "learning_rate": 0.000759,
      "loss": 0.1636,
      "step": 48200
    },
    {
      "epoch": 0.2415,
      "grad_norm": 0.7499333024024963,
      "learning_rate": 0.0007585,
      "loss": 0.159,
      "step": 48300
    },
    {
      "epoch": 0.242,
      "grad_norm": 0.8119515776634216,
      "learning_rate": 0.000758,
      "loss": 0.1562,
      "step": 48400
    },
    {
      "epoch": 0.2425,
      "grad_norm": 0.8181039690971375,
      "learning_rate": 0.0007574999999999999,
      "loss": 0.1531,
      "step": 48500
    },
    {
      "epoch": 0.243,
      "grad_norm": 0.6589792370796204,
      "learning_rate": 0.000757,
      "loss": 0.1525,
      "step": 48600
    },
    {
      "epoch": 0.2435,
      "grad_norm": 1.1454373598098755,
      "learning_rate": 0.0007565,
      "loss": 0.1574,
      "step": 48700
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.7605599164962769,
      "learning_rate": 0.000756,
      "loss": 0.1566,
      "step": 48800
    },
    {
      "epoch": 0.2445,
      "grad_norm": 1.0617053508758545,
      "learning_rate": 0.0007555,
      "loss": 0.1688,
      "step": 48900
    },
    {
      "epoch": 0.245,
      "grad_norm": 0.6083104610443115,
      "learning_rate": 0.000755,
      "loss": 0.1614,
      "step": 49000
    },
    {
      "epoch": 0.2455,
      "grad_norm": 1.4572652578353882,
      "learning_rate": 0.0007545,
      "loss": 0.1548,
      "step": 49100
    },
    {
      "epoch": 0.246,
      "grad_norm": 0.7619720697402954,
      "learning_rate": 0.000754,
      "loss": 0.1656,
      "step": 49200
    },
    {
      "epoch": 0.2465,
      "grad_norm": 1.3005492687225342,
      "learning_rate": 0.0007534999999999999,
      "loss": 0.1506,
      "step": 49300
    },
    {
      "epoch": 0.247,
      "grad_norm": 1.1836144924163818,
      "learning_rate": 0.000753,
      "loss": 0.1449,
      "step": 49400
    },
    {
      "epoch": 0.2475,
      "grad_norm": 3.446016311645508,
      "learning_rate": 0.0007524999999999999,
      "loss": 0.1574,
      "step": 49500
    },
    {
      "epoch": 0.248,
      "grad_norm": 1.203588604927063,
      "learning_rate": 0.0007520000000000001,
      "loss": 0.1623,
      "step": 49600
    },
    {
      "epoch": 0.2485,
      "grad_norm": 0.8148259520530701,
      "learning_rate": 0.0007515,
      "loss": 0.1585,
      "step": 49700
    },
    {
      "epoch": 0.249,
      "grad_norm": 1.1251938343048096,
      "learning_rate": 0.000751,
      "loss": 0.146,
      "step": 49800
    },
    {
      "epoch": 0.2495,
      "grad_norm": 1.2971431016921997,
      "learning_rate": 0.0007505,
      "loss": 0.1627,
      "step": 49900
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7486809492111206,
      "learning_rate": 0.00075,
      "loss": 0.1632,
      "step": 50000
    },
    {
      "epoch": 0.2505,
      "grad_norm": 0.6840145587921143,
      "learning_rate": 0.0007495000000000001,
      "loss": 0.1554,
      "step": 50100
    },
    {
      "epoch": 0.251,
      "grad_norm": 1.0453495979309082,
      "learning_rate": 0.000749,
      "loss": 0.1503,
      "step": 50200
    },
    {
      "epoch": 0.2515,
      "grad_norm": 0.8604412078857422,
      "learning_rate": 0.0007485,
      "loss": 0.1519,
      "step": 50300
    },
    {
      "epoch": 0.252,
      "grad_norm": 1.0067646503448486,
      "learning_rate": 0.000748,
      "loss": 0.1489,
      "step": 50400
    },
    {
      "epoch": 0.2525,
      "grad_norm": 0.9309881925582886,
      "learning_rate": 0.0007475000000000001,
      "loss": 0.1517,
      "step": 50500
    },
    {
      "epoch": 0.253,
      "grad_norm": 0.7939937114715576,
      "learning_rate": 0.000747,
      "loss": 0.1441,
      "step": 50600
    },
    {
      "epoch": 0.2535,
      "grad_norm": 0.6950222253799438,
      "learning_rate": 0.0007465000000000001,
      "loss": 0.1508,
      "step": 50700
    },
    {
      "epoch": 0.254,
      "grad_norm": 0.6599935293197632,
      "learning_rate": 0.000746,
      "loss": 0.1582,
      "step": 50800
    },
    {
      "epoch": 0.2545,
      "grad_norm": 0.8070138692855835,
      "learning_rate": 0.0007455000000000001,
      "loss": 0.1506,
      "step": 50900
    },
    {
      "epoch": 0.255,
      "grad_norm": 2.9357998371124268,
      "learning_rate": 0.000745,
      "loss": 0.1575,
      "step": 51000
    },
    {
      "epoch": 0.2555,
      "grad_norm": 0.8091779947280884,
      "learning_rate": 0.0007445,
      "loss": 0.1529,
      "step": 51100
    },
    {
      "epoch": 0.256,
      "grad_norm": 1.4779375791549683,
      "learning_rate": 0.000744,
      "loss": 0.149,
      "step": 51200
    },
    {
      "epoch": 0.2565,
      "grad_norm": 0.6975380778312683,
      "learning_rate": 0.0007435,
      "loss": 0.1568,
      "step": 51300
    },
    {
      "epoch": 0.257,
      "grad_norm": 1.4785059690475464,
      "learning_rate": 0.0007430000000000001,
      "loss": 0.1538,
      "step": 51400
    },
    {
      "epoch": 0.2575,
      "grad_norm": 1.0947521924972534,
      "learning_rate": 0.0007425000000000001,
      "loss": 0.1511,
      "step": 51500
    },
    {
      "epoch": 0.258,
      "grad_norm": 1.5066413879394531,
      "learning_rate": 0.000742,
      "loss": 0.1563,
      "step": 51600
    },
    {
      "epoch": 0.2585,
      "grad_norm": 0.8895684480667114,
      "learning_rate": 0.0007415000000000001,
      "loss": 0.1542,
      "step": 51700
    },
    {
      "epoch": 0.259,
      "grad_norm": 1.4817073345184326,
      "learning_rate": 0.000741,
      "loss": 0.1502,
      "step": 51800
    },
    {
      "epoch": 0.2595,
      "grad_norm": 2.0291483402252197,
      "learning_rate": 0.0007405000000000001,
      "loss": 0.15,
      "step": 51900
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1655797958374023,
      "learning_rate": 0.00074,
      "loss": 0.1522,
      "step": 52000
    },
    {
      "epoch": 0.2605,
      "grad_norm": 0.850309431552887,
      "learning_rate": 0.0007395,
      "loss": 0.1484,
      "step": 52100
    },
    {
      "epoch": 0.261,
      "grad_norm": 1.8570506572723389,
      "learning_rate": 0.000739,
      "loss": 0.1628,
      "step": 52200
    },
    {
      "epoch": 0.2615,
      "grad_norm": 0.714566707611084,
      "learning_rate": 0.0007385,
      "loss": 0.1514,
      "step": 52300
    },
    {
      "epoch": 0.262,
      "grad_norm": 0.9615573883056641,
      "learning_rate": 0.000738,
      "loss": 0.159,
      "step": 52400
    },
    {
      "epoch": 0.2625,
      "grad_norm": 0.8237669467926025,
      "learning_rate": 0.0007375000000000001,
      "loss": 0.1447,
      "step": 52500
    },
    {
      "epoch": 0.263,
      "grad_norm": 0.7926157116889954,
      "learning_rate": 0.000737,
      "loss": 0.1505,
      "step": 52600
    },
    {
      "epoch": 0.2635,
      "grad_norm": 0.8950397372245789,
      "learning_rate": 0.0007365000000000001,
      "loss": 0.1486,
      "step": 52700
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.8430452942848206,
      "learning_rate": 0.000736,
      "loss": 0.1486,
      "step": 52800
    },
    {
      "epoch": 0.2645,
      "grad_norm": 0.8833858370780945,
      "learning_rate": 0.0007355,
      "loss": 0.1539,
      "step": 52900
    },
    {
      "epoch": 0.265,
      "grad_norm": 0.9664725065231323,
      "learning_rate": 0.000735,
      "loss": 0.1521,
      "step": 53000
    },
    {
      "epoch": 0.2655,
      "grad_norm": 1.0616809129714966,
      "learning_rate": 0.0007345,
      "loss": 0.1506,
      "step": 53100
    },
    {
      "epoch": 0.266,
      "grad_norm": 1.4667811393737793,
      "learning_rate": 0.000734,
      "loss": 0.1588,
      "step": 53200
    },
    {
      "epoch": 0.2665,
      "grad_norm": 0.5646447539329529,
      "learning_rate": 0.0007335000000000001,
      "loss": 0.1492,
      "step": 53300
    },
    {
      "epoch": 0.267,
      "grad_norm": 1.1709057092666626,
      "learning_rate": 0.000733,
      "loss": 0.1434,
      "step": 53400
    },
    {
      "epoch": 0.2675,
      "grad_norm": 1.380683183670044,
      "learning_rate": 0.0007325000000000001,
      "loss": 0.1452,
      "step": 53500
    },
    {
      "epoch": 0.268,
      "grad_norm": 1.0938118696212769,
      "learning_rate": 0.000732,
      "loss": 0.1446,
      "step": 53600
    },
    {
      "epoch": 0.2685,
      "grad_norm": 4.407830715179443,
      "learning_rate": 0.0007315,
      "loss": 0.1418,
      "step": 53700
    },
    {
      "epoch": 0.269,
      "grad_norm": 1.0208011865615845,
      "learning_rate": 0.000731,
      "loss": 0.1479,
      "step": 53800
    },
    {
      "epoch": 0.2695,
      "grad_norm": 1.0853501558303833,
      "learning_rate": 0.0007305,
      "loss": 0.1498,
      "step": 53900
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.2151124477386475,
      "learning_rate": 0.00073,
      "loss": 0.149,
      "step": 54000
    },
    {
      "epoch": 0.2705,
      "grad_norm": 0.6658626794815063,
      "learning_rate": 0.0007295,
      "loss": 0.1441,
      "step": 54100
    },
    {
      "epoch": 0.271,
      "grad_norm": 0.7954118847846985,
      "learning_rate": 0.000729,
      "loss": 0.1425,
      "step": 54200
    },
    {
      "epoch": 0.2715,
      "grad_norm": 1.098461389541626,
      "learning_rate": 0.0007285000000000001,
      "loss": 0.1449,
      "step": 54300
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.9165052175521851,
      "learning_rate": 0.000728,
      "loss": 0.1543,
      "step": 54400
    },
    {
      "epoch": 0.2725,
      "grad_norm": 1.5737195014953613,
      "learning_rate": 0.0007275000000000001,
      "loss": 0.1515,
      "step": 54500
    },
    {
      "epoch": 0.273,
      "grad_norm": 0.7152983546257019,
      "learning_rate": 0.000727,
      "loss": 0.1571,
      "step": 54600
    },
    {
      "epoch": 0.2735,
      "grad_norm": 0.5842479467391968,
      "learning_rate": 0.0007265,
      "loss": 0.1504,
      "step": 54700
    },
    {
      "epoch": 0.274,
      "grad_norm": 1.111961841583252,
      "learning_rate": 0.000726,
      "loss": 0.1426,
      "step": 54800
    },
    {
      "epoch": 0.2745,
      "grad_norm": 0.7388787865638733,
      "learning_rate": 0.0007255,
      "loss": 0.1561,
      "step": 54900
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.9886196851730347,
      "learning_rate": 0.000725,
      "loss": 0.1518,
      "step": 55000
    },
    {
      "epoch": 0.2755,
      "grad_norm": 0.5616511702537537,
      "learning_rate": 0.0007245000000000001,
      "loss": 0.1489,
      "step": 55100
    },
    {
      "epoch": 0.276,
      "grad_norm": 9.589142799377441,
      "learning_rate": 0.000724,
      "loss": 0.1457,
      "step": 55200
    },
    {
      "epoch": 0.2765,
      "grad_norm": 2.0797057151794434,
      "learning_rate": 0.0007235000000000001,
      "loss": 0.1488,
      "step": 55300
    },
    {
      "epoch": 0.277,
      "grad_norm": 0.7451168298721313,
      "learning_rate": 0.000723,
      "loss": 0.1497,
      "step": 55400
    },
    {
      "epoch": 0.2775,
      "grad_norm": 1.3374717235565186,
      "learning_rate": 0.0007225,
      "loss": 0.1489,
      "step": 55500
    },
    {
      "epoch": 0.278,
      "grad_norm": 0.6476002335548401,
      "learning_rate": 0.000722,
      "loss": 0.1446,
      "step": 55600
    },
    {
      "epoch": 0.2785,
      "grad_norm": 1.1622400283813477,
      "learning_rate": 0.0007215,
      "loss": 0.1467,
      "step": 55700
    },
    {
      "epoch": 0.279,
      "grad_norm": 0.9555070996284485,
      "learning_rate": 0.000721,
      "loss": 0.1415,
      "step": 55800
    },
    {
      "epoch": 0.2795,
      "grad_norm": 1.067880392074585,
      "learning_rate": 0.0007205,
      "loss": 0.1425,
      "step": 55900
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7585445046424866,
      "learning_rate": 0.0007199999999999999,
      "loss": 0.1472,
      "step": 56000
    },
    {
      "epoch": 0.2805,
      "grad_norm": 1.994367003440857,
      "learning_rate": 0.0007195000000000001,
      "loss": 0.1422,
      "step": 56100
    },
    {
      "epoch": 0.281,
      "grad_norm": 0.8206411004066467,
      "learning_rate": 0.000719,
      "loss": 0.1446,
      "step": 56200
    },
    {
      "epoch": 0.2815,
      "grad_norm": 1.1932549476623535,
      "learning_rate": 0.0007185000000000001,
      "loss": 0.143,
      "step": 56300
    },
    {
      "epoch": 0.282,
      "grad_norm": 1.0282738208770752,
      "learning_rate": 0.000718,
      "loss": 0.1438,
      "step": 56400
    },
    {
      "epoch": 0.2825,
      "grad_norm": 0.7928071022033691,
      "learning_rate": 0.0007175,
      "loss": 0.1451,
      "step": 56500
    },
    {
      "epoch": 0.283,
      "grad_norm": 0.4260195195674896,
      "learning_rate": 0.000717,
      "loss": 0.1495,
      "step": 56600
    },
    {
      "epoch": 0.2835,
      "grad_norm": 0.873577356338501,
      "learning_rate": 0.0007165,
      "loss": 0.1431,
      "step": 56700
    },
    {
      "epoch": 0.284,
      "grad_norm": 1.054919719696045,
      "learning_rate": 0.000716,
      "loss": 0.1334,
      "step": 56800
    },
    {
      "epoch": 0.2845,
      "grad_norm": 0.8846709132194519,
      "learning_rate": 0.0007155,
      "loss": 0.1371,
      "step": 56900
    },
    {
      "epoch": 0.285,
      "grad_norm": 0.45615026354789734,
      "learning_rate": 0.000715,
      "loss": 0.1399,
      "step": 57000
    },
    {
      "epoch": 0.2855,
      "grad_norm": 0.49856996536254883,
      "learning_rate": 0.0007145000000000001,
      "loss": 0.1394,
      "step": 57100
    },
    {
      "epoch": 0.286,
      "grad_norm": 0.7776841521263123,
      "learning_rate": 0.000714,
      "loss": 0.1396,
      "step": 57200
    },
    {
      "epoch": 0.2865,
      "grad_norm": 1.817234754562378,
      "learning_rate": 0.0007135,
      "loss": 0.1394,
      "step": 57300
    },
    {
      "epoch": 0.287,
      "grad_norm": 0.8022769689559937,
      "learning_rate": 0.000713,
      "loss": 0.1418,
      "step": 57400
    },
    {
      "epoch": 0.2875,
      "grad_norm": 0.8963757753372192,
      "learning_rate": 0.0007125,
      "loss": 0.1466,
      "step": 57500
    },
    {
      "epoch": 0.288,
      "grad_norm": 4.011616230010986,
      "learning_rate": 0.000712,
      "loss": 0.1379,
      "step": 57600
    },
    {
      "epoch": 0.2885,
      "grad_norm": 2.2720115184783936,
      "learning_rate": 0.0007115,
      "loss": 0.1461,
      "step": 57700
    },
    {
      "epoch": 0.289,
      "grad_norm": 1.3537733554840088,
      "learning_rate": 0.0007109999999999999,
      "loss": 0.1353,
      "step": 57800
    },
    {
      "epoch": 0.2895,
      "grad_norm": 1.0283935070037842,
      "learning_rate": 0.0007105000000000001,
      "loss": 0.1418,
      "step": 57900
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8711853623390198,
      "learning_rate": 0.00071,
      "loss": 0.1375,
      "step": 58000
    },
    {
      "epoch": 0.2905,
      "grad_norm": 0.812437117099762,
      "learning_rate": 0.0007095000000000001,
      "loss": 0.1442,
      "step": 58100
    },
    {
      "epoch": 0.291,
      "grad_norm": 0.8270577192306519,
      "learning_rate": 0.000709,
      "loss": 0.1411,
      "step": 58200
    },
    {
      "epoch": 0.2915,
      "grad_norm": 0.9091202020645142,
      "learning_rate": 0.0007085,
      "loss": 0.1406,
      "step": 58300
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.9206516742706299,
      "learning_rate": 0.000708,
      "loss": 0.1398,
      "step": 58400
    },
    {
      "epoch": 0.2925,
      "grad_norm": 0.7024865746498108,
      "learning_rate": 0.0007075,
      "loss": 0.1375,
      "step": 58500
    },
    {
      "epoch": 0.293,
      "grad_norm": 0.6703580021858215,
      "learning_rate": 0.000707,
      "loss": 0.1429,
      "step": 58600
    },
    {
      "epoch": 0.2935,
      "grad_norm": 4.753198146820068,
      "learning_rate": 0.0007065,
      "loss": 0.1451,
      "step": 58700
    },
    {
      "epoch": 0.294,
      "grad_norm": 1.6022402048110962,
      "learning_rate": 0.0007059999999999999,
      "loss": 0.1378,
      "step": 58800
    },
    {
      "epoch": 0.2945,
      "grad_norm": 3.7894909381866455,
      "learning_rate": 0.0007055000000000001,
      "loss": 0.1392,
      "step": 58900
    },
    {
      "epoch": 0.295,
      "grad_norm": 0.48355260491371155,
      "learning_rate": 0.000705,
      "loss": 0.145,
      "step": 59000
    },
    {
      "epoch": 0.2955,
      "grad_norm": 1.1303684711456299,
      "learning_rate": 0.0007045,
      "loss": 0.1347,
      "step": 59100
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.6824121475219727,
      "learning_rate": 0.000704,
      "loss": 0.1306,
      "step": 59200
    },
    {
      "epoch": 0.2965,
      "grad_norm": 0.9802485108375549,
      "learning_rate": 0.0007035,
      "loss": 0.1338,
      "step": 59300
    },
    {
      "epoch": 0.297,
      "grad_norm": 1.3058574199676514,
      "learning_rate": 0.000703,
      "loss": 0.1329,
      "step": 59400
    },
    {
      "epoch": 0.2975,
      "grad_norm": 0.7491982579231262,
      "learning_rate": 0.0007025,
      "loss": 0.1326,
      "step": 59500
    },
    {
      "epoch": 0.298,
      "grad_norm": 1.6020911931991577,
      "learning_rate": 0.0007019999999999999,
      "loss": 0.1431,
      "step": 59600
    },
    {
      "epoch": 0.2985,
      "grad_norm": 0.8427903652191162,
      "learning_rate": 0.0007015,
      "loss": 0.1403,
      "step": 59700
    },
    {
      "epoch": 0.299,
      "grad_norm": 0.9188587665557861,
      "learning_rate": 0.000701,
      "loss": 0.1388,
      "step": 59800
    },
    {
      "epoch": 0.2995,
      "grad_norm": 1.6000442504882812,
      "learning_rate": 0.0007005000000000001,
      "loss": 0.1356,
      "step": 59900
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5208260416984558,
      "learning_rate": 0.0007,
      "loss": 0.1259,
      "step": 60000
    },
    {
      "epoch": 0.3005,
      "grad_norm": 1.2357314825057983,
      "learning_rate": 0.0006995,
      "loss": 0.1334,
      "step": 60100
    },
    {
      "epoch": 0.301,
      "grad_norm": 0.718100905418396,
      "learning_rate": 0.000699,
      "loss": 0.1334,
      "step": 60200
    },
    {
      "epoch": 0.3015,
      "grad_norm": 0.8331184387207031,
      "learning_rate": 0.0006985,
      "loss": 0.1416,
      "step": 60300
    },
    {
      "epoch": 0.302,
      "grad_norm": 1.1153305768966675,
      "learning_rate": 0.0006979999999999999,
      "loss": 0.1344,
      "step": 60400
    },
    {
      "epoch": 0.3025,
      "grad_norm": 0.852735698223114,
      "learning_rate": 0.0006975,
      "loss": 0.1422,
      "step": 60500
    },
    {
      "epoch": 0.303,
      "grad_norm": 1.3291999101638794,
      "learning_rate": 0.0006969999999999999,
      "loss": 0.1387,
      "step": 60600
    },
    {
      "epoch": 0.3035,
      "grad_norm": 1.2762728929519653,
      "learning_rate": 0.0006965000000000001,
      "loss": 0.135,
      "step": 60700
    },
    {
      "epoch": 0.304,
      "grad_norm": 1.0029975175857544,
      "learning_rate": 0.000696,
      "loss": 0.1389,
      "step": 60800
    },
    {
      "epoch": 0.3045,
      "grad_norm": 1.0583592653274536,
      "learning_rate": 0.0006955,
      "loss": 0.1348,
      "step": 60900
    },
    {
      "epoch": 0.305,
      "grad_norm": 0.6311802268028259,
      "learning_rate": 0.000695,
      "loss": 0.1346,
      "step": 61000
    },
    {
      "epoch": 0.3055,
      "grad_norm": 2.952791452407837,
      "learning_rate": 0.0006945,
      "loss": 0.1328,
      "step": 61100
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.7664200067520142,
      "learning_rate": 0.000694,
      "loss": 0.1348,
      "step": 61200
    },
    {
      "epoch": 0.3065,
      "grad_norm": 1.1230387687683105,
      "learning_rate": 0.0006935,
      "loss": 0.1398,
      "step": 61300
    },
    {
      "epoch": 0.307,
      "grad_norm": 0.6299355626106262,
      "learning_rate": 0.0006929999999999999,
      "loss": 0.1272,
      "step": 61400
    },
    {
      "epoch": 0.3075,
      "grad_norm": 0.5937413573265076,
      "learning_rate": 0.0006925,
      "loss": 0.1363,
      "step": 61500
    },
    {
      "epoch": 0.308,
      "grad_norm": 1.2448480129241943,
      "learning_rate": 0.000692,
      "loss": 0.1384,
      "step": 61600
    },
    {
      "epoch": 0.3085,
      "grad_norm": 0.9336912035942078,
      "learning_rate": 0.0006915000000000001,
      "loss": 0.1363,
      "step": 61700
    },
    {
      "epoch": 0.309,
      "grad_norm": 0.80271315574646,
      "learning_rate": 0.000691,
      "loss": 0.1339,
      "step": 61800
    },
    {
      "epoch": 0.3095,
      "grad_norm": 0.6889151930809021,
      "learning_rate": 0.0006905,
      "loss": 0.1364,
      "step": 61900
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5914427042007446,
      "learning_rate": 0.00069,
      "loss": 0.1401,
      "step": 62000
    },
    {
      "epoch": 0.3105,
      "grad_norm": 0.7353571653366089,
      "learning_rate": 0.0006895,
      "loss": 0.1331,
      "step": 62100
    },
    {
      "epoch": 0.311,
      "grad_norm": 0.7989123463630676,
      "learning_rate": 0.0006889999999999999,
      "loss": 0.1349,
      "step": 62200
    },
    {
      "epoch": 0.3115,
      "grad_norm": 0.7580326795578003,
      "learning_rate": 0.0006885,
      "loss": 0.1314,
      "step": 62300
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.6871103644371033,
      "learning_rate": 0.0006879999999999999,
      "loss": 0.1314,
      "step": 62400
    },
    {
      "epoch": 0.3125,
      "grad_norm": 12.45051097869873,
      "learning_rate": 0.0006875,
      "loss": 0.1351,
      "step": 62500
    },
    {
      "epoch": 0.313,
      "grad_norm": 0.6535751819610596,
      "learning_rate": 0.0006870000000000001,
      "loss": 0.1341,
      "step": 62600
    },
    {
      "epoch": 0.3135,
      "grad_norm": 0.8524852395057678,
      "learning_rate": 0.0006865,
      "loss": 0.1277,
      "step": 62700
    },
    {
      "epoch": 0.314,
      "grad_norm": 0.45792558789253235,
      "learning_rate": 0.0006860000000000001,
      "loss": 0.1341,
      "step": 62800
    },
    {
      "epoch": 0.3145,
      "grad_norm": 0.8871792554855347,
      "learning_rate": 0.0006855,
      "loss": 0.1316,
      "step": 62900
    },
    {
      "epoch": 0.315,
      "grad_norm": 0.5539901256561279,
      "learning_rate": 0.0006850000000000001,
      "loss": 0.1309,
      "step": 63000
    },
    {
      "epoch": 0.3155,
      "grad_norm": 16.510847091674805,
      "learning_rate": 0.0006845,
      "loss": 0.1297,
      "step": 63100
    },
    {
      "epoch": 0.316,
      "grad_norm": 1.7059088945388794,
      "learning_rate": 0.000684,
      "loss": 0.1303,
      "step": 63200
    },
    {
      "epoch": 0.3165,
      "grad_norm": 1.0142526626586914,
      "learning_rate": 0.0006835,
      "loss": 0.1323,
      "step": 63300
    },
    {
      "epoch": 0.317,
      "grad_norm": 0.9442932605743408,
      "learning_rate": 0.000683,
      "loss": 0.1272,
      "step": 63400
    },
    {
      "epoch": 0.3175,
      "grad_norm": 0.83927321434021,
      "learning_rate": 0.0006825000000000001,
      "loss": 0.1302,
      "step": 63500
    },
    {
      "epoch": 0.318,
      "grad_norm": 2.0273916721343994,
      "learning_rate": 0.0006820000000000001,
      "loss": 0.1242,
      "step": 63600
    },
    {
      "epoch": 0.3185,
      "grad_norm": 1.4582029581069946,
      "learning_rate": 0.0006815,
      "loss": 0.1344,
      "step": 63700
    },
    {
      "epoch": 0.319,
      "grad_norm": 0.7574070692062378,
      "learning_rate": 0.0006810000000000001,
      "loss": 0.1282,
      "step": 63800
    },
    {
      "epoch": 0.3195,
      "grad_norm": 1.316701889038086,
      "learning_rate": 0.0006805,
      "loss": 0.1272,
      "step": 63900
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7911993861198425,
      "learning_rate": 0.00068,
      "loss": 0.1327,
      "step": 64000
    },
    {
      "epoch": 0.3205,
      "grad_norm": 1.7778788805007935,
      "learning_rate": 0.0006795,
      "loss": 0.1313,
      "step": 64100
    },
    {
      "epoch": 0.321,
      "grad_norm": 0.4049510061740875,
      "learning_rate": 0.000679,
      "loss": 0.1326,
      "step": 64200
    },
    {
      "epoch": 0.3215,
      "grad_norm": 0.8139572739601135,
      "learning_rate": 0.0006785,
      "loss": 0.1429,
      "step": 64300
    },
    {
      "epoch": 0.322,
      "grad_norm": 4.387753009796143,
      "learning_rate": 0.0006780000000000001,
      "loss": 0.1241,
      "step": 64400
    },
    {
      "epoch": 0.3225,
      "grad_norm": 0.5893359780311584,
      "learning_rate": 0.0006775,
      "loss": 0.1304,
      "step": 64500
    },
    {
      "epoch": 0.323,
      "grad_norm": 1.018851637840271,
      "learning_rate": 0.0006770000000000001,
      "loss": 0.1245,
      "step": 64600
    },
    {
      "epoch": 0.3235,
      "grad_norm": 1.0718014240264893,
      "learning_rate": 0.0006765,
      "loss": 0.1278,
      "step": 64700
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.8022565841674805,
      "learning_rate": 0.0006760000000000001,
      "loss": 0.131,
      "step": 64800
    },
    {
      "epoch": 0.3245,
      "grad_norm": 1.9266787767410278,
      "learning_rate": 0.0006755,
      "loss": 0.1264,
      "step": 64900
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.0105894804000854,
      "learning_rate": 0.000675,
      "loss": 0.1312,
      "step": 65000
    },
    {
      "epoch": 0.3255,
      "grad_norm": 0.6726004481315613,
      "learning_rate": 0.0006745,
      "loss": 0.1335,
      "step": 65100
    },
    {
      "epoch": 0.326,
      "grad_norm": 1.2309272289276123,
      "learning_rate": 0.000674,
      "loss": 0.127,
      "step": 65200
    },
    {
      "epoch": 0.3265,
      "grad_norm": 0.9760638475418091,
      "learning_rate": 0.0006735,
      "loss": 0.1252,
      "step": 65300
    },
    {
      "epoch": 0.327,
      "grad_norm": 0.7860243320465088,
      "learning_rate": 0.0006730000000000001,
      "loss": 0.1336,
      "step": 65400
    },
    {
      "epoch": 0.3275,
      "grad_norm": 0.9157624840736389,
      "learning_rate": 0.0006725,
      "loss": 0.1315,
      "step": 65500
    },
    {
      "epoch": 0.328,
      "grad_norm": 9.576457023620605,
      "learning_rate": 0.0006720000000000001,
      "loss": 0.128,
      "step": 65600
    },
    {
      "epoch": 0.3285,
      "grad_norm": 0.7685140371322632,
      "learning_rate": 0.0006715,
      "loss": 0.1338,
      "step": 65700
    },
    {
      "epoch": 0.329,
      "grad_norm": 0.9340679049491882,
      "learning_rate": 0.000671,
      "loss": 0.1267,
      "step": 65800
    },
    {
      "epoch": 0.3295,
      "grad_norm": 0.6635313630104065,
      "learning_rate": 0.0006705,
      "loss": 0.1295,
      "step": 65900
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1532421112060547,
      "learning_rate": 0.00067,
      "loss": 0.1247,
      "step": 66000
    },
    {
      "epoch": 0.3305,
      "grad_norm": 0.7555730938911438,
      "learning_rate": 0.0006695,
      "loss": 0.1315,
      "step": 66100
    },
    {
      "epoch": 0.331,
      "grad_norm": 1.4225987195968628,
      "learning_rate": 0.0006690000000000001,
      "loss": 0.1313,
      "step": 66200
    },
    {
      "epoch": 0.3315,
      "grad_norm": 15.53293228149414,
      "learning_rate": 0.0006685,
      "loss": 0.1249,
      "step": 66300
    },
    {
      "epoch": 0.332,
      "grad_norm": 1.1682287454605103,
      "learning_rate": 0.0006680000000000001,
      "loss": 0.1304,
      "step": 66400
    },
    {
      "epoch": 0.3325,
      "grad_norm": 0.7468570470809937,
      "learning_rate": 0.0006675,
      "loss": 0.1242,
      "step": 66500
    },
    {
      "epoch": 0.333,
      "grad_norm": 0.8005268573760986,
      "learning_rate": 0.0006670000000000001,
      "loss": 0.1308,
      "step": 66600
    },
    {
      "epoch": 0.3335,
      "grad_norm": 0.6988043189048767,
      "learning_rate": 0.0006665,
      "loss": 0.1276,
      "step": 66700
    },
    {
      "epoch": 0.334,
      "grad_norm": 1.0833468437194824,
      "learning_rate": 0.000666,
      "loss": 0.1157,
      "step": 66800
    },
    {
      "epoch": 0.3345,
      "grad_norm": 0.9618375897407532,
      "learning_rate": 0.0006655,
      "loss": 0.1257,
      "step": 66900
    },
    {
      "epoch": 0.335,
      "grad_norm": 0.5763999819755554,
      "learning_rate": 0.000665,
      "loss": 0.1212,
      "step": 67000
    },
    {
      "epoch": 0.3355,
      "grad_norm": 1.1774232387542725,
      "learning_rate": 0.0006644999999999999,
      "loss": 0.1287,
      "step": 67100
    },
    {
      "epoch": 0.336,
      "grad_norm": 2.10847544670105,
      "learning_rate": 0.0006640000000000001,
      "loss": 0.1282,
      "step": 67200
    },
    {
      "epoch": 0.3365,
      "grad_norm": 5.831546306610107,
      "learning_rate": 0.0006635,
      "loss": 0.1258,
      "step": 67300
    },
    {
      "epoch": 0.337,
      "grad_norm": 1.5135740041732788,
      "learning_rate": 0.0006630000000000001,
      "loss": 0.1262,
      "step": 67400
    },
    {
      "epoch": 0.3375,
      "grad_norm": 1.1405019760131836,
      "learning_rate": 0.0006625,
      "loss": 0.1273,
      "step": 67500
    },
    {
      "epoch": 0.338,
      "grad_norm": 0.815851628780365,
      "learning_rate": 0.000662,
      "loss": 0.1252,
      "step": 67600
    },
    {
      "epoch": 0.3385,
      "grad_norm": 1.1467339992523193,
      "learning_rate": 0.0006615,
      "loss": 0.1225,
      "step": 67700
    },
    {
      "epoch": 0.339,
      "grad_norm": 1.4622106552124023,
      "learning_rate": 0.000661,
      "loss": 0.1271,
      "step": 67800
    },
    {
      "epoch": 0.3395,
      "grad_norm": 0.9701496958732605,
      "learning_rate": 0.0006605,
      "loss": 0.1251,
      "step": 67900
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6752293705940247,
      "learning_rate": 0.00066,
      "loss": 0.1219,
      "step": 68000
    },
    {
      "epoch": 0.3405,
      "grad_norm": 1.1317458152770996,
      "learning_rate": 0.0006595,
      "loss": 0.1286,
      "step": 68100
    },
    {
      "epoch": 0.341,
      "grad_norm": 5.36008358001709,
      "learning_rate": 0.0006590000000000001,
      "loss": 0.1267,
      "step": 68200
    },
    {
      "epoch": 0.3415,
      "grad_norm": 1.4010919332504272,
      "learning_rate": 0.0006585,
      "loss": 0.1299,
      "step": 68300
    },
    {
      "epoch": 0.342,
      "grad_norm": 0.965735673904419,
      "learning_rate": 0.0006580000000000001,
      "loss": 0.1293,
      "step": 68400
    },
    {
      "epoch": 0.3425,
      "grad_norm": 0.9733277559280396,
      "learning_rate": 0.0006575,
      "loss": 0.1236,
      "step": 68500
    },
    {
      "epoch": 0.343,
      "grad_norm": 0.9578225016593933,
      "learning_rate": 0.000657,
      "loss": 0.1237,
      "step": 68600
    },
    {
      "epoch": 0.3435,
      "grad_norm": 0.6928899884223938,
      "learning_rate": 0.0006565,
      "loss": 0.1263,
      "step": 68700
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.7371251583099365,
      "learning_rate": 0.000656,
      "loss": 0.1302,
      "step": 68800
    },
    {
      "epoch": 0.3445,
      "grad_norm": 0.7043028473854065,
      "learning_rate": 0.0006554999999999999,
      "loss": 0.1222,
      "step": 68900
    },
    {
      "epoch": 0.345,
      "grad_norm": 0.5049395561218262,
      "learning_rate": 0.0006550000000000001,
      "loss": 0.1242,
      "step": 69000
    },
    {
      "epoch": 0.3455,
      "grad_norm": 0.5890044569969177,
      "learning_rate": 0.0006545,
      "loss": 0.127,
      "step": 69100
    },
    {
      "epoch": 0.346,
      "grad_norm": 0.891730785369873,
      "learning_rate": 0.0006540000000000001,
      "loss": 0.1264,
      "step": 69200
    },
    {
      "epoch": 0.3465,
      "grad_norm": 1.169337511062622,
      "learning_rate": 0.0006535,
      "loss": 0.1204,
      "step": 69300
    },
    {
      "epoch": 0.347,
      "grad_norm": 1.137252688407898,
      "learning_rate": 0.000653,
      "loss": 0.1289,
      "step": 69400
    },
    {
      "epoch": 0.3475,
      "grad_norm": 0.8521708846092224,
      "learning_rate": 0.0006525,
      "loss": 0.1215,
      "step": 69500
    },
    {
      "epoch": 0.348,
      "grad_norm": 1.4237653017044067,
      "learning_rate": 0.000652,
      "loss": 0.1228,
      "step": 69600
    },
    {
      "epoch": 0.3485,
      "grad_norm": 1.3075443506240845,
      "learning_rate": 0.0006515,
      "loss": 0.1199,
      "step": 69700
    },
    {
      "epoch": 0.349,
      "grad_norm": 1.257380485534668,
      "learning_rate": 0.000651,
      "loss": 0.124,
      "step": 69800
    },
    {
      "epoch": 0.3495,
      "grad_norm": 0.7285829782485962,
      "learning_rate": 0.0006504999999999999,
      "loss": 0.1184,
      "step": 69900
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5307683944702148,
      "learning_rate": 0.0006500000000000001,
      "loss": 0.1256,
      "step": 70000
    },
    {
      "epoch": 0.3505,
      "grad_norm": 0.6038328409194946,
      "learning_rate": 0.0006495,
      "loss": 0.1239,
      "step": 70100
    },
    {
      "epoch": 0.351,
      "grad_norm": 1.2548719644546509,
      "learning_rate": 0.0006490000000000001,
      "loss": 0.1259,
      "step": 70200
    },
    {
      "epoch": 0.3515,
      "grad_norm": 6.205047130584717,
      "learning_rate": 0.0006485,
      "loss": 0.1233,
      "step": 70300
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.4260917901992798,
      "learning_rate": 0.000648,
      "loss": 0.1202,
      "step": 70400
    },
    {
      "epoch": 0.3525,
      "grad_norm": 0.7065140604972839,
      "learning_rate": 0.0006475,
      "loss": 0.124,
      "step": 70500
    },
    {
      "epoch": 0.353,
      "grad_norm": 0.6509730219841003,
      "learning_rate": 0.000647,
      "loss": 0.1219,
      "step": 70600
    },
    {
      "epoch": 0.3535,
      "grad_norm": 0.8087737560272217,
      "learning_rate": 0.0006464999999999999,
      "loss": 0.1266,
      "step": 70700
    },
    {
      "epoch": 0.354,
      "grad_norm": 1.6602104902267456,
      "learning_rate": 0.000646,
      "loss": 0.1214,
      "step": 70800
    },
    {
      "epoch": 0.3545,
      "grad_norm": 2.4126229286193848,
      "learning_rate": 0.0006455,
      "loss": 0.1228,
      "step": 70900
    },
    {
      "epoch": 0.355,
      "grad_norm": 2.701629877090454,
      "learning_rate": 0.0006450000000000001,
      "loss": 0.1224,
      "step": 71000
    },
    {
      "epoch": 0.3555,
      "grad_norm": 0.8357603549957275,
      "learning_rate": 0.0006445,
      "loss": 0.1117,
      "step": 71100
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.7806758880615234,
      "learning_rate": 0.000644,
      "loss": 0.1171,
      "step": 71200
    },
    {
      "epoch": 0.3565,
      "grad_norm": 1.123923659324646,
      "learning_rate": 0.0006435,
      "loss": 0.1227,
      "step": 71300
    },
    {
      "epoch": 0.357,
      "grad_norm": 1.8405348062515259,
      "learning_rate": 0.000643,
      "loss": 0.1189,
      "step": 71400
    },
    {
      "epoch": 0.3575,
      "grad_norm": 0.8491808772087097,
      "learning_rate": 0.0006425,
      "loss": 0.1209,
      "step": 71500
    },
    {
      "epoch": 0.358,
      "grad_norm": 0.9193253517150879,
      "learning_rate": 0.000642,
      "loss": 0.1216,
      "step": 71600
    },
    {
      "epoch": 0.3585,
      "grad_norm": 1.4800103902816772,
      "learning_rate": 0.0006414999999999999,
      "loss": 0.12,
      "step": 71700
    },
    {
      "epoch": 0.359,
      "grad_norm": 0.8921129107475281,
      "learning_rate": 0.0006410000000000001,
      "loss": 0.1223,
      "step": 71800
    },
    {
      "epoch": 0.3595,
      "grad_norm": 1.0496727228164673,
      "learning_rate": 0.0006405,
      "loss": 0.1183,
      "step": 71900
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.4739584922790527,
      "learning_rate": 0.00064,
      "loss": 0.1207,
      "step": 72000
    },
    {
      "epoch": 0.3605,
      "grad_norm": 1.0585020780563354,
      "learning_rate": 0.0006395,
      "loss": 0.1182,
      "step": 72100
    },
    {
      "epoch": 0.361,
      "grad_norm": 1.0125017166137695,
      "learning_rate": 0.000639,
      "loss": 0.1136,
      "step": 72200
    },
    {
      "epoch": 0.3615,
      "grad_norm": 0.5150189399719238,
      "learning_rate": 0.0006385,
      "loss": 0.1169,
      "step": 72300
    },
    {
      "epoch": 0.362,
      "grad_norm": 0.6059636473655701,
      "learning_rate": 0.000638,
      "loss": 0.1242,
      "step": 72400
    },
    {
      "epoch": 0.3625,
      "grad_norm": 4.249351501464844,
      "learning_rate": 0.0006374999999999999,
      "loss": 0.1243,
      "step": 72500
    },
    {
      "epoch": 0.363,
      "grad_norm": 1.1661664247512817,
      "learning_rate": 0.000637,
      "loss": 0.1164,
      "step": 72600
    },
    {
      "epoch": 0.3635,
      "grad_norm": 1.174426794052124,
      "learning_rate": 0.0006365,
      "loss": 0.1184,
      "step": 72700
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.815997302532196,
      "learning_rate": 0.0006360000000000001,
      "loss": 0.1127,
      "step": 72800
    },
    {
      "epoch": 0.3645,
      "grad_norm": 0.8279076218605042,
      "learning_rate": 0.0006355,
      "loss": 0.1172,
      "step": 72900
    },
    {
      "epoch": 0.365,
      "grad_norm": 1.2099509239196777,
      "learning_rate": 0.000635,
      "loss": 0.115,
      "step": 73000
    },
    {
      "epoch": 0.3655,
      "grad_norm": 0.6573533415794373,
      "learning_rate": 0.0006345,
      "loss": 0.1195,
      "step": 73100
    },
    {
      "epoch": 0.366,
      "grad_norm": 1.0064982175827026,
      "learning_rate": 0.000634,
      "loss": 0.1236,
      "step": 73200
    },
    {
      "epoch": 0.3665,
      "grad_norm": 1.5359466075897217,
      "learning_rate": 0.0006335,
      "loss": 0.1248,
      "step": 73300
    },
    {
      "epoch": 0.367,
      "grad_norm": 1.0726234912872314,
      "learning_rate": 0.000633,
      "loss": 0.1135,
      "step": 73400
    },
    {
      "epoch": 0.3675,
      "grad_norm": 0.6196833252906799,
      "learning_rate": 0.0006324999999999999,
      "loss": 0.1289,
      "step": 73500
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.8432338237762451,
      "learning_rate": 0.000632,
      "loss": 0.1191,
      "step": 73600
    },
    {
      "epoch": 0.3685,
      "grad_norm": 1.7597650289535522,
      "learning_rate": 0.0006315,
      "loss": 0.1175,
      "step": 73700
    },
    {
      "epoch": 0.369,
      "grad_norm": 0.7212964296340942,
      "learning_rate": 0.000631,
      "loss": 0.1194,
      "step": 73800
    },
    {
      "epoch": 0.3695,
      "grad_norm": 0.7681143879890442,
      "learning_rate": 0.0006305,
      "loss": 0.1224,
      "step": 73900
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.159852147102356,
      "learning_rate": 0.00063,
      "loss": 0.1125,
      "step": 74000
    },
    {
      "epoch": 0.3705,
      "grad_norm": 8.104414939880371,
      "learning_rate": 0.0006295,
      "loss": 0.1164,
      "step": 74100
    },
    {
      "epoch": 0.371,
      "grad_norm": 2.396115779876709,
      "learning_rate": 0.000629,
      "loss": 0.1177,
      "step": 74200
    },
    {
      "epoch": 0.3715,
      "grad_norm": 0.57906174659729,
      "learning_rate": 0.0006284999999999999,
      "loss": 0.1148,
      "step": 74300
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.591866672039032,
      "learning_rate": 0.000628,
      "loss": 0.1164,
      "step": 74400
    },
    {
      "epoch": 0.3725,
      "grad_norm": 0.833472728729248,
      "learning_rate": 0.0006274999999999999,
      "loss": 0.1088,
      "step": 74500
    },
    {
      "epoch": 0.373,
      "grad_norm": 0.8778560161590576,
      "learning_rate": 0.0006270000000000001,
      "loss": 0.1239,
      "step": 74600
    },
    {
      "epoch": 0.3735,
      "grad_norm": 0.5293627381324768,
      "learning_rate": 0.0006265,
      "loss": 0.1188,
      "step": 74700
    },
    {
      "epoch": 0.374,
      "grad_norm": 1.07764732837677,
      "learning_rate": 0.000626,
      "loss": 0.1171,
      "step": 74800
    },
    {
      "epoch": 0.3745,
      "grad_norm": 5.6450018882751465,
      "learning_rate": 0.0006255,
      "loss": 0.1193,
      "step": 74900
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.5483449697494507,
      "learning_rate": 0.000625,
      "loss": 0.1148,
      "step": 75000
    },
    {
      "epoch": 0.3755,
      "grad_norm": 0.6434332728385925,
      "learning_rate": 0.0006245000000000001,
      "loss": 0.1164,
      "step": 75100
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.6680665016174316,
      "learning_rate": 0.000624,
      "loss": 0.1182,
      "step": 75200
    },
    {
      "epoch": 0.3765,
      "grad_norm": 1.3527443408966064,
      "learning_rate": 0.0006235,
      "loss": 0.113,
      "step": 75300
    },
    {
      "epoch": 0.377,
      "grad_norm": 0.49048376083374023,
      "learning_rate": 0.000623,
      "loss": 0.1108,
      "step": 75400
    },
    {
      "epoch": 0.3775,
      "grad_norm": 0.6297667622566223,
      "learning_rate": 0.0006225000000000001,
      "loss": 0.1158,
      "step": 75500
    },
    {
      "epoch": 0.378,
      "grad_norm": 0.6702401638031006,
      "learning_rate": 0.000622,
      "loss": 0.1131,
      "step": 75600
    },
    {
      "epoch": 0.3785,
      "grad_norm": 0.45767447352409363,
      "learning_rate": 0.0006215000000000001,
      "loss": 0.1165,
      "step": 75700
    },
    {
      "epoch": 0.379,
      "grad_norm": 0.7854911684989929,
      "learning_rate": 0.000621,
      "loss": 0.112,
      "step": 75800
    },
    {
      "epoch": 0.3795,
      "grad_norm": 0.9002453088760376,
      "learning_rate": 0.0006205000000000001,
      "loss": 0.1103,
      "step": 75900
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.43577131628990173,
      "learning_rate": 0.00062,
      "loss": 0.1125,
      "step": 76000
    },
    {
      "epoch": 0.3805,
      "grad_norm": 1.8680663108825684,
      "learning_rate": 0.0006195,
      "loss": 0.1113,
      "step": 76100
    },
    {
      "epoch": 0.381,
      "grad_norm": 0.7740439772605896,
      "learning_rate": 0.000619,
      "loss": 0.1075,
      "step": 76200
    },
    {
      "epoch": 0.3815,
      "grad_norm": 0.5074549913406372,
      "learning_rate": 0.0006185,
      "loss": 0.1143,
      "step": 76300
    },
    {
      "epoch": 0.382,
      "grad_norm": 0.5185867547988892,
      "learning_rate": 0.0006180000000000001,
      "loss": 0.1091,
      "step": 76400
    },
    {
      "epoch": 0.3825,
      "grad_norm": 3.5969512462615967,
      "learning_rate": 0.0006175000000000001,
      "loss": 0.119,
      "step": 76500
    },
    {
      "epoch": 0.383,
      "grad_norm": 7.447351455688477,
      "learning_rate": 0.000617,
      "loss": 0.1193,
      "step": 76600
    },
    {
      "epoch": 0.3835,
      "grad_norm": 0.762231171131134,
      "learning_rate": 0.0006165000000000001,
      "loss": 0.1149,
      "step": 76700
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.5851653814315796,
      "learning_rate": 0.000616,
      "loss": 0.111,
      "step": 76800
    },
    {
      "epoch": 0.3845,
      "grad_norm": 1.9088077545166016,
      "learning_rate": 0.0006155,
      "loss": 0.1066,
      "step": 76900
    },
    {
      "epoch": 0.385,
      "grad_norm": 0.515343189239502,
      "learning_rate": 0.000615,
      "loss": 0.1141,
      "step": 77000
    },
    {
      "epoch": 0.3855,
      "grad_norm": 0.5754256844520569,
      "learning_rate": 0.0006145,
      "loss": 0.1148,
      "step": 77100
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.6161118745803833,
      "learning_rate": 0.000614,
      "loss": 0.1074,
      "step": 77200
    },
    {
      "epoch": 0.3865,
      "grad_norm": 0.7162662148475647,
      "learning_rate": 0.0006135,
      "loss": 0.1072,
      "step": 77300
    },
    {
      "epoch": 0.387,
      "grad_norm": 0.45540884137153625,
      "learning_rate": 0.000613,
      "loss": 0.1097,
      "step": 77400
    },
    {
      "epoch": 0.3875,
      "grad_norm": 1.2056723833084106,
      "learning_rate": 0.0006125000000000001,
      "loss": 0.109,
      "step": 77500
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.9182775020599365,
      "learning_rate": 0.000612,
      "loss": 0.1165,
      "step": 77600
    },
    {
      "epoch": 0.3885,
      "grad_norm": 4.417275905609131,
      "learning_rate": 0.0006115000000000001,
      "loss": 0.1198,
      "step": 77700
    },
    {
      "epoch": 0.389,
      "grad_norm": 0.6249905824661255,
      "learning_rate": 0.000611,
      "loss": 0.1128,
      "step": 77800
    },
    {
      "epoch": 0.3895,
      "grad_norm": 0.5221095085144043,
      "learning_rate": 0.0006105,
      "loss": 0.1135,
      "step": 77900
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.47330087423324585,
      "learning_rate": 0.00061,
      "loss": 0.1166,
      "step": 78000
    },
    {
      "epoch": 0.3905,
      "grad_norm": 3.41416072845459,
      "learning_rate": 0.0006095,
      "loss": 0.1103,
      "step": 78100
    },
    {
      "epoch": 0.391,
      "grad_norm": 1.5702003240585327,
      "learning_rate": 0.000609,
      "loss": 0.1126,
      "step": 78200
    },
    {
      "epoch": 0.3915,
      "grad_norm": 0.8092412352561951,
      "learning_rate": 0.0006085000000000001,
      "loss": 0.1142,
      "step": 78300
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.842760443687439,
      "learning_rate": 0.000608,
      "loss": 0.1096,
      "step": 78400
    },
    {
      "epoch": 0.3925,
      "grad_norm": 2.2410945892333984,
      "learning_rate": 0.0006075000000000001,
      "loss": 0.1112,
      "step": 78500
    },
    {
      "epoch": 0.393,
      "grad_norm": 1.7456384897232056,
      "learning_rate": 0.000607,
      "loss": 0.1112,
      "step": 78600
    },
    {
      "epoch": 0.3935,
      "grad_norm": 0.8887413740158081,
      "learning_rate": 0.0006065,
      "loss": 0.1186,
      "step": 78700
    },
    {
      "epoch": 0.394,
      "grad_norm": 0.7200588583946228,
      "learning_rate": 0.000606,
      "loss": 0.1158,
      "step": 78800
    },
    {
      "epoch": 0.3945,
      "grad_norm": 0.7299772500991821,
      "learning_rate": 0.0006055,
      "loss": 0.1085,
      "step": 78900
    },
    {
      "epoch": 0.395,
      "grad_norm": 2.796905755996704,
      "learning_rate": 0.000605,
      "loss": 0.112,
      "step": 79000
    },
    {
      "epoch": 0.3955,
      "grad_norm": 0.5816653370857239,
      "learning_rate": 0.0006045,
      "loss": 0.1141,
      "step": 79100
    },
    {
      "epoch": 0.396,
      "grad_norm": 1.1554276943206787,
      "learning_rate": 0.000604,
      "loss": 0.1087,
      "step": 79200
    },
    {
      "epoch": 0.3965,
      "grad_norm": 1.3252969980239868,
      "learning_rate": 0.0006035000000000001,
      "loss": 0.1089,
      "step": 79300
    },
    {
      "epoch": 0.397,
      "grad_norm": 0.5919490456581116,
      "learning_rate": 0.000603,
      "loss": 0.1049,
      "step": 79400
    },
    {
      "epoch": 0.3975,
      "grad_norm": 0.8412919640541077,
      "learning_rate": 0.0006025000000000001,
      "loss": 0.1124,
      "step": 79500
    },
    {
      "epoch": 0.398,
      "grad_norm": 0.7243421673774719,
      "learning_rate": 0.000602,
      "loss": 0.1204,
      "step": 79600
    },
    {
      "epoch": 0.3985,
      "grad_norm": 1.5364174842834473,
      "learning_rate": 0.0006015,
      "loss": 0.1079,
      "step": 79700
    },
    {
      "epoch": 0.399,
      "grad_norm": 0.685399055480957,
      "learning_rate": 0.000601,
      "loss": 0.1141,
      "step": 79800
    },
    {
      "epoch": 0.3995,
      "grad_norm": 8.134093284606934,
      "learning_rate": 0.0006005,
      "loss": 0.1099,
      "step": 79900
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2603753805160522,
      "learning_rate": 0.0006,
      "loss": 0.1151,
      "step": 80000
    },
    {
      "epoch": 0.4005,
      "grad_norm": 0.754227340221405,
      "learning_rate": 0.0005995000000000001,
      "loss": 0.1112,
      "step": 80100
    },
    {
      "epoch": 0.401,
      "grad_norm": 0.9075669050216675,
      "learning_rate": 0.000599,
      "loss": 0.1077,
      "step": 80200
    },
    {
      "epoch": 0.4015,
      "grad_norm": 0.656746506690979,
      "learning_rate": 0.0005985000000000001,
      "loss": 0.1092,
      "step": 80300
    },
    {
      "epoch": 0.402,
      "grad_norm": 0.7287092804908752,
      "learning_rate": 0.000598,
      "loss": 0.117,
      "step": 80400
    },
    {
      "epoch": 0.4025,
      "grad_norm": 7.47230863571167,
      "learning_rate": 0.0005975,
      "loss": 0.1076,
      "step": 80500
    },
    {
      "epoch": 0.403,
      "grad_norm": 1.611350655555725,
      "learning_rate": 0.000597,
      "loss": 0.1096,
      "step": 80600
    },
    {
      "epoch": 0.4035,
      "grad_norm": 0.6291453838348389,
      "learning_rate": 0.0005965,
      "loss": 0.1068,
      "step": 80700
    },
    {
      "epoch": 0.404,
      "grad_norm": 2.0908658504486084,
      "learning_rate": 0.000596,
      "loss": 0.1019,
      "step": 80800
    },
    {
      "epoch": 0.4045,
      "grad_norm": 0.5331222414970398,
      "learning_rate": 0.0005955,
      "loss": 0.1081,
      "step": 80900
    },
    {
      "epoch": 0.405,
      "grad_norm": 15.899876594543457,
      "learning_rate": 0.0005949999999999999,
      "loss": 0.1092,
      "step": 81000
    },
    {
      "epoch": 0.4055,
      "grad_norm": 0.38843464851379395,
      "learning_rate": 0.0005945000000000001,
      "loss": 0.113,
      "step": 81100
    },
    {
      "epoch": 0.406,
      "grad_norm": 0.9584948420524597,
      "learning_rate": 0.000594,
      "loss": 0.1083,
      "step": 81200
    },
    {
      "epoch": 0.4065,
      "grad_norm": 0.7919455766677856,
      "learning_rate": 0.0005935000000000001,
      "loss": 0.107,
      "step": 81300
    },
    {
      "epoch": 0.407,
      "grad_norm": 0.9097302556037903,
      "learning_rate": 0.000593,
      "loss": 0.1146,
      "step": 81400
    },
    {
      "epoch": 0.4075,
      "grad_norm": 1.572311282157898,
      "learning_rate": 0.0005925,
      "loss": 0.1017,
      "step": 81500
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.5834524035453796,
      "learning_rate": 0.000592,
      "loss": 0.112,
      "step": 81600
    },
    {
      "epoch": 0.4085,
      "grad_norm": 0.6401387453079224,
      "learning_rate": 0.0005915,
      "loss": 0.1044,
      "step": 81700
    },
    {
      "epoch": 0.409,
      "grad_norm": 1.2453023195266724,
      "learning_rate": 0.0005909999999999999,
      "loss": 0.1116,
      "step": 81800
    },
    {
      "epoch": 0.4095,
      "grad_norm": 1.2535576820373535,
      "learning_rate": 0.0005905,
      "loss": 0.1082,
      "step": 81900
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9773992300033569,
      "learning_rate": 0.00059,
      "loss": 0.1112,
      "step": 82000
    },
    {
      "epoch": 0.4105,
      "grad_norm": 0.8914644122123718,
      "learning_rate": 0.0005895000000000001,
      "loss": 0.1059,
      "step": 82100
    },
    {
      "epoch": 0.411,
      "grad_norm": 0.7375967502593994,
      "learning_rate": 0.000589,
      "loss": 0.1082,
      "step": 82200
    },
    {
      "epoch": 0.4115,
      "grad_norm": 0.5375344157218933,
      "learning_rate": 0.0005885,
      "loss": 0.1115,
      "step": 82300
    },
    {
      "epoch": 0.412,
      "grad_norm": 2.6752207279205322,
      "learning_rate": 0.000588,
      "loss": 0.1051,
      "step": 82400
    },
    {
      "epoch": 0.4125,
      "grad_norm": 0.3778594732284546,
      "learning_rate": 0.0005875,
      "loss": 0.1046,
      "step": 82500
    },
    {
      "epoch": 0.413,
      "grad_norm": 0.5286787748336792,
      "learning_rate": 0.000587,
      "loss": 0.108,
      "step": 82600
    },
    {
      "epoch": 0.4135,
      "grad_norm": 0.5308660268783569,
      "learning_rate": 0.0005865,
      "loss": 0.1035,
      "step": 82700
    },
    {
      "epoch": 0.414,
      "grad_norm": 0.6128093600273132,
      "learning_rate": 0.0005859999999999999,
      "loss": 0.1096,
      "step": 82800
    },
    {
      "epoch": 0.4145,
      "grad_norm": 6.798674583435059,
      "learning_rate": 0.0005855000000000001,
      "loss": 0.1077,
      "step": 82900
    },
    {
      "epoch": 0.415,
      "grad_norm": 0.7759203910827637,
      "learning_rate": 0.000585,
      "loss": 0.1068,
      "step": 83000
    },
    {
      "epoch": 0.4155,
      "grad_norm": 0.849995493888855,
      "learning_rate": 0.0005845000000000001,
      "loss": 0.1099,
      "step": 83100
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.6822906136512756,
      "learning_rate": 0.000584,
      "loss": 0.1059,
      "step": 83200
    },
    {
      "epoch": 0.4165,
      "grad_norm": 0.5051085948944092,
      "learning_rate": 0.0005835,
      "loss": 0.1094,
      "step": 83300
    },
    {
      "epoch": 0.417,
      "grad_norm": 1.0262116193771362,
      "learning_rate": 0.000583,
      "loss": 0.0952,
      "step": 83400
    },
    {
      "epoch": 0.4175,
      "grad_norm": 0.9262454509735107,
      "learning_rate": 0.0005825,
      "loss": 0.1073,
      "step": 83500
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.7796856164932251,
      "learning_rate": 0.0005819999999999999,
      "loss": 0.107,
      "step": 83600
    },
    {
      "epoch": 0.4185,
      "grad_norm": 2.5559544563293457,
      "learning_rate": 0.0005815,
      "loss": 0.102,
      "step": 83700
    },
    {
      "epoch": 0.419,
      "grad_norm": 0.7127931118011475,
      "learning_rate": 0.0005809999999999999,
      "loss": 0.0996,
      "step": 83800
    },
    {
      "epoch": 0.4195,
      "grad_norm": 1.1559044122695923,
      "learning_rate": 0.0005805000000000001,
      "loss": 0.1067,
      "step": 83900
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.39685046672821045,
      "learning_rate": 0.00058,
      "loss": 0.1083,
      "step": 84000
    },
    {
      "epoch": 0.4205,
      "grad_norm": 0.9972206354141235,
      "learning_rate": 0.0005795,
      "loss": 0.1007,
      "step": 84100
    },
    {
      "epoch": 0.421,
      "grad_norm": 0.5488970875740051,
      "learning_rate": 0.000579,
      "loss": 0.1068,
      "step": 84200
    },
    {
      "epoch": 0.4215,
      "grad_norm": 3.1377670764923096,
      "learning_rate": 0.0005785,
      "loss": 0.1008,
      "step": 84300
    },
    {
      "epoch": 0.422,
      "grad_norm": 0.6591252088546753,
      "learning_rate": 0.000578,
      "loss": 0.1056,
      "step": 84400
    },
    {
      "epoch": 0.4225,
      "grad_norm": 1.9055371284484863,
      "learning_rate": 0.0005775,
      "loss": 0.1051,
      "step": 84500
    },
    {
      "epoch": 0.423,
      "grad_norm": 0.6776098608970642,
      "learning_rate": 0.0005769999999999999,
      "loss": 0.1082,
      "step": 84600
    },
    {
      "epoch": 0.4235,
      "grad_norm": 0.5972740650177002,
      "learning_rate": 0.0005765,
      "loss": 0.107,
      "step": 84700
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.8828896880149841,
      "learning_rate": 0.000576,
      "loss": 0.1028,
      "step": 84800
    },
    {
      "epoch": 0.4245,
      "grad_norm": 0.3900953233242035,
      "learning_rate": 0.0005755000000000001,
      "loss": 0.1054,
      "step": 84900
    },
    {
      "epoch": 0.425,
      "grad_norm": 1.6910232305526733,
      "learning_rate": 0.000575,
      "loss": 0.1035,
      "step": 85000
    },
    {
      "epoch": 0.4255,
      "grad_norm": 0.7217594385147095,
      "learning_rate": 0.0005745,
      "loss": 0.1054,
      "step": 85100
    },
    {
      "epoch": 0.426,
      "grad_norm": 0.5612683892250061,
      "learning_rate": 0.000574,
      "loss": 0.1006,
      "step": 85200
    },
    {
      "epoch": 0.4265,
      "grad_norm": 0.9495294690132141,
      "learning_rate": 0.0005735,
      "loss": 0.1097,
      "step": 85300
    },
    {
      "epoch": 0.427,
      "grad_norm": 0.6848065257072449,
      "learning_rate": 0.0005729999999999999,
      "loss": 0.0977,
      "step": 85400
    },
    {
      "epoch": 0.4275,
      "grad_norm": 1.4101967811584473,
      "learning_rate": 0.0005725,
      "loss": 0.1061,
      "step": 85500
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.4324294626712799,
      "learning_rate": 0.0005719999999999999,
      "loss": 0.1133,
      "step": 85600
    },
    {
      "epoch": 0.4285,
      "grad_norm": 0.9519045352935791,
      "learning_rate": 0.0005715000000000001,
      "loss": 0.106,
      "step": 85700
    },
    {
      "epoch": 0.429,
      "grad_norm": 0.5953518152236938,
      "learning_rate": 0.000571,
      "loss": 0.1135,
      "step": 85800
    },
    {
      "epoch": 0.4295,
      "grad_norm": 0.34381237626075745,
      "learning_rate": 0.0005705,
      "loss": 0.105,
      "step": 85900
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3859666883945465,
      "learning_rate": 0.00057,
      "loss": 0.0981,
      "step": 86000
    },
    {
      "epoch": 0.4305,
      "grad_norm": 0.9281555414199829,
      "learning_rate": 0.0005695,
      "loss": 0.1046,
      "step": 86100
    },
    {
      "epoch": 0.431,
      "grad_norm": 0.5556046962738037,
      "learning_rate": 0.000569,
      "loss": 0.1077,
      "step": 86200
    },
    {
      "epoch": 0.4315,
      "grad_norm": 0.7334836721420288,
      "learning_rate": 0.0005685,
      "loss": 0.0969,
      "step": 86300
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.8171658515930176,
      "learning_rate": 0.0005679999999999999,
      "loss": 0.1055,
      "step": 86400
    },
    {
      "epoch": 0.4325,
      "grad_norm": 0.9937109351158142,
      "learning_rate": 0.0005675,
      "loss": 0.1021,
      "step": 86500
    },
    {
      "epoch": 0.433,
      "grad_norm": 1.9264904260635376,
      "learning_rate": 0.000567,
      "loss": 0.1081,
      "step": 86600
    },
    {
      "epoch": 0.4335,
      "grad_norm": 0.5908502340316772,
      "learning_rate": 0.0005665000000000001,
      "loss": 0.1077,
      "step": 86700
    },
    {
      "epoch": 0.434,
      "grad_norm": 0.7344657182693481,
      "learning_rate": 0.000566,
      "loss": 0.108,
      "step": 86800
    },
    {
      "epoch": 0.4345,
      "grad_norm": 0.6766228079795837,
      "learning_rate": 0.0005655,
      "loss": 0.1097,
      "step": 86900
    },
    {
      "epoch": 0.435,
      "grad_norm": 0.814411461353302,
      "learning_rate": 0.000565,
      "loss": 0.1049,
      "step": 87000
    },
    {
      "epoch": 0.4355,
      "grad_norm": 0.6783535480499268,
      "learning_rate": 0.0005645,
      "loss": 0.0977,
      "step": 87100
    },
    {
      "epoch": 0.436,
      "grad_norm": 1.2054768800735474,
      "learning_rate": 0.0005639999999999999,
      "loss": 0.1055,
      "step": 87200
    },
    {
      "epoch": 0.4365,
      "grad_norm": 0.8979182243347168,
      "learning_rate": 0.0005635,
      "loss": 0.0999,
      "step": 87300
    },
    {
      "epoch": 0.437,
      "grad_norm": 1.5112016201019287,
      "learning_rate": 0.0005629999999999999,
      "loss": 0.0991,
      "step": 87400
    },
    {
      "epoch": 0.4375,
      "grad_norm": 2.018338680267334,
      "learning_rate": 0.0005625000000000001,
      "loss": 0.098,
      "step": 87500
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.636472225189209,
      "learning_rate": 0.0005620000000000001,
      "loss": 0.1018,
      "step": 87600
    },
    {
      "epoch": 0.4385,
      "grad_norm": 0.4020445644855499,
      "learning_rate": 0.0005615,
      "loss": 0.0982,
      "step": 87700
    },
    {
      "epoch": 0.439,
      "grad_norm": 0.8202052712440491,
      "learning_rate": 0.0005610000000000001,
      "loss": 0.102,
      "step": 87800
    },
    {
      "epoch": 0.4395,
      "grad_norm": 0.8766127228736877,
      "learning_rate": 0.0005605,
      "loss": 0.0998,
      "step": 87900
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6661813259124756,
      "learning_rate": 0.0005600000000000001,
      "loss": 0.0948,
      "step": 88000
    },
    {
      "epoch": 0.4405,
      "grad_norm": 2.010265588760376,
      "learning_rate": 0.0005595,
      "loss": 0.1035,
      "step": 88100
    },
    {
      "epoch": 0.441,
      "grad_norm": 1.5023056268692017,
      "learning_rate": 0.000559,
      "loss": 0.1014,
      "step": 88200
    },
    {
      "epoch": 0.4415,
      "grad_norm": 0.7546437382698059,
      "learning_rate": 0.0005585,
      "loss": 0.1026,
      "step": 88300
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.7146749496459961,
      "learning_rate": 0.000558,
      "loss": 0.1051,
      "step": 88400
    },
    {
      "epoch": 0.4425,
      "grad_norm": 0.3617675304412842,
      "learning_rate": 0.0005575,
      "loss": 0.0985,
      "step": 88500
    },
    {
      "epoch": 0.443,
      "grad_norm": 0.9607686996459961,
      "learning_rate": 0.0005570000000000001,
      "loss": 0.0986,
      "step": 88600
    },
    {
      "epoch": 0.4435,
      "grad_norm": 3.612900733947754,
      "learning_rate": 0.0005565,
      "loss": 0.1011,
      "step": 88700
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.6403970122337341,
      "learning_rate": 0.0005560000000000001,
      "loss": 0.103,
      "step": 88800
    },
    {
      "epoch": 0.4445,
      "grad_norm": 0.508996307849884,
      "learning_rate": 0.0005555,
      "loss": 0.1071,
      "step": 88900
    },
    {
      "epoch": 0.445,
      "grad_norm": 1.2874783277511597,
      "learning_rate": 0.000555,
      "loss": 0.1018,
      "step": 89000
    },
    {
      "epoch": 0.4455,
      "grad_norm": 0.5973296761512756,
      "learning_rate": 0.0005545,
      "loss": 0.1033,
      "step": 89100
    },
    {
      "epoch": 0.446,
      "grad_norm": 1.5520071983337402,
      "learning_rate": 0.000554,
      "loss": 0.0973,
      "step": 89200
    },
    {
      "epoch": 0.4465,
      "grad_norm": 1.183115005493164,
      "learning_rate": 0.0005535,
      "loss": 0.1017,
      "step": 89300
    },
    {
      "epoch": 0.447,
      "grad_norm": 1.0029741525650024,
      "learning_rate": 0.0005530000000000001,
      "loss": 0.0976,
      "step": 89400
    },
    {
      "epoch": 0.4475,
      "grad_norm": 0.8303937315940857,
      "learning_rate": 0.0005525,
      "loss": 0.1045,
      "step": 89500
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.48997294902801514,
      "learning_rate": 0.0005520000000000001,
      "loss": 0.1039,
      "step": 89600
    },
    {
      "epoch": 0.4485,
      "grad_norm": 0.8395571112632751,
      "learning_rate": 0.0005515,
      "loss": 0.0949,
      "step": 89700
    },
    {
      "epoch": 0.449,
      "grad_norm": 1.9086779356002808,
      "learning_rate": 0.0005510000000000001,
      "loss": 0.1046,
      "step": 89800
    },
    {
      "epoch": 0.4495,
      "grad_norm": 0.8083503246307373,
      "learning_rate": 0.0005505,
      "loss": 0.0985,
      "step": 89900
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8446694612503052,
      "learning_rate": 0.00055,
      "loss": 0.1004,
      "step": 90000
    },
    {
      "epoch": 0.4505,
      "grad_norm": 1.0257831811904907,
      "learning_rate": 0.0005495,
      "loss": 0.097,
      "step": 90100
    },
    {
      "epoch": 0.451,
      "grad_norm": 0.6484299302101135,
      "learning_rate": 0.000549,
      "loss": 0.0994,
      "step": 90200
    },
    {
      "epoch": 0.4515,
      "grad_norm": 0.49748364090919495,
      "learning_rate": 0.0005485,
      "loss": 0.1063,
      "step": 90300
    },
    {
      "epoch": 0.452,
      "grad_norm": 29.658620834350586,
      "learning_rate": 0.0005480000000000001,
      "loss": 0.103,
      "step": 90400
    },
    {
      "epoch": 0.4525,
      "grad_norm": 4.785343647003174,
      "learning_rate": 0.0005475,
      "loss": 0.0944,
      "step": 90500
    },
    {
      "epoch": 0.453,
      "grad_norm": 0.46145099401474,
      "learning_rate": 0.0005470000000000001,
      "loss": 0.1067,
      "step": 90600
    },
    {
      "epoch": 0.4535,
      "grad_norm": 0.6435754895210266,
      "learning_rate": 0.0005465,
      "loss": 0.0977,
      "step": 90700
    },
    {
      "epoch": 0.454,
      "grad_norm": 3.385246992111206,
      "learning_rate": 0.000546,
      "loss": 0.0976,
      "step": 90800
    },
    {
      "epoch": 0.4545,
      "grad_norm": 12.17259693145752,
      "learning_rate": 0.0005455,
      "loss": 0.1012,
      "step": 90900
    },
    {
      "epoch": 0.455,
      "grad_norm": 0.7247257232666016,
      "learning_rate": 0.000545,
      "loss": 0.0994,
      "step": 91000
    },
    {
      "epoch": 0.4555,
      "grad_norm": 0.7282042503356934,
      "learning_rate": 0.0005445,
      "loss": 0.101,
      "step": 91100
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.897674024105072,
      "learning_rate": 0.0005440000000000001,
      "loss": 0.0996,
      "step": 91200
    },
    {
      "epoch": 0.4565,
      "grad_norm": 1.2386107444763184,
      "learning_rate": 0.0005435,
      "loss": 0.0936,
      "step": 91300
    },
    {
      "epoch": 0.457,
      "grad_norm": 1.8200873136520386,
      "learning_rate": 0.0005430000000000001,
      "loss": 0.0972,
      "step": 91400
    },
    {
      "epoch": 0.4575,
      "grad_norm": 0.5680263638496399,
      "learning_rate": 0.0005425,
      "loss": 0.102,
      "step": 91500
    },
    {
      "epoch": 0.458,
      "grad_norm": 1.020856261253357,
      "learning_rate": 0.0005420000000000001,
      "loss": 0.0983,
      "step": 91600
    },
    {
      "epoch": 0.4585,
      "grad_norm": 1.1090469360351562,
      "learning_rate": 0.0005415,
      "loss": 0.102,
      "step": 91700
    },
    {
      "epoch": 0.459,
      "grad_norm": 0.550605833530426,
      "learning_rate": 0.000541,
      "loss": 0.1009,
      "step": 91800
    },
    {
      "epoch": 0.4595,
      "grad_norm": 2.5615994930267334,
      "learning_rate": 0.0005405,
      "loss": 0.0999,
      "step": 91900
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6846345067024231,
      "learning_rate": 0.00054,
      "loss": 0.0983,
      "step": 92000
    },
    {
      "epoch": 0.4605,
      "grad_norm": 0.5977089405059814,
      "learning_rate": 0.0005394999999999999,
      "loss": 0.0943,
      "step": 92100
    },
    {
      "epoch": 0.461,
      "grad_norm": 0.4482610523700714,
      "learning_rate": 0.0005390000000000001,
      "loss": 0.1,
      "step": 92200
    },
    {
      "epoch": 0.4615,
      "grad_norm": 0.4213564693927765,
      "learning_rate": 0.0005385,
      "loss": 0.1058,
      "step": 92300
    },
    {
      "epoch": 0.462,
      "grad_norm": 0.5313313007354736,
      "learning_rate": 0.0005380000000000001,
      "loss": 0.0952,
      "step": 92400
    },
    {
      "epoch": 0.4625,
      "grad_norm": 1.1108320951461792,
      "learning_rate": 0.0005375,
      "loss": 0.0928,
      "step": 92500
    },
    {
      "epoch": 0.463,
      "grad_norm": 1.2701594829559326,
      "learning_rate": 0.000537,
      "loss": 0.0952,
      "step": 92600
    },
    {
      "epoch": 0.4635,
      "grad_norm": 2.3331849575042725,
      "learning_rate": 0.0005365,
      "loss": 0.0953,
      "step": 92700
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.96783047914505,
      "learning_rate": 0.000536,
      "loss": 0.1001,
      "step": 92800
    },
    {
      "epoch": 0.4645,
      "grad_norm": 1.1987417936325073,
      "learning_rate": 0.0005355,
      "loss": 0.096,
      "step": 92900
    },
    {
      "epoch": 0.465,
      "grad_norm": 0.7840311527252197,
      "learning_rate": 0.000535,
      "loss": 0.0953,
      "step": 93000
    },
    {
      "epoch": 0.4655,
      "grad_norm": 4.239896774291992,
      "learning_rate": 0.0005345,
      "loss": 0.0983,
      "step": 93100
    },
    {
      "epoch": 0.466,
      "grad_norm": 2.0749659538269043,
      "learning_rate": 0.0005340000000000001,
      "loss": 0.0965,
      "step": 93200
    },
    {
      "epoch": 0.4665,
      "grad_norm": 0.8030183911323547,
      "learning_rate": 0.0005335,
      "loss": 0.088,
      "step": 93300
    },
    {
      "epoch": 0.467,
      "grad_norm": 8.663429260253906,
      "learning_rate": 0.000533,
      "loss": 0.1022,
      "step": 93400
    },
    {
      "epoch": 0.4675,
      "grad_norm": 0.6399542093276978,
      "learning_rate": 0.0005325,
      "loss": 0.0926,
      "step": 93500
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.75480717420578,
      "learning_rate": 0.000532,
      "loss": 0.0975,
      "step": 93600
    },
    {
      "epoch": 0.4685,
      "grad_norm": 0.9666817784309387,
      "learning_rate": 0.0005315,
      "loss": 0.1004,
      "step": 93700
    },
    {
      "epoch": 0.469,
      "grad_norm": 0.5475233793258667,
      "learning_rate": 0.000531,
      "loss": 0.0964,
      "step": 93800
    },
    {
      "epoch": 0.4695,
      "grad_norm": 1.1494537591934204,
      "learning_rate": 0.0005304999999999999,
      "loss": 0.0986,
      "step": 93900
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2462700605392456,
      "learning_rate": 0.0005300000000000001,
      "loss": 0.0882,
      "step": 94000
    },
    {
      "epoch": 0.4705,
      "grad_norm": 1.425241231918335,
      "learning_rate": 0.0005295,
      "loss": 0.0963,
      "step": 94100
    },
    {
      "epoch": 0.471,
      "grad_norm": 0.981158971786499,
      "learning_rate": 0.0005290000000000001,
      "loss": 0.0939,
      "step": 94200
    },
    {
      "epoch": 0.4715,
      "grad_norm": 0.9058347344398499,
      "learning_rate": 0.0005285,
      "loss": 0.0999,
      "step": 94300
    },
    {
      "epoch": 0.472,
      "grad_norm": 1.1663750410079956,
      "learning_rate": 0.000528,
      "loss": 0.09,
      "step": 94400
    },
    {
      "epoch": 0.4725,
      "grad_norm": 0.3962150514125824,
      "learning_rate": 0.0005275,
      "loss": 0.0932,
      "step": 94500
    },
    {
      "epoch": 0.473,
      "grad_norm": 2.373619318008423,
      "learning_rate": 0.000527,
      "loss": 0.0918,
      "step": 94600
    },
    {
      "epoch": 0.4735,
      "grad_norm": 0.970184326171875,
      "learning_rate": 0.0005265,
      "loss": 0.0947,
      "step": 94700
    },
    {
      "epoch": 0.474,
      "grad_norm": 0.6772695779800415,
      "learning_rate": 0.000526,
      "loss": 0.0927,
      "step": 94800
    },
    {
      "epoch": 0.4745,
      "grad_norm": 0.9883314371109009,
      "learning_rate": 0.0005254999999999999,
      "loss": 0.0982,
      "step": 94900
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.8177340030670166,
      "learning_rate": 0.0005250000000000001,
      "loss": 0.0899,
      "step": 95000
    },
    {
      "epoch": 0.4755,
      "grad_norm": 0.8045396208763123,
      "learning_rate": 0.0005245,
      "loss": 0.0884,
      "step": 95100
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.7882497310638428,
      "learning_rate": 0.000524,
      "loss": 0.0969,
      "step": 95200
    },
    {
      "epoch": 0.4765,
      "grad_norm": 4.438310623168945,
      "learning_rate": 0.0005235,
      "loss": 0.098,
      "step": 95300
    },
    {
      "epoch": 0.477,
      "grad_norm": 4.736423015594482,
      "learning_rate": 0.000523,
      "loss": 0.0982,
      "step": 95400
    },
    {
      "epoch": 0.4775,
      "grad_norm": 1.0460577011108398,
      "learning_rate": 0.0005225,
      "loss": 0.0942,
      "step": 95500
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.586864173412323,
      "learning_rate": 0.000522,
      "loss": 0.0908,
      "step": 95600
    },
    {
      "epoch": 0.4785,
      "grad_norm": 2.9302144050598145,
      "learning_rate": 0.0005214999999999999,
      "loss": 0.0936,
      "step": 95700
    },
    {
      "epoch": 0.479,
      "grad_norm": 1.3613349199295044,
      "learning_rate": 0.000521,
      "loss": 0.0924,
      "step": 95800
    },
    {
      "epoch": 0.4795,
      "grad_norm": 1.1047805547714233,
      "learning_rate": 0.0005205,
      "loss": 0.0953,
      "step": 95900
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.7872633337974548,
      "learning_rate": 0.0005200000000000001,
      "loss": 0.0956,
      "step": 96000
    },
    {
      "epoch": 0.4805,
      "grad_norm": 0.5796558856964111,
      "learning_rate": 0.0005195,
      "loss": 0.0958,
      "step": 96100
    },
    {
      "epoch": 0.481,
      "grad_norm": 1.367766261100769,
      "learning_rate": 0.000519,
      "loss": 0.1001,
      "step": 96200
    },
    {
      "epoch": 0.4815,
      "grad_norm": 0.6011171340942383,
      "learning_rate": 0.0005185,
      "loss": 0.098,
      "step": 96300
    },
    {
      "epoch": 0.482,
      "grad_norm": 0.37365075945854187,
      "learning_rate": 0.000518,
      "loss": 0.0958,
      "step": 96400
    },
    {
      "epoch": 0.4825,
      "grad_norm": 0.8404912948608398,
      "learning_rate": 0.0005175,
      "loss": 0.1001,
      "step": 96500
    },
    {
      "epoch": 0.483,
      "grad_norm": 0.9107031226158142,
      "learning_rate": 0.000517,
      "loss": 0.0916,
      "step": 96600
    },
    {
      "epoch": 0.4835,
      "grad_norm": 0.7320605516433716,
      "learning_rate": 0.0005164999999999999,
      "loss": 0.0943,
      "step": 96700
    },
    {
      "epoch": 0.484,
      "grad_norm": 2.2640347480773926,
      "learning_rate": 0.0005160000000000001,
      "loss": 0.0848,
      "step": 96800
    },
    {
      "epoch": 0.4845,
      "grad_norm": 0.7635399699211121,
      "learning_rate": 0.0005155,
      "loss": 0.0889,
      "step": 96900
    },
    {
      "epoch": 0.485,
      "grad_norm": 1.433056354522705,
      "learning_rate": 0.000515,
      "loss": 0.0895,
      "step": 97000
    },
    {
      "epoch": 0.4855,
      "grad_norm": 0.5521774888038635,
      "learning_rate": 0.0005145,
      "loss": 0.0883,
      "step": 97100
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.7014260292053223,
      "learning_rate": 0.000514,
      "loss": 0.0967,
      "step": 97200
    },
    {
      "epoch": 0.4865,
      "grad_norm": 0.47328874468803406,
      "learning_rate": 0.0005135,
      "loss": 0.0942,
      "step": 97300
    },
    {
      "epoch": 0.487,
      "grad_norm": 1.3468085527420044,
      "learning_rate": 0.000513,
      "loss": 0.0938,
      "step": 97400
    },
    {
      "epoch": 0.4875,
      "grad_norm": 17.899621963500977,
      "learning_rate": 0.0005124999999999999,
      "loss": 0.0887,
      "step": 97500
    },
    {
      "epoch": 0.488,
      "grad_norm": 14.677657127380371,
      "learning_rate": 0.000512,
      "loss": 0.0916,
      "step": 97600
    },
    {
      "epoch": 0.4885,
      "grad_norm": 0.8092691898345947,
      "learning_rate": 0.0005115,
      "loss": 0.0927,
      "step": 97700
    },
    {
      "epoch": 0.489,
      "grad_norm": 0.5824605822563171,
      "learning_rate": 0.0005110000000000001,
      "loss": 0.0916,
      "step": 97800
    },
    {
      "epoch": 0.4895,
      "grad_norm": 0.8269854187965393,
      "learning_rate": 0.0005105,
      "loss": 0.098,
      "step": 97900
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.47565802931785583,
      "learning_rate": 0.00051,
      "loss": 0.0902,
      "step": 98000
    },
    {
      "epoch": 0.4905,
      "grad_norm": 0.7842142581939697,
      "learning_rate": 0.0005095,
      "loss": 0.0899,
      "step": 98100
    },
    {
      "epoch": 0.491,
      "grad_norm": 0.6322533488273621,
      "learning_rate": 0.000509,
      "loss": 0.0905,
      "step": 98200
    },
    {
      "epoch": 0.4915,
      "grad_norm": 0.732342004776001,
      "learning_rate": 0.0005085,
      "loss": 0.1005,
      "step": 98300
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.6545742750167847,
      "learning_rate": 0.000508,
      "loss": 0.0943,
      "step": 98400
    },
    {
      "epoch": 0.4925,
      "grad_norm": 0.5754479169845581,
      "learning_rate": 0.0005074999999999999,
      "loss": 0.0898,
      "step": 98500
    },
    {
      "epoch": 0.493,
      "grad_norm": 0.9136813282966614,
      "learning_rate": 0.000507,
      "loss": 0.0923,
      "step": 98600
    },
    {
      "epoch": 0.4935,
      "grad_norm": 0.495975136756897,
      "learning_rate": 0.0005065,
      "loss": 0.0918,
      "step": 98700
    },
    {
      "epoch": 0.494,
      "grad_norm": 1.3860104084014893,
      "learning_rate": 0.000506,
      "loss": 0.0905,
      "step": 98800
    },
    {
      "epoch": 0.4945,
      "grad_norm": 0.8568295240402222,
      "learning_rate": 0.0005055,
      "loss": 0.0917,
      "step": 98900
    },
    {
      "epoch": 0.495,
      "grad_norm": 0.6977808475494385,
      "learning_rate": 0.000505,
      "loss": 0.0928,
      "step": 99000
    },
    {
      "epoch": 0.4955,
      "grad_norm": 0.6246140003204346,
      "learning_rate": 0.0005045,
      "loss": 0.0871,
      "step": 99100
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.6078643798828125,
      "learning_rate": 0.000504,
      "loss": 0.0922,
      "step": 99200
    },
    {
      "epoch": 0.4965,
      "grad_norm": 0.7913713455200195,
      "learning_rate": 0.0005034999999999999,
      "loss": 0.088,
      "step": 99300
    },
    {
      "epoch": 0.497,
      "grad_norm": 0.518234133720398,
      "learning_rate": 0.000503,
      "loss": 0.0892,
      "step": 99400
    },
    {
      "epoch": 0.4975,
      "grad_norm": 1.739946722984314,
      "learning_rate": 0.0005024999999999999,
      "loss": 0.0945,
      "step": 99500
    },
    {
      "epoch": 0.498,
      "grad_norm": 0.5086148977279663,
      "learning_rate": 0.0005020000000000001,
      "loss": 0.0917,
      "step": 99600
    },
    {
      "epoch": 0.4985,
      "grad_norm": 0.40489715337753296,
      "learning_rate": 0.0005015,
      "loss": 0.0884,
      "step": 99700
    },
    {
      "epoch": 0.499,
      "grad_norm": 0.5486173629760742,
      "learning_rate": 0.000501,
      "loss": 0.096,
      "step": 99800
    },
    {
      "epoch": 0.4995,
      "grad_norm": 0.6605997681617737,
      "learning_rate": 0.0005005,
      "loss": 0.0941,
      "step": 99900
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.0208916664123535,
      "learning_rate": 0.0005,
      "loss": 0.0897,
      "step": 100000
    },
    {
      "epoch": 0.5005,
      "grad_norm": 0.6761100888252258,
      "learning_rate": 0.0004995,
      "loss": 0.0907,
      "step": 100100
    },
    {
      "epoch": 0.501,
      "grad_norm": 2.5326762199401855,
      "learning_rate": 0.000499,
      "loss": 0.097,
      "step": 100200
    },
    {
      "epoch": 0.5015,
      "grad_norm": 1.2156251668930054,
      "learning_rate": 0.0004985,
      "loss": 0.0922,
      "step": 100300
    },
    {
      "epoch": 0.502,
      "grad_norm": 7.959685325622559,
      "learning_rate": 0.000498,
      "loss": 0.0957,
      "step": 100400
    },
    {
      "epoch": 0.5025,
      "grad_norm": 0.513879120349884,
      "learning_rate": 0.0004975,
      "loss": 0.0868,
      "step": 100500
    },
    {
      "epoch": 0.503,
      "grad_norm": 0.8612940311431885,
      "learning_rate": 0.000497,
      "loss": 0.0835,
      "step": 100600
    },
    {
      "epoch": 0.5035,
      "grad_norm": 0.6086638569831848,
      "learning_rate": 0.0004965,
      "loss": 0.0925,
      "step": 100700
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.49873510003089905,
      "learning_rate": 0.000496,
      "loss": 0.0893,
      "step": 100800
    },
    {
      "epoch": 0.5045,
      "grad_norm": 2.6685750484466553,
      "learning_rate": 0.0004955,
      "loss": 0.0855,
      "step": 100900
    },
    {
      "epoch": 0.505,
      "grad_norm": 1.4306526184082031,
      "learning_rate": 0.000495,
      "loss": 0.0883,
      "step": 101000
    },
    {
      "epoch": 0.5055,
      "grad_norm": 0.3717811703681946,
      "learning_rate": 0.0004945,
      "loss": 0.0852,
      "step": 101100
    },
    {
      "epoch": 0.506,
      "grad_norm": 1.7075777053833008,
      "learning_rate": 0.000494,
      "loss": 0.0911,
      "step": 101200
    },
    {
      "epoch": 0.5065,
      "grad_norm": 1.8426698446273804,
      "learning_rate": 0.0004935,
      "loss": 0.0947,
      "step": 101300
    },
    {
      "epoch": 0.507,
      "grad_norm": 15.531453132629395,
      "learning_rate": 0.0004930000000000001,
      "loss": 0.0818,
      "step": 101400
    },
    {
      "epoch": 0.5075,
      "grad_norm": 0.44101041555404663,
      "learning_rate": 0.0004925,
      "loss": 0.0942,
      "step": 101500
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.5299765467643738,
      "learning_rate": 0.000492,
      "loss": 0.0867,
      "step": 101600
    },
    {
      "epoch": 0.5085,
      "grad_norm": 0.9114413261413574,
      "learning_rate": 0.0004915,
      "loss": 0.0919,
      "step": 101700
    },
    {
      "epoch": 0.509,
      "grad_norm": 1.4895039796829224,
      "learning_rate": 0.000491,
      "loss": 0.0888,
      "step": 101800
    },
    {
      "epoch": 0.5095,
      "grad_norm": 0.4845879077911377,
      "learning_rate": 0.0004905,
      "loss": 0.0839,
      "step": 101900
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.8220176100730896,
      "learning_rate": 0.00049,
      "loss": 0.0937,
      "step": 102000
    },
    {
      "epoch": 0.5105,
      "grad_norm": 0.3314768970012665,
      "learning_rate": 0.0004895,
      "loss": 0.0914,
      "step": 102100
    },
    {
      "epoch": 0.511,
      "grad_norm": 1.0798888206481934,
      "learning_rate": 0.000489,
      "loss": 0.0885,
      "step": 102200
    },
    {
      "epoch": 0.5115,
      "grad_norm": 0.7376024723052979,
      "learning_rate": 0.0004885,
      "loss": 0.0916,
      "step": 102300
    },
    {
      "epoch": 0.512,
      "grad_norm": 1.0369389057159424,
      "learning_rate": 0.000488,
      "loss": 0.0908,
      "step": 102400
    },
    {
      "epoch": 0.5125,
      "grad_norm": 0.7239527106285095,
      "learning_rate": 0.0004875,
      "loss": 0.082,
      "step": 102500
    },
    {
      "epoch": 0.513,
      "grad_norm": 0.5823758244514465,
      "learning_rate": 0.000487,
      "loss": 0.0857,
      "step": 102600
    },
    {
      "epoch": 0.5135,
      "grad_norm": 0.38523203134536743,
      "learning_rate": 0.0004865,
      "loss": 0.0867,
      "step": 102700
    },
    {
      "epoch": 0.514,
      "grad_norm": 0.8716737627983093,
      "learning_rate": 0.000486,
      "loss": 0.0908,
      "step": 102800
    },
    {
      "epoch": 0.5145,
      "grad_norm": 0.7529094815254211,
      "learning_rate": 0.0004855,
      "loss": 0.0887,
      "step": 102900
    },
    {
      "epoch": 0.515,
      "grad_norm": 1.261007308959961,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.0843,
      "step": 103000
    },
    {
      "epoch": 0.5155,
      "grad_norm": 0.3815322518348694,
      "learning_rate": 0.0004845,
      "loss": 0.085,
      "step": 103100
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.46227020025253296,
      "learning_rate": 0.000484,
      "loss": 0.0904,
      "step": 103200
    },
    {
      "epoch": 0.5165,
      "grad_norm": 0.5315748453140259,
      "learning_rate": 0.0004835,
      "loss": 0.0863,
      "step": 103300
    },
    {
      "epoch": 0.517,
      "grad_norm": 0.48098722100257874,
      "learning_rate": 0.000483,
      "loss": 0.0908,
      "step": 103400
    },
    {
      "epoch": 0.5175,
      "grad_norm": 1.9203133583068848,
      "learning_rate": 0.0004825,
      "loss": 0.0903,
      "step": 103500
    },
    {
      "epoch": 0.518,
      "grad_norm": 0.49801647663116455,
      "learning_rate": 0.000482,
      "loss": 0.0899,
      "step": 103600
    },
    {
      "epoch": 0.5185,
      "grad_norm": 0.8406738638877869,
      "learning_rate": 0.0004815,
      "loss": 0.0888,
      "step": 103700
    },
    {
      "epoch": 0.519,
      "grad_norm": 1.0987298488616943,
      "learning_rate": 0.000481,
      "loss": 0.087,
      "step": 103800
    },
    {
      "epoch": 0.5195,
      "grad_norm": 0.9139363169670105,
      "learning_rate": 0.00048049999999999997,
      "loss": 0.0802,
      "step": 103900
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.0371789932250977,
      "learning_rate": 0.00048,
      "loss": 0.0849,
      "step": 104000
    },
    {
      "epoch": 0.5205,
      "grad_norm": 2.044973850250244,
      "learning_rate": 0.0004795,
      "loss": 0.0882,
      "step": 104100
    },
    {
      "epoch": 0.521,
      "grad_norm": 0.406400591135025,
      "learning_rate": 0.000479,
      "loss": 0.0922,
      "step": 104200
    },
    {
      "epoch": 0.5215,
      "grad_norm": 0.5525016188621521,
      "learning_rate": 0.0004785,
      "loss": 0.0878,
      "step": 104300
    },
    {
      "epoch": 0.522,
      "grad_norm": 0.6167718768119812,
      "learning_rate": 0.00047799999999999996,
      "loss": 0.0837,
      "step": 104400
    },
    {
      "epoch": 0.5225,
      "grad_norm": 0.5276816487312317,
      "learning_rate": 0.0004775,
      "loss": 0.0923,
      "step": 104500
    },
    {
      "epoch": 0.523,
      "grad_norm": 2.325512170791626,
      "learning_rate": 0.000477,
      "loss": 0.086,
      "step": 104600
    },
    {
      "epoch": 0.5235,
      "grad_norm": 3.9491560459136963,
      "learning_rate": 0.0004765,
      "loss": 0.0875,
      "step": 104700
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.454144150018692,
      "learning_rate": 0.00047599999999999997,
      "loss": 0.0904,
      "step": 104800
    },
    {
      "epoch": 0.5245,
      "grad_norm": 0.6639575362205505,
      "learning_rate": 0.0004755,
      "loss": 0.0893,
      "step": 104900
    },
    {
      "epoch": 0.525,
      "grad_norm": 0.9825823307037354,
      "learning_rate": 0.000475,
      "loss": 0.0897,
      "step": 105000
    },
    {
      "epoch": 0.5255,
      "grad_norm": 0.6050187945365906,
      "learning_rate": 0.0004745,
      "loss": 0.0856,
      "step": 105100
    },
    {
      "epoch": 0.526,
      "grad_norm": 0.4262171685695648,
      "learning_rate": 0.000474,
      "loss": 0.089,
      "step": 105200
    },
    {
      "epoch": 0.5265,
      "grad_norm": 1.327673077583313,
      "learning_rate": 0.00047349999999999996,
      "loss": 0.0868,
      "step": 105300
    },
    {
      "epoch": 0.527,
      "grad_norm": 0.6121888756752014,
      "learning_rate": 0.000473,
      "loss": 0.0909,
      "step": 105400
    },
    {
      "epoch": 0.5275,
      "grad_norm": 0.6734451651573181,
      "learning_rate": 0.0004725,
      "loss": 0.0814,
      "step": 105500
    },
    {
      "epoch": 0.528,
      "grad_norm": 1.0490541458129883,
      "learning_rate": 0.000472,
      "loss": 0.0932,
      "step": 105600
    },
    {
      "epoch": 0.5285,
      "grad_norm": 0.5143136978149414,
      "learning_rate": 0.00047149999999999997,
      "loss": 0.0857,
      "step": 105700
    },
    {
      "epoch": 0.529,
      "grad_norm": 0.6430474519729614,
      "learning_rate": 0.000471,
      "loss": 0.0832,
      "step": 105800
    },
    {
      "epoch": 0.5295,
      "grad_norm": 0.7063400745391846,
      "learning_rate": 0.0004705,
      "loss": 0.0859,
      "step": 105900
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6886008977890015,
      "learning_rate": 0.00047,
      "loss": 0.0907,
      "step": 106000
    },
    {
      "epoch": 0.5305,
      "grad_norm": 0.8522655367851257,
      "learning_rate": 0.0004695,
      "loss": 0.088,
      "step": 106100
    },
    {
      "epoch": 0.531,
      "grad_norm": 3.0992860794067383,
      "learning_rate": 0.00046899999999999996,
      "loss": 0.081,
      "step": 106200
    },
    {
      "epoch": 0.5315,
      "grad_norm": 0.8054497241973877,
      "learning_rate": 0.00046850000000000006,
      "loss": 0.0815,
      "step": 106300
    },
    {
      "epoch": 0.532,
      "grad_norm": 4.731417655944824,
      "learning_rate": 0.00046800000000000005,
      "loss": 0.0864,
      "step": 106400
    },
    {
      "epoch": 0.5325,
      "grad_norm": 1.2943189144134521,
      "learning_rate": 0.00046750000000000003,
      "loss": 0.0844,
      "step": 106500
    },
    {
      "epoch": 0.533,
      "grad_norm": 2.1121647357940674,
      "learning_rate": 0.000467,
      "loss": 0.0857,
      "step": 106600
    },
    {
      "epoch": 0.5335,
      "grad_norm": 64.78998565673828,
      "learning_rate": 0.0004665,
      "loss": 0.0827,
      "step": 106700
    },
    {
      "epoch": 0.534,
      "grad_norm": 1.0413392782211304,
      "learning_rate": 0.00046600000000000005,
      "loss": 0.0866,
      "step": 106800
    },
    {
      "epoch": 0.5345,
      "grad_norm": 0.7060707211494446,
      "learning_rate": 0.00046550000000000004,
      "loss": 0.0822,
      "step": 106900
    },
    {
      "epoch": 0.535,
      "grad_norm": 0.43822017312049866,
      "learning_rate": 0.000465,
      "loss": 0.0795,
      "step": 107000
    },
    {
      "epoch": 0.5355,
      "grad_norm": 0.5543079376220703,
      "learning_rate": 0.0004645,
      "loss": 0.08,
      "step": 107100
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.8447282910346985,
      "learning_rate": 0.00046400000000000006,
      "loss": 0.088,
      "step": 107200
    },
    {
      "epoch": 0.5365,
      "grad_norm": 0.7711150646209717,
      "learning_rate": 0.00046350000000000004,
      "loss": 0.0808,
      "step": 107300
    },
    {
      "epoch": 0.537,
      "grad_norm": 2.410574197769165,
      "learning_rate": 0.00046300000000000003,
      "loss": 0.083,
      "step": 107400
    },
    {
      "epoch": 0.5375,
      "grad_norm": 0.7292252779006958,
      "learning_rate": 0.0004625,
      "loss": 0.0856,
      "step": 107500
    },
    {
      "epoch": 0.538,
      "grad_norm": 0.4927728772163391,
      "learning_rate": 0.000462,
      "loss": 0.0858,
      "step": 107600
    },
    {
      "epoch": 0.5385,
      "grad_norm": 0.751497745513916,
      "learning_rate": 0.00046150000000000005,
      "loss": 0.0872,
      "step": 107700
    },
    {
      "epoch": 0.539,
      "grad_norm": 1.8275465965270996,
      "learning_rate": 0.00046100000000000004,
      "loss": 0.0779,
      "step": 107800
    },
    {
      "epoch": 0.5395,
      "grad_norm": 0.8191806674003601,
      "learning_rate": 0.0004605,
      "loss": 0.0868,
      "step": 107900
    },
    {
      "epoch": 0.54,
      "grad_norm": 5.382432460784912,
      "learning_rate": 0.00046,
      "loss": 0.0923,
      "step": 108000
    },
    {
      "epoch": 0.5405,
      "grad_norm": 0.8236855864524841,
      "learning_rate": 0.00045950000000000006,
      "loss": 0.0815,
      "step": 108100
    },
    {
      "epoch": 0.541,
      "grad_norm": 0.644646406173706,
      "learning_rate": 0.00045900000000000004,
      "loss": 0.0785,
      "step": 108200
    },
    {
      "epoch": 0.5415,
      "grad_norm": 0.5567591786384583,
      "learning_rate": 0.00045850000000000003,
      "loss": 0.0842,
      "step": 108300
    },
    {
      "epoch": 0.542,
      "grad_norm": 0.6780977845191956,
      "learning_rate": 0.000458,
      "loss": 0.0888,
      "step": 108400
    },
    {
      "epoch": 0.5425,
      "grad_norm": 0.5981294512748718,
      "learning_rate": 0.0004575,
      "loss": 0.0817,
      "step": 108500
    },
    {
      "epoch": 0.543,
      "grad_norm": 0.6213749051094055,
      "learning_rate": 0.00045700000000000005,
      "loss": 0.0859,
      "step": 108600
    },
    {
      "epoch": 0.5435,
      "grad_norm": 0.6396611332893372,
      "learning_rate": 0.00045650000000000004,
      "loss": 0.0839,
      "step": 108700
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.5106882452964783,
      "learning_rate": 0.000456,
      "loss": 0.0815,
      "step": 108800
    },
    {
      "epoch": 0.5445,
      "grad_norm": 0.9681829810142517,
      "learning_rate": 0.0004555,
      "loss": 0.0837,
      "step": 108900
    },
    {
      "epoch": 0.545,
      "grad_norm": 0.5051434636116028,
      "learning_rate": 0.000455,
      "loss": 0.0902,
      "step": 109000
    },
    {
      "epoch": 0.5455,
      "grad_norm": 0.8952889442443848,
      "learning_rate": 0.00045450000000000004,
      "loss": 0.0854,
      "step": 109100
    },
    {
      "epoch": 0.546,
      "grad_norm": 1.0976473093032837,
      "learning_rate": 0.00045400000000000003,
      "loss": 0.0902,
      "step": 109200
    },
    {
      "epoch": 0.5465,
      "grad_norm": 0.8629715442657471,
      "learning_rate": 0.0004535,
      "loss": 0.0879,
      "step": 109300
    },
    {
      "epoch": 0.547,
      "grad_norm": 0.7641075849533081,
      "learning_rate": 0.000453,
      "loss": 0.0867,
      "step": 109400
    },
    {
      "epoch": 0.5475,
      "grad_norm": 21.544923782348633,
      "learning_rate": 0.00045250000000000005,
      "loss": 0.0868,
      "step": 109500
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.8598489761352539,
      "learning_rate": 0.00045200000000000004,
      "loss": 0.0799,
      "step": 109600
    },
    {
      "epoch": 0.5485,
      "grad_norm": 0.5953009128570557,
      "learning_rate": 0.0004515,
      "loss": 0.0815,
      "step": 109700
    },
    {
      "epoch": 0.549,
      "grad_norm": 0.9723601341247559,
      "learning_rate": 0.000451,
      "loss": 0.0897,
      "step": 109800
    },
    {
      "epoch": 0.5495,
      "grad_norm": 0.6420943737030029,
      "learning_rate": 0.0004505,
      "loss": 0.0857,
      "step": 109900
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6210476756095886,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.0858,
      "step": 110000
    },
    {
      "epoch": 0.5505,
      "grad_norm": 0.4082527756690979,
      "learning_rate": 0.00044950000000000003,
      "loss": 0.0903,
      "step": 110100
    },
    {
      "epoch": 0.551,
      "grad_norm": 0.699095606803894,
      "learning_rate": 0.000449,
      "loss": 0.0824,
      "step": 110200
    },
    {
      "epoch": 0.5515,
      "grad_norm": 4.86379861831665,
      "learning_rate": 0.0004485,
      "loss": 0.083,
      "step": 110300
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.5969064235687256,
      "learning_rate": 0.000448,
      "loss": 0.0807,
      "step": 110400
    },
    {
      "epoch": 0.5525,
      "grad_norm": 0.7972493767738342,
      "learning_rate": 0.00044750000000000004,
      "loss": 0.0772,
      "step": 110500
    },
    {
      "epoch": 0.553,
      "grad_norm": 0.4845038950443268,
      "learning_rate": 0.000447,
      "loss": 0.0822,
      "step": 110600
    },
    {
      "epoch": 0.5535,
      "grad_norm": 0.6686877012252808,
      "learning_rate": 0.0004465,
      "loss": 0.0852,
      "step": 110700
    },
    {
      "epoch": 0.554,
      "grad_norm": 1.07035493850708,
      "learning_rate": 0.000446,
      "loss": 0.0741,
      "step": 110800
    },
    {
      "epoch": 0.5545,
      "grad_norm": 0.4215294122695923,
      "learning_rate": 0.00044550000000000004,
      "loss": 0.0867,
      "step": 110900
    },
    {
      "epoch": 0.555,
      "grad_norm": 0.5372055768966675,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.0844,
      "step": 111000
    },
    {
      "epoch": 0.5555,
      "grad_norm": 0.3406016230583191,
      "learning_rate": 0.0004445,
      "loss": 0.0847,
      "step": 111100
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.5603391528129578,
      "learning_rate": 0.000444,
      "loss": 0.082,
      "step": 111200
    },
    {
      "epoch": 0.5565,
      "grad_norm": 0.564383327960968,
      "learning_rate": 0.0004435,
      "loss": 0.0836,
      "step": 111300
    },
    {
      "epoch": 0.557,
      "grad_norm": 0.8498138785362244,
      "learning_rate": 0.00044300000000000003,
      "loss": 0.0812,
      "step": 111400
    },
    {
      "epoch": 0.5575,
      "grad_norm": 0.5599277019500732,
      "learning_rate": 0.0004425,
      "loss": 0.089,
      "step": 111500
    },
    {
      "epoch": 0.558,
      "grad_norm": 0.8089733719825745,
      "learning_rate": 0.000442,
      "loss": 0.0757,
      "step": 111600
    },
    {
      "epoch": 0.5585,
      "grad_norm": 0.5910351872444153,
      "learning_rate": 0.0004415,
      "loss": 0.0768,
      "step": 111700
    },
    {
      "epoch": 0.559,
      "grad_norm": 0.6637527346611023,
      "learning_rate": 0.000441,
      "loss": 0.0803,
      "step": 111800
    },
    {
      "epoch": 0.5595,
      "grad_norm": 1.1469944715499878,
      "learning_rate": 0.00044050000000000003,
      "loss": 0.0825,
      "step": 111900
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.46538034081459045,
      "learning_rate": 0.00044,
      "loss": 0.0892,
      "step": 112000
    },
    {
      "epoch": 0.5605,
      "grad_norm": 0.7365739345550537,
      "learning_rate": 0.0004395,
      "loss": 0.0848,
      "step": 112100
    },
    {
      "epoch": 0.561,
      "grad_norm": 1.119340419769287,
      "learning_rate": 0.000439,
      "loss": 0.0786,
      "step": 112200
    },
    {
      "epoch": 0.5615,
      "grad_norm": 1.3458486795425415,
      "learning_rate": 0.00043850000000000003,
      "loss": 0.0748,
      "step": 112300
    },
    {
      "epoch": 0.562,
      "grad_norm": 0.6827976703643799,
      "learning_rate": 0.000438,
      "loss": 0.0826,
      "step": 112400
    },
    {
      "epoch": 0.5625,
      "grad_norm": 2.1012814044952393,
      "learning_rate": 0.0004375,
      "loss": 0.0831,
      "step": 112500
    },
    {
      "epoch": 0.563,
      "grad_norm": 0.9407244920730591,
      "learning_rate": 0.000437,
      "loss": 0.0819,
      "step": 112600
    },
    {
      "epoch": 0.5635,
      "grad_norm": 0.903852105140686,
      "learning_rate": 0.0004365,
      "loss": 0.0761,
      "step": 112700
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.9598912596702576,
      "learning_rate": 0.000436,
      "loss": 0.0898,
      "step": 112800
    },
    {
      "epoch": 0.5645,
      "grad_norm": 0.7262057065963745,
      "learning_rate": 0.0004355,
      "loss": 0.0831,
      "step": 112900
    },
    {
      "epoch": 0.565,
      "grad_norm": 2.808161497116089,
      "learning_rate": 0.000435,
      "loss": 0.0784,
      "step": 113000
    },
    {
      "epoch": 0.5655,
      "grad_norm": 0.47451257705688477,
      "learning_rate": 0.0004345,
      "loss": 0.0819,
      "step": 113100
    },
    {
      "epoch": 0.566,
      "grad_norm": 2.3483777046203613,
      "learning_rate": 0.00043400000000000003,
      "loss": 0.0841,
      "step": 113200
    },
    {
      "epoch": 0.5665,
      "grad_norm": 0.5693898797035217,
      "learning_rate": 0.0004335,
      "loss": 0.0833,
      "step": 113300
    },
    {
      "epoch": 0.567,
      "grad_norm": 0.9658030867576599,
      "learning_rate": 0.000433,
      "loss": 0.0818,
      "step": 113400
    },
    {
      "epoch": 0.5675,
      "grad_norm": 0.4051656424999237,
      "learning_rate": 0.0004325,
      "loss": 0.0774,
      "step": 113500
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.49144768714904785,
      "learning_rate": 0.000432,
      "loss": 0.0776,
      "step": 113600
    },
    {
      "epoch": 0.5685,
      "grad_norm": 0.6459184885025024,
      "learning_rate": 0.0004315,
      "loss": 0.0777,
      "step": 113700
    },
    {
      "epoch": 0.569,
      "grad_norm": 0.4013043940067291,
      "learning_rate": 0.000431,
      "loss": 0.0788,
      "step": 113800
    },
    {
      "epoch": 0.5695,
      "grad_norm": 0.3196176588535309,
      "learning_rate": 0.0004305,
      "loss": 0.0803,
      "step": 113900
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5198481678962708,
      "learning_rate": 0.00043,
      "loss": 0.0798,
      "step": 114000
    },
    {
      "epoch": 0.5705,
      "grad_norm": 0.5310810208320618,
      "learning_rate": 0.0004295,
      "loss": 0.0778,
      "step": 114100
    },
    {
      "epoch": 0.571,
      "grad_norm": 0.961436927318573,
      "learning_rate": 0.000429,
      "loss": 0.0809,
      "step": 114200
    },
    {
      "epoch": 0.5715,
      "grad_norm": 0.8021628856658936,
      "learning_rate": 0.0004285,
      "loss": 0.0761,
      "step": 114300
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.6444065570831299,
      "learning_rate": 0.000428,
      "loss": 0.0827,
      "step": 114400
    },
    {
      "epoch": 0.5725,
      "grad_norm": 0.6986187696456909,
      "learning_rate": 0.0004275,
      "loss": 0.0829,
      "step": 114500
    },
    {
      "epoch": 0.573,
      "grad_norm": 1.8079240322113037,
      "learning_rate": 0.000427,
      "loss": 0.081,
      "step": 114600
    },
    {
      "epoch": 0.5735,
      "grad_norm": 0.939025342464447,
      "learning_rate": 0.0004265,
      "loss": 0.0858,
      "step": 114700
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.5588817000389099,
      "learning_rate": 0.000426,
      "loss": 0.0794,
      "step": 114800
    },
    {
      "epoch": 0.5745,
      "grad_norm": 8.973097801208496,
      "learning_rate": 0.0004255,
      "loss": 0.0814,
      "step": 114900
    },
    {
      "epoch": 0.575,
      "grad_norm": 0.9907682538032532,
      "learning_rate": 0.000425,
      "loss": 0.0828,
      "step": 115000
    },
    {
      "epoch": 0.5755,
      "grad_norm": 0.668647289276123,
      "learning_rate": 0.0004245,
      "loss": 0.0777,
      "step": 115100
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.9367860555648804,
      "learning_rate": 0.000424,
      "loss": 0.0819,
      "step": 115200
    },
    {
      "epoch": 0.5765,
      "grad_norm": 0.8064669370651245,
      "learning_rate": 0.0004235,
      "loss": 0.0788,
      "step": 115300
    },
    {
      "epoch": 0.577,
      "grad_norm": 1.0632833242416382,
      "learning_rate": 0.000423,
      "loss": 0.0837,
      "step": 115400
    },
    {
      "epoch": 0.5775,
      "grad_norm": 1.0289807319641113,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.084,
      "step": 115500
    },
    {
      "epoch": 0.578,
      "grad_norm": 0.4343947470188141,
      "learning_rate": 0.000422,
      "loss": 0.0805,
      "step": 115600
    },
    {
      "epoch": 0.5785,
      "grad_norm": 0.5394876003265381,
      "learning_rate": 0.0004215,
      "loss": 0.079,
      "step": 115700
    },
    {
      "epoch": 0.579,
      "grad_norm": 3.3243985176086426,
      "learning_rate": 0.000421,
      "loss": 0.0834,
      "step": 115800
    },
    {
      "epoch": 0.5795,
      "grad_norm": 0.6790035963058472,
      "learning_rate": 0.0004205,
      "loss": 0.0814,
      "step": 115900
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6249688267707825,
      "learning_rate": 0.00042,
      "loss": 0.0797,
      "step": 116000
    },
    {
      "epoch": 0.5805,
      "grad_norm": 1.7230517864227295,
      "learning_rate": 0.0004195,
      "loss": 0.0741,
      "step": 116100
    },
    {
      "epoch": 0.581,
      "grad_norm": 0.5811848044395447,
      "learning_rate": 0.000419,
      "loss": 0.0778,
      "step": 116200
    },
    {
      "epoch": 0.5815,
      "grad_norm": 0.48804816603660583,
      "learning_rate": 0.0004185,
      "loss": 0.0783,
      "step": 116300
    },
    {
      "epoch": 0.582,
      "grad_norm": 1.3337231874465942,
      "learning_rate": 0.00041799999999999997,
      "loss": 0.0793,
      "step": 116400
    },
    {
      "epoch": 0.5825,
      "grad_norm": 0.6453302502632141,
      "learning_rate": 0.0004175,
      "loss": 0.079,
      "step": 116500
    },
    {
      "epoch": 0.583,
      "grad_norm": 0.5057465434074402,
      "learning_rate": 0.000417,
      "loss": 0.0798,
      "step": 116600
    },
    {
      "epoch": 0.5835,
      "grad_norm": 0.5265913605690002,
      "learning_rate": 0.0004165,
      "loss": 0.0885,
      "step": 116700
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.9827829599380493,
      "learning_rate": 0.000416,
      "loss": 0.0881,
      "step": 116800
    },
    {
      "epoch": 0.5845,
      "grad_norm": 2.5253472328186035,
      "learning_rate": 0.00041549999999999996,
      "loss": 0.0776,
      "step": 116900
    },
    {
      "epoch": 0.585,
      "grad_norm": 0.7925022840499878,
      "learning_rate": 0.000415,
      "loss": 0.0811,
      "step": 117000
    },
    {
      "epoch": 0.5855,
      "grad_norm": 9.475923538208008,
      "learning_rate": 0.0004145,
      "loss": 0.076,
      "step": 117100
    },
    {
      "epoch": 0.586,
      "grad_norm": 1.1486674547195435,
      "learning_rate": 0.000414,
      "loss": 0.0812,
      "step": 117200
    },
    {
      "epoch": 0.5865,
      "grad_norm": 0.6191943287849426,
      "learning_rate": 0.00041349999999999997,
      "loss": 0.0816,
      "step": 117300
    },
    {
      "epoch": 0.587,
      "grad_norm": 0.526479959487915,
      "learning_rate": 0.000413,
      "loss": 0.075,
      "step": 117400
    },
    {
      "epoch": 0.5875,
      "grad_norm": 1.1469495296478271,
      "learning_rate": 0.0004125,
      "loss": 0.0772,
      "step": 117500
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.8491094708442688,
      "learning_rate": 0.000412,
      "loss": 0.082,
      "step": 117600
    },
    {
      "epoch": 0.5885,
      "grad_norm": 1.6003614664077759,
      "learning_rate": 0.0004115,
      "loss": 0.0791,
      "step": 117700
    },
    {
      "epoch": 0.589,
      "grad_norm": 0.8896270394325256,
      "learning_rate": 0.00041099999999999996,
      "loss": 0.076,
      "step": 117800
    },
    {
      "epoch": 0.5895,
      "grad_norm": 0.7168596386909485,
      "learning_rate": 0.0004105,
      "loss": 0.0818,
      "step": 117900
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5265429019927979,
      "learning_rate": 0.00041,
      "loss": 0.0719,
      "step": 118000
    },
    {
      "epoch": 0.5905,
      "grad_norm": 0.6623482704162598,
      "learning_rate": 0.0004095,
      "loss": 0.0794,
      "step": 118100
    },
    {
      "epoch": 0.591,
      "grad_norm": 0.6432811617851257,
      "learning_rate": 0.00040899999999999997,
      "loss": 0.0823,
      "step": 118200
    },
    {
      "epoch": 0.5915,
      "grad_norm": 1.0048103332519531,
      "learning_rate": 0.0004085,
      "loss": 0.0783,
      "step": 118300
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.5890230536460876,
      "learning_rate": 0.000408,
      "loss": 0.0783,
      "step": 118400
    },
    {
      "epoch": 0.5925,
      "grad_norm": 0.7131264209747314,
      "learning_rate": 0.0004075,
      "loss": 0.0816,
      "step": 118500
    },
    {
      "epoch": 0.593,
      "grad_norm": 0.6559370160102844,
      "learning_rate": 0.00040699999999999997,
      "loss": 0.0824,
      "step": 118600
    },
    {
      "epoch": 0.5935,
      "grad_norm": 8.404237747192383,
      "learning_rate": 0.00040649999999999996,
      "loss": 0.0781,
      "step": 118700
    },
    {
      "epoch": 0.594,
      "grad_norm": 0.3082483410835266,
      "learning_rate": 0.00040600000000000006,
      "loss": 0.0733,
      "step": 118800
    },
    {
      "epoch": 0.5945,
      "grad_norm": 0.9026047587394714,
      "learning_rate": 0.00040550000000000004,
      "loss": 0.0757,
      "step": 118900
    },
    {
      "epoch": 0.595,
      "grad_norm": 1.070361852645874,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.0802,
      "step": 119000
    },
    {
      "epoch": 0.5955,
      "grad_norm": 0.5281915664672852,
      "learning_rate": 0.0004045,
      "loss": 0.0786,
      "step": 119100
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.6059525012969971,
      "learning_rate": 0.000404,
      "loss": 0.0823,
      "step": 119200
    },
    {
      "epoch": 0.5965,
      "grad_norm": 0.5265495777130127,
      "learning_rate": 0.00040350000000000005,
      "loss": 0.0812,
      "step": 119300
    },
    {
      "epoch": 0.597,
      "grad_norm": 0.4242868423461914,
      "learning_rate": 0.00040300000000000004,
      "loss": 0.0714,
      "step": 119400
    },
    {
      "epoch": 0.5975,
      "grad_norm": 0.5600500106811523,
      "learning_rate": 0.0004025,
      "loss": 0.0732,
      "step": 119500
    },
    {
      "epoch": 0.598,
      "grad_norm": 0.8160683512687683,
      "learning_rate": 0.000402,
      "loss": 0.0817,
      "step": 119600
    },
    {
      "epoch": 0.5985,
      "grad_norm": 9.501559257507324,
      "learning_rate": 0.00040150000000000006,
      "loss": 0.0734,
      "step": 119700
    },
    {
      "epoch": 0.599,
      "grad_norm": 1.8996042013168335,
      "learning_rate": 0.00040100000000000004,
      "loss": 0.0686,
      "step": 119800
    },
    {
      "epoch": 0.5995,
      "grad_norm": 0.7028172612190247,
      "learning_rate": 0.00040050000000000003,
      "loss": 0.0794,
      "step": 119900
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.492061614990234,
      "learning_rate": 0.0004,
      "loss": 0.0768,
      "step": 120000
    },
    {
      "epoch": 0.6005,
      "grad_norm": 0.4611140489578247,
      "learning_rate": 0.0003995,
      "loss": 0.0749,
      "step": 120100
    },
    {
      "epoch": 0.601,
      "grad_norm": 0.4831526279449463,
      "learning_rate": 0.00039900000000000005,
      "loss": 0.0792,
      "step": 120200
    },
    {
      "epoch": 0.6015,
      "grad_norm": 1.1129472255706787,
      "learning_rate": 0.00039850000000000004,
      "loss": 0.077,
      "step": 120300
    },
    {
      "epoch": 0.602,
      "grad_norm": 2.846076250076294,
      "learning_rate": 0.000398,
      "loss": 0.0722,
      "step": 120400
    },
    {
      "epoch": 0.6025,
      "grad_norm": 0.7222604155540466,
      "learning_rate": 0.0003975,
      "loss": 0.0795,
      "step": 120500
    },
    {
      "epoch": 0.603,
      "grad_norm": 0.6656510829925537,
      "learning_rate": 0.00039700000000000005,
      "loss": 0.0763,
      "step": 120600
    },
    {
      "epoch": 0.6035,
      "grad_norm": 0.34625664353370667,
      "learning_rate": 0.00039650000000000004,
      "loss": 0.0816,
      "step": 120700
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.6923341751098633,
      "learning_rate": 0.00039600000000000003,
      "loss": 0.0747,
      "step": 120800
    },
    {
      "epoch": 0.6045,
      "grad_norm": 0.8472738862037659,
      "learning_rate": 0.0003955,
      "loss": 0.0689,
      "step": 120900
    },
    {
      "epoch": 0.605,
      "grad_norm": 2.3855488300323486,
      "learning_rate": 0.000395,
      "loss": 0.0737,
      "step": 121000
    },
    {
      "epoch": 0.6055,
      "grad_norm": 0.5829660892486572,
      "learning_rate": 0.00039450000000000005,
      "loss": 0.0737,
      "step": 121100
    },
    {
      "epoch": 0.606,
      "grad_norm": 1.599015712738037,
      "learning_rate": 0.00039400000000000004,
      "loss": 0.0728,
      "step": 121200
    },
    {
      "epoch": 0.6065,
      "grad_norm": 0.35035204887390137,
      "learning_rate": 0.0003935,
      "loss": 0.0755,
      "step": 121300
    },
    {
      "epoch": 0.607,
      "grad_norm": 0.45426979660987854,
      "learning_rate": 0.000393,
      "loss": 0.0697,
      "step": 121400
    },
    {
      "epoch": 0.6075,
      "grad_norm": 0.5705509781837463,
      "learning_rate": 0.0003925,
      "loss": 0.0756,
      "step": 121500
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.7873463034629822,
      "learning_rate": 0.00039200000000000004,
      "loss": 0.0729,
      "step": 121600
    },
    {
      "epoch": 0.6085,
      "grad_norm": 2.683624505996704,
      "learning_rate": 0.00039150000000000003,
      "loss": 0.0734,
      "step": 121700
    },
    {
      "epoch": 0.609,
      "grad_norm": 0.8848355412483215,
      "learning_rate": 0.000391,
      "loss": 0.0728,
      "step": 121800
    },
    {
      "epoch": 0.6095,
      "grad_norm": 1.567567229270935,
      "learning_rate": 0.0003905,
      "loss": 0.0746,
      "step": 121900
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.952793836593628,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.0731,
      "step": 122000
    },
    {
      "epoch": 0.6105,
      "grad_norm": 1.993184208869934,
      "learning_rate": 0.00038950000000000003,
      "loss": 0.0736,
      "step": 122100
    },
    {
      "epoch": 0.611,
      "grad_norm": 1.2468056678771973,
      "learning_rate": 0.000389,
      "loss": 0.0747,
      "step": 122200
    },
    {
      "epoch": 0.6115,
      "grad_norm": 0.6006130576133728,
      "learning_rate": 0.0003885,
      "loss": 0.069,
      "step": 122300
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.5498878955841064,
      "learning_rate": 0.000388,
      "loss": 0.0725,
      "step": 122400
    },
    {
      "epoch": 0.6125,
      "grad_norm": 0.7728239893913269,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.0713,
      "step": 122500
    },
    {
      "epoch": 0.613,
      "grad_norm": 0.3923279047012329,
      "learning_rate": 0.00038700000000000003,
      "loss": 0.0763,
      "step": 122600
    },
    {
      "epoch": 0.6135,
      "grad_norm": 0.5480594038963318,
      "learning_rate": 0.0003865,
      "loss": 0.0826,
      "step": 122700
    },
    {
      "epoch": 0.614,
      "grad_norm": 0.6762264370918274,
      "learning_rate": 0.000386,
      "loss": 0.0759,
      "step": 122800
    },
    {
      "epoch": 0.6145,
      "grad_norm": 0.4552084505558014,
      "learning_rate": 0.0003855,
      "loss": 0.0728,
      "step": 122900
    },
    {
      "epoch": 0.615,
      "grad_norm": 1.7408647537231445,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.072,
      "step": 123000
    },
    {
      "epoch": 0.6155,
      "grad_norm": 0.6936059594154358,
      "learning_rate": 0.0003845,
      "loss": 0.0721,
      "step": 123100
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.4533272981643677,
      "learning_rate": 0.000384,
      "loss": 0.0734,
      "step": 123200
    },
    {
      "epoch": 0.6165,
      "grad_norm": 0.716455340385437,
      "learning_rate": 0.0003835,
      "loss": 0.0701,
      "step": 123300
    },
    {
      "epoch": 0.617,
      "grad_norm": 1.4972507953643799,
      "learning_rate": 0.00038300000000000004,
      "loss": 0.0771,
      "step": 123400
    },
    {
      "epoch": 0.6175,
      "grad_norm": 1.0744117498397827,
      "learning_rate": 0.00038250000000000003,
      "loss": 0.074,
      "step": 123500
    },
    {
      "epoch": 0.618,
      "grad_norm": 1.643386960029602,
      "learning_rate": 0.000382,
      "loss": 0.0784,
      "step": 123600
    },
    {
      "epoch": 0.6185,
      "grad_norm": 0.6948801279067993,
      "learning_rate": 0.0003815,
      "loss": 0.0749,
      "step": 123700
    },
    {
      "epoch": 0.619,
      "grad_norm": 0.6955493688583374,
      "learning_rate": 0.000381,
      "loss": 0.0759,
      "step": 123800
    },
    {
      "epoch": 0.6195,
      "grad_norm": 1.432833194732666,
      "learning_rate": 0.00038050000000000003,
      "loss": 0.0718,
      "step": 123900
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3187518119812012,
      "learning_rate": 0.00038,
      "loss": 0.0692,
      "step": 124000
    },
    {
      "epoch": 0.6205,
      "grad_norm": 0.5890330672264099,
      "learning_rate": 0.0003795,
      "loss": 0.0742,
      "step": 124100
    },
    {
      "epoch": 0.621,
      "grad_norm": 0.7804819941520691,
      "learning_rate": 0.000379,
      "loss": 0.0786,
      "step": 124200
    },
    {
      "epoch": 0.6215,
      "grad_norm": 0.3931860029697418,
      "learning_rate": 0.0003785,
      "loss": 0.072,
      "step": 124300
    },
    {
      "epoch": 0.622,
      "grad_norm": 4.331853866577148,
      "learning_rate": 0.000378,
      "loss": 0.0801,
      "step": 124400
    },
    {
      "epoch": 0.6225,
      "grad_norm": 0.3502908945083618,
      "learning_rate": 0.0003775,
      "loss": 0.0754,
      "step": 124500
    },
    {
      "epoch": 0.623,
      "grad_norm": 0.47377899289131165,
      "learning_rate": 0.000377,
      "loss": 0.0729,
      "step": 124600
    },
    {
      "epoch": 0.6235,
      "grad_norm": 0.5676678419113159,
      "learning_rate": 0.0003765,
      "loss": 0.0756,
      "step": 124700
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.46149712800979614,
      "learning_rate": 0.00037600000000000003,
      "loss": 0.078,
      "step": 124800
    },
    {
      "epoch": 0.6245,
      "grad_norm": 0.8105000853538513,
      "learning_rate": 0.0003755,
      "loss": 0.0729,
      "step": 124900
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.47776004672050476,
      "learning_rate": 0.000375,
      "loss": 0.0711,
      "step": 125000
    },
    {
      "epoch": 0.6255,
      "grad_norm": 0.7198265194892883,
      "learning_rate": 0.0003745,
      "loss": 0.0708,
      "step": 125100
    },
    {
      "epoch": 0.626,
      "grad_norm": 0.47317609190940857,
      "learning_rate": 0.000374,
      "loss": 0.0743,
      "step": 125200
    },
    {
      "epoch": 0.6265,
      "grad_norm": 0.7765183448791504,
      "learning_rate": 0.0003735,
      "loss": 0.0694,
      "step": 125300
    },
    {
      "epoch": 0.627,
      "grad_norm": 0.3590785264968872,
      "learning_rate": 0.000373,
      "loss": 0.0717,
      "step": 125400
    },
    {
      "epoch": 0.6275,
      "grad_norm": 3.4472193717956543,
      "learning_rate": 0.0003725,
      "loss": 0.0743,
      "step": 125500
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.547690212726593,
      "learning_rate": 0.000372,
      "loss": 0.07,
      "step": 125600
    },
    {
      "epoch": 0.6285,
      "grad_norm": 0.7304516434669495,
      "learning_rate": 0.00037150000000000003,
      "loss": 0.074,
      "step": 125700
    },
    {
      "epoch": 0.629,
      "grad_norm": 5.633772850036621,
      "learning_rate": 0.000371,
      "loss": 0.0773,
      "step": 125800
    },
    {
      "epoch": 0.6295,
      "grad_norm": 0.6549218893051147,
      "learning_rate": 0.0003705,
      "loss": 0.0749,
      "step": 125900
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4245377480983734,
      "learning_rate": 0.00037,
      "loss": 0.0712,
      "step": 126000
    },
    {
      "epoch": 0.6305,
      "grad_norm": 1.816442847251892,
      "learning_rate": 0.0003695,
      "loss": 0.0693,
      "step": 126100
    },
    {
      "epoch": 0.631,
      "grad_norm": 0.9112985730171204,
      "learning_rate": 0.000369,
      "loss": 0.0743,
      "step": 126200
    },
    {
      "epoch": 0.6315,
      "grad_norm": 0.7855173945426941,
      "learning_rate": 0.0003685,
      "loss": 0.0697,
      "step": 126300
    },
    {
      "epoch": 0.632,
      "grad_norm": 9.651954650878906,
      "learning_rate": 0.000368,
      "loss": 0.0728,
      "step": 126400
    },
    {
      "epoch": 0.6325,
      "grad_norm": 0.42057526111602783,
      "learning_rate": 0.0003675,
      "loss": 0.0724,
      "step": 126500
    },
    {
      "epoch": 0.633,
      "grad_norm": 0.3863475024700165,
      "learning_rate": 0.000367,
      "loss": 0.0708,
      "step": 126600
    },
    {
      "epoch": 0.6335,
      "grad_norm": 0.6834591627120972,
      "learning_rate": 0.0003665,
      "loss": 0.0735,
      "step": 126700
    },
    {
      "epoch": 0.634,
      "grad_norm": 4.987070083618164,
      "learning_rate": 0.000366,
      "loss": 0.071,
      "step": 126800
    },
    {
      "epoch": 0.6345,
      "grad_norm": 0.3907402753829956,
      "learning_rate": 0.0003655,
      "loss": 0.0678,
      "step": 126900
    },
    {
      "epoch": 0.635,
      "grad_norm": 1.5152580738067627,
      "learning_rate": 0.000365,
      "loss": 0.077,
      "step": 127000
    },
    {
      "epoch": 0.6355,
      "grad_norm": 0.4055579602718353,
      "learning_rate": 0.0003645,
      "loss": 0.0724,
      "step": 127100
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.5424858927726746,
      "learning_rate": 0.000364,
      "loss": 0.0698,
      "step": 127200
    },
    {
      "epoch": 0.6365,
      "grad_norm": 0.7847221493721008,
      "learning_rate": 0.0003635,
      "loss": 0.0785,
      "step": 127300
    },
    {
      "epoch": 0.637,
      "grad_norm": 2.4678056240081787,
      "learning_rate": 0.000363,
      "loss": 0.0762,
      "step": 127400
    },
    {
      "epoch": 0.6375,
      "grad_norm": 0.38214173913002014,
      "learning_rate": 0.0003625,
      "loss": 0.0702,
      "step": 127500
    },
    {
      "epoch": 0.638,
      "grad_norm": 0.5506687164306641,
      "learning_rate": 0.000362,
      "loss": 0.0781,
      "step": 127600
    },
    {
      "epoch": 0.6385,
      "grad_norm": 1.5330008268356323,
      "learning_rate": 0.0003615,
      "loss": 0.0741,
      "step": 127700
    },
    {
      "epoch": 0.639,
      "grad_norm": 0.9462459087371826,
      "learning_rate": 0.000361,
      "loss": 0.0719,
      "step": 127800
    },
    {
      "epoch": 0.6395,
      "grad_norm": 0.7995006442070007,
      "learning_rate": 0.0003605,
      "loss": 0.0746,
      "step": 127900
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.9468166828155518,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.0739,
      "step": 128000
    },
    {
      "epoch": 0.6405,
      "grad_norm": 0.6624258160591125,
      "learning_rate": 0.0003595,
      "loss": 0.0744,
      "step": 128100
    },
    {
      "epoch": 0.641,
      "grad_norm": 0.6612836718559265,
      "learning_rate": 0.000359,
      "loss": 0.0693,
      "step": 128200
    },
    {
      "epoch": 0.6415,
      "grad_norm": 0.8359890580177307,
      "learning_rate": 0.0003585,
      "loss": 0.0682,
      "step": 128300
    },
    {
      "epoch": 0.642,
      "grad_norm": 1.0645672082901,
      "learning_rate": 0.000358,
      "loss": 0.0737,
      "step": 128400
    },
    {
      "epoch": 0.6425,
      "grad_norm": 0.7726072072982788,
      "learning_rate": 0.0003575,
      "loss": 0.0706,
      "step": 128500
    },
    {
      "epoch": 0.643,
      "grad_norm": 0.7131614089012146,
      "learning_rate": 0.000357,
      "loss": 0.071,
      "step": 128600
    },
    {
      "epoch": 0.6435,
      "grad_norm": 0.7385838031768799,
      "learning_rate": 0.0003565,
      "loss": 0.0724,
      "step": 128700
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.8849976658821106,
      "learning_rate": 0.000356,
      "loss": 0.0656,
      "step": 128800
    },
    {
      "epoch": 0.6445,
      "grad_norm": 1.1711931228637695,
      "learning_rate": 0.00035549999999999997,
      "loss": 0.0738,
      "step": 128900
    },
    {
      "epoch": 0.645,
      "grad_norm": 0.1716408133506775,
      "learning_rate": 0.000355,
      "loss": 0.0679,
      "step": 129000
    },
    {
      "epoch": 0.6455,
      "grad_norm": 0.7267371416091919,
      "learning_rate": 0.0003545,
      "loss": 0.0673,
      "step": 129100
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.6903825998306274,
      "learning_rate": 0.000354,
      "loss": 0.0684,
      "step": 129200
    },
    {
      "epoch": 0.6465,
      "grad_norm": 0.6871960163116455,
      "learning_rate": 0.0003535,
      "loss": 0.0718,
      "step": 129300
    },
    {
      "epoch": 0.647,
      "grad_norm": 0.5430539846420288,
      "learning_rate": 0.00035299999999999996,
      "loss": 0.0737,
      "step": 129400
    },
    {
      "epoch": 0.6475,
      "grad_norm": 0.6895673274993896,
      "learning_rate": 0.0003525,
      "loss": 0.0679,
      "step": 129500
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.5531039237976074,
      "learning_rate": 0.000352,
      "loss": 0.0738,
      "step": 129600
    },
    {
      "epoch": 0.6485,
      "grad_norm": 0.4560004770755768,
      "learning_rate": 0.0003515,
      "loss": 0.0741,
      "step": 129700
    },
    {
      "epoch": 0.649,
      "grad_norm": 0.6768845915794373,
      "learning_rate": 0.00035099999999999997,
      "loss": 0.0759,
      "step": 129800
    },
    {
      "epoch": 0.6495,
      "grad_norm": 0.942808210849762,
      "learning_rate": 0.0003505,
      "loss": 0.0692,
      "step": 129900
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.623752236366272,
      "learning_rate": 0.00035,
      "loss": 0.0682,
      "step": 130000
    },
    {
      "epoch": 0.6505,
      "grad_norm": 0.7189190983772278,
      "learning_rate": 0.0003495,
      "loss": 0.0701,
      "step": 130100
    },
    {
      "epoch": 0.651,
      "grad_norm": 0.8042269945144653,
      "learning_rate": 0.00034899999999999997,
      "loss": 0.0744,
      "step": 130200
    },
    {
      "epoch": 0.6515,
      "grad_norm": 1.0408833026885986,
      "learning_rate": 0.00034849999999999996,
      "loss": 0.0703,
      "step": 130300
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.7560732960700989,
      "learning_rate": 0.000348,
      "loss": 0.0725,
      "step": 130400
    },
    {
      "epoch": 0.6525,
      "grad_norm": 0.8034030795097351,
      "learning_rate": 0.0003475,
      "loss": 0.0664,
      "step": 130500
    },
    {
      "epoch": 0.653,
      "grad_norm": 0.828624427318573,
      "learning_rate": 0.000347,
      "loss": 0.0771,
      "step": 130600
    },
    {
      "epoch": 0.6535,
      "grad_norm": 0.48021867871284485,
      "learning_rate": 0.00034649999999999997,
      "loss": 0.0604,
      "step": 130700
    },
    {
      "epoch": 0.654,
      "grad_norm": 1.1602987051010132,
      "learning_rate": 0.000346,
      "loss": 0.071,
      "step": 130800
    },
    {
      "epoch": 0.6545,
      "grad_norm": 0.7179624438285828,
      "learning_rate": 0.0003455,
      "loss": 0.0717,
      "step": 130900
    },
    {
      "epoch": 0.655,
      "grad_norm": 0.3962653577327728,
      "learning_rate": 0.000345,
      "loss": 0.0739,
      "step": 131000
    },
    {
      "epoch": 0.6555,
      "grad_norm": 0.41052284836769104,
      "learning_rate": 0.00034449999999999997,
      "loss": 0.0696,
      "step": 131100
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.39784765243530273,
      "learning_rate": 0.00034399999999999996,
      "loss": 0.067,
      "step": 131200
    },
    {
      "epoch": 0.6565,
      "grad_norm": 0.7565488815307617,
      "learning_rate": 0.00034350000000000006,
      "loss": 0.0681,
      "step": 131300
    },
    {
      "epoch": 0.657,
      "grad_norm": 0.7728180289268494,
      "learning_rate": 0.00034300000000000004,
      "loss": 0.0676,
      "step": 131400
    },
    {
      "epoch": 0.6575,
      "grad_norm": 0.6035076975822449,
      "learning_rate": 0.00034250000000000003,
      "loss": 0.0724,
      "step": 131500
    },
    {
      "epoch": 0.658,
      "grad_norm": 0.5688918232917786,
      "learning_rate": 0.000342,
      "loss": 0.0695,
      "step": 131600
    },
    {
      "epoch": 0.6585,
      "grad_norm": 1.1276919841766357,
      "learning_rate": 0.0003415,
      "loss": 0.0665,
      "step": 131700
    },
    {
      "epoch": 0.659,
      "grad_norm": 0.6049774885177612,
      "learning_rate": 0.00034100000000000005,
      "loss": 0.07,
      "step": 131800
    },
    {
      "epoch": 0.6595,
      "grad_norm": 0.8585573434829712,
      "learning_rate": 0.00034050000000000004,
      "loss": 0.0667,
      "step": 131900
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5062931180000305,
      "learning_rate": 0.00034,
      "loss": 0.0689,
      "step": 132000
    },
    {
      "epoch": 0.6605,
      "grad_norm": 0.6242019534111023,
      "learning_rate": 0.0003395,
      "loss": 0.063,
      "step": 132100
    },
    {
      "epoch": 0.661,
      "grad_norm": 0.39770156145095825,
      "learning_rate": 0.00033900000000000005,
      "loss": 0.0695,
      "step": 132200
    },
    {
      "epoch": 0.6615,
      "grad_norm": 0.5441810488700867,
      "learning_rate": 0.00033850000000000004,
      "loss": 0.0716,
      "step": 132300
    },
    {
      "epoch": 0.662,
      "grad_norm": 0.7298738360404968,
      "learning_rate": 0.00033800000000000003,
      "loss": 0.0676,
      "step": 132400
    },
    {
      "epoch": 0.6625,
      "grad_norm": 0.6632569432258606,
      "learning_rate": 0.0003375,
      "loss": 0.0678,
      "step": 132500
    },
    {
      "epoch": 0.663,
      "grad_norm": 0.761498212814331,
      "learning_rate": 0.000337,
      "loss": 0.07,
      "step": 132600
    },
    {
      "epoch": 0.6635,
      "grad_norm": 0.8397284150123596,
      "learning_rate": 0.00033650000000000005,
      "loss": 0.0682,
      "step": 132700
    },
    {
      "epoch": 0.664,
      "grad_norm": 5.286845684051514,
      "learning_rate": 0.00033600000000000004,
      "loss": 0.0672,
      "step": 132800
    },
    {
      "epoch": 0.6645,
      "grad_norm": 0.8305708765983582,
      "learning_rate": 0.0003355,
      "loss": 0.0797,
      "step": 132900
    },
    {
      "epoch": 0.665,
      "grad_norm": 0.383590966463089,
      "learning_rate": 0.000335,
      "loss": 0.0768,
      "step": 133000
    },
    {
      "epoch": 0.6655,
      "grad_norm": 0.3979184627532959,
      "learning_rate": 0.00033450000000000005,
      "loss": 0.071,
      "step": 133100
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.5592891573905945,
      "learning_rate": 0.00033400000000000004,
      "loss": 0.0717,
      "step": 133200
    },
    {
      "epoch": 0.6665,
      "grad_norm": 1.6890689134597778,
      "learning_rate": 0.00033350000000000003,
      "loss": 0.0674,
      "step": 133300
    },
    {
      "epoch": 0.667,
      "grad_norm": 1.2048667669296265,
      "learning_rate": 0.000333,
      "loss": 0.0678,
      "step": 133400
    },
    {
      "epoch": 0.6675,
      "grad_norm": 0.41615211963653564,
      "learning_rate": 0.0003325,
      "loss": 0.0677,
      "step": 133500
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.3610696494579315,
      "learning_rate": 0.00033200000000000005,
      "loss": 0.0621,
      "step": 133600
    },
    {
      "epoch": 0.6685,
      "grad_norm": 1.2134864330291748,
      "learning_rate": 0.00033150000000000003,
      "loss": 0.0703,
      "step": 133700
    },
    {
      "epoch": 0.669,
      "grad_norm": 0.5004628896713257,
      "learning_rate": 0.000331,
      "loss": 0.0716,
      "step": 133800
    },
    {
      "epoch": 0.6695,
      "grad_norm": 0.3563741147518158,
      "learning_rate": 0.0003305,
      "loss": 0.0648,
      "step": 133900
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.39862024784088135,
      "learning_rate": 0.00033,
      "loss": 0.0704,
      "step": 134000
    },
    {
      "epoch": 0.6705,
      "grad_norm": 0.46210727095603943,
      "learning_rate": 0.00032950000000000004,
      "loss": 0.0697,
      "step": 134100
    },
    {
      "epoch": 0.671,
      "grad_norm": 0.49135786294937134,
      "learning_rate": 0.00032900000000000003,
      "loss": 0.0703,
      "step": 134200
    },
    {
      "epoch": 0.6715,
      "grad_norm": 0.599989116191864,
      "learning_rate": 0.0003285,
      "loss": 0.0641,
      "step": 134300
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.4724334180355072,
      "learning_rate": 0.000328,
      "loss": 0.0689,
      "step": 134400
    },
    {
      "epoch": 0.6725,
      "grad_norm": 0.5908575654029846,
      "learning_rate": 0.00032750000000000005,
      "loss": 0.0684,
      "step": 134500
    },
    {
      "epoch": 0.673,
      "grad_norm": 2.0992374420166016,
      "learning_rate": 0.00032700000000000003,
      "loss": 0.068,
      "step": 134600
    },
    {
      "epoch": 0.6735,
      "grad_norm": 1.918891429901123,
      "learning_rate": 0.0003265,
      "loss": 0.0653,
      "step": 134700
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.4272191822528839,
      "learning_rate": 0.000326,
      "loss": 0.0656,
      "step": 134800
    },
    {
      "epoch": 0.6745,
      "grad_norm": 1.089651107788086,
      "learning_rate": 0.0003255,
      "loss": 0.0604,
      "step": 134900
    },
    {
      "epoch": 0.675,
      "grad_norm": 0.7485438585281372,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.0681,
      "step": 135000
    },
    {
      "epoch": 0.6755,
      "grad_norm": 0.617786169052124,
      "learning_rate": 0.00032450000000000003,
      "loss": 0.0687,
      "step": 135100
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.584395170211792,
      "learning_rate": 0.000324,
      "loss": 0.0704,
      "step": 135200
    },
    {
      "epoch": 0.6765,
      "grad_norm": 1.3027101755142212,
      "learning_rate": 0.0003235,
      "loss": 0.0666,
      "step": 135300
    },
    {
      "epoch": 0.677,
      "grad_norm": 2.318551778793335,
      "learning_rate": 0.000323,
      "loss": 0.064,
      "step": 135400
    },
    {
      "epoch": 0.6775,
      "grad_norm": 0.4781447649002075,
      "learning_rate": 0.00032250000000000003,
      "loss": 0.0646,
      "step": 135500
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.7674691677093506,
      "learning_rate": 0.000322,
      "loss": 0.0629,
      "step": 135600
    },
    {
      "epoch": 0.6785,
      "grad_norm": 0.6373204588890076,
      "learning_rate": 0.0003215,
      "loss": 0.0679,
      "step": 135700
    },
    {
      "epoch": 0.679,
      "grad_norm": 0.8526124954223633,
      "learning_rate": 0.000321,
      "loss": 0.0628,
      "step": 135800
    },
    {
      "epoch": 0.6795,
      "grad_norm": 1.639337420463562,
      "learning_rate": 0.00032050000000000004,
      "loss": 0.0712,
      "step": 135900
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.4927908182144165,
      "learning_rate": 0.00032,
      "loss": 0.0606,
      "step": 136000
    },
    {
      "epoch": 0.6805,
      "grad_norm": 0.9625974297523499,
      "learning_rate": 0.0003195,
      "loss": 0.0656,
      "step": 136100
    },
    {
      "epoch": 0.681,
      "grad_norm": 0.5483779907226562,
      "learning_rate": 0.000319,
      "loss": 0.0669,
      "step": 136200
    },
    {
      "epoch": 0.6815,
      "grad_norm": 0.5749574899673462,
      "learning_rate": 0.0003185,
      "loss": 0.0686,
      "step": 136300
    },
    {
      "epoch": 0.682,
      "grad_norm": 1.6822377443313599,
      "learning_rate": 0.00031800000000000003,
      "loss": 0.0661,
      "step": 136400
    },
    {
      "epoch": 0.6825,
      "grad_norm": 1.5519461631774902,
      "learning_rate": 0.0003175,
      "loss": 0.0653,
      "step": 136500
    },
    {
      "epoch": 0.683,
      "grad_norm": 2.4539339542388916,
      "learning_rate": 0.000317,
      "loss": 0.0706,
      "step": 136600
    },
    {
      "epoch": 0.6835,
      "grad_norm": 0.3385275900363922,
      "learning_rate": 0.0003165,
      "loss": 0.0679,
      "step": 136700
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.8503822088241577,
      "learning_rate": 0.000316,
      "loss": 0.0685,
      "step": 136800
    },
    {
      "epoch": 0.6845,
      "grad_norm": 8.703845977783203,
      "learning_rate": 0.0003155,
      "loss": 0.0691,
      "step": 136900
    },
    {
      "epoch": 0.685,
      "grad_norm": 9.484862327575684,
      "learning_rate": 0.000315,
      "loss": 0.0681,
      "step": 137000
    },
    {
      "epoch": 0.6855,
      "grad_norm": 0.4743660092353821,
      "learning_rate": 0.0003145,
      "loss": 0.0681,
      "step": 137100
    },
    {
      "epoch": 0.686,
      "grad_norm": 0.4950956702232361,
      "learning_rate": 0.000314,
      "loss": 0.0631,
      "step": 137200
    },
    {
      "epoch": 0.6865,
      "grad_norm": 0.7371023893356323,
      "learning_rate": 0.00031350000000000003,
      "loss": 0.0686,
      "step": 137300
    },
    {
      "epoch": 0.687,
      "grad_norm": 0.7955124974250793,
      "learning_rate": 0.000313,
      "loss": 0.0692,
      "step": 137400
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.6352910995483398,
      "learning_rate": 0.0003125,
      "loss": 0.0718,
      "step": 137500
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.9238734245300293,
      "learning_rate": 0.000312,
      "loss": 0.0683,
      "step": 137600
    },
    {
      "epoch": 0.6885,
      "grad_norm": 0.5370764136314392,
      "learning_rate": 0.0003115,
      "loss": 0.0697,
      "step": 137700
    },
    {
      "epoch": 0.689,
      "grad_norm": 0.442561537027359,
      "learning_rate": 0.000311,
      "loss": 0.0689,
      "step": 137800
    },
    {
      "epoch": 0.6895,
      "grad_norm": 0.43326276540756226,
      "learning_rate": 0.0003105,
      "loss": 0.0651,
      "step": 137900
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.4193965196609497,
      "learning_rate": 0.00031,
      "loss": 0.0669,
      "step": 138000
    },
    {
      "epoch": 0.6905,
      "grad_norm": 0.672075092792511,
      "learning_rate": 0.0003095,
      "loss": 0.0614,
      "step": 138100
    },
    {
      "epoch": 0.691,
      "grad_norm": 4.132575035095215,
      "learning_rate": 0.00030900000000000003,
      "loss": 0.0613,
      "step": 138200
    },
    {
      "epoch": 0.6915,
      "grad_norm": 0.5846537351608276,
      "learning_rate": 0.0003085,
      "loss": 0.0709,
      "step": 138300
    },
    {
      "epoch": 0.692,
      "grad_norm": 3.5640499591827393,
      "learning_rate": 0.000308,
      "loss": 0.0717,
      "step": 138400
    },
    {
      "epoch": 0.6925,
      "grad_norm": 1.3695403337478638,
      "learning_rate": 0.0003075,
      "loss": 0.0627,
      "step": 138500
    },
    {
      "epoch": 0.693,
      "grad_norm": 0.5247820019721985,
      "learning_rate": 0.000307,
      "loss": 0.0683,
      "step": 138600
    },
    {
      "epoch": 0.6935,
      "grad_norm": 0.4821862280368805,
      "learning_rate": 0.0003065,
      "loss": 0.0682,
      "step": 138700
    },
    {
      "epoch": 0.694,
      "grad_norm": 0.4620548188686371,
      "learning_rate": 0.000306,
      "loss": 0.0623,
      "step": 138800
    },
    {
      "epoch": 0.6945,
      "grad_norm": 1.2124977111816406,
      "learning_rate": 0.0003055,
      "loss": 0.0687,
      "step": 138900
    },
    {
      "epoch": 0.695,
      "grad_norm": 2.1440560817718506,
      "learning_rate": 0.000305,
      "loss": 0.068,
      "step": 139000
    },
    {
      "epoch": 0.6955,
      "grad_norm": 0.8028063178062439,
      "learning_rate": 0.0003045,
      "loss": 0.0642,
      "step": 139100
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.5519770383834839,
      "learning_rate": 0.000304,
      "loss": 0.0648,
      "step": 139200
    },
    {
      "epoch": 0.6965,
      "grad_norm": 0.5000242590904236,
      "learning_rate": 0.0003035,
      "loss": 0.059,
      "step": 139300
    },
    {
      "epoch": 0.697,
      "grad_norm": 0.5726708173751831,
      "learning_rate": 0.000303,
      "loss": 0.0656,
      "step": 139400
    },
    {
      "epoch": 0.6975,
      "grad_norm": 0.6159951090812683,
      "learning_rate": 0.0003025,
      "loss": 0.0648,
      "step": 139500
    },
    {
      "epoch": 0.698,
      "grad_norm": 28.763629913330078,
      "learning_rate": 0.000302,
      "loss": 0.0664,
      "step": 139600
    },
    {
      "epoch": 0.6985,
      "grad_norm": 0.6298037171363831,
      "learning_rate": 0.0003015,
      "loss": 0.0644,
      "step": 139700
    },
    {
      "epoch": 0.699,
      "grad_norm": 0.7154455780982971,
      "learning_rate": 0.000301,
      "loss": 0.069,
      "step": 139800
    },
    {
      "epoch": 0.6995,
      "grad_norm": 0.3693673312664032,
      "learning_rate": 0.0003005,
      "loss": 0.0645,
      "step": 139900
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.36127129197120667,
      "learning_rate": 0.0003,
      "loss": 0.0667,
      "step": 140000
    },
    {
      "epoch": 0.7005,
      "grad_norm": 0.683205783367157,
      "learning_rate": 0.0002995,
      "loss": 0.0652,
      "step": 140100
    },
    {
      "epoch": 0.701,
      "grad_norm": 1.3738510608673096,
      "learning_rate": 0.000299,
      "loss": 0.0694,
      "step": 140200
    },
    {
      "epoch": 0.7015,
      "grad_norm": 0.8940864205360413,
      "learning_rate": 0.0002985,
      "loss": 0.0625,
      "step": 140300
    },
    {
      "epoch": 0.702,
      "grad_norm": 0.44777247309684753,
      "learning_rate": 0.000298,
      "loss": 0.0646,
      "step": 140400
    },
    {
      "epoch": 0.7025,
      "grad_norm": 1.2169382572174072,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.0694,
      "step": 140500
    },
    {
      "epoch": 0.703,
      "grad_norm": 1.613305687904358,
      "learning_rate": 0.000297,
      "loss": 0.0645,
      "step": 140600
    },
    {
      "epoch": 0.7035,
      "grad_norm": 1.6110044717788696,
      "learning_rate": 0.0002965,
      "loss": 0.0615,
      "step": 140700
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.4808231294155121,
      "learning_rate": 0.000296,
      "loss": 0.0677,
      "step": 140800
    },
    {
      "epoch": 0.7045,
      "grad_norm": 0.6062952876091003,
      "learning_rate": 0.00029549999999999997,
      "loss": 0.0666,
      "step": 140900
    },
    {
      "epoch": 0.705,
      "grad_norm": 0.49192652106285095,
      "learning_rate": 0.000295,
      "loss": 0.0677,
      "step": 141000
    },
    {
      "epoch": 0.7055,
      "grad_norm": 0.36617717146873474,
      "learning_rate": 0.0002945,
      "loss": 0.0677,
      "step": 141100
    },
    {
      "epoch": 0.706,
      "grad_norm": 0.528778076171875,
      "learning_rate": 0.000294,
      "loss": 0.0643,
      "step": 141200
    },
    {
      "epoch": 0.7065,
      "grad_norm": 3.2401297092437744,
      "learning_rate": 0.0002935,
      "loss": 0.0655,
      "step": 141300
    },
    {
      "epoch": 0.707,
      "grad_norm": 1.523862361907959,
      "learning_rate": 0.00029299999999999997,
      "loss": 0.0679,
      "step": 141400
    },
    {
      "epoch": 0.7075,
      "grad_norm": 1.7246476411819458,
      "learning_rate": 0.0002925,
      "loss": 0.06,
      "step": 141500
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.772697389125824,
      "learning_rate": 0.000292,
      "loss": 0.0673,
      "step": 141600
    },
    {
      "epoch": 0.7085,
      "grad_norm": 0.40624871850013733,
      "learning_rate": 0.0002915,
      "loss": 0.0617,
      "step": 141700
    },
    {
      "epoch": 0.709,
      "grad_norm": 1.3165193796157837,
      "learning_rate": 0.00029099999999999997,
      "loss": 0.0678,
      "step": 141800
    },
    {
      "epoch": 0.7095,
      "grad_norm": 1.1988195180892944,
      "learning_rate": 0.00029049999999999996,
      "loss": 0.0635,
      "step": 141900
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0860395431518555,
      "learning_rate": 0.00029,
      "loss": 0.0631,
      "step": 142000
    },
    {
      "epoch": 0.7105,
      "grad_norm": 0.4189983606338501,
      "learning_rate": 0.0002895,
      "loss": 0.0599,
      "step": 142100
    },
    {
      "epoch": 0.711,
      "grad_norm": 0.5465316772460938,
      "learning_rate": 0.000289,
      "loss": 0.0689,
      "step": 142200
    },
    {
      "epoch": 0.7115,
      "grad_norm": 0.41407233476638794,
      "learning_rate": 0.00028849999999999997,
      "loss": 0.0695,
      "step": 142300
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.21535834670066833,
      "learning_rate": 0.000288,
      "loss": 0.0621,
      "step": 142400
    },
    {
      "epoch": 0.7125,
      "grad_norm": 0.7365595102310181,
      "learning_rate": 0.0002875,
      "loss": 0.0608,
      "step": 142500
    },
    {
      "epoch": 0.713,
      "grad_norm": 1.1573867797851562,
      "learning_rate": 0.000287,
      "loss": 0.0653,
      "step": 142600
    },
    {
      "epoch": 0.7135,
      "grad_norm": 0.3683297336101532,
      "learning_rate": 0.00028649999999999997,
      "loss": 0.0648,
      "step": 142700
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.7415937781333923,
      "learning_rate": 0.00028599999999999996,
      "loss": 0.0647,
      "step": 142800
    },
    {
      "epoch": 0.7145,
      "grad_norm": 1.8706626892089844,
      "learning_rate": 0.0002855,
      "loss": 0.0692,
      "step": 142900
    },
    {
      "epoch": 0.715,
      "grad_norm": 0.427608460187912,
      "learning_rate": 0.000285,
      "loss": 0.0633,
      "step": 143000
    },
    {
      "epoch": 0.7155,
      "grad_norm": 2.4087815284729004,
      "learning_rate": 0.0002845,
      "loss": 0.0605,
      "step": 143100
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.6822043061256409,
      "learning_rate": 0.00028399999999999996,
      "loss": 0.0663,
      "step": 143200
    },
    {
      "epoch": 0.7165,
      "grad_norm": 0.5784707069396973,
      "learning_rate": 0.0002835,
      "loss": 0.0698,
      "step": 143300
    },
    {
      "epoch": 0.717,
      "grad_norm": 1.4852317571640015,
      "learning_rate": 0.000283,
      "loss": 0.0644,
      "step": 143400
    },
    {
      "epoch": 0.7175,
      "grad_norm": 1.384448766708374,
      "learning_rate": 0.0002825,
      "loss": 0.0623,
      "step": 143500
    },
    {
      "epoch": 0.718,
      "grad_norm": 0.5907333493232727,
      "learning_rate": 0.00028199999999999997,
      "loss": 0.0652,
      "step": 143600
    },
    {
      "epoch": 0.7185,
      "grad_norm": 1.8240188360214233,
      "learning_rate": 0.00028149999999999996,
      "loss": 0.0633,
      "step": 143700
    },
    {
      "epoch": 0.719,
      "grad_norm": 0.4523595869541168,
      "learning_rate": 0.00028100000000000005,
      "loss": 0.0622,
      "step": 143800
    },
    {
      "epoch": 0.7195,
      "grad_norm": 0.38393253087997437,
      "learning_rate": 0.00028050000000000004,
      "loss": 0.0648,
      "step": 143900
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.41448745131492615,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.0635,
      "step": 144000
    },
    {
      "epoch": 0.7205,
      "grad_norm": 1.8017910718917847,
      "learning_rate": 0.0002795,
      "loss": 0.0613,
      "step": 144100
    },
    {
      "epoch": 0.721,
      "grad_norm": 0.614971935749054,
      "learning_rate": 0.000279,
      "loss": 0.0668,
      "step": 144200
    },
    {
      "epoch": 0.7215,
      "grad_norm": 1.011574149131775,
      "learning_rate": 0.00027850000000000005,
      "loss": 0.0655,
      "step": 144300
    },
    {
      "epoch": 0.722,
      "grad_norm": 0.2897176146507263,
      "learning_rate": 0.00027800000000000004,
      "loss": 0.0637,
      "step": 144400
    },
    {
      "epoch": 0.7225,
      "grad_norm": 0.5013541579246521,
      "learning_rate": 0.0002775,
      "loss": 0.0615,
      "step": 144500
    },
    {
      "epoch": 0.723,
      "grad_norm": 0.3851567804813385,
      "learning_rate": 0.000277,
      "loss": 0.063,
      "step": 144600
    },
    {
      "epoch": 0.7235,
      "grad_norm": 3.5506842136383057,
      "learning_rate": 0.00027650000000000005,
      "loss": 0.0632,
      "step": 144700
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.9050723314285278,
      "learning_rate": 0.00027600000000000004,
      "loss": 0.0642,
      "step": 144800
    },
    {
      "epoch": 0.7245,
      "grad_norm": 0.3465585708618164,
      "learning_rate": 0.00027550000000000003,
      "loss": 0.0683,
      "step": 144900
    },
    {
      "epoch": 0.725,
      "grad_norm": 0.3993834853172302,
      "learning_rate": 0.000275,
      "loss": 0.0626,
      "step": 145000
    },
    {
      "epoch": 0.7255,
      "grad_norm": 4.762778282165527,
      "learning_rate": 0.0002745,
      "loss": 0.064,
      "step": 145100
    },
    {
      "epoch": 0.726,
      "grad_norm": 1.2968961000442505,
      "learning_rate": 0.00027400000000000005,
      "loss": 0.0638,
      "step": 145200
    },
    {
      "epoch": 0.7265,
      "grad_norm": 0.717647135257721,
      "learning_rate": 0.00027350000000000003,
      "loss": 0.0578,
      "step": 145300
    },
    {
      "epoch": 0.727,
      "grad_norm": 0.8762092590332031,
      "learning_rate": 0.000273,
      "loss": 0.0552,
      "step": 145400
    },
    {
      "epoch": 0.7275,
      "grad_norm": 0.8489934206008911,
      "learning_rate": 0.0002725,
      "loss": 0.0611,
      "step": 145500
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.7925792336463928,
      "learning_rate": 0.00027200000000000005,
      "loss": 0.0633,
      "step": 145600
    },
    {
      "epoch": 0.7285,
      "grad_norm": 0.9143207669258118,
      "learning_rate": 0.00027150000000000004,
      "loss": 0.0613,
      "step": 145700
    },
    {
      "epoch": 0.729,
      "grad_norm": 0.579939603805542,
      "learning_rate": 0.00027100000000000003,
      "loss": 0.0643,
      "step": 145800
    },
    {
      "epoch": 0.7295,
      "grad_norm": 16.66600799560547,
      "learning_rate": 0.0002705,
      "loss": 0.0618,
      "step": 145900
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5408696532249451,
      "learning_rate": 0.00027,
      "loss": 0.0632,
      "step": 146000
    },
    {
      "epoch": 0.7305,
      "grad_norm": 0.3701627552509308,
      "learning_rate": 0.00026950000000000005,
      "loss": 0.0566,
      "step": 146100
    },
    {
      "epoch": 0.731,
      "grad_norm": 0.4618232846260071,
      "learning_rate": 0.00026900000000000003,
      "loss": 0.0609,
      "step": 146200
    },
    {
      "epoch": 0.7315,
      "grad_norm": 0.4597022831439972,
      "learning_rate": 0.0002685,
      "loss": 0.0635,
      "step": 146300
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.7285879254341125,
      "learning_rate": 0.000268,
      "loss": 0.0624,
      "step": 146400
    },
    {
      "epoch": 0.7325,
      "grad_norm": 0.5969328880310059,
      "learning_rate": 0.0002675,
      "loss": 0.0644,
      "step": 146500
    },
    {
      "epoch": 0.733,
      "grad_norm": 0.3007151186466217,
      "learning_rate": 0.00026700000000000004,
      "loss": 0.0566,
      "step": 146600
    },
    {
      "epoch": 0.7335,
      "grad_norm": 0.44145169854164124,
      "learning_rate": 0.0002665,
      "loss": 0.0608,
      "step": 146700
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.6629061698913574,
      "learning_rate": 0.000266,
      "loss": 0.0645,
      "step": 146800
    },
    {
      "epoch": 0.7345,
      "grad_norm": 0.6617127060890198,
      "learning_rate": 0.0002655,
      "loss": 0.063,
      "step": 146900
    },
    {
      "epoch": 0.735,
      "grad_norm": 0.3225206136703491,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.0596,
      "step": 147000
    },
    {
      "epoch": 0.7355,
      "grad_norm": 0.49791038036346436,
      "learning_rate": 0.00026450000000000003,
      "loss": 0.0581,
      "step": 147100
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.8211376667022705,
      "learning_rate": 0.000264,
      "loss": 0.0651,
      "step": 147200
    },
    {
      "epoch": 0.7365,
      "grad_norm": 1.26377272605896,
      "learning_rate": 0.0002635,
      "loss": 0.0609,
      "step": 147300
    },
    {
      "epoch": 0.737,
      "grad_norm": 0.8357188701629639,
      "learning_rate": 0.000263,
      "loss": 0.0649,
      "step": 147400
    },
    {
      "epoch": 0.7375,
      "grad_norm": 1.671193242073059,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.0593,
      "step": 147500
    },
    {
      "epoch": 0.738,
      "grad_norm": 3.0310781002044678,
      "learning_rate": 0.000262,
      "loss": 0.058,
      "step": 147600
    },
    {
      "epoch": 0.7385,
      "grad_norm": 0.59788578748703,
      "learning_rate": 0.0002615,
      "loss": 0.0601,
      "step": 147700
    },
    {
      "epoch": 0.739,
      "grad_norm": 0.9611639380455017,
      "learning_rate": 0.000261,
      "loss": 0.0635,
      "step": 147800
    },
    {
      "epoch": 0.7395,
      "grad_norm": 0.4281579554080963,
      "learning_rate": 0.0002605,
      "loss": 0.058,
      "step": 147900
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.4240313172340393,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.0629,
      "step": 148000
    },
    {
      "epoch": 0.7405,
      "grad_norm": 0.30140748620033264,
      "learning_rate": 0.0002595,
      "loss": 0.0583,
      "step": 148100
    },
    {
      "epoch": 0.741,
      "grad_norm": 0.43051519989967346,
      "learning_rate": 0.000259,
      "loss": 0.0589,
      "step": 148200
    },
    {
      "epoch": 0.7415,
      "grad_norm": 0.4468829929828644,
      "learning_rate": 0.0002585,
      "loss": 0.0585,
      "step": 148300
    },
    {
      "epoch": 0.742,
      "grad_norm": 0.6291782855987549,
      "learning_rate": 0.00025800000000000004,
      "loss": 0.0646,
      "step": 148400
    },
    {
      "epoch": 0.7425,
      "grad_norm": 1.3462178707122803,
      "learning_rate": 0.0002575,
      "loss": 0.06,
      "step": 148500
    },
    {
      "epoch": 0.743,
      "grad_norm": 1.8392966985702515,
      "learning_rate": 0.000257,
      "loss": 0.0586,
      "step": 148600
    },
    {
      "epoch": 0.7435,
      "grad_norm": 0.5872984528541565,
      "learning_rate": 0.0002565,
      "loss": 0.0576,
      "step": 148700
    },
    {
      "epoch": 0.744,
      "grad_norm": 4.343123912811279,
      "learning_rate": 0.000256,
      "loss": 0.062,
      "step": 148800
    },
    {
      "epoch": 0.7445,
      "grad_norm": 2.95188307762146,
      "learning_rate": 0.00025550000000000003,
      "loss": 0.0594,
      "step": 148900
    },
    {
      "epoch": 0.745,
      "grad_norm": 0.5868414640426636,
      "learning_rate": 0.000255,
      "loss": 0.0589,
      "step": 149000
    },
    {
      "epoch": 0.7455,
      "grad_norm": 1.4104901552200317,
      "learning_rate": 0.0002545,
      "loss": 0.0591,
      "step": 149100
    },
    {
      "epoch": 0.746,
      "grad_norm": 1.1663261651992798,
      "learning_rate": 0.000254,
      "loss": 0.0628,
      "step": 149200
    },
    {
      "epoch": 0.7465,
      "grad_norm": 1.1478816270828247,
      "learning_rate": 0.0002535,
      "loss": 0.0596,
      "step": 149300
    },
    {
      "epoch": 0.747,
      "grad_norm": 2.1715168952941895,
      "learning_rate": 0.000253,
      "loss": 0.0608,
      "step": 149400
    },
    {
      "epoch": 0.7475,
      "grad_norm": 0.41165420413017273,
      "learning_rate": 0.0002525,
      "loss": 0.0609,
      "step": 149500
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.44685858488082886,
      "learning_rate": 0.000252,
      "loss": 0.0585,
      "step": 149600
    },
    {
      "epoch": 0.7485,
      "grad_norm": 0.6469841003417969,
      "learning_rate": 0.0002515,
      "loss": 0.0563,
      "step": 149700
    },
    {
      "epoch": 0.749,
      "grad_norm": 6.992936611175537,
      "learning_rate": 0.00025100000000000003,
      "loss": 0.0649,
      "step": 149800
    },
    {
      "epoch": 0.7495,
      "grad_norm": 1.0411975383758545,
      "learning_rate": 0.0002505,
      "loss": 0.0615,
      "step": 149900
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7431332468986511,
      "learning_rate": 0.00025,
      "loss": 0.064,
      "step": 150000
    },
    {
      "epoch": 0.7505,
      "grad_norm": 1.1453524827957153,
      "learning_rate": 0.0002495,
      "loss": 0.0568,
      "step": 150100
    },
    {
      "epoch": 0.751,
      "grad_norm": 0.647181510925293,
      "learning_rate": 0.000249,
      "loss": 0.0605,
      "step": 150200
    },
    {
      "epoch": 0.7515,
      "grad_norm": 0.4725658595561981,
      "learning_rate": 0.0002485,
      "loss": 0.0577,
      "step": 150300
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.8465694189071655,
      "learning_rate": 0.000248,
      "loss": 0.0635,
      "step": 150400
    },
    {
      "epoch": 0.7525,
      "grad_norm": 0.6590819954872131,
      "learning_rate": 0.0002475,
      "loss": 0.0581,
      "step": 150500
    },
    {
      "epoch": 0.753,
      "grad_norm": 1.1086698770523071,
      "learning_rate": 0.000247,
      "loss": 0.0669,
      "step": 150600
    },
    {
      "epoch": 0.7535,
      "grad_norm": 0.339424192905426,
      "learning_rate": 0.00024650000000000003,
      "loss": 0.0594,
      "step": 150700
    },
    {
      "epoch": 0.754,
      "grad_norm": 0.5276224613189697,
      "learning_rate": 0.000246,
      "loss": 0.0613,
      "step": 150800
    },
    {
      "epoch": 0.7545,
      "grad_norm": 2.266033887863159,
      "learning_rate": 0.0002455,
      "loss": 0.0618,
      "step": 150900
    },
    {
      "epoch": 0.755,
      "grad_norm": 0.4878002107143402,
      "learning_rate": 0.000245,
      "loss": 0.059,
      "step": 151000
    },
    {
      "epoch": 0.7555,
      "grad_norm": 0.43336623907089233,
      "learning_rate": 0.0002445,
      "loss": 0.0566,
      "step": 151100
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.4150676429271698,
      "learning_rate": 0.000244,
      "loss": 0.0619,
      "step": 151200
    },
    {
      "epoch": 0.7565,
      "grad_norm": 0.29805928468704224,
      "learning_rate": 0.0002435,
      "loss": 0.0618,
      "step": 151300
    },
    {
      "epoch": 0.757,
      "grad_norm": 0.5556151270866394,
      "learning_rate": 0.000243,
      "loss": 0.0573,
      "step": 151400
    },
    {
      "epoch": 0.7575,
      "grad_norm": 1.0723397731781006,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.0607,
      "step": 151500
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.4535667896270752,
      "learning_rate": 0.000242,
      "loss": 0.0553,
      "step": 151600
    },
    {
      "epoch": 0.7585,
      "grad_norm": 0.3437575697898865,
      "learning_rate": 0.0002415,
      "loss": 0.055,
      "step": 151700
    },
    {
      "epoch": 0.759,
      "grad_norm": 0.6445747017860413,
      "learning_rate": 0.000241,
      "loss": 0.0613,
      "step": 151800
    },
    {
      "epoch": 0.7595,
      "grad_norm": 0.3544796109199524,
      "learning_rate": 0.0002405,
      "loss": 0.0592,
      "step": 151900
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.37460148334503174,
      "learning_rate": 0.00024,
      "loss": 0.0507,
      "step": 152000
    },
    {
      "epoch": 0.7605,
      "grad_norm": 0.4449946880340576,
      "learning_rate": 0.0002395,
      "loss": 0.0601,
      "step": 152100
    },
    {
      "epoch": 0.761,
      "grad_norm": 3.2590434551239014,
      "learning_rate": 0.00023899999999999998,
      "loss": 0.0625,
      "step": 152200
    },
    {
      "epoch": 0.7615,
      "grad_norm": 0.36846375465393066,
      "learning_rate": 0.0002385,
      "loss": 0.0568,
      "step": 152300
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.4514448344707489,
      "learning_rate": 0.00023799999999999998,
      "loss": 0.0539,
      "step": 152400
    },
    {
      "epoch": 0.7625,
      "grad_norm": 0.3922349214553833,
      "learning_rate": 0.0002375,
      "loss": 0.057,
      "step": 152500
    },
    {
      "epoch": 0.763,
      "grad_norm": 0.32626956701278687,
      "learning_rate": 0.000237,
      "loss": 0.0588,
      "step": 152600
    },
    {
      "epoch": 0.7635,
      "grad_norm": 0.5362566709518433,
      "learning_rate": 0.0002365,
      "loss": 0.0525,
      "step": 152700
    },
    {
      "epoch": 0.764,
      "grad_norm": 1.0190171003341675,
      "learning_rate": 0.000236,
      "loss": 0.0577,
      "step": 152800
    },
    {
      "epoch": 0.7645,
      "grad_norm": 0.45095595717430115,
      "learning_rate": 0.0002355,
      "loss": 0.0643,
      "step": 152900
    },
    {
      "epoch": 0.765,
      "grad_norm": 0.3562895953655243,
      "learning_rate": 0.000235,
      "loss": 0.0542,
      "step": 153000
    },
    {
      "epoch": 0.7655,
      "grad_norm": 1.1701133251190186,
      "learning_rate": 0.00023449999999999998,
      "loss": 0.0607,
      "step": 153100
    },
    {
      "epoch": 0.766,
      "grad_norm": 0.3468588590621948,
      "learning_rate": 0.00023400000000000002,
      "loss": 0.0557,
      "step": 153200
    },
    {
      "epoch": 0.7665,
      "grad_norm": 0.6734883189201355,
      "learning_rate": 0.0002335,
      "loss": 0.0569,
      "step": 153300
    },
    {
      "epoch": 0.767,
      "grad_norm": 0.4104020297527313,
      "learning_rate": 0.00023300000000000003,
      "loss": 0.0605,
      "step": 153400
    },
    {
      "epoch": 0.7675,
      "grad_norm": 0.6143349409103394,
      "learning_rate": 0.0002325,
      "loss": 0.0598,
      "step": 153500
    },
    {
      "epoch": 0.768,
      "grad_norm": 1.0759047269821167,
      "learning_rate": 0.00023200000000000003,
      "loss": 0.0565,
      "step": 153600
    },
    {
      "epoch": 0.7685,
      "grad_norm": 0.5267716646194458,
      "learning_rate": 0.00023150000000000002,
      "loss": 0.0605,
      "step": 153700
    },
    {
      "epoch": 0.769,
      "grad_norm": 0.5482197403907776,
      "learning_rate": 0.000231,
      "loss": 0.0579,
      "step": 153800
    },
    {
      "epoch": 0.7695,
      "grad_norm": 0.4792190194129944,
      "learning_rate": 0.00023050000000000002,
      "loss": 0.0611,
      "step": 153900
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.0068857669830322,
      "learning_rate": 0.00023,
      "loss": 0.0553,
      "step": 154000
    },
    {
      "epoch": 0.7705,
      "grad_norm": 0.5622209906578064,
      "learning_rate": 0.00022950000000000002,
      "loss": 0.0608,
      "step": 154100
    },
    {
      "epoch": 0.771,
      "grad_norm": 0.6065596342086792,
      "learning_rate": 0.000229,
      "loss": 0.0628,
      "step": 154200
    },
    {
      "epoch": 0.7715,
      "grad_norm": 0.5175911784172058,
      "learning_rate": 0.00022850000000000002,
      "loss": 0.0576,
      "step": 154300
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.7805227041244507,
      "learning_rate": 0.000228,
      "loss": 0.0544,
      "step": 154400
    },
    {
      "epoch": 0.7725,
      "grad_norm": 0.5336642265319824,
      "learning_rate": 0.0002275,
      "loss": 0.0594,
      "step": 154500
    },
    {
      "epoch": 0.773,
      "grad_norm": 9.419154167175293,
      "learning_rate": 0.00022700000000000002,
      "loss": 0.0565,
      "step": 154600
    },
    {
      "epoch": 0.7735,
      "grad_norm": 0.9664813876152039,
      "learning_rate": 0.0002265,
      "loss": 0.0595,
      "step": 154700
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.9873095154762268,
      "learning_rate": 0.00022600000000000002,
      "loss": 0.0625,
      "step": 154800
    },
    {
      "epoch": 0.7745,
      "grad_norm": 0.5366846323013306,
      "learning_rate": 0.0002255,
      "loss": 0.0583,
      "step": 154900
    },
    {
      "epoch": 0.775,
      "grad_norm": 0.45230942964553833,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.06,
      "step": 155000
    },
    {
      "epoch": 0.7755,
      "grad_norm": 0.48311561346054077,
      "learning_rate": 0.0002245,
      "loss": 0.0567,
      "step": 155100
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.8162359595298767,
      "learning_rate": 0.000224,
      "loss": 0.0584,
      "step": 155200
    },
    {
      "epoch": 0.7765,
      "grad_norm": 0.6149207949638367,
      "learning_rate": 0.0002235,
      "loss": 0.0548,
      "step": 155300
    },
    {
      "epoch": 0.777,
      "grad_norm": 0.7941977381706238,
      "learning_rate": 0.000223,
      "loss": 0.0603,
      "step": 155400
    },
    {
      "epoch": 0.7775,
      "grad_norm": 0.43047773838043213,
      "learning_rate": 0.00022250000000000001,
      "loss": 0.0546,
      "step": 155500
    },
    {
      "epoch": 0.778,
      "grad_norm": 14.534104347229004,
      "learning_rate": 0.000222,
      "loss": 0.0579,
      "step": 155600
    },
    {
      "epoch": 0.7785,
      "grad_norm": 0.5066201686859131,
      "learning_rate": 0.00022150000000000002,
      "loss": 0.0548,
      "step": 155700
    },
    {
      "epoch": 0.779,
      "grad_norm": 0.7694276571273804,
      "learning_rate": 0.000221,
      "loss": 0.0606,
      "step": 155800
    },
    {
      "epoch": 0.7795,
      "grad_norm": 0.36340105533599854,
      "learning_rate": 0.0002205,
      "loss": 0.0583,
      "step": 155900
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3715408444404602,
      "learning_rate": 0.00022,
      "loss": 0.0563,
      "step": 156000
    },
    {
      "epoch": 0.7805,
      "grad_norm": 0.40410280227661133,
      "learning_rate": 0.0002195,
      "loss": 0.0565,
      "step": 156100
    },
    {
      "epoch": 0.781,
      "grad_norm": 0.43821772933006287,
      "learning_rate": 0.000219,
      "loss": 0.0566,
      "step": 156200
    },
    {
      "epoch": 0.7815,
      "grad_norm": 0.6246071457862854,
      "learning_rate": 0.0002185,
      "loss": 0.0626,
      "step": 156300
    },
    {
      "epoch": 0.782,
      "grad_norm": 0.4968351125717163,
      "learning_rate": 0.000218,
      "loss": 0.06,
      "step": 156400
    },
    {
      "epoch": 0.7825,
      "grad_norm": 0.9002155065536499,
      "learning_rate": 0.0002175,
      "loss": 0.0566,
      "step": 156500
    },
    {
      "epoch": 0.783,
      "grad_norm": 0.8079544305801392,
      "learning_rate": 0.00021700000000000002,
      "loss": 0.0541,
      "step": 156600
    },
    {
      "epoch": 0.7835,
      "grad_norm": 0.5421781539916992,
      "learning_rate": 0.0002165,
      "loss": 0.0593,
      "step": 156700
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.8724090456962585,
      "learning_rate": 0.000216,
      "loss": 0.058,
      "step": 156800
    },
    {
      "epoch": 0.7845,
      "grad_norm": 0.7320283651351929,
      "learning_rate": 0.0002155,
      "loss": 0.0575,
      "step": 156900
    },
    {
      "epoch": 0.785,
      "grad_norm": 0.33909884095191956,
      "learning_rate": 0.000215,
      "loss": 0.0574,
      "step": 157000
    },
    {
      "epoch": 0.7855,
      "grad_norm": 0.27339673042297363,
      "learning_rate": 0.0002145,
      "loss": 0.0558,
      "step": 157100
    },
    {
      "epoch": 0.786,
      "grad_norm": 0.46471381187438965,
      "learning_rate": 0.000214,
      "loss": 0.0633,
      "step": 157200
    },
    {
      "epoch": 0.7865,
      "grad_norm": 0.8849296569824219,
      "learning_rate": 0.0002135,
      "loss": 0.0603,
      "step": 157300
    },
    {
      "epoch": 0.787,
      "grad_norm": 0.36706048250198364,
      "learning_rate": 0.000213,
      "loss": 0.0559,
      "step": 157400
    },
    {
      "epoch": 0.7875,
      "grad_norm": 0.8864485025405884,
      "learning_rate": 0.0002125,
      "loss": 0.0557,
      "step": 157500
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.8698787689208984,
      "learning_rate": 0.000212,
      "loss": 0.059,
      "step": 157600
    },
    {
      "epoch": 0.7885,
      "grad_norm": 0.3626636862754822,
      "learning_rate": 0.0002115,
      "loss": 0.0578,
      "step": 157700
    },
    {
      "epoch": 0.789,
      "grad_norm": 18.277271270751953,
      "learning_rate": 0.000211,
      "loss": 0.0583,
      "step": 157800
    },
    {
      "epoch": 0.7895,
      "grad_norm": 3.9338555335998535,
      "learning_rate": 0.0002105,
      "loss": 0.0567,
      "step": 157900
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5218176245689392,
      "learning_rate": 0.00021,
      "loss": 0.0505,
      "step": 158000
    },
    {
      "epoch": 0.7905,
      "grad_norm": 0.40643930435180664,
      "learning_rate": 0.0002095,
      "loss": 0.0582,
      "step": 158100
    },
    {
      "epoch": 0.791,
      "grad_norm": 0.2909625470638275,
      "learning_rate": 0.00020899999999999998,
      "loss": 0.0563,
      "step": 158200
    },
    {
      "epoch": 0.7915,
      "grad_norm": 0.751469612121582,
      "learning_rate": 0.0002085,
      "loss": 0.0534,
      "step": 158300
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.6480317711830139,
      "learning_rate": 0.000208,
      "loss": 0.0564,
      "step": 158400
    },
    {
      "epoch": 0.7925,
      "grad_norm": 0.7193228006362915,
      "learning_rate": 0.0002075,
      "loss": 0.0536,
      "step": 158500
    },
    {
      "epoch": 0.793,
      "grad_norm": 0.3466929495334625,
      "learning_rate": 0.000207,
      "loss": 0.0541,
      "step": 158600
    },
    {
      "epoch": 0.7935,
      "grad_norm": 0.6495843529701233,
      "learning_rate": 0.0002065,
      "loss": 0.0557,
      "step": 158700
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.3997823894023895,
      "learning_rate": 0.000206,
      "loss": 0.0589,
      "step": 158800
    },
    {
      "epoch": 0.7945,
      "grad_norm": 1.2986754179000854,
      "learning_rate": 0.00020549999999999998,
      "loss": 0.0583,
      "step": 158900
    },
    {
      "epoch": 0.795,
      "grad_norm": 2.719341516494751,
      "learning_rate": 0.000205,
      "loss": 0.0527,
      "step": 159000
    },
    {
      "epoch": 0.7955,
      "grad_norm": 0.6203500628471375,
      "learning_rate": 0.00020449999999999998,
      "loss": 0.0604,
      "step": 159100
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.27088236808776855,
      "learning_rate": 0.000204,
      "loss": 0.058,
      "step": 159200
    },
    {
      "epoch": 0.7965,
      "grad_norm": 0.5601471066474915,
      "learning_rate": 0.00020349999999999999,
      "loss": 0.0568,
      "step": 159300
    },
    {
      "epoch": 0.797,
      "grad_norm": 0.6415727138519287,
      "learning_rate": 0.00020300000000000003,
      "loss": 0.0541,
      "step": 159400
    },
    {
      "epoch": 0.7975,
      "grad_norm": 0.7551962733268738,
      "learning_rate": 0.00020250000000000002,
      "loss": 0.06,
      "step": 159500
    },
    {
      "epoch": 0.798,
      "grad_norm": 0.3091927170753479,
      "learning_rate": 0.000202,
      "loss": 0.0557,
      "step": 159600
    },
    {
      "epoch": 0.7985,
      "grad_norm": 0.9203265905380249,
      "learning_rate": 0.00020150000000000002,
      "loss": 0.0561,
      "step": 159700
    },
    {
      "epoch": 0.799,
      "grad_norm": 0.3941384553909302,
      "learning_rate": 0.000201,
      "loss": 0.0549,
      "step": 159800
    },
    {
      "epoch": 0.7995,
      "grad_norm": 0.8731900453567505,
      "learning_rate": 0.00020050000000000002,
      "loss": 0.0584,
      "step": 159900
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6325924396514893,
      "learning_rate": 0.0002,
      "loss": 0.0566,
      "step": 160000
    },
    {
      "epoch": 0.8005,
      "grad_norm": 0.7347636818885803,
      "learning_rate": 0.00019950000000000002,
      "loss": 0.0583,
      "step": 160100
    },
    {
      "epoch": 0.801,
      "grad_norm": 0.4558461606502533,
      "learning_rate": 0.000199,
      "loss": 0.0539,
      "step": 160200
    },
    {
      "epoch": 0.8015,
      "grad_norm": 1.1161692142486572,
      "learning_rate": 0.00019850000000000003,
      "loss": 0.0573,
      "step": 160300
    },
    {
      "epoch": 0.802,
      "grad_norm": 0.3197368085384369,
      "learning_rate": 0.00019800000000000002,
      "loss": 0.0567,
      "step": 160400
    },
    {
      "epoch": 0.8025,
      "grad_norm": 0.984758734703064,
      "learning_rate": 0.0001975,
      "loss": 0.0531,
      "step": 160500
    },
    {
      "epoch": 0.803,
      "grad_norm": 0.6184144616127014,
      "learning_rate": 0.00019700000000000002,
      "loss": 0.0557,
      "step": 160600
    },
    {
      "epoch": 0.8035,
      "grad_norm": 0.3880115747451782,
      "learning_rate": 0.0001965,
      "loss": 0.0548,
      "step": 160700
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.5611394643783569,
      "learning_rate": 0.00019600000000000002,
      "loss": 0.0557,
      "step": 160800
    },
    {
      "epoch": 0.8045,
      "grad_norm": 0.5385037064552307,
      "learning_rate": 0.0001955,
      "loss": 0.0557,
      "step": 160900
    },
    {
      "epoch": 0.805,
      "grad_norm": 1.4856419563293457,
      "learning_rate": 0.00019500000000000002,
      "loss": 0.0545,
      "step": 161000
    },
    {
      "epoch": 0.8055,
      "grad_norm": 2.206511974334717,
      "learning_rate": 0.0001945,
      "loss": 0.0557,
      "step": 161100
    },
    {
      "epoch": 0.806,
      "grad_norm": 1.158799171447754,
      "learning_rate": 0.000194,
      "loss": 0.0566,
      "step": 161200
    },
    {
      "epoch": 0.8065,
      "grad_norm": 0.4643654525279999,
      "learning_rate": 0.00019350000000000001,
      "loss": 0.0559,
      "step": 161300
    },
    {
      "epoch": 0.807,
      "grad_norm": 0.8958401083946228,
      "learning_rate": 0.000193,
      "loss": 0.0559,
      "step": 161400
    },
    {
      "epoch": 0.8075,
      "grad_norm": 2.4773433208465576,
      "learning_rate": 0.00019250000000000002,
      "loss": 0.0525,
      "step": 161500
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.9990741610527039,
      "learning_rate": 0.000192,
      "loss": 0.0571,
      "step": 161600
    },
    {
      "epoch": 0.8085,
      "grad_norm": 0.5398056507110596,
      "learning_rate": 0.00019150000000000002,
      "loss": 0.052,
      "step": 161700
    },
    {
      "epoch": 0.809,
      "grad_norm": 0.33994629979133606,
      "learning_rate": 0.000191,
      "loss": 0.0526,
      "step": 161800
    },
    {
      "epoch": 0.8095,
      "grad_norm": 0.8507422804832458,
      "learning_rate": 0.0001905,
      "loss": 0.0571,
      "step": 161900
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.42078572511672974,
      "learning_rate": 0.00019,
      "loss": 0.0556,
      "step": 162000
    },
    {
      "epoch": 0.8105,
      "grad_norm": 0.13957946002483368,
      "learning_rate": 0.0001895,
      "loss": 0.0562,
      "step": 162100
    },
    {
      "epoch": 0.811,
      "grad_norm": 0.5413252115249634,
      "learning_rate": 0.000189,
      "loss": 0.0545,
      "step": 162200
    },
    {
      "epoch": 0.8115,
      "grad_norm": 0.7080214619636536,
      "learning_rate": 0.0001885,
      "loss": 0.0567,
      "step": 162300
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.5771125555038452,
      "learning_rate": 0.00018800000000000002,
      "loss": 0.0547,
      "step": 162400
    },
    {
      "epoch": 0.8125,
      "grad_norm": 0.4716532230377197,
      "learning_rate": 0.0001875,
      "loss": 0.0543,
      "step": 162500
    },
    {
      "epoch": 0.813,
      "grad_norm": 0.4115513563156128,
      "learning_rate": 0.000187,
      "loss": 0.0559,
      "step": 162600
    },
    {
      "epoch": 0.8135,
      "grad_norm": 0.688633143901825,
      "learning_rate": 0.0001865,
      "loss": 0.0561,
      "step": 162700
    },
    {
      "epoch": 0.814,
      "grad_norm": 10.067432403564453,
      "learning_rate": 0.000186,
      "loss": 0.0542,
      "step": 162800
    },
    {
      "epoch": 0.8145,
      "grad_norm": 0.44968587160110474,
      "learning_rate": 0.0001855,
      "loss": 0.054,
      "step": 162900
    },
    {
      "epoch": 0.815,
      "grad_norm": 0.6321461796760559,
      "learning_rate": 0.000185,
      "loss": 0.0528,
      "step": 163000
    },
    {
      "epoch": 0.8155,
      "grad_norm": 1.8811445236206055,
      "learning_rate": 0.0001845,
      "loss": 0.0491,
      "step": 163100
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.37313881516456604,
      "learning_rate": 0.000184,
      "loss": 0.0487,
      "step": 163200
    },
    {
      "epoch": 0.8165,
      "grad_norm": 10.01307201385498,
      "learning_rate": 0.0001835,
      "loss": 0.0536,
      "step": 163300
    },
    {
      "epoch": 0.817,
      "grad_norm": 0.4212345778942108,
      "learning_rate": 0.000183,
      "loss": 0.0533,
      "step": 163400
    },
    {
      "epoch": 0.8175,
      "grad_norm": 1.0766669511795044,
      "learning_rate": 0.0001825,
      "loss": 0.053,
      "step": 163500
    },
    {
      "epoch": 0.818,
      "grad_norm": 0.349025160074234,
      "learning_rate": 0.000182,
      "loss": 0.0518,
      "step": 163600
    },
    {
      "epoch": 0.8185,
      "grad_norm": 1.086440086364746,
      "learning_rate": 0.0001815,
      "loss": 0.0518,
      "step": 163700
    },
    {
      "epoch": 0.819,
      "grad_norm": 0.6255761981010437,
      "learning_rate": 0.000181,
      "loss": 0.0541,
      "step": 163800
    },
    {
      "epoch": 0.8195,
      "grad_norm": 1.1769931316375732,
      "learning_rate": 0.0001805,
      "loss": 0.0553,
      "step": 163900
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4272770881652832,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.051,
      "step": 164000
    },
    {
      "epoch": 0.8205,
      "grad_norm": 0.35075846314430237,
      "learning_rate": 0.0001795,
      "loss": 0.0554,
      "step": 164100
    },
    {
      "epoch": 0.821,
      "grad_norm": 0.4124167859554291,
      "learning_rate": 0.000179,
      "loss": 0.0523,
      "step": 164200
    },
    {
      "epoch": 0.8215,
      "grad_norm": 0.6972954869270325,
      "learning_rate": 0.0001785,
      "loss": 0.054,
      "step": 164300
    },
    {
      "epoch": 0.822,
      "grad_norm": 3.445679187774658,
      "learning_rate": 0.000178,
      "loss": 0.0549,
      "step": 164400
    },
    {
      "epoch": 0.8225,
      "grad_norm": 0.6450902223587036,
      "learning_rate": 0.0001775,
      "loss": 0.0546,
      "step": 164500
    },
    {
      "epoch": 0.823,
      "grad_norm": 0.4749627709388733,
      "learning_rate": 0.000177,
      "loss": 0.0536,
      "step": 164600
    },
    {
      "epoch": 0.8235,
      "grad_norm": 1.0269489288330078,
      "learning_rate": 0.00017649999999999998,
      "loss": 0.0511,
      "step": 164700
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.3384743928909302,
      "learning_rate": 0.000176,
      "loss": 0.0572,
      "step": 164800
    },
    {
      "epoch": 0.8245,
      "grad_norm": 0.48912569880485535,
      "learning_rate": 0.00017549999999999998,
      "loss": 0.0491,
      "step": 164900
    },
    {
      "epoch": 0.825,
      "grad_norm": 0.4911589026451111,
      "learning_rate": 0.000175,
      "loss": 0.056,
      "step": 165000
    },
    {
      "epoch": 0.8255,
      "grad_norm": 0.3877849876880646,
      "learning_rate": 0.00017449999999999999,
      "loss": 0.0506,
      "step": 165100
    },
    {
      "epoch": 0.826,
      "grad_norm": 0.5833094120025635,
      "learning_rate": 0.000174,
      "loss": 0.0509,
      "step": 165200
    },
    {
      "epoch": 0.8265,
      "grad_norm": 0.62422776222229,
      "learning_rate": 0.0001735,
      "loss": 0.051,
      "step": 165300
    },
    {
      "epoch": 0.827,
      "grad_norm": 0.5136759877204895,
      "learning_rate": 0.000173,
      "loss": 0.0551,
      "step": 165400
    },
    {
      "epoch": 0.8275,
      "grad_norm": 0.4103195369243622,
      "learning_rate": 0.0001725,
      "loss": 0.0531,
      "step": 165500
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.5204859972000122,
      "learning_rate": 0.00017199999999999998,
      "loss": 0.0526,
      "step": 165600
    },
    {
      "epoch": 0.8285,
      "grad_norm": 0.5534353256225586,
      "learning_rate": 0.00017150000000000002,
      "loss": 0.0567,
      "step": 165700
    },
    {
      "epoch": 0.829,
      "grad_norm": 0.5160815119743347,
      "learning_rate": 0.000171,
      "loss": 0.055,
      "step": 165800
    },
    {
      "epoch": 0.8295,
      "grad_norm": 0.858032763004303,
      "learning_rate": 0.00017050000000000002,
      "loss": 0.0555,
      "step": 165900
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.3517414629459381,
      "learning_rate": 0.00017,
      "loss": 0.0514,
      "step": 166000
    },
    {
      "epoch": 0.8305,
      "grad_norm": 0.4409961402416229,
      "learning_rate": 0.00016950000000000003,
      "loss": 0.0531,
      "step": 166100
    },
    {
      "epoch": 0.831,
      "grad_norm": 0.5381865501403809,
      "learning_rate": 0.00016900000000000002,
      "loss": 0.0574,
      "step": 166200
    },
    {
      "epoch": 0.8315,
      "grad_norm": 0.42948660254478455,
      "learning_rate": 0.0001685,
      "loss": 0.0483,
      "step": 166300
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.6692767143249512,
      "learning_rate": 0.00016800000000000002,
      "loss": 0.0533,
      "step": 166400
    },
    {
      "epoch": 0.8325,
      "grad_norm": 0.3641245663166046,
      "learning_rate": 0.0001675,
      "loss": 0.0513,
      "step": 166500
    },
    {
      "epoch": 0.833,
      "grad_norm": 1.9319658279418945,
      "learning_rate": 0.00016700000000000002,
      "loss": 0.0536,
      "step": 166600
    },
    {
      "epoch": 0.8335,
      "grad_norm": 2.0195465087890625,
      "learning_rate": 0.0001665,
      "loss": 0.0564,
      "step": 166700
    },
    {
      "epoch": 0.834,
      "grad_norm": 0.4024418890476227,
      "learning_rate": 0.00016600000000000002,
      "loss": 0.0502,
      "step": 166800
    },
    {
      "epoch": 0.8345,
      "grad_norm": 0.3806999921798706,
      "learning_rate": 0.0001655,
      "loss": 0.0531,
      "step": 166900
    },
    {
      "epoch": 0.835,
      "grad_norm": 1.1436244249343872,
      "learning_rate": 0.000165,
      "loss": 0.051,
      "step": 167000
    },
    {
      "epoch": 0.8355,
      "grad_norm": 0.2498253732919693,
      "learning_rate": 0.00016450000000000001,
      "loss": 0.0517,
      "step": 167100
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.6592722535133362,
      "learning_rate": 0.000164,
      "loss": 0.0486,
      "step": 167200
    },
    {
      "epoch": 0.8365,
      "grad_norm": 0.8611249327659607,
      "learning_rate": 0.00016350000000000002,
      "loss": 0.0504,
      "step": 167300
    },
    {
      "epoch": 0.837,
      "grad_norm": 0.32927119731903076,
      "learning_rate": 0.000163,
      "loss": 0.0486,
      "step": 167400
    },
    {
      "epoch": 0.8375,
      "grad_norm": 0.31366345286369324,
      "learning_rate": 0.00016250000000000002,
      "loss": 0.0562,
      "step": 167500
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.28525352478027344,
      "learning_rate": 0.000162,
      "loss": 0.0503,
      "step": 167600
    },
    {
      "epoch": 0.8385,
      "grad_norm": 0.30138999223709106,
      "learning_rate": 0.0001615,
      "loss": 0.0518,
      "step": 167700
    },
    {
      "epoch": 0.839,
      "grad_norm": 0.5513673424720764,
      "learning_rate": 0.000161,
      "loss": 0.0517,
      "step": 167800
    },
    {
      "epoch": 0.8395,
      "grad_norm": 0.4111673831939697,
      "learning_rate": 0.0001605,
      "loss": 0.0522,
      "step": 167900
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.30137699842453003,
      "learning_rate": 0.00016,
      "loss": 0.0503,
      "step": 168000
    },
    {
      "epoch": 0.8405,
      "grad_norm": 0.4785774350166321,
      "learning_rate": 0.0001595,
      "loss": 0.0505,
      "step": 168100
    },
    {
      "epoch": 0.841,
      "grad_norm": 0.4989745616912842,
      "learning_rate": 0.00015900000000000002,
      "loss": 0.0454,
      "step": 168200
    },
    {
      "epoch": 0.8415,
      "grad_norm": 0.5313795208930969,
      "learning_rate": 0.0001585,
      "loss": 0.053,
      "step": 168300
    },
    {
      "epoch": 0.842,
      "grad_norm": 0.41023167967796326,
      "learning_rate": 0.000158,
      "loss": 0.0508,
      "step": 168400
    },
    {
      "epoch": 0.8425,
      "grad_norm": 0.3164096176624298,
      "learning_rate": 0.0001575,
      "loss": 0.0492,
      "step": 168500
    },
    {
      "epoch": 0.843,
      "grad_norm": 0.3110639750957489,
      "learning_rate": 0.000157,
      "loss": 0.0537,
      "step": 168600
    },
    {
      "epoch": 0.8435,
      "grad_norm": 1.450697422027588,
      "learning_rate": 0.0001565,
      "loss": 0.0515,
      "step": 168700
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.3859589993953705,
      "learning_rate": 0.000156,
      "loss": 0.0555,
      "step": 168800
    },
    {
      "epoch": 0.8445,
      "grad_norm": 0.4104633629322052,
      "learning_rate": 0.0001555,
      "loss": 0.0513,
      "step": 168900
    },
    {
      "epoch": 0.845,
      "grad_norm": 0.7399042248725891,
      "learning_rate": 0.000155,
      "loss": 0.0544,
      "step": 169000
    },
    {
      "epoch": 0.8455,
      "grad_norm": 0.7285867929458618,
      "learning_rate": 0.00015450000000000001,
      "loss": 0.0534,
      "step": 169100
    },
    {
      "epoch": 0.846,
      "grad_norm": 0.9154348373413086,
      "learning_rate": 0.000154,
      "loss": 0.0535,
      "step": 169200
    },
    {
      "epoch": 0.8465,
      "grad_norm": 0.7875219583511353,
      "learning_rate": 0.0001535,
      "loss": 0.0566,
      "step": 169300
    },
    {
      "epoch": 0.847,
      "grad_norm": 0.460172563791275,
      "learning_rate": 0.000153,
      "loss": 0.0479,
      "step": 169400
    },
    {
      "epoch": 0.8475,
      "grad_norm": 0.844217836856842,
      "learning_rate": 0.0001525,
      "loss": 0.0562,
      "step": 169500
    },
    {
      "epoch": 0.848,
      "grad_norm": 1.0002495050430298,
      "learning_rate": 0.000152,
      "loss": 0.0499,
      "step": 169600
    },
    {
      "epoch": 0.8485,
      "grad_norm": 0.5579130053520203,
      "learning_rate": 0.0001515,
      "loss": 0.0509,
      "step": 169700
    },
    {
      "epoch": 0.849,
      "grad_norm": 0.43230119347572327,
      "learning_rate": 0.000151,
      "loss": 0.0485,
      "step": 169800
    },
    {
      "epoch": 0.8495,
      "grad_norm": 0.40404972434043884,
      "learning_rate": 0.0001505,
      "loss": 0.0502,
      "step": 169900
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.9135701656341553,
      "learning_rate": 0.00015,
      "loss": 0.0508,
      "step": 170000
    },
    {
      "epoch": 0.8505,
      "grad_norm": 0.6157453060150146,
      "learning_rate": 0.0001495,
      "loss": 0.0541,
      "step": 170100
    },
    {
      "epoch": 0.851,
      "grad_norm": 0.7274208664894104,
      "learning_rate": 0.000149,
      "loss": 0.0494,
      "step": 170200
    },
    {
      "epoch": 0.8515,
      "grad_norm": 0.49589803814888,
      "learning_rate": 0.0001485,
      "loss": 0.0536,
      "step": 170300
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.3698994219303131,
      "learning_rate": 0.000148,
      "loss": 0.0542,
      "step": 170400
    },
    {
      "epoch": 0.8525,
      "grad_norm": 0.817974865436554,
      "learning_rate": 0.0001475,
      "loss": 0.0548,
      "step": 170500
    },
    {
      "epoch": 0.853,
      "grad_norm": 0.40961161255836487,
      "learning_rate": 0.000147,
      "loss": 0.0567,
      "step": 170600
    },
    {
      "epoch": 0.8535,
      "grad_norm": 1.6731181144714355,
      "learning_rate": 0.00014649999999999998,
      "loss": 0.0478,
      "step": 170700
    },
    {
      "epoch": 0.854,
      "grad_norm": 2.019582986831665,
      "learning_rate": 0.000146,
      "loss": 0.052,
      "step": 170800
    },
    {
      "epoch": 0.8545,
      "grad_norm": 33.12285614013672,
      "learning_rate": 0.00014549999999999999,
      "loss": 0.0507,
      "step": 170900
    },
    {
      "epoch": 0.855,
      "grad_norm": 0.4003414511680603,
      "learning_rate": 0.000145,
      "loss": 0.0505,
      "step": 171000
    },
    {
      "epoch": 0.8555,
      "grad_norm": 0.5342335104942322,
      "learning_rate": 0.0001445,
      "loss": 0.0555,
      "step": 171100
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.6133169531822205,
      "learning_rate": 0.000144,
      "loss": 0.0535,
      "step": 171200
    },
    {
      "epoch": 0.8565,
      "grad_norm": 0.2806451618671417,
      "learning_rate": 0.0001435,
      "loss": 0.0464,
      "step": 171300
    },
    {
      "epoch": 0.857,
      "grad_norm": 0.4458375573158264,
      "learning_rate": 0.00014299999999999998,
      "loss": 0.0503,
      "step": 171400
    },
    {
      "epoch": 0.8575,
      "grad_norm": 0.3359220623970032,
      "learning_rate": 0.0001425,
      "loss": 0.0465,
      "step": 171500
    },
    {
      "epoch": 0.858,
      "grad_norm": 0.994361162185669,
      "learning_rate": 0.00014199999999999998,
      "loss": 0.0496,
      "step": 171600
    },
    {
      "epoch": 0.8585,
      "grad_norm": 3.244155168533325,
      "learning_rate": 0.0001415,
      "loss": 0.0512,
      "step": 171700
    },
    {
      "epoch": 0.859,
      "grad_norm": 0.5380393862724304,
      "learning_rate": 0.00014099999999999998,
      "loss": 0.0514,
      "step": 171800
    },
    {
      "epoch": 0.8595,
      "grad_norm": 0.42978641390800476,
      "learning_rate": 0.00014050000000000003,
      "loss": 0.0503,
      "step": 171900
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5860536694526672,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.048,
      "step": 172000
    },
    {
      "epoch": 0.8605,
      "grad_norm": 0.31298741698265076,
      "learning_rate": 0.0001395,
      "loss": 0.0516,
      "step": 172100
    },
    {
      "epoch": 0.861,
      "grad_norm": 5.7115631103515625,
      "learning_rate": 0.00013900000000000002,
      "loss": 0.0521,
      "step": 172200
    },
    {
      "epoch": 0.8615,
      "grad_norm": 0.33228376507759094,
      "learning_rate": 0.0001385,
      "loss": 0.0524,
      "step": 172300
    },
    {
      "epoch": 0.862,
      "grad_norm": 0.633553147315979,
      "learning_rate": 0.00013800000000000002,
      "loss": 0.0552,
      "step": 172400
    },
    {
      "epoch": 0.8625,
      "grad_norm": 10.353970527648926,
      "learning_rate": 0.0001375,
      "loss": 0.0512,
      "step": 172500
    },
    {
      "epoch": 0.863,
      "grad_norm": 0.40192195773124695,
      "learning_rate": 0.00013700000000000002,
      "loss": 0.0496,
      "step": 172600
    },
    {
      "epoch": 0.8635,
      "grad_norm": 0.2493492215871811,
      "learning_rate": 0.0001365,
      "loss": 0.0511,
      "step": 172700
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.9898802042007446,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.047,
      "step": 172800
    },
    {
      "epoch": 0.8645,
      "grad_norm": 3.256443500518799,
      "learning_rate": 0.00013550000000000001,
      "loss": 0.0537,
      "step": 172900
    },
    {
      "epoch": 0.865,
      "grad_norm": 0.7820326685905457,
      "learning_rate": 0.000135,
      "loss": 0.0533,
      "step": 173000
    },
    {
      "epoch": 0.8655,
      "grad_norm": 0.8961427211761475,
      "learning_rate": 0.00013450000000000002,
      "loss": 0.0495,
      "step": 173100
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.5637275576591492,
      "learning_rate": 0.000134,
      "loss": 0.0513,
      "step": 173200
    },
    {
      "epoch": 0.8665,
      "grad_norm": 0.5936540365219116,
      "learning_rate": 0.00013350000000000002,
      "loss": 0.0468,
      "step": 173300
    },
    {
      "epoch": 0.867,
      "grad_norm": 0.22617210447788239,
      "learning_rate": 0.000133,
      "loss": 0.0508,
      "step": 173400
    },
    {
      "epoch": 0.8675,
      "grad_norm": 1.863442063331604,
      "learning_rate": 0.00013250000000000002,
      "loss": 0.0485,
      "step": 173500
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.6068965196609497,
      "learning_rate": 0.000132,
      "loss": 0.0524,
      "step": 173600
    },
    {
      "epoch": 0.8685,
      "grad_norm": 0.39903661608695984,
      "learning_rate": 0.0001315,
      "loss": 0.0482,
      "step": 173700
    },
    {
      "epoch": 0.869,
      "grad_norm": 0.20943963527679443,
      "learning_rate": 0.000131,
      "loss": 0.046,
      "step": 173800
    },
    {
      "epoch": 0.8695,
      "grad_norm": 1.2976453304290771,
      "learning_rate": 0.0001305,
      "loss": 0.0489,
      "step": 173900
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5105366110801697,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.0473,
      "step": 174000
    },
    {
      "epoch": 0.8705,
      "grad_norm": 7.618621349334717,
      "learning_rate": 0.0001295,
      "loss": 0.0542,
      "step": 174100
    },
    {
      "epoch": 0.871,
      "grad_norm": 0.43083328008651733,
      "learning_rate": 0.00012900000000000002,
      "loss": 0.0513,
      "step": 174200
    },
    {
      "epoch": 0.8715,
      "grad_norm": 0.300743967294693,
      "learning_rate": 0.0001285,
      "loss": 0.048,
      "step": 174300
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.5483168959617615,
      "learning_rate": 0.000128,
      "loss": 0.0487,
      "step": 174400
    },
    {
      "epoch": 0.8725,
      "grad_norm": 0.3160404860973358,
      "learning_rate": 0.0001275,
      "loss": 0.0511,
      "step": 174500
    },
    {
      "epoch": 0.873,
      "grad_norm": 8.532404899597168,
      "learning_rate": 0.000127,
      "loss": 0.0545,
      "step": 174600
    },
    {
      "epoch": 0.8735,
      "grad_norm": 1.5969113111495972,
      "learning_rate": 0.0001265,
      "loss": 0.0519,
      "step": 174700
    },
    {
      "epoch": 0.874,
      "grad_norm": 0.37686580419540405,
      "learning_rate": 0.000126,
      "loss": 0.0479,
      "step": 174800
    },
    {
      "epoch": 0.8745,
      "grad_norm": 0.7219357490539551,
      "learning_rate": 0.00012550000000000001,
      "loss": 0.048,
      "step": 174900
    },
    {
      "epoch": 0.875,
      "grad_norm": 0.8619278073310852,
      "learning_rate": 0.000125,
      "loss": 0.05,
      "step": 175000
    },
    {
      "epoch": 0.8755,
      "grad_norm": 0.4279673993587494,
      "learning_rate": 0.0001245,
      "loss": 0.0489,
      "step": 175100
    },
    {
      "epoch": 0.876,
      "grad_norm": 1.5184299945831299,
      "learning_rate": 0.000124,
      "loss": 0.0444,
      "step": 175200
    },
    {
      "epoch": 0.8765,
      "grad_norm": 0.28366976976394653,
      "learning_rate": 0.0001235,
      "loss": 0.0511,
      "step": 175300
    },
    {
      "epoch": 0.877,
      "grad_norm": 0.4457322657108307,
      "learning_rate": 0.000123,
      "loss": 0.0502,
      "step": 175400
    },
    {
      "epoch": 0.8775,
      "grad_norm": 0.7278748154640198,
      "learning_rate": 0.0001225,
      "loss": 0.0479,
      "step": 175500
    },
    {
      "epoch": 0.878,
      "grad_norm": 1.8025755882263184,
      "learning_rate": 0.000122,
      "loss": 0.0498,
      "step": 175600
    },
    {
      "epoch": 0.8785,
      "grad_norm": 0.36249399185180664,
      "learning_rate": 0.0001215,
      "loss": 0.0478,
      "step": 175700
    },
    {
      "epoch": 0.879,
      "grad_norm": 0.4950045049190521,
      "learning_rate": 0.000121,
      "loss": 0.0521,
      "step": 175800
    },
    {
      "epoch": 0.8795,
      "grad_norm": 0.31986260414123535,
      "learning_rate": 0.0001205,
      "loss": 0.0487,
      "step": 175900
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3225764334201813,
      "learning_rate": 0.00012,
      "loss": 0.0462,
      "step": 176000
    },
    {
      "epoch": 0.8805,
      "grad_norm": 0.502717137336731,
      "learning_rate": 0.00011949999999999999,
      "loss": 0.0456,
      "step": 176100
    },
    {
      "epoch": 0.881,
      "grad_norm": 0.5016180872917175,
      "learning_rate": 0.00011899999999999999,
      "loss": 0.0465,
      "step": 176200
    },
    {
      "epoch": 0.8815,
      "grad_norm": 0.766770601272583,
      "learning_rate": 0.0001185,
      "loss": 0.0454,
      "step": 176300
    },
    {
      "epoch": 0.882,
      "grad_norm": 0.31123092770576477,
      "learning_rate": 0.000118,
      "loss": 0.0456,
      "step": 176400
    },
    {
      "epoch": 0.8825,
      "grad_norm": 0.4160073697566986,
      "learning_rate": 0.0001175,
      "loss": 0.0529,
      "step": 176500
    },
    {
      "epoch": 0.883,
      "grad_norm": 0.4739537537097931,
      "learning_rate": 0.00011700000000000001,
      "loss": 0.0509,
      "step": 176600
    },
    {
      "epoch": 0.8835,
      "grad_norm": 0.33307966589927673,
      "learning_rate": 0.00011650000000000001,
      "loss": 0.0491,
      "step": 176700
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.42842531204223633,
      "learning_rate": 0.00011600000000000001,
      "loss": 0.0499,
      "step": 176800
    },
    {
      "epoch": 0.8845,
      "grad_norm": 6.812960147857666,
      "learning_rate": 0.0001155,
      "loss": 0.0532,
      "step": 176900
    },
    {
      "epoch": 0.885,
      "grad_norm": 0.4886644780635834,
      "learning_rate": 0.000115,
      "loss": 0.0528,
      "step": 177000
    },
    {
      "epoch": 0.8855,
      "grad_norm": 14.833866119384766,
      "learning_rate": 0.0001145,
      "loss": 0.0486,
      "step": 177100
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.31653696298599243,
      "learning_rate": 0.000114,
      "loss": 0.0482,
      "step": 177200
    },
    {
      "epoch": 0.8865,
      "grad_norm": 0.8655526638031006,
      "learning_rate": 0.00011350000000000001,
      "loss": 0.0486,
      "step": 177300
    },
    {
      "epoch": 0.887,
      "grad_norm": 0.5823476314544678,
      "learning_rate": 0.00011300000000000001,
      "loss": 0.0479,
      "step": 177400
    },
    {
      "epoch": 0.8875,
      "grad_norm": 0.43294525146484375,
      "learning_rate": 0.00011250000000000001,
      "loss": 0.0507,
      "step": 177500
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.5263826251029968,
      "learning_rate": 0.000112,
      "loss": 0.0514,
      "step": 177600
    },
    {
      "epoch": 0.8885,
      "grad_norm": 0.5739597082138062,
      "learning_rate": 0.0001115,
      "loss": 0.0491,
      "step": 177700
    },
    {
      "epoch": 0.889,
      "grad_norm": 0.42268887162208557,
      "learning_rate": 0.000111,
      "loss": 0.05,
      "step": 177800
    },
    {
      "epoch": 0.8895,
      "grad_norm": 0.4903064966201782,
      "learning_rate": 0.0001105,
      "loss": 0.0502,
      "step": 177900
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.726065754890442,
      "learning_rate": 0.00011,
      "loss": 0.0494,
      "step": 178000
    },
    {
      "epoch": 0.8905,
      "grad_norm": 0.6357321739196777,
      "learning_rate": 0.0001095,
      "loss": 0.0495,
      "step": 178100
    },
    {
      "epoch": 0.891,
      "grad_norm": 0.19301220774650574,
      "learning_rate": 0.000109,
      "loss": 0.0468,
      "step": 178200
    },
    {
      "epoch": 0.8915,
      "grad_norm": 0.5125719904899597,
      "learning_rate": 0.00010850000000000001,
      "loss": 0.0492,
      "step": 178300
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.6487463116645813,
      "learning_rate": 0.000108,
      "loss": 0.0491,
      "step": 178400
    },
    {
      "epoch": 0.8925,
      "grad_norm": 0.547709047794342,
      "learning_rate": 0.0001075,
      "loss": 0.0488,
      "step": 178500
    },
    {
      "epoch": 0.893,
      "grad_norm": 0.793785810470581,
      "learning_rate": 0.000107,
      "loss": 0.0473,
      "step": 178600
    },
    {
      "epoch": 0.8935,
      "grad_norm": 0.24277818202972412,
      "learning_rate": 0.0001065,
      "loss": 0.0462,
      "step": 178700
    },
    {
      "epoch": 0.894,
      "grad_norm": 0.41421887278556824,
      "learning_rate": 0.000106,
      "loss": 0.0474,
      "step": 178800
    },
    {
      "epoch": 0.8945,
      "grad_norm": 0.2820870876312256,
      "learning_rate": 0.0001055,
      "loss": 0.0469,
      "step": 178900
    },
    {
      "epoch": 0.895,
      "grad_norm": 0.42840924859046936,
      "learning_rate": 0.000105,
      "loss": 0.0461,
      "step": 179000
    },
    {
      "epoch": 0.8955,
      "grad_norm": 2.6445744037628174,
      "learning_rate": 0.00010449999999999999,
      "loss": 0.0473,
      "step": 179100
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.5661221146583557,
      "learning_rate": 0.000104,
      "loss": 0.0504,
      "step": 179200
    },
    {
      "epoch": 0.8965,
      "grad_norm": 5.401871204376221,
      "learning_rate": 0.0001035,
      "loss": 0.0507,
      "step": 179300
    },
    {
      "epoch": 0.897,
      "grad_norm": 0.43795862793922424,
      "learning_rate": 0.000103,
      "loss": 0.0483,
      "step": 179400
    },
    {
      "epoch": 0.8975,
      "grad_norm": 0.3780480623245239,
      "learning_rate": 0.0001025,
      "loss": 0.0487,
      "step": 179500
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.4649639427661896,
      "learning_rate": 0.000102,
      "loss": 0.0474,
      "step": 179600
    },
    {
      "epoch": 0.8985,
      "grad_norm": 3.1771280765533447,
      "learning_rate": 0.00010150000000000001,
      "loss": 0.0462,
      "step": 179700
    },
    {
      "epoch": 0.899,
      "grad_norm": 0.45891162753105164,
      "learning_rate": 0.000101,
      "loss": 0.051,
      "step": 179800
    },
    {
      "epoch": 0.8995,
      "grad_norm": 1.1964040994644165,
      "learning_rate": 0.0001005,
      "loss": 0.053,
      "step": 179900
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.47895413637161255,
      "learning_rate": 0.0001,
      "loss": 0.0465,
      "step": 180000
    },
    {
      "epoch": 0.9005,
      "grad_norm": 0.5255268812179565,
      "learning_rate": 9.95e-05,
      "loss": 0.0481,
      "step": 180100
    },
    {
      "epoch": 0.901,
      "grad_norm": 0.6643580198287964,
      "learning_rate": 9.900000000000001e-05,
      "loss": 0.0494,
      "step": 180200
    },
    {
      "epoch": 0.9015,
      "grad_norm": 0.17309711873531342,
      "learning_rate": 9.850000000000001e-05,
      "loss": 0.0473,
      "step": 180300
    },
    {
      "epoch": 0.902,
      "grad_norm": 1.554274082183838,
      "learning_rate": 9.800000000000001e-05,
      "loss": 0.0463,
      "step": 180400
    },
    {
      "epoch": 0.9025,
      "grad_norm": 0.5344311594963074,
      "learning_rate": 9.750000000000001e-05,
      "loss": 0.0446,
      "step": 180500
    },
    {
      "epoch": 0.903,
      "grad_norm": 0.41750428080558777,
      "learning_rate": 9.7e-05,
      "loss": 0.0441,
      "step": 180600
    },
    {
      "epoch": 0.9035,
      "grad_norm": 0.4205039441585541,
      "learning_rate": 9.65e-05,
      "loss": 0.0481,
      "step": 180700
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.9350860714912415,
      "learning_rate": 9.6e-05,
      "loss": 0.0452,
      "step": 180800
    },
    {
      "epoch": 0.9045,
      "grad_norm": 0.3464353084564209,
      "learning_rate": 9.55e-05,
      "loss": 0.0492,
      "step": 180900
    },
    {
      "epoch": 0.905,
      "grad_norm": 0.2992027997970581,
      "learning_rate": 9.5e-05,
      "loss": 0.05,
      "step": 181000
    },
    {
      "epoch": 0.9055,
      "grad_norm": 0.43193382024765015,
      "learning_rate": 9.45e-05,
      "loss": 0.0487,
      "step": 181100
    },
    {
      "epoch": 0.906,
      "grad_norm": 0.6238839626312256,
      "learning_rate": 9.400000000000001e-05,
      "loss": 0.0518,
      "step": 181200
    },
    {
      "epoch": 0.9065,
      "grad_norm": 1.8606150150299072,
      "learning_rate": 9.35e-05,
      "loss": 0.0448,
      "step": 181300
    },
    {
      "epoch": 0.907,
      "grad_norm": 0.8016290664672852,
      "learning_rate": 9.3e-05,
      "loss": 0.0519,
      "step": 181400
    },
    {
      "epoch": 0.9075,
      "grad_norm": 0.36775803565979004,
      "learning_rate": 9.25e-05,
      "loss": 0.0462,
      "step": 181500
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.4756050407886505,
      "learning_rate": 9.2e-05,
      "loss": 0.0471,
      "step": 181600
    },
    {
      "epoch": 0.9085,
      "grad_norm": 0.28731730580329895,
      "learning_rate": 9.15e-05,
      "loss": 0.0455,
      "step": 181700
    },
    {
      "epoch": 0.909,
      "grad_norm": 0.5124653577804565,
      "learning_rate": 9.1e-05,
      "loss": 0.0441,
      "step": 181800
    },
    {
      "epoch": 0.9095,
      "grad_norm": 0.5256989598274231,
      "learning_rate": 9.05e-05,
      "loss": 0.0457,
      "step": 181900
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.4561634063720703,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.0522,
      "step": 182000
    },
    {
      "epoch": 0.9105,
      "grad_norm": 2.25404953956604,
      "learning_rate": 8.95e-05,
      "loss": 0.0473,
      "step": 182100
    },
    {
      "epoch": 0.911,
      "grad_norm": 0.40786248445510864,
      "learning_rate": 8.9e-05,
      "loss": 0.0539,
      "step": 182200
    },
    {
      "epoch": 0.9115,
      "grad_norm": 0.5730506181716919,
      "learning_rate": 8.85e-05,
      "loss": 0.0465,
      "step": 182300
    },
    {
      "epoch": 0.912,
      "grad_norm": 2.5990517139434814,
      "learning_rate": 8.8e-05,
      "loss": 0.0464,
      "step": 182400
    },
    {
      "epoch": 0.9125,
      "grad_norm": 0.26897144317626953,
      "learning_rate": 8.75e-05,
      "loss": 0.0495,
      "step": 182500
    },
    {
      "epoch": 0.913,
      "grad_norm": 2.1891424655914307,
      "learning_rate": 8.7e-05,
      "loss": 0.0481,
      "step": 182600
    },
    {
      "epoch": 0.9135,
      "grad_norm": 0.4138150215148926,
      "learning_rate": 8.65e-05,
      "loss": 0.0466,
      "step": 182700
    },
    {
      "epoch": 0.914,
      "grad_norm": 0.4097312092781067,
      "learning_rate": 8.599999999999999e-05,
      "loss": 0.0462,
      "step": 182800
    },
    {
      "epoch": 0.9145,
      "grad_norm": 0.5812852382659912,
      "learning_rate": 8.55e-05,
      "loss": 0.0493,
      "step": 182900
    },
    {
      "epoch": 0.915,
      "grad_norm": 0.4815557599067688,
      "learning_rate": 8.5e-05,
      "loss": 0.0424,
      "step": 183000
    },
    {
      "epoch": 0.9155,
      "grad_norm": 0.36280640959739685,
      "learning_rate": 8.450000000000001e-05,
      "loss": 0.0459,
      "step": 183100
    },
    {
      "epoch": 0.916,
      "grad_norm": 1.3662835359573364,
      "learning_rate": 8.400000000000001e-05,
      "loss": 0.0438,
      "step": 183200
    },
    {
      "epoch": 0.9165,
      "grad_norm": 0.46888086199760437,
      "learning_rate": 8.350000000000001e-05,
      "loss": 0.0447,
      "step": 183300
    },
    {
      "epoch": 0.917,
      "grad_norm": 0.3848666250705719,
      "learning_rate": 8.300000000000001e-05,
      "loss": 0.0454,
      "step": 183400
    },
    {
      "epoch": 0.9175,
      "grad_norm": 0.6420987844467163,
      "learning_rate": 8.25e-05,
      "loss": 0.0468,
      "step": 183500
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.4750566780567169,
      "learning_rate": 8.2e-05,
      "loss": 0.0459,
      "step": 183600
    },
    {
      "epoch": 0.9185,
      "grad_norm": 0.8622003197669983,
      "learning_rate": 8.15e-05,
      "loss": 0.0468,
      "step": 183700
    },
    {
      "epoch": 0.919,
      "grad_norm": 0.4722045660018921,
      "learning_rate": 8.1e-05,
      "loss": 0.0492,
      "step": 183800
    },
    {
      "epoch": 0.9195,
      "grad_norm": 0.3758142590522766,
      "learning_rate": 8.05e-05,
      "loss": 0.0451,
      "step": 183900
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.3213154077529907,
      "learning_rate": 8e-05,
      "loss": 0.0445,
      "step": 184000
    },
    {
      "epoch": 0.9205,
      "grad_norm": 0.9114222526550293,
      "learning_rate": 7.950000000000001e-05,
      "loss": 0.0464,
      "step": 184100
    },
    {
      "epoch": 0.921,
      "grad_norm": 0.43653538823127747,
      "learning_rate": 7.9e-05,
      "loss": 0.0443,
      "step": 184200
    },
    {
      "epoch": 0.9215,
      "grad_norm": 0.5940946340560913,
      "learning_rate": 7.85e-05,
      "loss": 0.0472,
      "step": 184300
    },
    {
      "epoch": 0.922,
      "grad_norm": 13.745450973510742,
      "learning_rate": 7.8e-05,
      "loss": 0.0452,
      "step": 184400
    },
    {
      "epoch": 0.9225,
      "grad_norm": 1.3769657611846924,
      "learning_rate": 7.75e-05,
      "loss": 0.0443,
      "step": 184500
    },
    {
      "epoch": 0.923,
      "grad_norm": 0.4341965615749359,
      "learning_rate": 7.7e-05,
      "loss": 0.0492,
      "step": 184600
    },
    {
      "epoch": 0.9235,
      "grad_norm": 0.41797107458114624,
      "learning_rate": 7.65e-05,
      "loss": 0.044,
      "step": 184700
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.2905426025390625,
      "learning_rate": 7.6e-05,
      "loss": 0.0489,
      "step": 184800
    },
    {
      "epoch": 0.9245,
      "grad_norm": 0.397022008895874,
      "learning_rate": 7.55e-05,
      "loss": 0.0479,
      "step": 184900
    },
    {
      "epoch": 0.925,
      "grad_norm": 0.35463249683380127,
      "learning_rate": 7.5e-05,
      "loss": 0.0445,
      "step": 185000
    },
    {
      "epoch": 0.9255,
      "grad_norm": 0.5588381290435791,
      "learning_rate": 7.45e-05,
      "loss": 0.0457,
      "step": 185100
    },
    {
      "epoch": 0.926,
      "grad_norm": 0.3271836042404175,
      "learning_rate": 7.4e-05,
      "loss": 0.0457,
      "step": 185200
    },
    {
      "epoch": 0.9265,
      "grad_norm": 0.44235938787460327,
      "learning_rate": 7.35e-05,
      "loss": 0.0477,
      "step": 185300
    },
    {
      "epoch": 0.927,
      "grad_norm": 0.7288813591003418,
      "learning_rate": 7.3e-05,
      "loss": 0.0478,
      "step": 185400
    },
    {
      "epoch": 0.9275,
      "grad_norm": 0.431022971868515,
      "learning_rate": 7.25e-05,
      "loss": 0.0465,
      "step": 185500
    },
    {
      "epoch": 0.928,
      "grad_norm": 2.525751829147339,
      "learning_rate": 7.2e-05,
      "loss": 0.0462,
      "step": 185600
    },
    {
      "epoch": 0.9285,
      "grad_norm": 0.28652602434158325,
      "learning_rate": 7.149999999999999e-05,
      "loss": 0.0451,
      "step": 185700
    },
    {
      "epoch": 0.929,
      "grad_norm": 0.47800615429878235,
      "learning_rate": 7.099999999999999e-05,
      "loss": 0.0443,
      "step": 185800
    },
    {
      "epoch": 0.9295,
      "grad_norm": 0.514394998550415,
      "learning_rate": 7.049999999999999e-05,
      "loss": 0.0468,
      "step": 185900
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.35181084275245667,
      "learning_rate": 7.000000000000001e-05,
      "loss": 0.046,
      "step": 186000
    },
    {
      "epoch": 0.9305,
      "grad_norm": 0.8677217960357666,
      "learning_rate": 6.950000000000001e-05,
      "loss": 0.0495,
      "step": 186100
    },
    {
      "epoch": 0.931,
      "grad_norm": 0.389524906873703,
      "learning_rate": 6.900000000000001e-05,
      "loss": 0.0443,
      "step": 186200
    },
    {
      "epoch": 0.9315,
      "grad_norm": 0.499666303396225,
      "learning_rate": 6.850000000000001e-05,
      "loss": 0.0439,
      "step": 186300
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.29888468980789185,
      "learning_rate": 6.800000000000001e-05,
      "loss": 0.0475,
      "step": 186400
    },
    {
      "epoch": 0.9325,
      "grad_norm": 12.305658340454102,
      "learning_rate": 6.75e-05,
      "loss": 0.0486,
      "step": 186500
    },
    {
      "epoch": 0.933,
      "grad_norm": 0.5622857809066772,
      "learning_rate": 6.7e-05,
      "loss": 0.0474,
      "step": 186600
    },
    {
      "epoch": 0.9335,
      "grad_norm": 0.5142041444778442,
      "learning_rate": 6.65e-05,
      "loss": 0.0456,
      "step": 186700
    },
    {
      "epoch": 0.934,
      "grad_norm": 0.3043961226940155,
      "learning_rate": 6.6e-05,
      "loss": 0.0459,
      "step": 186800
    },
    {
      "epoch": 0.9345,
      "grad_norm": 0.522195041179657,
      "learning_rate": 6.55e-05,
      "loss": 0.0445,
      "step": 186900
    },
    {
      "epoch": 0.935,
      "grad_norm": 1.2649708986282349,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.0448,
      "step": 187000
    },
    {
      "epoch": 0.9355,
      "grad_norm": 0.4706501066684723,
      "learning_rate": 6.450000000000001e-05,
      "loss": 0.0483,
      "step": 187100
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.45174694061279297,
      "learning_rate": 6.4e-05,
      "loss": 0.0431,
      "step": 187200
    },
    {
      "epoch": 0.9365,
      "grad_norm": 0.4605901837348938,
      "learning_rate": 6.35e-05,
      "loss": 0.048,
      "step": 187300
    },
    {
      "epoch": 0.937,
      "grad_norm": 0.6339470148086548,
      "learning_rate": 6.3e-05,
      "loss": 0.0428,
      "step": 187400
    },
    {
      "epoch": 0.9375,
      "grad_norm": 83.70642852783203,
      "learning_rate": 6.25e-05,
      "loss": 0.0487,
      "step": 187500
    },
    {
      "epoch": 0.938,
      "grad_norm": 0.4979473948478699,
      "learning_rate": 6.2e-05,
      "loss": 0.0453,
      "step": 187600
    },
    {
      "epoch": 0.9385,
      "grad_norm": 0.35182124376296997,
      "learning_rate": 6.15e-05,
      "loss": 0.0413,
      "step": 187700
    },
    {
      "epoch": 0.939,
      "grad_norm": 0.7626076340675354,
      "learning_rate": 6.1e-05,
      "loss": 0.0443,
      "step": 187800
    },
    {
      "epoch": 0.9395,
      "grad_norm": 0.4614697992801666,
      "learning_rate": 6.05e-05,
      "loss": 0.0474,
      "step": 187900
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.041591763496399,
      "learning_rate": 6e-05,
      "loss": 0.0419,
      "step": 188000
    },
    {
      "epoch": 0.9405,
      "grad_norm": 0.24730747938156128,
      "learning_rate": 5.9499999999999996e-05,
      "loss": 0.0447,
      "step": 188100
    },
    {
      "epoch": 0.941,
      "grad_norm": 0.48067668080329895,
      "learning_rate": 5.9e-05,
      "loss": 0.0441,
      "step": 188200
    },
    {
      "epoch": 0.9415,
      "grad_norm": 0.605044960975647,
      "learning_rate": 5.8500000000000006e-05,
      "loss": 0.0486,
      "step": 188300
    },
    {
      "epoch": 0.942,
      "grad_norm": 0.40418240427970886,
      "learning_rate": 5.800000000000001e-05,
      "loss": 0.0438,
      "step": 188400
    },
    {
      "epoch": 0.9425,
      "grad_norm": 0.2846597731113434,
      "learning_rate": 5.75e-05,
      "loss": 0.0421,
      "step": 188500
    },
    {
      "epoch": 0.943,
      "grad_norm": 0.7350648641586304,
      "learning_rate": 5.7e-05,
      "loss": 0.0463,
      "step": 188600
    },
    {
      "epoch": 0.9435,
      "grad_norm": 0.42924514412879944,
      "learning_rate": 5.6500000000000005e-05,
      "loss": 0.0445,
      "step": 188700
    },
    {
      "epoch": 0.944,
      "grad_norm": 95.9937515258789,
      "learning_rate": 5.6e-05,
      "loss": 0.0426,
      "step": 188800
    },
    {
      "epoch": 0.9445,
      "grad_norm": 0.4487326741218567,
      "learning_rate": 5.55e-05,
      "loss": 0.0457,
      "step": 188900
    },
    {
      "epoch": 0.945,
      "grad_norm": 0.5595148205757141,
      "learning_rate": 5.5e-05,
      "loss": 0.0435,
      "step": 189000
    },
    {
      "epoch": 0.9455,
      "grad_norm": 0.3989366888999939,
      "learning_rate": 5.45e-05,
      "loss": 0.0414,
      "step": 189100
    },
    {
      "epoch": 0.946,
      "grad_norm": 0.517630398273468,
      "learning_rate": 5.4e-05,
      "loss": 0.0452,
      "step": 189200
    },
    {
      "epoch": 0.9465,
      "grad_norm": 0.583288311958313,
      "learning_rate": 5.35e-05,
      "loss": 0.0454,
      "step": 189300
    },
    {
      "epoch": 0.947,
      "grad_norm": 0.40868595242500305,
      "learning_rate": 5.3e-05,
      "loss": 0.0439,
      "step": 189400
    },
    {
      "epoch": 0.9475,
      "grad_norm": 0.4654806852340698,
      "learning_rate": 5.25e-05,
      "loss": 0.0445,
      "step": 189500
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.24606986343860626,
      "learning_rate": 5.2e-05,
      "loss": 0.0407,
      "step": 189600
    },
    {
      "epoch": 0.9485,
      "grad_norm": 0.5594790577888489,
      "learning_rate": 5.15e-05,
      "loss": 0.042,
      "step": 189700
    },
    {
      "epoch": 0.949,
      "grad_norm": 1.2586073875427246,
      "learning_rate": 5.1e-05,
      "loss": 0.0426,
      "step": 189800
    },
    {
      "epoch": 0.9495,
      "grad_norm": 0.4710114598274231,
      "learning_rate": 5.05e-05,
      "loss": 0.0446,
      "step": 189900
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.423367440700531,
      "learning_rate": 5e-05,
      "loss": 0.0442,
      "step": 190000
    },
    {
      "epoch": 0.9505,
      "grad_norm": 0.5249196290969849,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.0431,
      "step": 190100
    },
    {
      "epoch": 0.951,
      "grad_norm": 0.4233136475086212,
      "learning_rate": 4.9000000000000005e-05,
      "loss": 0.0467,
      "step": 190200
    },
    {
      "epoch": 0.9515,
      "grad_norm": 5.218467712402344,
      "learning_rate": 4.85e-05,
      "loss": 0.044,
      "step": 190300
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.5257889628410339,
      "learning_rate": 4.8e-05,
      "loss": 0.0416,
      "step": 190400
    },
    {
      "epoch": 0.9525,
      "grad_norm": 2.343658685684204,
      "learning_rate": 4.75e-05,
      "loss": 0.0436,
      "step": 190500
    },
    {
      "epoch": 0.953,
      "grad_norm": 0.4259946644306183,
      "learning_rate": 4.7000000000000004e-05,
      "loss": 0.0448,
      "step": 190600
    },
    {
      "epoch": 0.9535,
      "grad_norm": 0.4210784435272217,
      "learning_rate": 4.65e-05,
      "loss": 0.0447,
      "step": 190700
    },
    {
      "epoch": 0.954,
      "grad_norm": 1.4960134029388428,
      "learning_rate": 4.6e-05,
      "loss": 0.0469,
      "step": 190800
    },
    {
      "epoch": 0.9545,
      "grad_norm": 0.38434261083602905,
      "learning_rate": 4.55e-05,
      "loss": 0.047,
      "step": 190900
    },
    {
      "epoch": 0.955,
      "grad_norm": 0.46535930037498474,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.0441,
      "step": 191000
    },
    {
      "epoch": 0.9555,
      "grad_norm": 0.32951468229293823,
      "learning_rate": 4.45e-05,
      "loss": 0.0443,
      "step": 191100
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.35198697447776794,
      "learning_rate": 4.4e-05,
      "loss": 0.0429,
      "step": 191200
    },
    {
      "epoch": 0.9565,
      "grad_norm": 0.28746116161346436,
      "learning_rate": 4.35e-05,
      "loss": 0.0434,
      "step": 191300
    },
    {
      "epoch": 0.957,
      "grad_norm": 138.48074340820312,
      "learning_rate": 4.2999999999999995e-05,
      "loss": 0.0437,
      "step": 191400
    },
    {
      "epoch": 0.9575,
      "grad_norm": 0.45412349700927734,
      "learning_rate": 4.25e-05,
      "loss": 0.041,
      "step": 191500
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.7929319739341736,
      "learning_rate": 4.2000000000000004e-05,
      "loss": 0.0421,
      "step": 191600
    },
    {
      "epoch": 0.9585,
      "grad_norm": 4.679356098175049,
      "learning_rate": 4.1500000000000006e-05,
      "loss": 0.048,
      "step": 191700
    },
    {
      "epoch": 0.959,
      "grad_norm": 1.2640899419784546,
      "learning_rate": 4.1e-05,
      "loss": 0.0489,
      "step": 191800
    },
    {
      "epoch": 0.9595,
      "grad_norm": 0.3603624403476715,
      "learning_rate": 4.05e-05,
      "loss": 0.0432,
      "step": 191900
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.7556240558624268,
      "learning_rate": 4e-05,
      "loss": 0.0448,
      "step": 192000
    },
    {
      "epoch": 0.9605,
      "grad_norm": 0.5293677449226379,
      "learning_rate": 3.95e-05,
      "loss": 0.044,
      "step": 192100
    },
    {
      "epoch": 0.961,
      "grad_norm": 0.5628283619880676,
      "learning_rate": 3.9e-05,
      "loss": 0.0474,
      "step": 192200
    },
    {
      "epoch": 0.9615,
      "grad_norm": 0.5697653293609619,
      "learning_rate": 3.85e-05,
      "loss": 0.0436,
      "step": 192300
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.48475319147109985,
      "learning_rate": 3.8e-05,
      "loss": 0.0446,
      "step": 192400
    },
    {
      "epoch": 0.9625,
      "grad_norm": 0.7723423838615417,
      "learning_rate": 3.75e-05,
      "loss": 0.0456,
      "step": 192500
    },
    {
      "epoch": 0.963,
      "grad_norm": 0.35925936698913574,
      "learning_rate": 3.7e-05,
      "loss": 0.0453,
      "step": 192600
    },
    {
      "epoch": 0.9635,
      "grad_norm": 0.345624715089798,
      "learning_rate": 3.65e-05,
      "loss": 0.0461,
      "step": 192700
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.2878056466579437,
      "learning_rate": 3.6e-05,
      "loss": 0.0451,
      "step": 192800
    },
    {
      "epoch": 0.9645,
      "grad_norm": 0.3319341838359833,
      "learning_rate": 3.5499999999999996e-05,
      "loss": 0.0447,
      "step": 192900
    },
    {
      "epoch": 0.965,
      "grad_norm": 0.5649136900901794,
      "learning_rate": 3.5000000000000004e-05,
      "loss": 0.0454,
      "step": 193000
    },
    {
      "epoch": 0.9655,
      "grad_norm": 0.5475701689720154,
      "learning_rate": 3.4500000000000005e-05,
      "loss": 0.0482,
      "step": 193100
    },
    {
      "epoch": 0.966,
      "grad_norm": 0.8001025319099426,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0453,
      "step": 193200
    },
    {
      "epoch": 0.9665,
      "grad_norm": 0.4177277088165283,
      "learning_rate": 3.35e-05,
      "loss": 0.0425,
      "step": 193300
    },
    {
      "epoch": 0.967,
      "grad_norm": 0.2811802923679352,
      "learning_rate": 3.3e-05,
      "loss": 0.0449,
      "step": 193400
    },
    {
      "epoch": 0.9675,
      "grad_norm": 0.21190103888511658,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.046,
      "step": 193500
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.4326845109462738,
      "learning_rate": 3.2e-05,
      "loss": 0.0441,
      "step": 193600
    },
    {
      "epoch": 0.9685,
      "grad_norm": 0.34413307905197144,
      "learning_rate": 3.15e-05,
      "loss": 0.0413,
      "step": 193700
    },
    {
      "epoch": 0.969,
      "grad_norm": 0.37691035866737366,
      "learning_rate": 3.1e-05,
      "loss": 0.0426,
      "step": 193800
    },
    {
      "epoch": 0.9695,
      "grad_norm": 1.0011063814163208,
      "learning_rate": 3.05e-05,
      "loss": 0.0418,
      "step": 193900
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.4938407242298126,
      "learning_rate": 3e-05,
      "loss": 0.0432,
      "step": 194000
    },
    {
      "epoch": 0.9705,
      "grad_norm": 0.45694902539253235,
      "learning_rate": 2.95e-05,
      "loss": 0.0433,
      "step": 194100
    },
    {
      "epoch": 0.971,
      "grad_norm": 0.7624590992927551,
      "learning_rate": 2.9000000000000004e-05,
      "loss": 0.0439,
      "step": 194200
    },
    {
      "epoch": 0.9715,
      "grad_norm": 0.9705049395561218,
      "learning_rate": 2.85e-05,
      "loss": 0.0404,
      "step": 194300
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.921788215637207,
      "learning_rate": 2.8e-05,
      "loss": 0.0437,
      "step": 194400
    },
    {
      "epoch": 0.9725,
      "grad_norm": 0.365603506565094,
      "learning_rate": 2.75e-05,
      "loss": 0.0438,
      "step": 194500
    },
    {
      "epoch": 0.973,
      "grad_norm": 0.450353741645813,
      "learning_rate": 2.7e-05,
      "loss": 0.0422,
      "step": 194600
    },
    {
      "epoch": 0.9735,
      "grad_norm": 0.3916011154651642,
      "learning_rate": 2.65e-05,
      "loss": 0.0477,
      "step": 194700
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.3539104163646698,
      "learning_rate": 2.6e-05,
      "loss": 0.0416,
      "step": 194800
    },
    {
      "epoch": 0.9745,
      "grad_norm": 0.7876798510551453,
      "learning_rate": 2.55e-05,
      "loss": 0.0467,
      "step": 194900
    },
    {
      "epoch": 0.975,
      "grad_norm": 0.3543640077114105,
      "learning_rate": 2.5e-05,
      "loss": 0.0411,
      "step": 195000
    },
    {
      "epoch": 0.9755,
      "grad_norm": 0.6962727904319763,
      "learning_rate": 2.4500000000000003e-05,
      "loss": 0.0474,
      "step": 195100
    },
    {
      "epoch": 0.976,
      "grad_norm": 3.691112756729126,
      "learning_rate": 2.4e-05,
      "loss": 0.042,
      "step": 195200
    },
    {
      "epoch": 0.9765,
      "grad_norm": 0.46255290508270264,
      "learning_rate": 2.3500000000000002e-05,
      "loss": 0.0435,
      "step": 195300
    },
    {
      "epoch": 0.977,
      "grad_norm": 0.3158110976219177,
      "learning_rate": 2.3e-05,
      "loss": 0.0425,
      "step": 195400
    },
    {
      "epoch": 0.9775,
      "grad_norm": 0.8954755663871765,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.0418,
      "step": 195500
    },
    {
      "epoch": 0.978,
      "grad_norm": 0.7088309526443481,
      "learning_rate": 2.2e-05,
      "loss": 0.0393,
      "step": 195600
    },
    {
      "epoch": 0.9785,
      "grad_norm": 0.3729564845561981,
      "learning_rate": 2.1499999999999997e-05,
      "loss": 0.0432,
      "step": 195700
    },
    {
      "epoch": 0.979,
      "grad_norm": 0.2961712181568146,
      "learning_rate": 2.1000000000000002e-05,
      "loss": 0.0413,
      "step": 195800
    },
    {
      "epoch": 0.9795,
      "grad_norm": 1.538583755493164,
      "learning_rate": 2.05e-05,
      "loss": 0.0449,
      "step": 195900
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.37618401646614075,
      "learning_rate": 2e-05,
      "loss": 0.0451,
      "step": 196000
    },
    {
      "epoch": 0.9805,
      "grad_norm": 0.4886358976364136,
      "learning_rate": 1.95e-05,
      "loss": 0.0421,
      "step": 196100
    },
    {
      "epoch": 0.981,
      "grad_norm": 1.1405954360961914,
      "learning_rate": 1.9e-05,
      "loss": 0.0428,
      "step": 196200
    },
    {
      "epoch": 0.9815,
      "grad_norm": 0.26423218846321106,
      "learning_rate": 1.85e-05,
      "loss": 0.0448,
      "step": 196300
    },
    {
      "epoch": 0.982,
      "grad_norm": 0.24506337940692902,
      "learning_rate": 1.8e-05,
      "loss": 0.0458,
      "step": 196400
    },
    {
      "epoch": 0.9825,
      "grad_norm": 0.35404691100120544,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.0417,
      "step": 196500
    },
    {
      "epoch": 0.983,
      "grad_norm": 0.38097041845321655,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.0419,
      "step": 196600
    },
    {
      "epoch": 0.9835,
      "grad_norm": 0.3094494938850403,
      "learning_rate": 1.65e-05,
      "loss": 0.0414,
      "step": 196700
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.4698568880558014,
      "learning_rate": 1.6e-05,
      "loss": 0.0452,
      "step": 196800
    },
    {
      "epoch": 0.9845,
      "grad_norm": 0.627916157245636,
      "learning_rate": 1.55e-05,
      "loss": 0.0416,
      "step": 196900
    },
    {
      "epoch": 0.985,
      "grad_norm": 0.22873666882514954,
      "learning_rate": 1.5e-05,
      "loss": 0.0446,
      "step": 197000
    },
    {
      "epoch": 0.9855,
      "grad_norm": 0.7176021933555603,
      "learning_rate": 1.4500000000000002e-05,
      "loss": 0.0474,
      "step": 197100
    },
    {
      "epoch": 0.986,
      "grad_norm": 0.4022168219089508,
      "learning_rate": 1.4e-05,
      "loss": 0.0458,
      "step": 197200
    },
    {
      "epoch": 0.9865,
      "grad_norm": 1.105566143989563,
      "learning_rate": 1.35e-05,
      "loss": 0.0474,
      "step": 197300
    },
    {
      "epoch": 0.987,
      "grad_norm": 0.20470960438251495,
      "learning_rate": 1.3e-05,
      "loss": 0.0442,
      "step": 197400
    },
    {
      "epoch": 0.9875,
      "grad_norm": 0.3965356647968292,
      "learning_rate": 1.25e-05,
      "loss": 0.0414,
      "step": 197500
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.9596337080001831,
      "learning_rate": 1.2e-05,
      "loss": 0.0445,
      "step": 197600
    },
    {
      "epoch": 0.9885,
      "grad_norm": 0.23863060772418976,
      "learning_rate": 1.15e-05,
      "loss": 0.0475,
      "step": 197700
    },
    {
      "epoch": 0.989,
      "grad_norm": 0.6487865447998047,
      "learning_rate": 1.1e-05,
      "loss": 0.0426,
      "step": 197800
    },
    {
      "epoch": 0.9895,
      "grad_norm": 0.44547754526138306,
      "learning_rate": 1.0500000000000001e-05,
      "loss": 0.0424,
      "step": 197900
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.34234708547592163,
      "learning_rate": 1e-05,
      "loss": 0.0421,
      "step": 198000
    },
    {
      "epoch": 0.9905,
      "grad_norm": 0.9058480262756348,
      "learning_rate": 9.5e-06,
      "loss": 0.0408,
      "step": 198100
    },
    {
      "epoch": 0.991,
      "grad_norm": 0.4080903232097626,
      "learning_rate": 9e-06,
      "loss": 0.0416,
      "step": 198200
    },
    {
      "epoch": 0.9915,
      "grad_norm": 1.7288650274276733,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.0398,
      "step": 198300
    },
    {
      "epoch": 0.992,
      "grad_norm": 1.4699605703353882,
      "learning_rate": 8e-06,
      "loss": 0.0458,
      "step": 198400
    },
    {
      "epoch": 0.9925,
      "grad_norm": 0.5855684876441956,
      "learning_rate": 7.5e-06,
      "loss": 0.0467,
      "step": 198500
    },
    {
      "epoch": 0.993,
      "grad_norm": 26.9866943359375,
      "learning_rate": 7e-06,
      "loss": 0.0412,
      "step": 198600
    },
    {
      "epoch": 0.9935,
      "grad_norm": 0.3863557279109955,
      "learning_rate": 6.5e-06,
      "loss": 0.0456,
      "step": 198700
    },
    {
      "epoch": 0.994,
      "grad_norm": 0.7858231067657471,
      "learning_rate": 6e-06,
      "loss": 0.04,
      "step": 198800
    },
    {
      "epoch": 0.9945,
      "grad_norm": 0.6092046499252319,
      "learning_rate": 5.5e-06,
      "loss": 0.0425,
      "step": 198900
    },
    {
      "epoch": 0.995,
      "grad_norm": 1.2612218856811523,
      "learning_rate": 5e-06,
      "loss": 0.0447,
      "step": 199000
    },
    {
      "epoch": 0.9955,
      "grad_norm": 0.4121760427951813,
      "learning_rate": 4.5e-06,
      "loss": 0.0416,
      "step": 199100
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.5040057301521301,
      "learning_rate": 4e-06,
      "loss": 0.0405,
      "step": 199200
    },
    {
      "epoch": 0.9965,
      "grad_norm": 0.9349333643913269,
      "learning_rate": 3.5e-06,
      "loss": 0.0461,
      "step": 199300
    },
    {
      "epoch": 0.997,
      "grad_norm": 0.48251938819885254,
      "learning_rate": 3e-06,
      "loss": 0.0434,
      "step": 199400
    },
    {
      "epoch": 0.9975,
      "grad_norm": 0.23008611798286438,
      "learning_rate": 2.5e-06,
      "loss": 0.0419,
      "step": 199500
    },
    {
      "epoch": 0.998,
      "grad_norm": 0.601586639881134,
      "learning_rate": 2e-06,
      "loss": 0.0403,
      "step": 199600
    },
    {
      "epoch": 0.9985,
      "grad_norm": 9.268521308898926,
      "learning_rate": 1.5e-06,
      "loss": 0.0419,
      "step": 199700
    },
    {
      "epoch": 0.999,
      "grad_norm": 1.5480633974075317,
      "learning_rate": 1e-06,
      "loss": 0.0429,
      "step": 199800
    },
    {
      "epoch": 0.9995,
      "grad_norm": 0.24212369322776794,
      "learning_rate": 5e-07,
      "loss": 0.0402,
      "step": 199900
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4260095953941345,
      "learning_rate": 0.0,
      "loss": 0.0434,
      "step": 200000
    }
  ],
  "logging_steps": 100,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.723753754624e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
