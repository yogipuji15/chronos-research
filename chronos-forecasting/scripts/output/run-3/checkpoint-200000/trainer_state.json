{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0025,
      "grad_norm": 0.3210807144641876,
      "learning_rate": 0.0009975000000000001,
      "loss": 2.2332,
      "step": 500
    },
    {
      "epoch": 0.005,
      "grad_norm": 0.37573015689849854,
      "learning_rate": 0.000995,
      "loss": 2.1729,
      "step": 1000
    },
    {
      "epoch": 0.0075,
      "grad_norm": 0.399301141500473,
      "learning_rate": 0.0009925000000000001,
      "loss": 2.1144,
      "step": 1500
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.5984369516372681,
      "learning_rate": 0.00099,
      "loss": 2.079,
      "step": 2000
    },
    {
      "epoch": 0.0125,
      "grad_norm": 0.47095194458961487,
      "learning_rate": 0.0009875,
      "loss": 2.0573,
      "step": 2500
    },
    {
      "epoch": 0.015,
      "grad_norm": 0.3986015021800995,
      "learning_rate": 0.000985,
      "loss": 2.0005,
      "step": 3000
    },
    {
      "epoch": 0.0175,
      "grad_norm": 0.4992119371891022,
      "learning_rate": 0.0009825,
      "loss": 1.9558,
      "step": 3500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5931411385536194,
      "learning_rate": 0.00098,
      "loss": 1.933,
      "step": 4000
    },
    {
      "epoch": 0.0225,
      "grad_norm": 0.638107419013977,
      "learning_rate": 0.0009775,
      "loss": 1.8985,
      "step": 4500
    },
    {
      "epoch": 0.025,
      "grad_norm": 0.6051150560379028,
      "learning_rate": 0.000975,
      "loss": 1.8644,
      "step": 5000
    },
    {
      "epoch": 0.0275,
      "grad_norm": 0.7450000047683716,
      "learning_rate": 0.0009725000000000001,
      "loss": 1.837,
      "step": 5500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6982364654541016,
      "learning_rate": 0.0009699999999999999,
      "loss": 1.8027,
      "step": 6000
    },
    {
      "epoch": 0.0325,
      "grad_norm": 0.6933330297470093,
      "learning_rate": 0.0009675,
      "loss": 1.7731,
      "step": 6500
    },
    {
      "epoch": 0.035,
      "grad_norm": 0.7108479738235474,
      "learning_rate": 0.000965,
      "loss": 1.7376,
      "step": 7000
    },
    {
      "epoch": 0.0375,
      "grad_norm": 0.8019313812255859,
      "learning_rate": 0.0009625,
      "loss": 1.697,
      "step": 7500
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.722719669342041,
      "learning_rate": 0.00096,
      "loss": 1.6754,
      "step": 8000
    },
    {
      "epoch": 0.0425,
      "grad_norm": 0.7936990261077881,
      "learning_rate": 0.0009575,
      "loss": 1.6662,
      "step": 8500
    },
    {
      "epoch": 0.045,
      "grad_norm": 0.7261826992034912,
      "learning_rate": 0.000955,
      "loss": 1.6331,
      "step": 9000
    },
    {
      "epoch": 0.0475,
      "grad_norm": 0.7375275492668152,
      "learning_rate": 0.0009525,
      "loss": 1.6156,
      "step": 9500
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8363162875175476,
      "learning_rate": 0.00095,
      "loss": 1.5898,
      "step": 10000
    },
    {
      "epoch": 0.0525,
      "grad_norm": 0.8287605047225952,
      "learning_rate": 0.0009475,
      "loss": 1.5626,
      "step": 10500
    },
    {
      "epoch": 0.055,
      "grad_norm": 0.8060746192932129,
      "learning_rate": 0.000945,
      "loss": 1.5393,
      "step": 11000
    },
    {
      "epoch": 0.0575,
      "grad_norm": 0.887279212474823,
      "learning_rate": 0.0009425,
      "loss": 1.5252,
      "step": 11500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8352940678596497,
      "learning_rate": 0.00094,
      "loss": 1.4955,
      "step": 12000
    },
    {
      "epoch": 0.0625,
      "grad_norm": 0.8019495010375977,
      "learning_rate": 0.0009375,
      "loss": 1.4928,
      "step": 12500
    },
    {
      "epoch": 0.065,
      "grad_norm": 0.952129602432251,
      "learning_rate": 0.0009350000000000001,
      "loss": 1.4547,
      "step": 13000
    },
    {
      "epoch": 0.0675,
      "grad_norm": 0.9293416142463684,
      "learning_rate": 0.0009325000000000001,
      "loss": 1.4394,
      "step": 13500
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.891226053237915,
      "learning_rate": 0.00093,
      "loss": 1.4326,
      "step": 14000
    },
    {
      "epoch": 0.0725,
      "grad_norm": 0.8729739785194397,
      "learning_rate": 0.0009275,
      "loss": 1.4206,
      "step": 14500
    },
    {
      "epoch": 0.075,
      "grad_norm": 0.8966922163963318,
      "learning_rate": 0.000925,
      "loss": 1.3903,
      "step": 15000
    },
    {
      "epoch": 0.0775,
      "grad_norm": 0.9902743101119995,
      "learning_rate": 0.0009225,
      "loss": 1.3762,
      "step": 15500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8437535166740417,
      "learning_rate": 0.00092,
      "loss": 1.371,
      "step": 16000
    },
    {
      "epoch": 0.0825,
      "grad_norm": 1.0151008367538452,
      "learning_rate": 0.0009175,
      "loss": 1.3535,
      "step": 16500
    },
    {
      "epoch": 0.085,
      "grad_norm": 0.8468011021614075,
      "learning_rate": 0.000915,
      "loss": 1.3415,
      "step": 17000
    },
    {
      "epoch": 0.0875,
      "grad_norm": 0.9721280932426453,
      "learning_rate": 0.0009125,
      "loss": 1.3342,
      "step": 17500
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9583833813667297,
      "learning_rate": 0.00091,
      "loss": 1.3173,
      "step": 18000
    },
    {
      "epoch": 0.0925,
      "grad_norm": 0.9431813955307007,
      "learning_rate": 0.0009075,
      "loss": 1.2911,
      "step": 18500
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.8799960613250732,
      "learning_rate": 0.0009050000000000001,
      "loss": 1.2844,
      "step": 19000
    },
    {
      "epoch": 0.0975,
      "grad_norm": 0.9892916679382324,
      "learning_rate": 0.0009025,
      "loss": 1.262,
      "step": 19500
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0990686416625977,
      "learning_rate": 0.0009000000000000001,
      "loss": 1.268,
      "step": 20000
    },
    {
      "epoch": 0.1025,
      "grad_norm": 0.8782588839530945,
      "learning_rate": 0.0008975,
      "loss": 1.2453,
      "step": 20500
    },
    {
      "epoch": 0.105,
      "grad_norm": 0.8185358047485352,
      "learning_rate": 0.0008950000000000001,
      "loss": 1.2314,
      "step": 21000
    },
    {
      "epoch": 0.1075,
      "grad_norm": 0.8625608086585999,
      "learning_rate": 0.0008925,
      "loss": 1.2374,
      "step": 21500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8420093655586243,
      "learning_rate": 0.0008900000000000001,
      "loss": 1.2163,
      "step": 22000
    },
    {
      "epoch": 0.1125,
      "grad_norm": 1.0686362981796265,
      "learning_rate": 0.0008874999999999999,
      "loss": 1.2056,
      "step": 22500
    },
    {
      "epoch": 0.115,
      "grad_norm": 0.955742359161377,
      "learning_rate": 0.000885,
      "loss": 1.2114,
      "step": 23000
    },
    {
      "epoch": 0.1175,
      "grad_norm": 1.0437450408935547,
      "learning_rate": 0.0008824999999999999,
      "loss": 1.1892,
      "step": 23500
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9380611777305603,
      "learning_rate": 0.00088,
      "loss": 1.1787,
      "step": 24000
    },
    {
      "epoch": 0.1225,
      "grad_norm": 0.9637361764907837,
      "learning_rate": 0.0008774999999999999,
      "loss": 1.1695,
      "step": 24500
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.0260294675827026,
      "learning_rate": 0.000875,
      "loss": 1.156,
      "step": 25000
    },
    {
      "epoch": 0.1275,
      "grad_norm": 0.9777217507362366,
      "learning_rate": 0.0008725000000000001,
      "loss": 1.1458,
      "step": 25500
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0530602931976318,
      "learning_rate": 0.00087,
      "loss": 1.146,
      "step": 26000
    },
    {
      "epoch": 0.1325,
      "grad_norm": 1.077185034751892,
      "learning_rate": 0.0008675000000000001,
      "loss": 1.1232,
      "step": 26500
    },
    {
      "epoch": 0.135,
      "grad_norm": 1.1338504552841187,
      "learning_rate": 0.000865,
      "loss": 1.1241,
      "step": 27000
    },
    {
      "epoch": 0.1375,
      "grad_norm": 0.8829214572906494,
      "learning_rate": 0.0008625000000000001,
      "loss": 1.1164,
      "step": 27500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9721338152885437,
      "learning_rate": 0.00086,
      "loss": 1.1072,
      "step": 28000
    },
    {
      "epoch": 0.1425,
      "grad_norm": 1.0600403547286987,
      "learning_rate": 0.0008575000000000001,
      "loss": 1.1031,
      "step": 28500
    },
    {
      "epoch": 0.145,
      "grad_norm": 1.041639804840088,
      "learning_rate": 0.000855,
      "loss": 1.0749,
      "step": 29000
    },
    {
      "epoch": 0.1475,
      "grad_norm": 0.8935268521308899,
      "learning_rate": 0.0008525000000000001,
      "loss": 1.0822,
      "step": 29500
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1473857164382935,
      "learning_rate": 0.00085,
      "loss": 1.0649,
      "step": 30000
    },
    {
      "epoch": 0.1525,
      "grad_norm": 1.0347400903701782,
      "learning_rate": 0.0008475000000000001,
      "loss": 1.0719,
      "step": 30500
    },
    {
      "epoch": 0.155,
      "grad_norm": 1.0135607719421387,
      "learning_rate": 0.0008449999999999999,
      "loss": 1.04,
      "step": 31000
    },
    {
      "epoch": 0.1575,
      "grad_norm": 0.9896047711372375,
      "learning_rate": 0.0008425,
      "loss": 1.0518,
      "step": 31500
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0202900171279907,
      "learning_rate": 0.00084,
      "loss": 1.0258,
      "step": 32000
    },
    {
      "epoch": 0.1625,
      "grad_norm": 0.9201035499572754,
      "learning_rate": 0.0008375,
      "loss": 1.0308,
      "step": 32500
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.9477457404136658,
      "learning_rate": 0.000835,
      "loss": 1.0196,
      "step": 33000
    },
    {
      "epoch": 0.1675,
      "grad_norm": 1.2033854722976685,
      "learning_rate": 0.0008325,
      "loss": 1.0128,
      "step": 33500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.935888946056366,
      "learning_rate": 0.00083,
      "loss": 1.0064,
      "step": 34000
    },
    {
      "epoch": 0.1725,
      "grad_norm": 0.8987390995025635,
      "learning_rate": 0.0008275,
      "loss": 1.0012,
      "step": 34500
    },
    {
      "epoch": 0.175,
      "grad_norm": 1.0454713106155396,
      "learning_rate": 0.000825,
      "loss": 0.9922,
      "step": 35000
    },
    {
      "epoch": 0.1775,
      "grad_norm": 1.0747498273849487,
      "learning_rate": 0.0008225,
      "loss": 0.9936,
      "step": 35500
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0532211065292358,
      "learning_rate": 0.00082,
      "loss": 0.9879,
      "step": 36000
    },
    {
      "epoch": 0.1825,
      "grad_norm": 0.989689290523529,
      "learning_rate": 0.0008175,
      "loss": 0.9747,
      "step": 36500
    },
    {
      "epoch": 0.185,
      "grad_norm": 1.0983383655548096,
      "learning_rate": 0.000815,
      "loss": 0.9593,
      "step": 37000
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.0781458616256714,
      "learning_rate": 0.0008125000000000001,
      "loss": 0.9546,
      "step": 37500
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.0386501550674438,
      "learning_rate": 0.0008100000000000001,
      "loss": 0.9544,
      "step": 38000
    },
    {
      "epoch": 0.1925,
      "grad_norm": 1.0214693546295166,
      "learning_rate": 0.0008075000000000001,
      "loss": 0.9465,
      "step": 38500
    },
    {
      "epoch": 0.195,
      "grad_norm": 0.9673373699188232,
      "learning_rate": 0.000805,
      "loss": 0.9409,
      "step": 39000
    },
    {
      "epoch": 0.1975,
      "grad_norm": 1.0344650745391846,
      "learning_rate": 0.0008025,
      "loss": 0.9423,
      "step": 39500
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9730107188224792,
      "learning_rate": 0.0008,
      "loss": 0.9308,
      "step": 40000
    },
    {
      "epoch": 0.2025,
      "grad_norm": 1.1189957857131958,
      "learning_rate": 0.0007975,
      "loss": 0.9243,
      "step": 40500
    },
    {
      "epoch": 0.205,
      "grad_norm": 1.0154788494110107,
      "learning_rate": 0.000795,
      "loss": 0.9159,
      "step": 41000
    },
    {
      "epoch": 0.2075,
      "grad_norm": 0.9190134406089783,
      "learning_rate": 0.0007925,
      "loss": 0.9104,
      "step": 41500
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8583394885063171,
      "learning_rate": 0.00079,
      "loss": 0.9046,
      "step": 42000
    },
    {
      "epoch": 0.2125,
      "grad_norm": 0.9747248291969299,
      "learning_rate": 0.0007875,
      "loss": 0.8876,
      "step": 42500
    },
    {
      "epoch": 0.215,
      "grad_norm": 0.9597927331924438,
      "learning_rate": 0.000785,
      "loss": 0.8961,
      "step": 43000
    },
    {
      "epoch": 0.2175,
      "grad_norm": 1.013256311416626,
      "learning_rate": 0.0007825,
      "loss": 0.8797,
      "step": 43500
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9999821186065674,
      "learning_rate": 0.0007800000000000001,
      "loss": 0.87,
      "step": 44000
    },
    {
      "epoch": 0.2225,
      "grad_norm": 0.9935672879219055,
      "learning_rate": 0.0007775,
      "loss": 0.8693,
      "step": 44500
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.069235920906067,
      "learning_rate": 0.0007750000000000001,
      "loss": 0.8765,
      "step": 45000
    },
    {
      "epoch": 0.2275,
      "grad_norm": 1.053348183631897,
      "learning_rate": 0.0007725,
      "loss": 0.8728,
      "step": 45500
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1187541484832764,
      "learning_rate": 0.0007700000000000001,
      "loss": 0.8681,
      "step": 46000
    },
    {
      "epoch": 0.2325,
      "grad_norm": 1.1009272336959839,
      "learning_rate": 0.0007675,
      "loss": 0.8548,
      "step": 46500
    },
    {
      "epoch": 0.235,
      "grad_norm": 1.0791724920272827,
      "learning_rate": 0.0007650000000000001,
      "loss": 0.8486,
      "step": 47000
    },
    {
      "epoch": 0.2375,
      "grad_norm": 1.0198209285736084,
      "learning_rate": 0.0007624999999999999,
      "loss": 0.8435,
      "step": 47500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9803317785263062,
      "learning_rate": 0.00076,
      "loss": 0.834,
      "step": 48000
    },
    {
      "epoch": 0.2425,
      "grad_norm": 1.0791972875595093,
      "learning_rate": 0.0007574999999999999,
      "loss": 0.8391,
      "step": 48500
    },
    {
      "epoch": 0.245,
      "grad_norm": 1.0035622119903564,
      "learning_rate": 0.000755,
      "loss": 0.8264,
      "step": 49000
    },
    {
      "epoch": 0.2475,
      "grad_norm": 0.9382076859474182,
      "learning_rate": 0.0007524999999999999,
      "loss": 0.8227,
      "step": 49500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9861664772033691,
      "learning_rate": 0.00075,
      "loss": 0.824,
      "step": 50000
    },
    {
      "epoch": 0.2525,
      "grad_norm": 0.9906631112098694,
      "learning_rate": 0.0007475000000000001,
      "loss": 0.8119,
      "step": 50500
    },
    {
      "epoch": 0.255,
      "grad_norm": 1.019593596458435,
      "learning_rate": 0.000745,
      "loss": 0.8149,
      "step": 51000
    },
    {
      "epoch": 0.2575,
      "grad_norm": 1.133406162261963,
      "learning_rate": 0.0007425000000000001,
      "loss": 0.7994,
      "step": 51500
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0688058137893677,
      "learning_rate": 0.00074,
      "loss": 0.8093,
      "step": 52000
    },
    {
      "epoch": 0.2625,
      "grad_norm": 1.1274720430374146,
      "learning_rate": 0.0007375000000000001,
      "loss": 0.7961,
      "step": 52500
    },
    {
      "epoch": 0.265,
      "grad_norm": 0.8534939289093018,
      "learning_rate": 0.000735,
      "loss": 0.7963,
      "step": 53000
    },
    {
      "epoch": 0.2675,
      "grad_norm": 0.923534095287323,
      "learning_rate": 0.0007325000000000001,
      "loss": 0.7895,
      "step": 53500
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9821487665176392,
      "learning_rate": 0.00073,
      "loss": 0.79,
      "step": 54000
    },
    {
      "epoch": 0.2725,
      "grad_norm": 0.9284172058105469,
      "learning_rate": 0.0007275000000000001,
      "loss": 0.7824,
      "step": 54500
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.9503477811813354,
      "learning_rate": 0.000725,
      "loss": 0.7716,
      "step": 55000
    },
    {
      "epoch": 0.2775,
      "grad_norm": 0.7646933794021606,
      "learning_rate": 0.0007225,
      "loss": 0.7648,
      "step": 55500
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9810500741004944,
      "learning_rate": 0.0007199999999999999,
      "loss": 0.7735,
      "step": 56000
    },
    {
      "epoch": 0.2825,
      "grad_norm": 1.073377251625061,
      "learning_rate": 0.0007175,
      "loss": 0.7627,
      "step": 56500
    },
    {
      "epoch": 0.285,
      "grad_norm": 0.961765468120575,
      "learning_rate": 0.000715,
      "loss": 0.7606,
      "step": 57000
    },
    {
      "epoch": 0.2875,
      "grad_norm": 0.9325813055038452,
      "learning_rate": 0.0007125,
      "loss": 0.7476,
      "step": 57500
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9999407529830933,
      "learning_rate": 0.00071,
      "loss": 0.7532,
      "step": 58000
    },
    {
      "epoch": 0.2925,
      "grad_norm": 1.0559402704238892,
      "learning_rate": 0.0007075,
      "loss": 0.7495,
      "step": 58500
    },
    {
      "epoch": 0.295,
      "grad_norm": 0.9832599759101868,
      "learning_rate": 0.000705,
      "loss": 0.7478,
      "step": 59000
    },
    {
      "epoch": 0.2975,
      "grad_norm": 0.9711126685142517,
      "learning_rate": 0.0007025,
      "loss": 0.741,
      "step": 59500
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1398991346359253,
      "learning_rate": 0.0007,
      "loss": 0.7359,
      "step": 60000
    },
    {
      "epoch": 0.3025,
      "grad_norm": 0.9497888088226318,
      "learning_rate": 0.0006975,
      "loss": 0.7344,
      "step": 60500
    },
    {
      "epoch": 0.305,
      "grad_norm": 1.0833396911621094,
      "learning_rate": 0.000695,
      "loss": 0.7271,
      "step": 61000
    },
    {
      "epoch": 0.3075,
      "grad_norm": 0.9524199366569519,
      "learning_rate": 0.0006925,
      "loss": 0.7279,
      "step": 61500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9858075976371765,
      "learning_rate": 0.00069,
      "loss": 0.7177,
      "step": 62000
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.0190215110778809,
      "learning_rate": 0.0006875,
      "loss": 0.7181,
      "step": 62500
    },
    {
      "epoch": 0.315,
      "grad_norm": 1.034468173980713,
      "learning_rate": 0.0006850000000000001,
      "loss": 0.709,
      "step": 63000
    },
    {
      "epoch": 0.3175,
      "grad_norm": 0.9594254493713379,
      "learning_rate": 0.0006825000000000001,
      "loss": 0.7114,
      "step": 63500
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9338377118110657,
      "learning_rate": 0.00068,
      "loss": 0.7046,
      "step": 64000
    },
    {
      "epoch": 0.3225,
      "grad_norm": 1.0552761554718018,
      "learning_rate": 0.0006775,
      "loss": 0.7095,
      "step": 64500
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.0176841020584106,
      "learning_rate": 0.000675,
      "loss": 0.6972,
      "step": 65000
    },
    {
      "epoch": 0.3275,
      "grad_norm": 0.9321394562721252,
      "learning_rate": 0.0006725,
      "loss": 0.7018,
      "step": 65500
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9338633418083191,
      "learning_rate": 0.00067,
      "loss": 0.6981,
      "step": 66000
    },
    {
      "epoch": 0.3325,
      "grad_norm": 0.9203548431396484,
      "learning_rate": 0.0006675,
      "loss": 0.6863,
      "step": 66500
    },
    {
      "epoch": 0.335,
      "grad_norm": 0.9380711317062378,
      "learning_rate": 0.000665,
      "loss": 0.6817,
      "step": 67000
    },
    {
      "epoch": 0.3375,
      "grad_norm": 1.1247562170028687,
      "learning_rate": 0.0006625,
      "loss": 0.686,
      "step": 67500
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9958891868591309,
      "learning_rate": 0.00066,
      "loss": 0.6733,
      "step": 68000
    },
    {
      "epoch": 0.3425,
      "grad_norm": 1.0443377494812012,
      "learning_rate": 0.0006575,
      "loss": 0.6807,
      "step": 68500
    },
    {
      "epoch": 0.345,
      "grad_norm": 0.9119365811347961,
      "learning_rate": 0.0006550000000000001,
      "loss": 0.671,
      "step": 69000
    },
    {
      "epoch": 0.3475,
      "grad_norm": 0.982496976852417,
      "learning_rate": 0.0006525,
      "loss": 0.668,
      "step": 69500
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0007128715515137,
      "learning_rate": 0.0006500000000000001,
      "loss": 0.661,
      "step": 70000
    },
    {
      "epoch": 0.3525,
      "grad_norm": 0.9686059355735779,
      "learning_rate": 0.0006475,
      "loss": 0.6648,
      "step": 70500
    },
    {
      "epoch": 0.355,
      "grad_norm": 0.9885823130607605,
      "learning_rate": 0.0006450000000000001,
      "loss": 0.6679,
      "step": 71000
    },
    {
      "epoch": 0.3575,
      "grad_norm": 1.0773123502731323,
      "learning_rate": 0.0006425,
      "loss": 0.6596,
      "step": 71500
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0303754806518555,
      "learning_rate": 0.00064,
      "loss": 0.6594,
      "step": 72000
    },
    {
      "epoch": 0.3625,
      "grad_norm": 1.249988079071045,
      "learning_rate": 0.0006374999999999999,
      "loss": 0.6526,
      "step": 72500
    },
    {
      "epoch": 0.365,
      "grad_norm": 0.7822865843772888,
      "learning_rate": 0.000635,
      "loss": 0.6464,
      "step": 73000
    },
    {
      "epoch": 0.3675,
      "grad_norm": 0.9326528906822205,
      "learning_rate": 0.0006324999999999999,
      "loss": 0.6428,
      "step": 73500
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.010664939880371,
      "learning_rate": 0.00063,
      "loss": 0.6407,
      "step": 74000
    },
    {
      "epoch": 0.3725,
      "grad_norm": 0.9556508660316467,
      "learning_rate": 0.0006274999999999999,
      "loss": 0.6383,
      "step": 74500
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.9133499264717102,
      "learning_rate": 0.000625,
      "loss": 0.6374,
      "step": 75000
    },
    {
      "epoch": 0.3775,
      "grad_norm": 0.9753139615058899,
      "learning_rate": 0.0006225000000000001,
      "loss": 0.6341,
      "step": 75500
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8827248811721802,
      "learning_rate": 0.00062,
      "loss": 0.6245,
      "step": 76000
    },
    {
      "epoch": 0.3825,
      "grad_norm": 1.0727614164352417,
      "learning_rate": 0.0006175000000000001,
      "loss": 0.6319,
      "step": 76500
    },
    {
      "epoch": 0.385,
      "grad_norm": 0.8870422840118408,
      "learning_rate": 0.000615,
      "loss": 0.6235,
      "step": 77000
    },
    {
      "epoch": 0.3875,
      "grad_norm": 0.7640088796615601,
      "learning_rate": 0.0006125000000000001,
      "loss": 0.6286,
      "step": 77500
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8906341791152954,
      "learning_rate": 0.00061,
      "loss": 0.6239,
      "step": 78000
    },
    {
      "epoch": 0.3925,
      "grad_norm": 0.8483075499534607,
      "learning_rate": 0.0006075000000000001,
      "loss": 0.6164,
      "step": 78500
    },
    {
      "epoch": 0.395,
      "grad_norm": 0.9552376866340637,
      "learning_rate": 0.000605,
      "loss": 0.6146,
      "step": 79000
    },
    {
      "epoch": 0.3975,
      "grad_norm": 1.0441840887069702,
      "learning_rate": 0.0006025000000000001,
      "loss": 0.6121,
      "step": 79500
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9045851230621338,
      "learning_rate": 0.0006,
      "loss": 0.6134,
      "step": 80000
    },
    {
      "epoch": 0.4025,
      "grad_norm": 0.9291741847991943,
      "learning_rate": 0.0005975,
      "loss": 0.6012,
      "step": 80500
    },
    {
      "epoch": 0.405,
      "grad_norm": 0.9120702743530273,
      "learning_rate": 0.0005949999999999999,
      "loss": 0.6035,
      "step": 81000
    },
    {
      "epoch": 0.4075,
      "grad_norm": 0.9051268696784973,
      "learning_rate": 0.0005925,
      "loss": 0.599,
      "step": 81500
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9338898062705994,
      "learning_rate": 0.00059,
      "loss": 0.5983,
      "step": 82000
    },
    {
      "epoch": 0.4125,
      "grad_norm": 1.0147273540496826,
      "learning_rate": 0.0005875,
      "loss": 0.5973,
      "step": 82500
    },
    {
      "epoch": 0.415,
      "grad_norm": 1.0779589414596558,
      "learning_rate": 0.000585,
      "loss": 0.5906,
      "step": 83000
    },
    {
      "epoch": 0.4175,
      "grad_norm": 0.8500300049781799,
      "learning_rate": 0.0005825,
      "loss": 0.5897,
      "step": 83500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9799704551696777,
      "learning_rate": 0.00058,
      "loss": 0.5923,
      "step": 84000
    },
    {
      "epoch": 0.4225,
      "grad_norm": 1.0634528398513794,
      "learning_rate": 0.0005775,
      "loss": 0.5898,
      "step": 84500
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.9595843553543091,
      "learning_rate": 0.000575,
      "loss": 0.5838,
      "step": 85000
    },
    {
      "epoch": 0.4275,
      "grad_norm": 0.9346839785575867,
      "learning_rate": 0.0005725,
      "loss": 0.5869,
      "step": 85500
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0334855318069458,
      "learning_rate": 0.00057,
      "loss": 0.5721,
      "step": 86000
    },
    {
      "epoch": 0.4325,
      "grad_norm": 1.023863434791565,
      "learning_rate": 0.0005675,
      "loss": 0.5753,
      "step": 86500
    },
    {
      "epoch": 0.435,
      "grad_norm": 0.8902463912963867,
      "learning_rate": 0.000565,
      "loss": 0.5803,
      "step": 87000
    },
    {
      "epoch": 0.4375,
      "grad_norm": 0.9872226715087891,
      "learning_rate": 0.0005625000000000001,
      "loss": 0.5708,
      "step": 87500
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9763571619987488,
      "learning_rate": 0.0005600000000000001,
      "loss": 0.5676,
      "step": 88000
    },
    {
      "epoch": 0.4425,
      "grad_norm": 1.1453049182891846,
      "learning_rate": 0.0005575,
      "loss": 0.5648,
      "step": 88500
    },
    {
      "epoch": 0.445,
      "grad_norm": 1.1058281660079956,
      "learning_rate": 0.000555,
      "loss": 0.5641,
      "step": 89000
    },
    {
      "epoch": 0.4475,
      "grad_norm": 0.8483547568321228,
      "learning_rate": 0.0005525,
      "loss": 0.566,
      "step": 89500
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9427286386489868,
      "learning_rate": 0.00055,
      "loss": 0.5605,
      "step": 90000
    },
    {
      "epoch": 0.4525,
      "grad_norm": 0.9962618947029114,
      "learning_rate": 0.0005475,
      "loss": 0.5527,
      "step": 90500
    },
    {
      "epoch": 0.455,
      "grad_norm": 0.8857517838478088,
      "learning_rate": 0.000545,
      "loss": 0.5517,
      "step": 91000
    },
    {
      "epoch": 0.4575,
      "grad_norm": 0.893782377243042,
      "learning_rate": 0.0005425,
      "loss": 0.5532,
      "step": 91500
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0462228059768677,
      "learning_rate": 0.00054,
      "loss": 0.5478,
      "step": 92000
    },
    {
      "epoch": 0.4625,
      "grad_norm": 0.9573895335197449,
      "learning_rate": 0.0005375,
      "loss": 0.5515,
      "step": 92500
    },
    {
      "epoch": 0.465,
      "grad_norm": 1.1831161975860596,
      "learning_rate": 0.000535,
      "loss": 0.5436,
      "step": 93000
    },
    {
      "epoch": 0.4675,
      "grad_norm": 0.8602913618087769,
      "learning_rate": 0.0005325,
      "loss": 0.5481,
      "step": 93500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8320614099502563,
      "learning_rate": 0.0005300000000000001,
      "loss": 0.5444,
      "step": 94000
    },
    {
      "epoch": 0.4725,
      "grad_norm": 1.11525297164917,
      "learning_rate": 0.0005275,
      "loss": 0.5413,
      "step": 94500
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.8841814398765564,
      "learning_rate": 0.0005250000000000001,
      "loss": 0.5378,
      "step": 95000
    },
    {
      "epoch": 0.4775,
      "grad_norm": 0.9821959137916565,
      "learning_rate": 0.0005225,
      "loss": 0.546,
      "step": 95500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.8790550827980042,
      "learning_rate": 0.0005200000000000001,
      "loss": 0.5426,
      "step": 96000
    },
    {
      "epoch": 0.4825,
      "grad_norm": 0.8972886800765991,
      "learning_rate": 0.0005175,
      "loss": 0.5326,
      "step": 96500
    },
    {
      "epoch": 0.485,
      "grad_norm": 1.140117883682251,
      "learning_rate": 0.000515,
      "loss": 0.5263,
      "step": 97000
    },
    {
      "epoch": 0.4875,
      "grad_norm": 0.8671894073486328,
      "learning_rate": 0.0005124999999999999,
      "loss": 0.5264,
      "step": 97500
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0444188117980957,
      "learning_rate": 0.00051,
      "loss": 0.525,
      "step": 98000
    },
    {
      "epoch": 0.4925,
      "grad_norm": 0.980679452419281,
      "learning_rate": 0.0005074999999999999,
      "loss": 0.5267,
      "step": 98500
    },
    {
      "epoch": 0.495,
      "grad_norm": 0.9694666862487793,
      "learning_rate": 0.000505,
      "loss": 0.5238,
      "step": 99000
    },
    {
      "epoch": 0.4975,
      "grad_norm": 0.8965983390808105,
      "learning_rate": 0.0005024999999999999,
      "loss": 0.5196,
      "step": 99500
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0294713973999023,
      "learning_rate": 0.0005,
      "loss": 0.518,
      "step": 100000
    },
    {
      "epoch": 0.5025,
      "grad_norm": 0.936659574508667,
      "learning_rate": 0.0004975,
      "loss": 0.5211,
      "step": 100500
    },
    {
      "epoch": 0.505,
      "grad_norm": 0.979568362236023,
      "learning_rate": 0.000495,
      "loss": 0.5125,
      "step": 101000
    },
    {
      "epoch": 0.5075,
      "grad_norm": 1.1976181268692017,
      "learning_rate": 0.0004925,
      "loss": 0.5104,
      "step": 101500
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9427805542945862,
      "learning_rate": 0.00049,
      "loss": 0.5143,
      "step": 102000
    },
    {
      "epoch": 0.5125,
      "grad_norm": 0.9826269745826721,
      "learning_rate": 0.0004875,
      "loss": 0.5116,
      "step": 102500
    },
    {
      "epoch": 0.515,
      "grad_norm": 1.0619758367538452,
      "learning_rate": 0.00048499999999999997,
      "loss": 0.5076,
      "step": 103000
    },
    {
      "epoch": 0.5175,
      "grad_norm": 0.9461635947227478,
      "learning_rate": 0.0004825,
      "loss": 0.51,
      "step": 103500
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.8274944424629211,
      "learning_rate": 0.00048,
      "loss": 0.5049,
      "step": 104000
    },
    {
      "epoch": 0.5225,
      "grad_norm": 0.8687776327133179,
      "learning_rate": 0.0004775,
      "loss": 0.4983,
      "step": 104500
    },
    {
      "epoch": 0.525,
      "grad_norm": 0.922590970993042,
      "learning_rate": 0.000475,
      "loss": 0.4967,
      "step": 105000
    },
    {
      "epoch": 0.5275,
      "grad_norm": 0.8645679950714111,
      "learning_rate": 0.0004725,
      "loss": 0.4966,
      "step": 105500
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.8599600195884705,
      "learning_rate": 0.00047,
      "loss": 0.4997,
      "step": 106000
    },
    {
      "epoch": 0.5325,
      "grad_norm": 1.495252013206482,
      "learning_rate": 0.00046750000000000003,
      "loss": 0.5008,
      "step": 106500
    },
    {
      "epoch": 0.535,
      "grad_norm": 0.9567371010780334,
      "learning_rate": 0.000465,
      "loss": 0.4936,
      "step": 107000
    },
    {
      "epoch": 0.5375,
      "grad_norm": 0.9585222005844116,
      "learning_rate": 0.0004625,
      "loss": 0.4947,
      "step": 107500
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8454384207725525,
      "learning_rate": 0.00046,
      "loss": 0.4853,
      "step": 108000
    },
    {
      "epoch": 0.5425,
      "grad_norm": 0.9477508664131165,
      "learning_rate": 0.0004575,
      "loss": 0.4861,
      "step": 108500
    },
    {
      "epoch": 0.545,
      "grad_norm": 0.8130492568016052,
      "learning_rate": 0.000455,
      "loss": 0.4846,
      "step": 109000
    },
    {
      "epoch": 0.5475,
      "grad_norm": 0.8611663579940796,
      "learning_rate": 0.00045250000000000005,
      "loss": 0.4898,
      "step": 109500
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.9914350509643555,
      "learning_rate": 0.00045000000000000004,
      "loss": 0.4828,
      "step": 110000
    },
    {
      "epoch": 0.5525,
      "grad_norm": 1.0152645111083984,
      "learning_rate": 0.00044750000000000004,
      "loss": 0.4817,
      "step": 110500
    },
    {
      "epoch": 0.555,
      "grad_norm": 1.143247127532959,
      "learning_rate": 0.00044500000000000003,
      "loss": 0.4833,
      "step": 111000
    },
    {
      "epoch": 0.5575,
      "grad_norm": 0.9433412551879883,
      "learning_rate": 0.0004425,
      "loss": 0.48,
      "step": 111500
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.9833225607872009,
      "learning_rate": 0.00044,
      "loss": 0.4779,
      "step": 112000
    },
    {
      "epoch": 0.5625,
      "grad_norm": 0.9049823880195618,
      "learning_rate": 0.0004375,
      "loss": 0.476,
      "step": 112500
    },
    {
      "epoch": 0.565,
      "grad_norm": 1.1675751209259033,
      "learning_rate": 0.000435,
      "loss": 0.4758,
      "step": 113000
    },
    {
      "epoch": 0.5675,
      "grad_norm": 0.8881930708885193,
      "learning_rate": 0.0004325,
      "loss": 0.4714,
      "step": 113500
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.7326158881187439,
      "learning_rate": 0.00043,
      "loss": 0.4682,
      "step": 114000
    },
    {
      "epoch": 0.5725,
      "grad_norm": 0.8444226980209351,
      "learning_rate": 0.0004275,
      "loss": 0.4697,
      "step": 114500
    },
    {
      "epoch": 0.575,
      "grad_norm": 0.9297171831130981,
      "learning_rate": 0.000425,
      "loss": 0.4655,
      "step": 115000
    },
    {
      "epoch": 0.5775,
      "grad_norm": 0.9315938353538513,
      "learning_rate": 0.00042249999999999997,
      "loss": 0.4655,
      "step": 115500
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.8721821308135986,
      "learning_rate": 0.00042,
      "loss": 0.4596,
      "step": 116000
    },
    {
      "epoch": 0.5825,
      "grad_norm": 0.8221698999404907,
      "learning_rate": 0.0004175,
      "loss": 0.4619,
      "step": 116500
    },
    {
      "epoch": 0.585,
      "grad_norm": 0.8757591247558594,
      "learning_rate": 0.000415,
      "loss": 0.4636,
      "step": 117000
    },
    {
      "epoch": 0.5875,
      "grad_norm": 0.8811506628990173,
      "learning_rate": 0.0004125,
      "loss": 0.4648,
      "step": 117500
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8971294164657593,
      "learning_rate": 0.00041,
      "loss": 0.4595,
      "step": 118000
    },
    {
      "epoch": 0.5925,
      "grad_norm": 0.9058002829551697,
      "learning_rate": 0.0004075,
      "loss": 0.4581,
      "step": 118500
    },
    {
      "epoch": 0.595,
      "grad_norm": 0.8538855314254761,
      "learning_rate": 0.00040500000000000003,
      "loss": 0.455,
      "step": 119000
    },
    {
      "epoch": 0.5975,
      "grad_norm": 0.8006027936935425,
      "learning_rate": 0.0004025,
      "loss": 0.4559,
      "step": 119500
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.8844053745269775,
      "learning_rate": 0.0004,
      "loss": 0.4532,
      "step": 120000
    },
    {
      "epoch": 0.6025,
      "grad_norm": 0.8738088011741638,
      "learning_rate": 0.0003975,
      "loss": 0.448,
      "step": 120500
    },
    {
      "epoch": 0.605,
      "grad_norm": 0.964787483215332,
      "learning_rate": 0.000395,
      "loss": 0.4475,
      "step": 121000
    },
    {
      "epoch": 0.6075,
      "grad_norm": 1.016556978225708,
      "learning_rate": 0.0003925,
      "loss": 0.4533,
      "step": 121500
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.8644399046897888,
      "learning_rate": 0.00039000000000000005,
      "loss": 0.4414,
      "step": 122000
    },
    {
      "epoch": 0.6125,
      "grad_norm": 1.1638849973678589,
      "learning_rate": 0.00038750000000000004,
      "loss": 0.4455,
      "step": 122500
    },
    {
      "epoch": 0.615,
      "grad_norm": 0.9745148420333862,
      "learning_rate": 0.00038500000000000003,
      "loss": 0.4429,
      "step": 123000
    },
    {
      "epoch": 0.6175,
      "grad_norm": 1.0803771018981934,
      "learning_rate": 0.00038250000000000003,
      "loss": 0.4451,
      "step": 123500
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.0543841123580933,
      "learning_rate": 0.00038,
      "loss": 0.4451,
      "step": 124000
    },
    {
      "epoch": 0.6225,
      "grad_norm": 0.8389125466346741,
      "learning_rate": 0.0003775,
      "loss": 0.4426,
      "step": 124500
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.8875498175621033,
      "learning_rate": 0.000375,
      "loss": 0.4401,
      "step": 125000
    },
    {
      "epoch": 0.6275,
      "grad_norm": 0.8467958569526672,
      "learning_rate": 0.0003725,
      "loss": 0.4414,
      "step": 125500
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8619393110275269,
      "learning_rate": 0.00037,
      "loss": 0.4389,
      "step": 126000
    },
    {
      "epoch": 0.6325,
      "grad_norm": 0.8943595886230469,
      "learning_rate": 0.0003675,
      "loss": 0.4385,
      "step": 126500
    },
    {
      "epoch": 0.635,
      "grad_norm": 1.0011250972747803,
      "learning_rate": 0.000365,
      "loss": 0.4273,
      "step": 127000
    },
    {
      "epoch": 0.6375,
      "grad_norm": 0.925356388092041,
      "learning_rate": 0.0003625,
      "loss": 0.4315,
      "step": 127500
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.9844728708267212,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.4323,
      "step": 128000
    },
    {
      "epoch": 0.6425,
      "grad_norm": 0.8561415672302246,
      "learning_rate": 0.0003575,
      "loss": 0.4358,
      "step": 128500
    },
    {
      "epoch": 0.645,
      "grad_norm": 0.9738279581069946,
      "learning_rate": 0.000355,
      "loss": 0.428,
      "step": 129000
    },
    {
      "epoch": 0.6475,
      "grad_norm": 1.0183966159820557,
      "learning_rate": 0.0003525,
      "loss": 0.427,
      "step": 129500
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.8410510420799255,
      "learning_rate": 0.00035,
      "loss": 0.4301,
      "step": 130000
    },
    {
      "epoch": 0.6525,
      "grad_norm": 0.8729934096336365,
      "learning_rate": 0.0003475,
      "loss": 0.4251,
      "step": 130500
    },
    {
      "epoch": 0.655,
      "grad_norm": 0.8726717829704285,
      "learning_rate": 0.000345,
      "loss": 0.4274,
      "step": 131000
    },
    {
      "epoch": 0.6575,
      "grad_norm": 0.9411290884017944,
      "learning_rate": 0.00034250000000000003,
      "loss": 0.423,
      "step": 131500
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0381312370300293,
      "learning_rate": 0.00034,
      "loss": 0.4222,
      "step": 132000
    },
    {
      "epoch": 0.6625,
      "grad_norm": 0.9127457737922668,
      "learning_rate": 0.0003375,
      "loss": 0.4194,
      "step": 132500
    },
    {
      "epoch": 0.665,
      "grad_norm": 0.9360501170158386,
      "learning_rate": 0.000335,
      "loss": 0.4179,
      "step": 133000
    },
    {
      "epoch": 0.6675,
      "grad_norm": 1.0274841785430908,
      "learning_rate": 0.0003325,
      "loss": 0.423,
      "step": 133500
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.9449383616447449,
      "learning_rate": 0.00033,
      "loss": 0.4179,
      "step": 134000
    },
    {
      "epoch": 0.6725,
      "grad_norm": 0.8390195369720459,
      "learning_rate": 0.00032750000000000005,
      "loss": 0.4189,
      "step": 134500
    },
    {
      "epoch": 0.675,
      "grad_norm": 0.8143808841705322,
      "learning_rate": 0.00032500000000000004,
      "loss": 0.4164,
      "step": 135000
    },
    {
      "epoch": 0.6775,
      "grad_norm": 0.8021345138549805,
      "learning_rate": 0.00032250000000000003,
      "loss": 0.4178,
      "step": 135500
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.9462330937385559,
      "learning_rate": 0.00032,
      "loss": 0.4115,
      "step": 136000
    },
    {
      "epoch": 0.6825,
      "grad_norm": 0.9009311199188232,
      "learning_rate": 0.0003175,
      "loss": 0.4136,
      "step": 136500
    },
    {
      "epoch": 0.685,
      "grad_norm": 0.8735049366950989,
      "learning_rate": 0.000315,
      "loss": 0.4104,
      "step": 137000
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.8276532292366028,
      "learning_rate": 0.0003125,
      "loss": 0.4109,
      "step": 137500
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.9801086187362671,
      "learning_rate": 0.00031,
      "loss": 0.4108,
      "step": 138000
    },
    {
      "epoch": 0.6925,
      "grad_norm": 0.8173744082450867,
      "learning_rate": 0.0003075,
      "loss": 0.4042,
      "step": 138500
    },
    {
      "epoch": 0.695,
      "grad_norm": 0.8260843753814697,
      "learning_rate": 0.000305,
      "loss": 0.4089,
      "step": 139000
    },
    {
      "epoch": 0.6975,
      "grad_norm": 0.9301255941390991,
      "learning_rate": 0.0003025,
      "loss": 0.4074,
      "step": 139500
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8367844820022583,
      "learning_rate": 0.0003,
      "loss": 0.4036,
      "step": 140000
    },
    {
      "epoch": 0.7025,
      "grad_norm": 0.7478563189506531,
      "learning_rate": 0.00029749999999999997,
      "loss": 0.4005,
      "step": 140500
    },
    {
      "epoch": 0.705,
      "grad_norm": 0.9122187495231628,
      "learning_rate": 0.000295,
      "loss": 0.4071,
      "step": 141000
    },
    {
      "epoch": 0.7075,
      "grad_norm": 0.7550624012947083,
      "learning_rate": 0.0002925,
      "loss": 0.3987,
      "step": 141500
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.8033981919288635,
      "learning_rate": 0.00029,
      "loss": 0.3954,
      "step": 142000
    },
    {
      "epoch": 0.7125,
      "grad_norm": 0.723085343837738,
      "learning_rate": 0.0002875,
      "loss": 0.3991,
      "step": 142500
    },
    {
      "epoch": 0.715,
      "grad_norm": 0.9484355449676514,
      "learning_rate": 0.000285,
      "loss": 0.3951,
      "step": 143000
    },
    {
      "epoch": 0.7175,
      "grad_norm": 0.9295548796653748,
      "learning_rate": 0.0002825,
      "loss": 0.3956,
      "step": 143500
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.9068970680236816,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.3989,
      "step": 144000
    },
    {
      "epoch": 0.7225,
      "grad_norm": 0.802410364151001,
      "learning_rate": 0.0002775,
      "loss": 0.3926,
      "step": 144500
    },
    {
      "epoch": 0.725,
      "grad_norm": 0.8215055465698242,
      "learning_rate": 0.000275,
      "loss": 0.3914,
      "step": 145000
    },
    {
      "epoch": 0.7275,
      "grad_norm": 0.9417942762374878,
      "learning_rate": 0.0002725,
      "loss": 0.3986,
      "step": 145500
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8318981528282166,
      "learning_rate": 0.00027,
      "loss": 0.3942,
      "step": 146000
    },
    {
      "epoch": 0.7325,
      "grad_norm": 1.008771300315857,
      "learning_rate": 0.0002675,
      "loss": 0.3898,
      "step": 146500
    },
    {
      "epoch": 0.735,
      "grad_norm": 1.0341229438781738,
      "learning_rate": 0.00026500000000000004,
      "loss": 0.3901,
      "step": 147000
    },
    {
      "epoch": 0.7375,
      "grad_norm": 0.8757597208023071,
      "learning_rate": 0.00026250000000000004,
      "loss": 0.3908,
      "step": 147500
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.8422958254814148,
      "learning_rate": 0.00026000000000000003,
      "loss": 0.3889,
      "step": 148000
    },
    {
      "epoch": 0.7425,
      "grad_norm": 0.8806750774383545,
      "learning_rate": 0.0002575,
      "loss": 0.3872,
      "step": 148500
    },
    {
      "epoch": 0.745,
      "grad_norm": 0.8841733336448669,
      "learning_rate": 0.000255,
      "loss": 0.3892,
      "step": 149000
    },
    {
      "epoch": 0.7475,
      "grad_norm": 0.7942102551460266,
      "learning_rate": 0.0002525,
      "loss": 0.3902,
      "step": 149500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.8088664412498474,
      "learning_rate": 0.00025,
      "loss": 0.3839,
      "step": 150000
    },
    {
      "epoch": 0.7525,
      "grad_norm": 0.75618976354599,
      "learning_rate": 0.0002475,
      "loss": 0.3788,
      "step": 150500
    },
    {
      "epoch": 0.755,
      "grad_norm": 0.8307444453239441,
      "learning_rate": 0.000245,
      "loss": 0.384,
      "step": 151000
    },
    {
      "epoch": 0.7575,
      "grad_norm": 0.8600874543190002,
      "learning_rate": 0.00024249999999999999,
      "loss": 0.3832,
      "step": 151500
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8942281007766724,
      "learning_rate": 0.00024,
      "loss": 0.3803,
      "step": 152000
    },
    {
      "epoch": 0.7625,
      "grad_norm": 0.898326575756073,
      "learning_rate": 0.0002375,
      "loss": 0.3794,
      "step": 152500
    },
    {
      "epoch": 0.765,
      "grad_norm": 0.7357004880905151,
      "learning_rate": 0.000235,
      "loss": 0.3782,
      "step": 153000
    },
    {
      "epoch": 0.7675,
      "grad_norm": 0.9393094778060913,
      "learning_rate": 0.0002325,
      "loss": 0.378,
      "step": 153500
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.811700701713562,
      "learning_rate": 0.00023,
      "loss": 0.3728,
      "step": 154000
    },
    {
      "epoch": 0.7725,
      "grad_norm": 0.9294859170913696,
      "learning_rate": 0.0002275,
      "loss": 0.3813,
      "step": 154500
    },
    {
      "epoch": 0.775,
      "grad_norm": 0.8190829753875732,
      "learning_rate": 0.00022500000000000002,
      "loss": 0.3768,
      "step": 155000
    },
    {
      "epoch": 0.7775,
      "grad_norm": 1.0014597177505493,
      "learning_rate": 0.00022250000000000001,
      "loss": 0.3762,
      "step": 155500
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.9188576340675354,
      "learning_rate": 0.00022,
      "loss": 0.3734,
      "step": 156000
    },
    {
      "epoch": 0.7825,
      "grad_norm": 0.8444845676422119,
      "learning_rate": 0.0002175,
      "loss": 0.3716,
      "step": 156500
    },
    {
      "epoch": 0.785,
      "grad_norm": 0.8642886281013489,
      "learning_rate": 0.000215,
      "loss": 0.3722,
      "step": 157000
    },
    {
      "epoch": 0.7875,
      "grad_norm": 0.8738716244697571,
      "learning_rate": 0.0002125,
      "loss": 0.3691,
      "step": 157500
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.8786160945892334,
      "learning_rate": 0.00021,
      "loss": 0.3702,
      "step": 158000
    },
    {
      "epoch": 0.7925,
      "grad_norm": 0.8072552680969238,
      "learning_rate": 0.0002075,
      "loss": 0.3669,
      "step": 158500
    },
    {
      "epoch": 0.795,
      "grad_norm": 0.8457185626029968,
      "learning_rate": 0.000205,
      "loss": 0.3691,
      "step": 159000
    },
    {
      "epoch": 0.7975,
      "grad_norm": 0.8239601254463196,
      "learning_rate": 0.00020250000000000002,
      "loss": 0.3691,
      "step": 159500
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.9770568013191223,
      "learning_rate": 0.0002,
      "loss": 0.3667,
      "step": 160000
    },
    {
      "epoch": 0.8025,
      "grad_norm": 0.780646026134491,
      "learning_rate": 0.0001975,
      "loss": 0.3615,
      "step": 160500
    },
    {
      "epoch": 0.805,
      "grad_norm": 0.840975821018219,
      "learning_rate": 0.00019500000000000002,
      "loss": 0.3657,
      "step": 161000
    },
    {
      "epoch": 0.8075,
      "grad_norm": 0.9257989525794983,
      "learning_rate": 0.00019250000000000002,
      "loss": 0.3597,
      "step": 161500
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3020392656326294,
      "learning_rate": 0.00019,
      "loss": 0.3589,
      "step": 162000
    },
    {
      "epoch": 0.8125,
      "grad_norm": 0.9252501130104065,
      "learning_rate": 0.0001875,
      "loss": 0.3605,
      "step": 162500
    },
    {
      "epoch": 0.815,
      "grad_norm": 0.8381876945495605,
      "learning_rate": 0.000185,
      "loss": 0.3637,
      "step": 163000
    },
    {
      "epoch": 0.8175,
      "grad_norm": 1.0705121755599976,
      "learning_rate": 0.0001825,
      "loss": 0.3595,
      "step": 163500
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.8349681496620178,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.3594,
      "step": 164000
    },
    {
      "epoch": 0.8225,
      "grad_norm": 0.8885754346847534,
      "learning_rate": 0.0001775,
      "loss": 0.3596,
      "step": 164500
    },
    {
      "epoch": 0.825,
      "grad_norm": 0.8317931890487671,
      "learning_rate": 0.000175,
      "loss": 0.3599,
      "step": 165000
    },
    {
      "epoch": 0.8275,
      "grad_norm": 0.933137059211731,
      "learning_rate": 0.0001725,
      "loss": 0.3604,
      "step": 165500
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.8547536134719849,
      "learning_rate": 0.00017,
      "loss": 0.3538,
      "step": 166000
    },
    {
      "epoch": 0.8325,
      "grad_norm": 0.7507143020629883,
      "learning_rate": 0.0001675,
      "loss": 0.3555,
      "step": 166500
    },
    {
      "epoch": 0.835,
      "grad_norm": 0.9085415005683899,
      "learning_rate": 0.000165,
      "loss": 0.3513,
      "step": 167000
    },
    {
      "epoch": 0.8375,
      "grad_norm": 0.9400590062141418,
      "learning_rate": 0.00016250000000000002,
      "loss": 0.3556,
      "step": 167500
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9716084599494934,
      "learning_rate": 0.00016,
      "loss": 0.3528,
      "step": 168000
    },
    {
      "epoch": 0.8425,
      "grad_norm": 0.8011981248855591,
      "learning_rate": 0.0001575,
      "loss": 0.3573,
      "step": 168500
    },
    {
      "epoch": 0.845,
      "grad_norm": 1.3237860202789307,
      "learning_rate": 0.000155,
      "loss": 0.3521,
      "step": 169000
    },
    {
      "epoch": 0.8475,
      "grad_norm": 0.8777256608009338,
      "learning_rate": 0.0001525,
      "loss": 0.3494,
      "step": 169500
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.8445271849632263,
      "learning_rate": 0.00015,
      "loss": 0.3522,
      "step": 170000
    },
    {
      "epoch": 0.8525,
      "grad_norm": 0.8710359334945679,
      "learning_rate": 0.0001475,
      "loss": 0.3505,
      "step": 170500
    },
    {
      "epoch": 0.855,
      "grad_norm": 0.9005342125892639,
      "learning_rate": 0.000145,
      "loss": 0.3509,
      "step": 171000
    },
    {
      "epoch": 0.8575,
      "grad_norm": 0.9540170431137085,
      "learning_rate": 0.0001425,
      "loss": 0.3526,
      "step": 171500
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8886176943778992,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.3474,
      "step": 172000
    },
    {
      "epoch": 0.8625,
      "grad_norm": 0.9540530443191528,
      "learning_rate": 0.0001375,
      "loss": 0.3484,
      "step": 172500
    },
    {
      "epoch": 0.865,
      "grad_norm": 0.8121699690818787,
      "learning_rate": 0.000135,
      "loss": 0.3425,
      "step": 173000
    },
    {
      "epoch": 0.8675,
      "grad_norm": 0.8678590655326843,
      "learning_rate": 0.00013250000000000002,
      "loss": 0.347,
      "step": 173500
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.8440560698509216,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.3436,
      "step": 174000
    },
    {
      "epoch": 0.8725,
      "grad_norm": 0.7756509780883789,
      "learning_rate": 0.0001275,
      "loss": 0.3448,
      "step": 174500
    },
    {
      "epoch": 0.875,
      "grad_norm": 0.9908772706985474,
      "learning_rate": 0.000125,
      "loss": 0.3412,
      "step": 175000
    },
    {
      "epoch": 0.8775,
      "grad_norm": 0.9362688660621643,
      "learning_rate": 0.0001225,
      "loss": 0.3391,
      "step": 175500
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.8679261803627014,
      "learning_rate": 0.00012,
      "loss": 0.3412,
      "step": 176000
    },
    {
      "epoch": 0.8825,
      "grad_norm": 0.696166455745697,
      "learning_rate": 0.0001175,
      "loss": 0.3403,
      "step": 176500
    },
    {
      "epoch": 0.885,
      "grad_norm": 0.8702895641326904,
      "learning_rate": 0.000115,
      "loss": 0.3439,
      "step": 177000
    },
    {
      "epoch": 0.8875,
      "grad_norm": 0.8078557252883911,
      "learning_rate": 0.00011250000000000001,
      "loss": 0.3382,
      "step": 177500
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.934415340423584,
      "learning_rate": 0.00011,
      "loss": 0.3418,
      "step": 178000
    },
    {
      "epoch": 0.8925,
      "grad_norm": 0.9653915762901306,
      "learning_rate": 0.0001075,
      "loss": 0.3393,
      "step": 178500
    },
    {
      "epoch": 0.895,
      "grad_norm": 0.8031246662139893,
      "learning_rate": 0.000105,
      "loss": 0.3345,
      "step": 179000
    },
    {
      "epoch": 0.8975,
      "grad_norm": 1.091472864151001,
      "learning_rate": 0.0001025,
      "loss": 0.3401,
      "step": 179500
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.8135733604431152,
      "learning_rate": 0.0001,
      "loss": 0.338,
      "step": 180000
    },
    {
      "epoch": 0.9025,
      "grad_norm": 0.8989848494529724,
      "learning_rate": 9.750000000000001e-05,
      "loss": 0.3362,
      "step": 180500
    },
    {
      "epoch": 0.905,
      "grad_norm": 0.8245798349380493,
      "learning_rate": 9.5e-05,
      "loss": 0.3358,
      "step": 181000
    },
    {
      "epoch": 0.9075,
      "grad_norm": 0.9996559023857117,
      "learning_rate": 9.25e-05,
      "loss": 0.3337,
      "step": 181500
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.8088461756706238,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.3329,
      "step": 182000
    },
    {
      "epoch": 0.9125,
      "grad_norm": 0.8346579670906067,
      "learning_rate": 8.75e-05,
      "loss": 0.3351,
      "step": 182500
    },
    {
      "epoch": 0.915,
      "grad_norm": 0.9154785871505737,
      "learning_rate": 8.5e-05,
      "loss": 0.3343,
      "step": 183000
    },
    {
      "epoch": 0.9175,
      "grad_norm": 0.8596900105476379,
      "learning_rate": 8.25e-05,
      "loss": 0.3306,
      "step": 183500
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7302775979042053,
      "learning_rate": 8e-05,
      "loss": 0.3282,
      "step": 184000
    },
    {
      "epoch": 0.9225,
      "grad_norm": 0.8430343270301819,
      "learning_rate": 7.75e-05,
      "loss": 0.3308,
      "step": 184500
    },
    {
      "epoch": 0.925,
      "grad_norm": 0.9300417304039001,
      "learning_rate": 7.5e-05,
      "loss": 0.3314,
      "step": 185000
    },
    {
      "epoch": 0.9275,
      "grad_norm": 0.7791295647621155,
      "learning_rate": 7.25e-05,
      "loss": 0.3306,
      "step": 185500
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7478705048561096,
      "learning_rate": 7.000000000000001e-05,
      "loss": 0.3328,
      "step": 186000
    },
    {
      "epoch": 0.9325,
      "grad_norm": 0.7758183479309082,
      "learning_rate": 6.75e-05,
      "loss": 0.3298,
      "step": 186500
    },
    {
      "epoch": 0.935,
      "grad_norm": 0.7060846090316772,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.3254,
      "step": 187000
    },
    {
      "epoch": 0.9375,
      "grad_norm": 0.8327595591545105,
      "learning_rate": 6.25e-05,
      "loss": 0.3362,
      "step": 187500
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8935821652412415,
      "learning_rate": 6e-05,
      "loss": 0.3272,
      "step": 188000
    },
    {
      "epoch": 0.9425,
      "grad_norm": 0.7706259489059448,
      "learning_rate": 5.75e-05,
      "loss": 0.323,
      "step": 188500
    },
    {
      "epoch": 0.945,
      "grad_norm": 0.770865261554718,
      "learning_rate": 5.5e-05,
      "loss": 0.3254,
      "step": 189000
    },
    {
      "epoch": 0.9475,
      "grad_norm": 0.8798490166664124,
      "learning_rate": 5.25e-05,
      "loss": 0.3328,
      "step": 189500
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8063675165176392,
      "learning_rate": 5e-05,
      "loss": 0.3275,
      "step": 190000
    },
    {
      "epoch": 0.9525,
      "grad_norm": 0.8538005948066711,
      "learning_rate": 4.75e-05,
      "loss": 0.3261,
      "step": 190500
    },
    {
      "epoch": 0.955,
      "grad_norm": 0.8266985416412354,
      "learning_rate": 4.4999999999999996e-05,
      "loss": 0.3295,
      "step": 191000
    },
    {
      "epoch": 0.9575,
      "grad_norm": 0.8279303312301636,
      "learning_rate": 4.25e-05,
      "loss": 0.3223,
      "step": 191500
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.8805099725723267,
      "learning_rate": 4e-05,
      "loss": 0.3264,
      "step": 192000
    },
    {
      "epoch": 0.9625,
      "grad_norm": 0.8602822422981262,
      "learning_rate": 3.75e-05,
      "loss": 0.3243,
      "step": 192500
    },
    {
      "epoch": 0.965,
      "grad_norm": 0.8286145329475403,
      "learning_rate": 3.5000000000000004e-05,
      "loss": 0.3266,
      "step": 193000
    },
    {
      "epoch": 0.9675,
      "grad_norm": 0.788804292678833,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.3221,
      "step": 193500
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.9167708158493042,
      "learning_rate": 3e-05,
      "loss": 0.3259,
      "step": 194000
    },
    {
      "epoch": 0.9725,
      "grad_norm": 0.7738156318664551,
      "learning_rate": 2.75e-05,
      "loss": 0.3264,
      "step": 194500
    },
    {
      "epoch": 0.975,
      "grad_norm": 0.8544257879257202,
      "learning_rate": 2.5e-05,
      "loss": 0.3214,
      "step": 195000
    },
    {
      "epoch": 0.9775,
      "grad_norm": 0.8660796880722046,
      "learning_rate": 2.2499999999999998e-05,
      "loss": 0.3215,
      "step": 195500
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.8667000532150269,
      "learning_rate": 2e-05,
      "loss": 0.3239,
      "step": 196000
    },
    {
      "epoch": 0.9825,
      "grad_norm": 0.6743556261062622,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 0.3242,
      "step": 196500
    },
    {
      "epoch": 0.985,
      "grad_norm": 0.8198208212852478,
      "learning_rate": 1.5e-05,
      "loss": 0.3244,
      "step": 197000
    },
    {
      "epoch": 0.9875,
      "grad_norm": 0.9382637739181519,
      "learning_rate": 1.25e-05,
      "loss": 0.3254,
      "step": 197500
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.860037624835968,
      "learning_rate": 1e-05,
      "loss": 0.3237,
      "step": 198000
    },
    {
      "epoch": 0.9925,
      "grad_norm": 0.888210117816925,
      "learning_rate": 7.5e-06,
      "loss": 0.3198,
      "step": 198500
    },
    {
      "epoch": 0.995,
      "grad_norm": 0.7729344367980957,
      "learning_rate": 5e-06,
      "loss": 0.3168,
      "step": 199000
    },
    {
      "epoch": 0.9975,
      "grad_norm": 0.8600977659225464,
      "learning_rate": 2.5e-06,
      "loss": 0.3208,
      "step": 199500
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8519359230995178,
      "learning_rate": 0.0,
      "loss": 0.3227,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 100000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.678793019392e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
